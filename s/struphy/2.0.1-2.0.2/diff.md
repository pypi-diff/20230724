# Comparing `tmp/struphy-2.0.1.tar.gz` & `tmp/struphy-2.0.2.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "struphy-2.0.1.tar", last modified: Wed Jul  5 18:44:37 2023, max compression
+gzip compressed data, was "struphy-2.0.2.tar", last modified: Mon Jul 24 06:56:24 2023, max compression
```

## Comparing `struphy-2.0.1.tar` & `struphy-2.0.2.tar`

### file list

```diff
@@ -1,365 +1,367 @@
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.556247 struphy-2.0.1/
--rw-rw-rw-   0 root         (0) root         (0)     1429 2023-06-21 05:54:37.000000 struphy-2.0.1/LICENSE
--rw-r--r--   0 root         (0) root         (0)     7600 2023-07-05 18:44:37.556247 struphy-2.0.1/PKG-INFO
--rwxrwxrwx   0 root         (0) root         (0)     5142 2023-07-04 15:04:56.000000 struphy-2.0.1/README.md
--rw-rw-rw-   0 root         (0) root         (0)     2128 2023-07-05 14:52:10.000000 struphy-2.0.1/pyproject.toml
--rw-rw-rw-   0 root         (0) root         (0)      124 2023-07-05 18:44:37.556247 struphy-2.0.1/setup.cfg
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.480248 struphy-2.0.1/src/
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.488247 struphy-2.0.1/src/struphy/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.492247 struphy-2.0.1/src/struphy/b_splines/
--rw-rw-rw-   0 root         (0) root         (0)     1621 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/b_splines/Bspline.py
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/b_splines/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     4670 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/b_splines/bspline_evaluation_1d.py
--rw-rw-rw-   0 root         (0) root         (0)    14007 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/b_splines/bspline_evaluation_2d.py
--rw-rw-rw-   0 root         (0) root         (0)    27508 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/b_splines/bspline_evaluation_3d.py
--rw-rw-rw-   0 root         (0) root         (0)    20754 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/b_splines/bsplines.py
--rw-rw-rw-   0 root         (0) root         (0)    20660 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/b_splines/bsplines_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)     6303 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/b_splines/bsplines_kernels_particles.py
--rw-rw-rw-   0 root         (0) root         (0)     6405 2023-07-03 14:56:04.000000 struphy-2.0.1/src/struphy/compile_struphy.mk
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.492247 struphy-2.0.1/src/struphy/console/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/console/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     2016 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/console/compile.py
--rw-rw-rw-   0 root         (0) root         (0)      705 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/console/example.py
--rw-rw-rw-   0 root         (0) root         (0)    18437 2023-07-03 14:23:35.000000 struphy-2.0.1/src/struphy/console/main.py
--rw-rw-rw-   0 root         (0) root         (0)     1250 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/console/pproc.py
--rw-rw-rw-   0 root         (0) root         (0)     5507 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/console/profile.py
--rw-rw-rw-   0 root         (0) root         (0)     6986 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/console/run.py
--rw-rw-rw-   0 root         (0) root         (0)     5089 2023-06-27 05:19:41.000000 struphy-2.0.1/src/struphy/console/test.py
--rw-rw-rw-   0 root         (0) root         (0)     1136 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/console/units.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.492247 struphy-2.0.1/src/struphy/diagnostics/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/diagnostics/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     5479 2023-07-04 12:08:43.000000 struphy-2.0.1/src/struphy/diagnostics/console_diagn.py
--rw-rw-rw-   0 root         (0) root         (0)    13915 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/diagnostics/continuous_spectra.py
--rw-rw-rw-   0 root         (0) root         (0)    12255 2023-07-04 12:08:43.000000 struphy-2.0.1/src/struphy/diagnostics/diagn_tools.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.492247 struphy-2.0.1/src/struphy/diagnostics/paraview/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/diagnostics/paraview/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    13277 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/diagnostics/paraview/mesh_creator.py
--rw-rw-rw-   0 root         (0) root         (0)     3004 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/diagnostics/paraview/vtk_writer.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.492247 struphy-2.0.1/src/struphy/dispersion_relations/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/dispersion_relations/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    38252 2023-06-27 05:19:41.000000 struphy-2.0.1/src/struphy/dispersion_relations/analytic.py
--rw-rw-rw-   0 root         (0) root         (0)     3838 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/dispersion_relations/base.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.496247 struphy-2.0.1/src/struphy/eigenvalue_solvers/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     5540 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/derivatives.py
--rw-rw-rw-   0 root         (0) root         (0)     5212 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/kernels_2d.py
--rw-rw-rw-   0 root         (0) root         (0)     7722 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/kernels_3d.py
--rw-rw-rw-   0 root         (0) root         (0)    23321 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/kernels_projectors_global.py
--rw-rw-rw-   0 root         (0) root         (0)    34110 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/kernels_projectors_global_mhd.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.500247 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/
--rw-rw-rw-   0 root         (0) root         (0)    32233 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/MHD_eigenvalues_cylinder_1D.py
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.500247 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    15856 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/control_variate.py
--rw-rw-rw-   0 root         (0) root         (0)     8521 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/kernels_control_variate.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.500247 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     7080 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fB_massless_control_variate.py
--rw-rw-rw-   0 root         (0) root         (0)    20929 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fB_massless_kernels_control_variate.py
--rw-rw-rw-   0 root         (0) root         (0)    11250 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_control_variate.py
--rw-rw-rw-   0 root         (0) root         (0)     1618 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_cv_kernel_2.py
--rw-rw-rw-   0 root         (0) root         (0)    21155 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_kernels_control_variate.py
--rw-rw-rw-   0 root         (0) root         (0)     9994 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_control_variate.py
--rw-rw-rw-   0 root         (0) root         (0)     8890 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_cvker.py
--rw-rw-rw-   0 root         (0) root         (0)    32983 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_kernels_control_variate.py
--rwxrwxrwx   0 root         (0) root         (0)     9189 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/emw_operators.py
--rw-rw-rw-   0 root         (0) root         (0)     3606 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/inner_products_1d.py
--rw-rw-rw-   0 root         (0) root         (0)    11738 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/inner_products_2d.py
--rw-rw-rw-   0 root         (0) root         (0)    12358 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/inner_products_3d.py
--rw-rw-rw-   0 root         (0) root         (0)     3432 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/l2_error_1d.py
--rw-rw-rw-   0 root         (0) root         (0)    17672 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/l2_error_2d.py
--rw-rw-rw-   0 root         (0) root         (0)    17438 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/l2_error_3d.py
--rw-rw-rw-   0 root         (0) root         (0)    16554 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/mass_matrices_3d_pre.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.504247 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/massless_operators/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/massless_operators/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    18026 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_arrays.py
--rw-rw-rw-   0 root         (0) root         (0)    14698 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_bb_kernel.py
--rw-rw-rw-   0 root         (0) root         (0)    25326 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_bv_kernel.py
--rw-rw-rw-   0 root         (0) root         (0)    46819 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_massless_linear_operators.py
--rw-rw-rw-   0 root         (0) root         (0)    27140 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_vv_kernel.py
--rw-rw-rw-   0 root         (0) root         (0)   139137 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/mhd_operators_MF.py
--rw-rw-rw-   0 root         (0) root         (0)   146225 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/mhd_operators_MF_for_tests.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.504247 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.504247 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    10395 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/kernels_projectors_local.py
--rw-rw-rw-   0 root         (0) root         (0)    22026 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/kernels_projectors_local_mhd.py
--rw-rw-rw-   0 root         (0) root         (0)   144069 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/mhd_operators_3d_local.py
--rw-rw-rw-   0 root         (0) root         (0)    72812 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/projectors_local.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.504247 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    94136 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_L2_projector_kernel.py
--rw-rw-rw-   0 root         (0) root         (0)    26256 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_function_projectors_L2.py
--rw-rw-rw-   0 root         (0) root         (0)    33024 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_function_projectors_local.py
--rw-rw-rw-   0 root         (0) root         (0)   129589 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_local_projector_kernel.py
--rw-rw-rw-   0 root         (0) root         (0)     8106 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/mass_matrices_1d.py
--rw-rw-rw-   0 root         (0) root         (0)    19797 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/mass_matrices_2d.py
--rw-rw-rw-   0 root         (0) root         (0)    21575 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/mass_matrices_3d.py
--rw-rw-rw-   0 root         (0) root         (0)     9549 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/mhd_axisymmetric_main.py
--rw-rw-rw-   0 root         (0) root         (0)     2296 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/mhd_axisymmetric_pproc.py
--rw-rw-rw-   0 root         (0) root         (0)    45855 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/mhd_operators.py
--rw-rw-rw-   0 root         (0) root         (0)    70280 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/mhd_operators_core.py
--rw-rw-rw-   0 root         (0) root         (0)    86755 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/projectors_global.py
--rw-rw-rw-   0 root         (0) root         (0)    93476 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/eigenvalue_solvers/spline_space.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.508247 struphy-2.0.1/src/struphy/examples/
--rw-rw-rw-   0 root         (0) root         (0)     7828 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/examples/TAE_tokamak.py
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/examples/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     2345 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/examples/_draw_parallel.py
--rw-rw-rw-   0 root         (0) root         (0)     5860 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/examples/_mhd_eigenvalues_cylinder.py
--rw-rw-rw-   0 root         (0) root         (0)     6072 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/examples/_mhd_eigenvalues_slab.py
--rw-rw-rw-   0 root         (0) root         (0)     8292 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/examples/_sendrecv.py
--rw-rw-rw-   0 root         (0) root         (0)     6993 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/examples/gc_orbits_tokamak.py
--rw-rw-rw-   0 root         (0) root         (0)     6901 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/examples/linearextendedmhd.py
--rw-rw-rw-   0 root         (0) root         (0)     4682 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/examples/linearmhd.py
--rw-rw-rw-   0 root         (0) root         (0)     4045 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/examples/linearmhdvlasov_cc.py
--rw-rw-rw-   0 root         (0) root         (0)     4045 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/examples/linearmhdvlasov_pc.py
--rw-rw-rw-   0 root         (0) root         (0)     3364 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/examples/maxwell.py
--rw-rw-rw-   0 root         (0) root         (0)     6961 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/examples/orbits_tokamak.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.508247 struphy-2.0.1/src/struphy/fields_background/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/fields_background/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.508247 struphy-2.0.1/src/struphy/fields_background/electric_equil/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/fields_background/electric_equil/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)      654 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/fields_background/electric_equil/analytical.py
--rw-rw-rw-   0 root         (0) root         (0)     1681 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/fields_background/electric_equil/base.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.508247 struphy-2.0.1/src/struphy/fields_background/mhd_equil/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/fields_background/mhd_equil/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    22702 2023-06-26 08:31:22.000000 struphy-2.0.1/src/struphy/fields_background/mhd_equil/base.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.508247 struphy-2.0.1/src/struphy/fields_background/mhd_equil/eqdsk/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/fields_background/mhd_equil/eqdsk/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.520247 struphy-2.0.1/src/struphy/fields_background/mhd_equil/eqdsk/data/
--rw-rw-rw-   0 root         (0) root         (0)  8579339 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/fields_background/mhd_equil/eqdsk/data/AUGNLED_g031213.00830.high
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/fields_background/mhd_equil/eqdsk/data/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     9280 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/fields_background/mhd_equil/eqdsk/readeqdsk.py
--rw-rw-rw-   0 root         (0) root         (0)    67736 2023-06-26 08:31:22.000000 struphy-2.0.1/src/struphy/fields_background/mhd_equil/equils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.520247 struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.480248 struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.520247 struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E1D6_M6N6/
--rw-rw-rw-   0 root         (0) root         (0)    65028 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E1D6_M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat
--rw-rw-rw-   0 root         (0) root         (0)     7253 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E1D6_M6N6/parameter.ini
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.520247 struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E4D6_M6N6/
--rw-rw-rw-   0 root         (0) root         (0)    89724 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E4D6_M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat
--rw-rw-rw-   0 root         (0) root         (0)     7276 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E4D6_M6N6/parameter.ini
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.520247 struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/oldBC_E40D5M6N6/
--rw-rw-rw-   0 root         (0) root         (0)   161316 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/oldBC_E40D5M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat
--rw-rw-rw-   0 root         (0) root         (0)     7249 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/oldBC_E40D5M6N6/parameter.ini
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.520247 struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/output/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/output/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.520247 struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/output/vtk/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/output/vtk/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.520247 struphy-2.0.1/src/struphy/fields_background/mhd_equil/vmec/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/fields_background/mhd_equil/vmec/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.520247 struphy-2.0.1/src/struphy/geometry/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/geometry/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    68667 2023-07-03 14:23:35.000000 struphy-2.0.1/src/struphy/geometry/base.py
--rw-rw-rw-   0 root         (0) root         (0)    40248 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/geometry/domains.py
--rw-rw-rw-   0 root         (0) root         (0)     3359 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/geometry/kernels.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.524247 struphy-2.0.1/src/struphy/geometry/map_coef/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/geometry/map_coef/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    26156 2023-07-03 14:23:35.000000 struphy-2.0.1/src/struphy/geometry/map_eval.py
--rw-rw-rw-   0 root         (0) root         (0)    32046 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/geometry/mappings_fast.py
--rw-rw-rw-   0 root         (0) root         (0)    16513 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/geometry/transform.py
--rw-rw-rw-   0 root         (0) root         (0)     8862 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/geometry/utilities.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.524247 struphy-2.0.1/src/struphy/initial/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/initial/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     3897 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/initial/analytic.py
--rw-rw-rw-   0 root         (0) root         (0)     7822 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/initial/base.py
--rw-rw-rw-   0 root         (0) root         (0)     8005 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/initial/eigenfunctions.py
--rw-rw-rw-   0 root         (0) root         (0)     4104 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/initial/initialize.py
--rw-rw-rw-   0 root         (0) root         (0)     4294 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/initial/perturbations.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.524247 struphy-2.0.1/src/struphy/io/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/io/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.524247 struphy-2.0.1/src/struphy/io/batch/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/io/batch/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     1073 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/batch/batch_cobra.sh
--rw-rw-rw-   0 root         (0) root         (0)     1302 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/batch/p_016.sh
--rw-rw-rw-   0 root         (0) root         (0)     1531 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/batch/p_032.sh
--rw-rw-rw-   0 root         (0) root         (0)     1531 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/batch/p_064.sh
--rw-rw-rw-   0 root         (0) root         (0)     1534 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/batch/p_128.sh
--rw-rw-rw-   0 root         (0) root         (0)     1534 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/batch/p_256.sh
--rw-rw-rw-   0 root         (0) root         (0)     1535 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/batch/p_512.sh
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.524247 struphy-2.0.1/src/struphy/io/inp/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/io/inp/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.528247 struphy-2.0.1/src/struphy/io/inp/examples/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/io/inp/examples/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     4815 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/inp/examples/params_TAE_tokamak.yml
--rw-rw-rw-   0 root         (0) root         (0)     5084 2023-07-03 14:23:35.000000 struphy-2.0.1/src/struphy/io/inp/examples/params_gc_orbits_tokamak.yml
--rw-rw-rw-   0 root         (0) root         (0)     5522 2023-07-03 14:23:35.000000 struphy-2.0.1/src/struphy/io/inp/examples/params_hybridmhdvlasovcc.yml
--rw-rw-rw-   0 root         (0) root         (0)     5308 2023-07-03 14:23:35.000000 struphy-2.0.1/src/struphy/io/inp/examples/params_hybridmhdvlasovpc.yml
--rw-rw-rw-   0 root         (0) root         (0)     3540 2023-06-28 09:15:27.000000 struphy-2.0.1/src/struphy/io/inp/examples/params_linearextendedmhd.yml
--rw-rw-rw-   0 root         (0) root         (0)     2981 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/inp/examples/params_linearmhd.yml
--rw-rw-rw-   0 root         (0) root         (0)     5518 2023-07-04 12:08:43.000000 struphy-2.0.1/src/struphy/io/inp/examples/params_linvlasovmaxwell_landau.yml
--rwxrwxrwx   0 root         (0) root         (0)     5788 2023-07-04 12:08:43.000000 struphy-2.0.1/src/struphy/io/inp/examples/params_linvlasovmaxwell_streaming_weibel.yml
--rw-rw-rw-   0 root         (0) root         (0)     6194 2023-07-04 12:08:43.000000 struphy-2.0.1/src/struphy/io/inp/examples/params_linvlasovmaxwell_weibel.yml
--rw-rw-rw-   0 root         (0) root         (0)     2049 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/inp/examples/params_maxwell.yml
--rw-rw-rw-   0 root         (0) root         (0)     4901 2023-07-03 14:23:35.000000 struphy-2.0.1/src/struphy/io/inp/examples/params_orbits_tokamak.yml
--rw-rw-rw-   0 root         (0) root         (0)    12847 2023-07-04 12:08:43.000000 struphy-2.0.1/src/struphy/io/inp/parameters.yml
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.532247 struphy-2.0.1/src/struphy/io/inp/tests/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/io/inp/tests/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     6052 2023-07-03 14:23:35.000000 struphy-2.0.1/src/struphy/io/inp/tests/params_cc_linmhd_5d.yml
--rwxrwxrwx   0 root         (0) root         (0)     3405 2023-06-27 05:19:41.000000 struphy-2.0.1/src/struphy/io/inp/tests/params_coldplasma.yml
--rw-rw-rw-   0 root         (0) root         (0)     5551 2023-07-03 14:23:35.000000 struphy-2.0.1/src/struphy/io/inp/tests/params_deltafvlasovmaxwell.yml
--rw-rw-rw-   0 root         (0) root         (0)     7776 2023-07-03 14:23:35.000000 struphy-2.0.1/src/struphy/io/inp/tests/params_hybrid_fA.yml
--rw-rw-rw-   0 root         (0) root         (0)     5475 2023-07-03 14:23:35.000000 struphy-2.0.1/src/struphy/io/inp/tests/params_hybridmhdvlasovcc.yml
--rw-rw-rw-   0 root         (0) root         (0)     5649 2023-07-03 14:23:35.000000 struphy-2.0.1/src/struphy/io/inp/tests/params_hybridmhdvlasovcc_control.yml
--rw-rw-rw-   0 root         (0) root         (0)     5408 2023-07-03 14:23:35.000000 struphy-2.0.1/src/struphy/io/inp/tests/params_hybridmhdvlasovcc_gvec.yml
--rw-rw-rw-   0 root         (0) root         (0)     5259 2023-07-03 14:23:35.000000 struphy-2.0.1/src/struphy/io/inp/tests/params_hybridmhdvlasovpc.yml
--rw-rw-rw-   0 root         (0) root         (0)     3023 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/inp/tests/params_linearmhd.yml
--rw-rw-rw-   0 root         (0) root         (0)     3447 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/inp/tests/params_linearmhd_gvec.yml
--rw-rw-rw-   0 root         (0) root         (0)     5650 2023-07-04 15:04:56.000000 struphy-2.0.1/src/struphy/io/inp/tests/params_linvlasovmaxwell.yml
--rw-rw-rw-   0 root         (0) root         (0)     2240 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/inp/tests/params_maxwell_1.yml
--rw-rw-rw-   0 root         (0) root         (0)     2316 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/inp/tests/params_maxwell_2.yml
--rw-rw-rw-   0 root         (0) root         (0)     1957 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/inp/tests/strscl.yml
--rw-rw-rw-   0 root         (0) root         (0)     1902 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/inp/tests/wkscl_1.yml
--rw-rw-rw-   0 root         (0) root         (0)     1902 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/inp/tests/wkscl_2.yml
--rw-rw-rw-   0 root         (0) root         (0)     1902 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/inp/tests/wkscl_3.yml
--rw-rw-rw-   0 root         (0) root         (0)     1902 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/inp/tests/wkscl_4.yml
--rw-rw-rw-   0 root         (0) root         (0)     1903 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/inp/tests/wkscl_5.yml
--rw-rw-rw-   0 root         (0) root         (0)     1905 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/inp/tests/wkscl_6.yml
--rw-rw-rw-   0 root         (0) root         (0)     1905 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/inp/tests/wkscl_7.yml
--rw-rw-rw-   0 root         (0) root         (0)     1905 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/io/inp/tests/wkscl_8.yml
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.532247 struphy-2.0.1/src/struphy/io/out/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/io/out/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.532247 struphy-2.0.1/src/struphy/kinetic_background/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/kinetic_background/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     1238 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/kinetic_background/background_eval.py
--rw-rw-rw-   0 root         (0) root         (0)     3629 2023-07-04 09:33:29.000000 struphy-2.0.1/src/struphy/kinetic_background/base.py
--rw-rw-rw-   0 root         (0) root         (0)     1722 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/kinetic_background/f0_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)    21280 2023-07-05 07:28:59.000000 struphy-2.0.1/src/struphy/kinetic_background/maxwellians.py
--rw-rw-rw-   0 root         (0) root         (0)    10095 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/kinetic_background/moments_kernels.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.532247 struphy-2.0.1/src/struphy/linear_algebra/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/linear_algebra/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     7557 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/linear_algebra/core.py
--rw-rw-rw-   0 root         (0) root         (0)    21910 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/linear_algebra/iterative_solvers.py
--rw-rw-rw-   0 root         (0) root         (0)    12463 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/linear_algebra/linalg_kron.py
--rw-rw-rw-   0 root         (0) root         (0)     5299 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/linear_algebra/schur_solver.py
--rw-rw-rw-   0 root         (0) root         (0)     8558 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/linear_algebra/stencil_dot_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)    14375 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/linear_algebra/stencil_transpose_kernels.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.536247 struphy-2.0.1/src/struphy/models/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/models/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    38411 2023-07-05 11:29:36.000000 struphy-2.0.1/src/struphy/models/base.py
--rw-rw-rw-   0 root         (0) root         (0)    18000 2023-06-27 05:19:41.000000 struphy-2.0.1/src/struphy/models/fluid.py
--rw-rw-rw-   0 root         (0) root         (0)    42265 2023-07-04 09:33:29.000000 struphy-2.0.1/src/struphy/models/hybrid.py
--rw-rw-rw-   0 root         (0) root         (0)    31429 2023-07-04 12:08:43.000000 struphy-2.0.1/src/struphy/models/kinetic.py
--rw-rw-rw-   0 root         (0) root         (0)     9070 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/models/main.py
--rw-rw-rw-   0 root         (0) root         (0)     4889 2023-07-03 14:23:35.000000 struphy-2.0.1/src/struphy/models/output_handling.py
--rw-rw-rw-   0 root         (0) root         (0)    13944 2023-07-03 14:23:35.000000 struphy-2.0.1/src/struphy/models/setup.py
--rw-rw-rw-   0 root         (0) root         (0)    13090 2023-06-26 08:31:22.000000 struphy-2.0.1/src/struphy/models/toy.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.540247 struphy-2.0.1/src/struphy/pic/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/pic/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)   138355 2023-07-04 12:08:43.000000 struphy-2.0.1/src/struphy/pic/accum_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)    20171 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/pic/filler_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)   247659 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/pic/mat_vec_filler.py
--rw-rw-rw-   0 root         (0) root         (0)    39865 2023-07-05 11:29:36.000000 struphy-2.0.1/src/struphy/pic/particles.py
--rw-rw-rw-   0 root         (0) root         (0)    18056 2023-07-04 09:50:44.000000 struphy-2.0.1/src/struphy/pic/particles_to_grid.py
--rw-rw-rw-   0 root         (0) root         (0)    15007 2023-07-05 14:52:10.000000 struphy-2.0.1/src/struphy/pic/pusher.py
--rw-rw-rw-   0 root         (0) root         (0)   204819 2023-07-04 12:08:43.000000 struphy-2.0.1/src/struphy/pic/pusher_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)    21310 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/pic/pusher_utilities.py
--rw-rw-rw-   0 root         (0) root         (0)     8535 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/pic/sampling.py
--rw-rw-rw-   0 root         (0) root         (0)    14923 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/pic/sobol_seq.py
--rw-rw-rw-   0 root         (0) root         (0)     5608 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/pic/utilities.py
--rw-rw-rw-   0 root         (0) root         (0)   104291 2023-06-26 08:31:22.000000 struphy-2.0.1/src/struphy/pic/utilities_kernels.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.540247 struphy-2.0.1/src/struphy/polar/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/polar/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    16532 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/polar/basic.py
--rw-rw-rw-   0 root         (0) root         (0)    52606 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/polar/extraction_operators.py
--rw-rw-rw-   0 root         (0) root         (0)    32352 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/polar/linear_operators.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.540247 struphy-2.0.1/src/struphy/post_processing/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/post_processing/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     6362 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/post_processing/cprofile_analyser.py
--rw-rw-rw-   0 root         (0) root         (0)    18853 2023-07-04 09:33:29.000000 struphy-2.0.1/src/struphy/post_processing/post_processing_tools.py
--rw-rw-rw-   0 root         (0) root         (0)     6489 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/post_processing/pproc_struphy.py
--rw-rw-rw-   0 root         (0) root         (0)     5300 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/post_processing/profile_struphy.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.540247 struphy-2.0.1/src/struphy/propagators/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/propagators/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     3421 2023-07-05 14:52:10.000000 struphy-2.0.1/src/struphy/propagators/base.py
--rw-rw-rw-   0 root         (0) root         (0)    62012 2023-07-04 12:08:43.000000 struphy-2.0.1/src/struphy/propagators/propagators_coupling.py
--rw-rw-rw-   0 root         (0) root         (0)    71738 2023-07-04 09:33:29.000000 struphy-2.0.1/src/struphy/propagators/propagators_fields.py
--rw-rw-rw-   0 root         (0) root         (0)    45141 2023-07-04 09:33:29.000000 struphy-2.0.1/src/struphy/propagators/propagators_markers.py
--rw-rw-rw-   0 root         (0) root         (0)     3826 2023-07-04 12:08:43.000000 struphy-2.0.1/src/struphy/propagators/solvers.py
--rw-rw-rw-   0 root         (0) root         (0)  1335528 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/psydac-0.1-py3-none-any.whl
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.544247 struphy-2.0.1/src/struphy/psydac_api/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/psydac_api/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     1839 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/psydac_api/banded_to_stencil_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)    19977 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/psydac_api/basis_projection_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)    43809 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/psydac_api/basis_projection_ops.py
--rw-rw-rw-   0 root         (0) root         (0)    22797 2023-07-03 14:23:35.000000 struphy-2.0.1/src/struphy/psydac_api/fields.py
--rw-rw-rw-   0 root         (0) root         (0)    22918 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/psydac_api/linear_operators.py
--rw-rw-rw-   0 root         (0) root         (0)    50895 2023-06-28 09:15:27.000000 struphy-2.0.1/src/struphy/psydac_api/mass.py
--rw-rw-rw-   0 root         (0) root         (0)    15604 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/psydac_api/mass_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)    15886 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/psydac_api/preconditioner.py
--rw-rw-rw-   0 root         (0) root         (0)    19799 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/psydac_api/projectors.py
--rw-rw-rw-   0 root         (0) root         (0)    35047 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/psydac_api/psydac_derham.py
--rw-rw-rw-   0 root         (0) root         (0)     5396 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/psydac_api/quadrature_evaluation_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)    14732 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/psydac_api/utilities.py
--rw-rw-rw-   0 root         (0) root         (0)     5381 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/psydac_api/utilities_kernels.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.544247 struphy-2.0.1/src/struphy/tests/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/tests/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.548247 struphy-2.0.1/src/struphy/tests/tests_mpi/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    30505 2023-07-05 11:29:36.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_accumulation.py
--rw-rw-rw-   0 root         (0) root         (0)    24182 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_basis_operators.py
--rw-rw-rw-   0 root         (0) root         (0)     3624 2023-07-05 11:29:36.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_draw_parallel.py
--rw-rw-rw-   0 root         (0) root         (0)    16166 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_eval_spline_mpi.py
--rw-rw-rw-   0 root         (0) root         (0)     6544 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_iterative_solvers.py
--rw-rw-rw-   0 root         (0) root         (0)    37746 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_mass_matrices.py
--rw-rw-rw-   0 root         (0) root         (0)    16313 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_mat_vec_filler.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.548247 struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    19425 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/accumulation.py
--rw-rw-rw-   0 root         (0) root         (0)    51404 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/accumulation_kernels_3d.py
--rw-rw-rw-   0 root         (0) root         (0)    22396 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/mappings_3d.py
--rw-rw-rw-   0 root         (0) root         (0)    14116 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/mappings_3d_fast.py
--rw-rw-rw-   0 root         (0) root         (0)    11123 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/pusher.py
--rw-rw-rw-   0 root         (0) root         (0)    64611 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/pusher_pos.py
--rw-rw-rw-   0 root         (0) root         (0)    17908 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/pusher_vel_2d.py
--rw-rw-rw-   0 root         (0) root         (0)    38069 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/pusher_vel_3d.py
--rw-rw-rw-   0 root         (0) root         (0)    14178 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/spline_evaluation_2d.py
--rw-rw-rw-   0 root         (0) root         (0)    33254 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/spline_evaluation_3d.py
--rw-rw-rw-   0 root         (0) root         (0)    13453 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_polar.py
--rw-rw-rw-   0 root         (0) root         (0)     2573 2023-07-04 12:08:43.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_prop_solvers.py
--rw-rw-rw-   0 root         (0) root         (0)    14324 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_psydac_basics.py
--rw-rw-rw-   0 root         (0) root         (0)     8477 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_psydac_derham.py
--rw-rw-rw-   0 root         (0) root         (0)    31868 2023-07-05 11:29:36.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_pushers.py
--rw-rw-rw-   0 root         (0) root         (0)    11285 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_stencil_dot_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)    11191 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_mpi/test_stencil_transpose_kernels.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.556247 struphy-2.0.1/src/struphy/tests/tests_serial/
--rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-05 18:44:25.000000 struphy-2.0.1/src/struphy/tests/tests_serial/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     7092 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/test_bsplines_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)    38312 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/test_domain.py
--rw-rw-rw-   0 root         (0) root         (0)     6770 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/test_gvec_equil.py
--rw-rw-rw-   0 root         (0) root         (0)    45719 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/test_legacy_mhd_projectors.py
--rw-rw-rw-   0 root         (0) root         (0)     4901 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/test_legacy_polar_splines.py
--rw-rw-rw-   0 root         (0) root         (0)    34306 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/test_mhd_equils.py
--rw-rw-rw-   0 root         (0) root         (0)     6283 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/test_numerical_MHD_equil.py
--rw-rw-rw-   0 root         (0) root         (0)    28774 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/test_projectors_global.py
--rw-rw-rw-   0 root         (0) root         (0)    20676 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/test_psydac_basis_operators.py
--rw-rw-rw-   0 root         (0) root         (0)     6177 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/test_psydac_linear_operators.py
--rw-rw-rw-   0 root         (0) root         (0)     2266 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/test_psydac_mapping.py
--rw-rw-rw-   0 root         (0) root         (0)     2924 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/test_spline_space_1d.py
--rw-rw-rw-   0 root         (0) root         (0)    23196 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/xx_psydac_lin_ops.py
--rw-rw-rw-   0 root         (0) root         (0)    23652 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_GVEC.py
--rw-rw-rw-   0 root         (0) root         (0)     1566 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_codes.py
--rw-rw-rw-   0 root         (0) root         (0)     1702 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_cprofiler.py
--rw-rw-rw-   0 root         (0) root         (0)    19344 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_divB.py
--rw-rw-rw-   0 root         (0) root         (0)    10695 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_filler_kernel.py
--rw-rw-rw-   0 root         (0) root         (0)    12684 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_mappings.py
--rw-rw-rw-   0 root         (0) root         (0)    16292 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_mat_vec_filler.py
--rw-rw-rw-   0 root         (0) root         (0)     2435 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_mhd_equil.py
--rw-rw-rw-   0 root         (0) root         (0)    15899 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_paraview.py
--rw-rw-rw-   0 root         (0) root         (0)   277942 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_polar_splines_3D.py
--rw-rw-rw-   0 root         (0) root         (0)     3530 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_preconditioner.py
--rw-rw-rw-   0 root         (0) root         (0)    32928 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_psydac_lin_ops_loop.py
--rw-rw-rw-   0 root         (0) root         (0)    15913 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_spline_evaluation.py
--rw-rw-rw-   0 root         (0) root         (0)     8515 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_spline_interpolation.py
--rw-rw-rw-   0 root         (0) root         (0)    10294 2023-06-21 05:54:37.000000 struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_template_gvec.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-05 18:44:37.488247 struphy-2.0.1/src/struphy.egg-info/
--rw-r--r--   0 root         (0) root         (0)     7600 2023-07-05 18:44:37.000000 struphy-2.0.1/src/struphy.egg-info/PKG-INFO
--rw-r--r--   0 root         (0) root         (0)    15601 2023-07-05 18:44:37.000000 struphy-2.0.1/src/struphy.egg-info/SOURCES.txt
--rw-r--r--   0 root         (0) root         (0)        1 2023-07-05 18:44:37.000000 struphy-2.0.1/src/struphy.egg-info/dependency_links.txt
--rw-r--r--   0 root         (0) root         (0)       57 2023-07-05 18:44:37.000000 struphy-2.0.1/src/struphy.egg-info/entry_points.txt
--rw-r--r--   0 root         (0) root         (0)      195 2023-07-05 18:44:37.000000 struphy-2.0.1/src/struphy.egg-info/requires.txt
--rw-r--r--   0 root         (0) root         (0)        8 2023-07-05 18:44:37.000000 struphy-2.0.1/src/struphy.egg-info/top_level.txt
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.956282 struphy-2.0.2/
+-rw-rw-rw-   0 root         (0) root         (0)     1449 2023-07-20 09:51:16.000000 struphy-2.0.2/LICENSE
+-rw-r--r--   0 root         (0) root         (0)     7657 2023-07-24 06:56:24.956282 struphy-2.0.2/PKG-INFO
+-rwxrwxrwx   0 root         (0) root         (0)     5161 2023-07-24 05:54:16.000000 struphy-2.0.2/README.md
+-rw-rw-rw-   0 root         (0) root         (0)     2181 2023-07-24 05:54:16.000000 struphy-2.0.2/pyproject.toml
+-rw-rw-rw-   0 root         (0) root         (0)      124 2023-07-24 06:56:24.956282 struphy-2.0.2/setup.cfg
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.856282 struphy-2.0.2/src/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.868282 struphy-2.0.2/src/struphy/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.872282 struphy-2.0.2/src/struphy/b_splines/
+-rw-rw-rw-   0 root         (0) root         (0)     1621 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/b_splines/Bspline.py
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/b_splines/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     4670 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/b_splines/bspline_evaluation_1d.py
+-rw-rw-rw-   0 root         (0) root         (0)    14007 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/b_splines/bspline_evaluation_2d.py
+-rw-rw-rw-   0 root         (0) root         (0)    27508 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/b_splines/bspline_evaluation_3d.py
+-rw-rw-rw-   0 root         (0) root         (0)    20754 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/b_splines/bsplines.py
+-rw-rw-rw-   0 root         (0) root         (0)    20660 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/b_splines/bsplines_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)     6303 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/b_splines/bsplines_kernels_particles.py
+-rw-rw-rw-   0 root         (0) root         (0)     6833 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/compile_struphy.mk
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.876282 struphy-2.0.2/src/struphy/console/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/console/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     2294 2023-07-20 09:51:16.000000 struphy-2.0.2/src/struphy/console/compile.py
+-rw-rw-rw-   0 root         (0) root         (0)      705 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/console/example.py
+-rw-rw-rw-   0 root         (0) root         (0)    20603 2023-07-21 12:05:57.000000 struphy-2.0.2/src/struphy/console/main.py
+-rw-rw-rw-   0 root         (0) root         (0)     1237 2023-07-21 12:05:57.000000 struphy-2.0.2/src/struphy/console/pproc.py
+-rw-rw-rw-   0 root         (0) root         (0)     6509 2023-07-21 12:05:57.000000 struphy-2.0.2/src/struphy/console/profile.py
+-rw-rw-rw-   0 root         (0) root         (0)     7130 2023-07-21 12:05:57.000000 struphy-2.0.2/src/struphy/console/run.py
+-rw-rw-rw-   0 root         (0) root         (0)     5862 2023-07-18 05:56:26.000000 struphy-2.0.2/src/struphy/console/test.py
+-rw-rw-rw-   0 root         (0) root         (0)     1122 2023-07-21 12:05:57.000000 struphy-2.0.2/src/struphy/console/units.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.876282 struphy-2.0.2/src/struphy/diagnostics/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/diagnostics/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     5466 2023-07-21 12:05:57.000000 struphy-2.0.2/src/struphy/diagnostics/console_diagn.py
+-rw-rw-rw-   0 root         (0) root         (0)    13902 2023-07-21 12:05:57.000000 struphy-2.0.2/src/struphy/diagnostics/continuous_spectra.py
+-rw-rw-rw-   0 root         (0) root         (0)    12255 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/diagnostics/diagn_tools.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.876282 struphy-2.0.2/src/struphy/diagnostics/paraview/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/diagnostics/paraview/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    13277 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/diagnostics/paraview/mesh_creator.py
+-rw-rw-rw-   0 root         (0) root         (0)     3004 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/diagnostics/paraview/vtk_writer.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.880282 struphy-2.0.2/src/struphy/dispersion_relations/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/dispersion_relations/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    38249 2023-07-18 05:56:26.000000 struphy-2.0.2/src/struphy/dispersion_relations/analytic.py
+-rw-rw-rw-   0 root         (0) root         (0)     3838 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/dispersion_relations/base.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.884282 struphy-2.0.2/src/struphy/eigenvalue_solvers/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     5540 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/derivatives.py
+-rw-rw-rw-   0 root         (0) root         (0)     5212 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/kernels_2d.py
+-rw-rw-rw-   0 root         (0) root         (0)     7722 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/kernels_3d.py
+-rw-rw-rw-   0 root         (0) root         (0)    23321 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/kernels_projectors_global.py
+-rw-rw-rw-   0 root         (0) root         (0)    34110 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/kernels_projectors_global_mhd.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.884282 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/
+-rw-rw-rw-   0 root         (0) root         (0)    32233 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/MHD_eigenvalues_cylinder_1D.py
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.888282 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    15856 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/control_variate.py
+-rw-rw-rw-   0 root         (0) root         (0)     8521 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/kernels_control_variate.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.888282 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     7080 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fB_massless_control_variate.py
+-rw-rw-rw-   0 root         (0) root         (0)    20929 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fB_massless_kernels_control_variate.py
+-rw-rw-rw-   0 root         (0) root         (0)    11250 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_control_variate.py
+-rw-rw-rw-   0 root         (0) root         (0)     1618 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_cv_kernel_2.py
+-rw-rw-rw-   0 root         (0) root         (0)    21155 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_kernels_control_variate.py
+-rw-rw-rw-   0 root         (0) root         (0)     9994 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_control_variate.py
+-rw-rw-rw-   0 root         (0) root         (0)     8890 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_cvker.py
+-rw-rw-rw-   0 root         (0) root         (0)    32983 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_kernels_control_variate.py
+-rwxrwxrwx   0 root         (0) root         (0)     9189 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/emw_operators.py
+-rw-rw-rw-   0 root         (0) root         (0)     3606 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/inner_products_1d.py
+-rw-rw-rw-   0 root         (0) root         (0)    11738 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/inner_products_2d.py
+-rw-rw-rw-   0 root         (0) root         (0)    12358 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/inner_products_3d.py
+-rw-rw-rw-   0 root         (0) root         (0)     3432 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/l2_error_1d.py
+-rw-rw-rw-   0 root         (0) root         (0)    17672 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/l2_error_2d.py
+-rw-rw-rw-   0 root         (0) root         (0)    17438 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/l2_error_3d.py
+-rw-rw-rw-   0 root         (0) root         (0)    16554 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/mass_matrices_3d_pre.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.892282 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/massless_operators/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/massless_operators/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    18026 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_arrays.py
+-rw-rw-rw-   0 root         (0) root         (0)    14698 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_bb_kernel.py
+-rw-rw-rw-   0 root         (0) root         (0)    25326 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_bv_kernel.py
+-rw-rw-rw-   0 root         (0) root         (0)    46819 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_massless_linear_operators.py
+-rw-rw-rw-   0 root         (0) root         (0)    27140 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_vv_kernel.py
+-rw-rw-rw-   0 root         (0) root         (0)   139137 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/mhd_operators_MF.py
+-rw-rw-rw-   0 root         (0) root         (0)   146225 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/mhd_operators_MF_for_tests.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.892282 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.892282 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    10395 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/kernels_projectors_local.py
+-rw-rw-rw-   0 root         (0) root         (0)    22026 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/kernels_projectors_local_mhd.py
+-rw-rw-rw-   0 root         (0) root         (0)   144069 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/mhd_operators_3d_local.py
+-rw-rw-rw-   0 root         (0) root         (0)    72812 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/projectors_local.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.892282 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    94136 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_L2_projector_kernel.py
+-rw-rw-rw-   0 root         (0) root         (0)    26256 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_function_projectors_L2.py
+-rw-rw-rw-   0 root         (0) root         (0)    33024 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_function_projectors_local.py
+-rw-rw-rw-   0 root         (0) root         (0)   129589 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_local_projector_kernel.py
+-rw-rw-rw-   0 root         (0) root         (0)     8106 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/mass_matrices_1d.py
+-rw-rw-rw-   0 root         (0) root         (0)    19797 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/mass_matrices_2d.py
+-rw-rw-rw-   0 root         (0) root         (0)    21575 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/mass_matrices_3d.py
+-rw-rw-rw-   0 root         (0) root         (0)     9617 2023-07-21 12:05:57.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/mhd_axisymmetric_main.py
+-rw-rw-rw-   0 root         (0) root         (0)     2283 2023-07-21 12:05:57.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/mhd_axisymmetric_pproc.py
+-rw-rw-rw-   0 root         (0) root         (0)    45855 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/mhd_operators.py
+-rw-rw-rw-   0 root         (0) root         (0)    70280 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/mhd_operators_core.py
+-rw-rw-rw-   0 root         (0) root         (0)    86755 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/projectors_global.py
+-rw-rw-rw-   0 root         (0) root         (0)    93476 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/eigenvalue_solvers/spline_space.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.896282 struphy-2.0.2/src/struphy/examples/
+-rw-rw-rw-   0 root         (0) root         (0)     7802 2023-07-21 12:05:58.000000 struphy-2.0.2/src/struphy/examples/TAE_tokamak.py
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/examples/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     2345 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/examples/_draw_parallel.py
+-rw-rw-rw-   0 root         (0) root         (0)     5860 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/examples/_mhd_eigenvalues_cylinder.py
+-rw-rw-rw-   0 root         (0) root         (0)     6072 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/examples/_mhd_eigenvalues_slab.py
+-rw-rw-rw-   0 root         (0) root         (0)     8292 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/examples/_sendrecv.py
+-rw-rw-rw-   0 root         (0) root         (0)     6980 2023-07-21 12:05:58.000000 struphy-2.0.2/src/struphy/examples/gc_orbits_tokamak.py
+-rw-rw-rw-   0 root         (0) root         (0)     6888 2023-07-21 12:05:58.000000 struphy-2.0.2/src/struphy/examples/linearextendedmhd.py
+-rw-rw-rw-   0 root         (0) root         (0)     4669 2023-07-21 12:05:58.000000 struphy-2.0.2/src/struphy/examples/linearmhd.py
+-rw-rw-rw-   0 root         (0) root         (0)     4032 2023-07-21 12:05:58.000000 struphy-2.0.2/src/struphy/examples/linearmhdvlasov_cc.py
+-rw-rw-rw-   0 root         (0) root         (0)     4032 2023-07-21 12:05:58.000000 struphy-2.0.2/src/struphy/examples/linearmhdvlasov_pc.py
+-rw-rw-rw-   0 root         (0) root         (0)     3351 2023-07-21 12:05:58.000000 struphy-2.0.2/src/struphy/examples/maxwell.py
+-rw-rw-rw-   0 root         (0) root         (0)     6948 2023-07-21 12:05:58.000000 struphy-2.0.2/src/struphy/examples/orbits_tokamak.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.896282 struphy-2.0.2/src/struphy/fields_background/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/fields_background/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.896282 struphy-2.0.2/src/struphy/fields_background/electric_equil/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/fields_background/electric_equil/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)      654 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/fields_background/electric_equil/analytical.py
+-rw-rw-rw-   0 root         (0) root         (0)     1681 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/fields_background/electric_equil/base.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.900282 struphy-2.0.2/src/struphy/fields_background/mhd_equil/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/fields_background/mhd_equil/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    22702 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/fields_background/mhd_equil/base.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.900282 struphy-2.0.2/src/struphy/fields_background/mhd_equil/eqdsk/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/fields_background/mhd_equil/eqdsk/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.908282 struphy-2.0.2/src/struphy/fields_background/mhd_equil/eqdsk/data/
+-rw-rw-rw-   0 root         (0) root         (0)  8579339 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/fields_background/mhd_equil/eqdsk/data/AUGNLED_g031213.00830.high
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/fields_background/mhd_equil/eqdsk/data/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     9280 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/fields_background/mhd_equil/eqdsk/readeqdsk.py
+-rw-rw-rw-   0 root         (0) root         (0)    67736 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/fields_background/mhd_equil/equils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.908282 struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.860282 struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.908282 struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E1D6_M6N6/
+-rw-rw-rw-   0 root         (0) root         (0)    65028 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E1D6_M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat
+-rw-rw-rw-   0 root         (0) root         (0)     7253 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E1D6_M6N6/parameter.ini
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.908282 struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E4D6_M6N6/
+-rw-rw-rw-   0 root         (0) root         (0)    89724 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E4D6_M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat
+-rw-rw-rw-   0 root         (0) root         (0)     7276 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E4D6_M6N6/parameter.ini
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.912282 struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/oldBC_E40D5M6N6/
+-rw-rw-rw-   0 root         (0) root         (0)   161316 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/oldBC_E40D5M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat
+-rw-rw-rw-   0 root         (0) root         (0)     7249 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/oldBC_E40D5M6N6/parameter.ini
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.912282 struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/output/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/output/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.912282 struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/output/vtk/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/output/vtk/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.912282 struphy-2.0.2/src/struphy/fields_background/mhd_equil/vmec/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/fields_background/mhd_equil/vmec/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.912282 struphy-2.0.2/src/struphy/geometry/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/geometry/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    68667 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/geometry/base.py
+-rw-rw-rw-   0 root         (0) root         (0)    40248 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/geometry/domains.py
+-rw-rw-rw-   0 root         (0) root         (0)     3359 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/geometry/kernels.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.912282 struphy-2.0.2/src/struphy/geometry/map_coef/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/geometry/map_coef/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    26156 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/geometry/map_eval.py
+-rw-rw-rw-   0 root         (0) root         (0)    32046 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/geometry/mappings_fast.py
+-rw-rw-rw-   0 root         (0) root         (0)    16513 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/geometry/transform.py
+-rw-rw-rw-   0 root         (0) root         (0)     8862 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/geometry/utilities.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.916282 struphy-2.0.2/src/struphy/initial/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/initial/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     8330 2023-07-21 12:05:58.000000 struphy-2.0.2/src/struphy/initial/eigenfunctions.py
+-rw-rw-rw-   0 root         (0) root         (0)     7463 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/initial/perturbations.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.916282 struphy-2.0.2/src/struphy/io/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/io/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.916282 struphy-2.0.2/src/struphy/io/batch/
+-rw-rw-rw-   0 root         (0) root         (0)     1073 2023-07-19 09:23:06.000000 struphy-2.0.2/src/struphy/io/batch/batch_cobra.sh
+-rw-rw-rw-   0 root         (0) root         (0)     1302 2023-07-19 09:23:06.000000 struphy-2.0.2/src/struphy/io/batch/p_016.sh
+-rw-rw-rw-   0 root         (0) root         (0)     1531 2023-07-19 09:23:06.000000 struphy-2.0.2/src/struphy/io/batch/p_032.sh
+-rw-rw-rw-   0 root         (0) root         (0)     1531 2023-07-19 09:23:06.000000 struphy-2.0.2/src/struphy/io/batch/p_064.sh
+-rw-rw-rw-   0 root         (0) root         (0)     1534 2023-07-19 09:23:06.000000 struphy-2.0.2/src/struphy/io/batch/p_128.sh
+-rw-rw-rw-   0 root         (0) root         (0)     1534 2023-07-19 09:23:06.000000 struphy-2.0.2/src/struphy/io/batch/p_256.sh
+-rw-rw-rw-   0 root         (0) root         (0)     1535 2023-07-19 09:23:06.000000 struphy-2.0.2/src/struphy/io/batch/p_512.sh
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.916282 struphy-2.0.2/src/struphy/io/inp/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/io/inp/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.920282 struphy-2.0.2/src/struphy/io/inp/examples/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/io/inp/examples/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     4815 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/examples/params_TAE_tokamak.yml
+-rw-rw-rw-   0 root         (0) root         (0)     5388 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/examples/params_gc_orbits_tokamak.yml
+-rw-rw-rw-   0 root         (0) root         (0)     5523 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/examples/params_hybridmhdvlasovcc.yml
+-rw-rw-rw-   0 root         (0) root         (0)     5309 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/examples/params_hybridmhdvlasovpc.yml
+-rw-rw-rw-   0 root         (0) root         (0)     3606 2023-07-18 11:52:24.000000 struphy-2.0.2/src/struphy/io/inp/examples/params_linearextendedmhd.yml
+-rw-rw-rw-   0 root         (0) root         (0)     3047 2023-07-24 05:54:16.000000 struphy-2.0.2/src/struphy/io/inp/examples/params_linearmhd.yml
+-rw-rw-rw-   0 root         (0) root         (0)     5518 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/examples/params_linvlasovmaxwell_landau.yml
+-rwxrwxrwx   0 root         (0) root         (0)     5788 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/examples/params_linvlasovmaxwell_streaming_weibel.yml
+-rw-rw-rw-   0 root         (0) root         (0)     6075 2023-07-18 11:52:24.000000 struphy-2.0.2/src/struphy/io/inp/examples/params_linvlasovmaxwell_weibel.yml
+-rw-rw-rw-   0 root         (0) root         (0)     2111 2023-07-18 11:52:24.000000 struphy-2.0.2/src/struphy/io/inp/examples/params_maxwell.yml
+-rw-rw-rw-   0 root         (0) root         (0)     4901 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/examples/params_orbits_tokamak.yml
+-rw-rw-rw-   0 root         (0) root         (0)    13429 2023-07-18 11:52:24.000000 struphy-2.0.2/src/struphy/io/inp/parameters.yml
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.924282 struphy-2.0.2/src/struphy/io/inp/tests/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/io/inp/tests/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     6118 2023-07-18 11:52:24.000000 struphy-2.0.2/src/struphy/io/inp/tests/params_cc_linmhd_5d.yml
+-rwxrwxrwx   0 root         (0) root         (0)     3551 2023-07-18 11:52:24.000000 struphy-2.0.2/src/struphy/io/inp/tests/params_coldplasma.yml
+-rwxrwxrwx   0 root         (0) root         (0)     6490 2023-07-18 05:56:26.000000 struphy-2.0.2/src/struphy/io/inp/tests/params_coldplasmavlasov.yml
+-rw-rw-rw-   0 root         (0) root         (0)     5572 2023-07-20 09:51:16.000000 struphy-2.0.2/src/struphy/io/inp/tests/params_deltafvlasovmaxwell.yml
+-rw-rw-rw-   0 root         (0) root         (0)     7841 2023-07-18 11:52:24.000000 struphy-2.0.2/src/struphy/io/inp/tests/params_hybrid_fA.yml
+-rw-rw-rw-   0 root         (0) root         (0)     5476 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/tests/params_hybridmhdvlasovcc.yml
+-rw-rw-rw-   0 root         (0) root         (0)     5650 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/tests/params_hybridmhdvlasovcc_control.yml
+-rw-rw-rw-   0 root         (0) root         (0)     5409 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/tests/params_hybridmhdvlasovcc_gvec.yml
+-rw-rw-rw-   0 root         (0) root         (0)     5260 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/tests/params_hybridmhdvlasovpc.yml
+-rw-rw-rw-   0 root         (0) root         (0)     3089 2023-07-18 11:52:24.000000 struphy-2.0.2/src/struphy/io/inp/tests/params_linearmhd.yml
+-rw-rw-rw-   0 root         (0) root         (0)     3513 2023-07-18 11:52:24.000000 struphy-2.0.2/src/struphy/io/inp/tests/params_linearmhd_gvec.yml
+-rw-rw-rw-   0 root         (0) root         (0)     5732 2023-07-20 09:51:16.000000 struphy-2.0.2/src/struphy/io/inp/tests/params_linvlasovmaxwell.yml
+-rw-rw-rw-   0 root         (0) root         (0)     2239 2023-07-20 09:51:16.000000 struphy-2.0.2/src/struphy/io/inp/tests/params_maxwell_1.yml
+-rw-rw-rw-   0 root         (0) root         (0)     2317 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/tests/params_maxwell_2.yml
+-rw-rw-rw-   0 root         (0) root         (0)     5708 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/tests/params_vlasovmaxwell.yml
+-rw-rw-rw-   0 root         (0) root         (0)     1957 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/tests/strscl.yml
+-rw-rw-rw-   0 root         (0) root         (0)     1902 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/tests/wkscl_1.yml
+-rw-rw-rw-   0 root         (0) root         (0)     1902 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/tests/wkscl_2.yml
+-rw-rw-rw-   0 root         (0) root         (0)     1902 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/tests/wkscl_3.yml
+-rw-rw-rw-   0 root         (0) root         (0)     1902 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/tests/wkscl_4.yml
+-rw-rw-rw-   0 root         (0) root         (0)     1903 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/tests/wkscl_5.yml
+-rw-rw-rw-   0 root         (0) root         (0)     1905 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/tests/wkscl_6.yml
+-rw-rw-rw-   0 root         (0) root         (0)     1905 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/tests/wkscl_7.yml
+-rw-rw-rw-   0 root         (0) root         (0)     1905 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/io/inp/tests/wkscl_8.yml
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.924282 struphy-2.0.2/src/struphy/io/out/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/io/out/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.928282 struphy-2.0.2/src/struphy/kinetic_background/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/kinetic_background/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     1238 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/kinetic_background/background_eval.py
+-rw-rw-rw-   0 root         (0) root         (0)     3629 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/kinetic_background/base.py
+-rw-rw-rw-   0 root         (0) root         (0)     1722 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/kinetic_background/f0_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)    21452 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/kinetic_background/maxwellians.py
+-rw-rw-rw-   0 root         (0) root         (0)    10095 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/kinetic_background/moments_kernels.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.928282 struphy-2.0.2/src/struphy/linear_algebra/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/linear_algebra/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     7557 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/linear_algebra/core.py
+-rw-rw-rw-   0 root         (0) root         (0)    21910 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/linear_algebra/iterative_solvers.py
+-rw-rw-rw-   0 root         (0) root         (0)    12463 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/linear_algebra/linalg_kron.py
+-rw-rw-rw-   0 root         (0) root         (0)     5299 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/linear_algebra/schur_solver.py
+-rw-rw-rw-   0 root         (0) root         (0)     8558 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/linear_algebra/stencil_dot_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)    14375 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/linear_algebra/stencil_transpose_kernels.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.932282 struphy-2.0.2/src/struphy/models/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/models/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    42773 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/models/base.py
+-rw-rw-rw-   0 root         (0) root         (0)    14775 2023-07-18 05:56:26.000000 struphy-2.0.2/src/struphy/models/fluid.py
+-rw-rw-rw-   0 root         (0) root         (0)    42869 2023-07-18 05:56:26.000000 struphy-2.0.2/src/struphy/models/hybrid.py
+-rw-rw-rw-   0 root         (0) root         (0)    37525 2023-07-18 11:52:24.000000 struphy-2.0.2/src/struphy/models/kinetic.py
+-rw-rw-rw-   0 root         (0) root         (0)     9428 2023-07-21 12:05:58.000000 struphy-2.0.2/src/struphy/models/main.py
+-rw-rw-rw-   0 root         (0) root         (0)     4889 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/models/output_handling.py
+-rw-rw-rw-   0 root         (0) root         (0)    13866 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/models/setup.py
+-rw-rw-rw-   0 root         (0) root         (0)     9875 2023-07-19 18:15:36.000000 struphy-2.0.2/src/struphy/models/toy.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.936282 struphy-2.0.2/src/struphy/pic/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/pic/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    69110 2023-07-18 05:56:26.000000 struphy-2.0.2/src/struphy/pic/accum_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)    81765 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/pic/accum_kernels_gc.py
+-rw-rw-rw-   0 root         (0) root         (0)    34509 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/pic/base.py
+-rw-rw-rw-   0 root         (0) root         (0)    20474 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/pic/filler_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)   247659 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/pic/mat_vec_filler.py
+-rw-rw-rw-   0 root         (0) root         (0)     9300 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/pic/particles.py
+-rw-rw-rw-   0 root         (0) root         (0)    18320 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/pic/particles_to_grid.py
+-rw-rw-rw-   0 root         (0) root         (0)    17022 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/pic/pusher.py
+-rw-rw-rw-   0 root         (0) root         (0)   109566 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/pic/pusher_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)   106629 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/pic/pusher_kernels_gc.py
+-rw-rw-rw-   0 root         (0) root         (0)    21388 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/pic/pusher_utilities.py
+-rw-rw-rw-   0 root         (0) root         (0)     8498 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/pic/sampling.py
+-rw-rw-rw-   0 root         (0) root         (0)    14808 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/pic/sobol_seq.py
+-rw-rw-rw-   0 root         (0) root         (0)     5678 2023-07-20 09:51:16.000000 struphy-2.0.2/src/struphy/pic/utilities.py
+-rw-rw-rw-   0 root         (0) root         (0)   105934 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/pic/utilities_kernels.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.936282 struphy-2.0.2/src/struphy/polar/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/polar/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    16623 2023-07-20 09:51:16.000000 struphy-2.0.2/src/struphy/polar/basic.py
+-rw-rw-rw-   0 root         (0) root         (0)    52606 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/polar/extraction_operators.py
+-rw-rw-rw-   0 root         (0) root         (0)    32352 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/polar/linear_operators.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.936282 struphy-2.0.2/src/struphy/post_processing/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/post_processing/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     6362 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/post_processing/cprofile_analyser.py
+-rw-rw-rw-   0 root         (0) root         (0)    18853 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/post_processing/post_processing_tools.py
+-rw-rw-rw-   0 root         (0) root         (0)     6489 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/post_processing/pproc_struphy.py
+-rw-rw-rw-   0 root         (0) root         (0)     5300 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/post_processing/profile_struphy.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.940282 struphy-2.0.2/src/struphy/propagators/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/propagators/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     4466 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/propagators/base.py
+-rw-rw-rw-   0 root         (0) root         (0)    67319 2023-07-20 09:51:16.000000 struphy-2.0.2/src/struphy/propagators/propagators_coupling.py
+-rw-rw-rw-   0 root         (0) root         (0)    74283 2023-07-20 09:51:16.000000 struphy-2.0.2/src/struphy/propagators/propagators_fields.py
+-rw-rw-rw-   0 root         (0) root         (0)    44185 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/propagators/propagators_markers.py
+-rw-rw-rw-   0 root         (0) root         (0)   615492 2023-07-20 09:51:16.000000 struphy-2.0.2/src/struphy/psydac-0.1.2-py3-none-any.whl
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.940282 struphy-2.0.2/src/struphy/psydac_api/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/psydac_api/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     1839 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/psydac_api/banded_to_stencil_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)    19977 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/psydac_api/basis_projection_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)    43878 2023-07-20 09:51:16.000000 struphy-2.0.2/src/struphy/psydac_api/basis_projection_ops.py
+-rw-rw-rw-   0 root         (0) root         (0)    28921 2023-07-20 09:51:16.000000 struphy-2.0.2/src/struphy/psydac_api/fields.py
+-rw-rw-rw-   0 root         (0) root         (0)    22918 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/psydac_api/linear_operators.py
+-rw-rw-rw-   0 root         (0) root         (0)    51476 2023-07-20 09:51:16.000000 struphy-2.0.2/src/struphy/psydac_api/mass.py
+-rw-rw-rw-   0 root         (0) root         (0)    15604 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/psydac_api/mass_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)    15832 2023-07-20 09:51:16.000000 struphy-2.0.2/src/struphy/psydac_api/preconditioner.py
+-rw-rw-rw-   0 root         (0) root         (0)    19799 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/psydac_api/projectors.py
+-rw-rw-rw-   0 root         (0) root         (0)    34973 2023-07-20 09:51:16.000000 struphy-2.0.2/src/struphy/psydac_api/psydac_derham.py
+-rw-rw-rw-   0 root         (0) root         (0)     5396 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/psydac_api/quadrature_evaluation_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)    14995 2023-07-20 09:51:16.000000 struphy-2.0.2/src/struphy/psydac_api/utilities.py
+-rw-rw-rw-   0 root         (0) root         (0)     5381 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/psydac_api/utilities_kernels.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.944282 struphy-2.0.2/src/struphy/tests/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/tests/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.948282 struphy-2.0.2/src/struphy/tests/tests_mpi/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    30189 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_accumulation.py
+-rw-rw-rw-   0 root         (0) root         (0)    24178 2023-07-20 09:51:16.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_basis_operators.py
+-rw-rw-rw-   0 root         (0) root         (0)     3624 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_draw_parallel.py
+-rw-rw-rw-   0 root         (0) root         (0)    16167 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_eval_spline_mpi.py
+-rw-rw-rw-   0 root         (0) root         (0)     2843 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_implicit_diffusion.py
+-rw-rw-rw-   0 root         (0) root         (0)     6751 2023-07-20 09:51:16.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_iterative_solvers.py
+-rw-rw-rw-   0 root         (0) root         (0)    37746 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_mass_matrices.py
+-rw-rw-rw-   0 root         (0) root         (0)    16313 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_mat_vec_filler.py
+-rw-rw-rw-   0 root         (0) root         (0)     1989 2023-07-18 11:52:24.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_noise_init.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.948282 struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    19425 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/accumulation.py
+-rw-rw-rw-   0 root         (0) root         (0)    51404 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/accumulation_kernels_3d.py
+-rw-rw-rw-   0 root         (0) root         (0)    22396 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/mappings_3d.py
+-rw-rw-rw-   0 root         (0) root         (0)    14116 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/mappings_3d_fast.py
+-rw-rw-rw-   0 root         (0) root         (0)    11123 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/pusher.py
+-rw-rw-rw-   0 root         (0) root         (0)    64611 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/pusher_pos.py
+-rw-rw-rw-   0 root         (0) root         (0)    17908 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/pusher_vel_2d.py
+-rw-rw-rw-   0 root         (0) root         (0)    38069 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/pusher_vel_3d.py
+-rw-rw-rw-   0 root         (0) root         (0)    14178 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/spline_evaluation_2d.py
+-rw-rw-rw-   0 root         (0) root         (0)    33254 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/spline_evaluation_3d.py
+-rw-rw-rw-   0 root         (0) root         (0)     3201 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_poisson.py
+-rw-rw-rw-   0 root         (0) root         (0)    13453 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_polar.py
+-rw-rw-rw-   0 root         (0) root         (0)    14414 2023-07-20 09:51:16.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_psydac_basics.py
+-rw-rw-rw-   0 root         (0) root         (0)     8477 2023-07-20 09:51:16.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_psydac_derham.py
+-rw-rw-rw-   0 root         (0) root         (0)    31868 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_pushers.py
+-rw-rw-rw-   0 root         (0) root         (0)    11285 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_stencil_dot_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)    11191 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_mpi/test_stencil_transpose_kernels.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.956282 struphy-2.0.2/src/struphy/tests/tests_serial/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2023-07-24 06:56:12.000000 struphy-2.0.2/src/struphy/tests/tests_serial/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     7092 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/test_bsplines_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)    38312 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/test_domain.py
+-rw-rw-rw-   0 root         (0) root         (0)     6770 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/test_gvec_equil.py
+-rw-rw-rw-   0 root         (0) root         (0)    45719 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/test_legacy_mhd_projectors.py
+-rw-rw-rw-   0 root         (0) root         (0)     4901 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/test_legacy_polar_splines.py
+-rw-rw-rw-   0 root         (0) root         (0)    34306 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/test_mhd_equils.py
+-rw-rw-rw-   0 root         (0) root         (0)     6283 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/test_numerical_MHD_equil.py
+-rw-rw-rw-   0 root         (0) root         (0)    28774 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/test_projectors_global.py
+-rw-rw-rw-   0 root         (0) root         (0)    20676 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/test_psydac_basis_operators.py
+-rw-rw-rw-   0 root         (0) root         (0)     6177 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/test_psydac_linear_operators.py
+-rw-rw-rw-   0 root         (0) root         (0)     2266 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/test_psydac_mapping.py
+-rw-rw-rw-   0 root         (0) root         (0)     2924 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/test_spline_space_1d.py
+-rw-rw-rw-   0 root         (0) root         (0)    23196 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/xx_psydac_lin_ops.py
+-rw-rw-rw-   0 root         (0) root         (0)    23652 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_GVEC.py
+-rw-rw-rw-   0 root         (0) root         (0)     1566 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_codes.py
+-rw-rw-rw-   0 root         (0) root         (0)     1702 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_cprofiler.py
+-rw-rw-rw-   0 root         (0) root         (0)    19344 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_divB.py
+-rw-rw-rw-   0 root         (0) root         (0)    10695 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_filler_kernel.py
+-rw-rw-rw-   0 root         (0) root         (0)    12684 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_mappings.py
+-rw-rw-rw-   0 root         (0) root         (0)    16292 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_mat_vec_filler.py
+-rw-rw-rw-   0 root         (0) root         (0)     2435 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_mhd_equil.py
+-rw-rw-rw-   0 root         (0) root         (0)    15899 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_paraview.py
+-rw-rw-rw-   0 root         (0) root         (0)   277942 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_polar_splines_3D.py
+-rw-rw-rw-   0 root         (0) root         (0)     3530 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_preconditioner.py
+-rw-rw-rw-   0 root         (0) root         (0)    32928 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_psydac_lin_ops_loop.py
+-rw-rw-rw-   0 root         (0) root         (0)    15913 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_spline_evaluation.py
+-rw-rw-rw-   0 root         (0) root         (0)     8515 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_spline_interpolation.py
+-rw-rw-rw-   0 root         (0) root         (0)    10294 2023-07-17 10:53:31.000000 struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_template_gvec.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-07-24 06:56:24.872282 struphy-2.0.2/src/struphy.egg-info/
+-rw-r--r--   0 root         (0) root         (0)     7657 2023-07-24 06:56:24.000000 struphy-2.0.2/src/struphy.egg-info/PKG-INFO
+-rw-r--r--   0 root         (0) root         (0)    15738 2023-07-24 06:56:24.000000 struphy-2.0.2/src/struphy.egg-info/SOURCES.txt
+-rw-r--r--   0 root         (0) root         (0)        1 2023-07-24 06:56:24.000000 struphy-2.0.2/src/struphy.egg-info/dependency_links.txt
+-rw-r--r--   0 root         (0) root         (0)       57 2023-07-24 06:56:24.000000 struphy-2.0.2/src/struphy.egg-info/entry_points.txt
+-rw-r--r--   0 root         (0) root         (0)      195 2023-07-24 06:56:24.000000 struphy-2.0.2/src/struphy.egg-info/requires.txt
+-rw-r--r--   0 root         (0) root         (0)        8 2023-07-24 06:56:24.000000 struphy-2.0.2/src/struphy.egg-info/top_level.txt
```

### Comparing `struphy-2.0.1/LICENSE` & `struphy-2.0.2/LICENSE`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,10 @@
-Copyright 2019 (c) Struphy dev team | Max Planck Institute for Plasma Physics
+MIT license
+
+Copyright (c) 2019-2023, Struphy developers, Max Planck Institute for Plasma Physics
 
 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and 
 associated documentation files (the "Software"), to deal in the Software without restriction, 
 including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, 
 and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, 
 subject to the following conditions:
```

### Comparing `struphy-2.0.1/PKG-INFO` & `struphy-2.0.2/PKG-INFO`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,16 @@
 Metadata-Version: 2.1
 Name: struphy
-Version: 2.0.1
+Version: 2.0.2
 Summary: Multi-model plasma physics package
 Author: Max Planck Institute for Plasma Physics
-Author-email: stefan.possanner@ipp.mpg.de, florian.holderied@ipp.mpg.de
-License: Copyright 2019 (c) Struphy dev team | Max Planck Institute for Plasma Physics
+Author-email: stefan.possanner@ipp.mpg.de, eric.sonnendruecker@ipp.mpg.de
+License: MIT license
+        
+        Copyright (c) 2019-2023, Struphy developers, Max Planck Institute for Plasma Physics
         
         Permission is hereby granted, free of charge, to any person obtaining a copy of this software and 
         associated documentation files (the "Software"), to deal in the Software without restriction, 
         including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, 
         and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, 
         subject to the following conditions:
         
@@ -31,15 +33,15 @@
 Project-URL: homepage, https://struphy.pages.mpcdf.de/struphy/
 Project-URL: documentation, https://struphy.pages.mpcdf.de/struphy/
 Project-URL: repository, https://gitlab.mpcdf.mpg.de/struphy/struphy
 Project-URL: changelog, https://gitlab.mpcdf.mpg.de/struphy/struphy/-/blob/devel/CHANGELOG.md
 Project-URL: Bug Tracker, https://gitlab.mpcdf.mpg.de/struphy/struphy/-/issues
 Keywords: plasma physics, fusion, numerical modeling, partial differential equations, energetic particles
 Classifier: Programming Language :: Python :: 3
-Requires-Python: <3.11,>=3.7
+Requires-Python: <3.12,>=3.7
 Description-Content-Type: text/markdown
 License-File: LICENSE
 
 # STRUPHY - STRUcture-Preserving HYbrid codes
 
 A Python package for energetic particles in plasma.
 
@@ -105,10 +107,10 @@
 In addition, we ask you to cite the following reference in scientific publications which contain results obtained with
 this software and developments:
 
 F. Holderied, S. Possanner, X. Wang, "MHD-kinetic hybrid code based on structure-preserving finite elements with particles-in-cell", J. Comp. Phys. 433 (2021) 110143
 
 ## Contact
 
-* Stefan Possanner [spossann@ipp.mpg.de](spossann@ipp.mpg.de)
-* Eric Sonnendrcker [spossann@ipp.mpg.de](eric.sonnendruecker@ipp.mpg.de)
+* Stefan Possanner [stefan.possanner@ipp.mpg.de](spossann@ipp.mpg.de)
+* Eric Sonnendrcker [eric.sonnendruecker@ipp.mpg.de](eric.sonnendruecker@ipp.mpg.de)
 * Xin Wang [xin.wang@ipp.mpg.de](xin.wang@ipp.mpg.de)
```

### Comparing `struphy-2.0.1/README.md` & `struphy-2.0.2/README.md`

 * *Files 2% similar despite different names*

```diff
@@ -64,10 +64,10 @@
 In addition, we ask you to cite the following reference in scientific publications which contain results obtained with
 this software and developments:
 
 F. Holderied, S. Possanner, X. Wang, "MHD-kinetic hybrid code based on structure-preserving finite elements with particles-in-cell", J. Comp. Phys. 433 (2021) 110143
 
 ## Contact
 
-* Stefan Possanner [spossann@ipp.mpg.de](spossann@ipp.mpg.de)
-* Eric Sonnendrcker [spossann@ipp.mpg.de](eric.sonnendruecker@ipp.mpg.de)
+* Stefan Possanner [stefan.possanner@ipp.mpg.de](spossann@ipp.mpg.de)
+* Eric Sonnendrcker [eric.sonnendruecker@ipp.mpg.de](eric.sonnendruecker@ipp.mpg.de)
 * Xin Wang [xin.wang@ipp.mpg.de](xin.wang@ipp.mpg.de)
```

### Comparing `struphy-2.0.1/pyproject.toml` & `struphy-2.0.2/pyproject.toml`

 * *Files 10% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 [build-system]
 requires = ["setuptools>=61.0"]
 build-backend = "setuptools.build_meta"
 
 [project]
 name = "struphy"
-version = "2.0.1"
+version = "2.0.2"
 readme = "README.md"
-requires-python = ">=3.7, <3.11"
+requires-python = ">=3.7, <3.12"
 license = {file = "LICENSE"}
 authors = [
   { name = "Max Planck Institute for Plasma Physics"},
   { email = "stefan.possanner@ipp.mpg.de"},
-  { email = "florian.holderied@ipp.mpg.de"}
+  { email = "eric.sonnendruecker@ipp.mpg.de"}
 ]
 description = "Multi-model plasma physics package"
 keywords = ["plasma physics, fusion, numerical modeling, partial differential equations, energetic particles"]
 classifiers = [
     "Programming Language :: Python :: 3",
     ]
 dependencies = [
@@ -68,10 +68,12 @@
 
 'struphy.io.inp' = ['parameters.yml',
                     'tests/*.yml',
                     'examples/*.yml',
                     ]
                     
 struphy = ['compile_struphy.mk',
-           'psydac-0.1-py3-none-any.whl',
-           'io_path.txt',
+           'psydac-0.1.2-py3-none-any.whl',
+           'i_path.txt',
+           'o_path.txt',
+           'p_path.txt',
            ]
```

### Comparing `struphy-2.0.1/src/struphy/b_splines/Bspline.py` & `struphy-2.0.2/src/struphy/b_splines/Bspline.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/b_splines/bspline_evaluation_1d.py` & `struphy-2.0.2/src/struphy/b_splines/bspline_evaluation_1d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/b_splines/bspline_evaluation_2d.py` & `struphy-2.0.2/src/struphy/b_splines/bspline_evaluation_2d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/b_splines/bspline_evaluation_3d.py` & `struphy-2.0.2/src/struphy/b_splines/bspline_evaluation_3d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/b_splines/bsplines.py` & `struphy-2.0.2/src/struphy/b_splines/bsplines.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/b_splines/bsplines_kernels.py` & `struphy-2.0.2/src/struphy/b_splines/bsplines_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/b_splines/bsplines_kernels_particles.py` & `struphy-2.0.2/src/struphy/b_splines/bsplines_kernels_particles.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/compile_struphy.mk` & `struphy-2.0.2/src/struphy/compile_struphy.mk`

 * *Files 4% similar despite different names*

```diff
@@ -8,15 +8,15 @@
 psydac_path := $(shell $(PYTHON) -c "import psydac as _; print(_.__path__[0])")
 struphy_path := $(shell $(PYTHON) -c "import struphy as _; print(_.__path__[0])")
 
 # Arguments to this script are: 
 # flags
 # flags_openmp_pic
 # flags_openmp_mhd
-FLAGS            := --libdir $(LIBDIR) $(flags) --conda-warnings off
+FLAGS            := --libdir $(LIBDIR) $(flags) 
 FLAGS_openmp_pic := $(flags_openmp_pic)
 FLAGS_openmp_mhd := $(flags_openmp_mhd)
 
 #--------------------------------------
 # SOURCE FILES PSYDAC
 #--------------------------------------
 
@@ -60,27 +60,29 @@
 
 # PIC
 UTL	 := $(struphy_path)/pic/utilities_kernels
 
 FK   := $(struphy_path)/pic/filler_kernels
 MVF  := $(struphy_path)/pic/mat_vec_filler
 ACC  := $(struphy_path)/pic/accum_kernels
+ACC_GC  := $(struphy_path)/pic/accum_kernels_gc
 
 PUTL := $(struphy_path)/pic/pusher_utilities
 PUSH := $(struphy_path)/pic/pusher_kernels
+PUSH_GC := $(struphy_path)/pic/pusher_kernels_gc
 PS   := $(struphy_path)/pic/sampling
 
 # Eigenvalue solver
 KM2  := $(struphy_path)/eigenvalue_solvers/kernels_2d
 KM3  := $(struphy_path)/eigenvalue_solvers/kernels_3d
 
 KPG  := $(struphy_path)/eigenvalue_solvers/kernels_projectors_global
 KPGM := $(struphy_path)/eigenvalue_solvers/kernels_projectors_global_mhd
 
-SOURCES := $(LAC).py $(LAMV).py $(LATR).py $(BK).py $(BKP).py $(BEV1).py $(BEV2).py $(BEV3).py $(MAFA).py $(MEVA).py $(TR3).py $(MK).py $(MOMK).py $(F0K).py $(BEVA).py $(PLP).py $(PLM).py $(BTS).py $(UTL).py $(FK).py $(MVF).py $(ACC).py $(PUTL).py $(PUSH).py $(PS).py $(KM2).py $(KM3).py $(KPG).py $(KPGM).py $(PSY1).py $(PSY2).py $(PSY3).py $(PSY4).py
+SOURCES := $(LAC).py $(LAMV).py $(LATR).py $(BK).py $(BKP).py $(BEV1).py $(BEV2).py $(BEV3).py $(MAFA).py $(MEVA).py $(TR3).py $(MK).py $(MOMK).py $(F0K).py $(BEVA).py $(PLP).py $(PLM).py $(BTS).py $(UTL).py $(FK).py $(MVF).py $(ACC).py $(ACC_GC).py $(PUTL).py $(PUSH).py $(PUSH_GC).py $(PS).py $(KM2).py $(KM3).py $(KPG).py $(KPGM).py $(PSY1).py $(PSY2).py $(PSY3).py $(PSY4).py
 
 OUTPUTS := $(SOURCES:.py=$(SO_EXT))
 
 
 #--------------------------------------
 # PYCCELIZE
 #--------------------------------------
@@ -167,20 +169,26 @@
 
 $(MVF)$(SO_EXT) : $(MVF).py $(FK)$(SO_EXT)
 	pyccel $< $(FLAGS)
 
 $(ACC)$(SO_EXT) : $(ACC).py $(MEVA)$(SO_EXT) $(BK)$(SO_EXT) $(BEV3)$(SO_EXT) $(BEVA)$(SO_EXT) $(MVF)$(SO_EXT) $(LAC)$(SO_EXT)  
 	pyccel $< $(FLAGS)
 
+$(ACC_GC)$(SO_EXT) : $(ACC_GC).py $(MEVA)$(SO_EXT) $(BK)$(SO_EXT) $(BEV3)$(SO_EXT) $(BEVA)$(SO_EXT) $(MVF)$(SO_EXT) $(LAC)$(SO_EXT)  
+	pyccel $< $(FLAGS)
+
 $(PUTL)$(SO_EXT) : $(PUTL).py $(LAC)$(SO_EXT)
 	pyccel $(FLAGS_openmp_pic) $< $(FLAGS)
 
 $(PUSH)$(SO_EXT) : $(PUSH).py $(PUTL).py $(LAC)$(SO_EXT) $(MEVA)$(SO_EXT) $(BK)$(SO_EXT) $(BKP)$(SO_EXT) $(BEV3)$(SO_EXT)
 	pyccel $(FLAGS_openmp_pic) $< $(FLAGS)
 
+$(PUSH_GC)$(SO_EXT) : $(PUSH_GC).py $(PUTL).py $(LAC)$(SO_EXT) $(MEVA)$(SO_EXT) $(BK)$(SO_EXT) $(BKP)$(SO_EXT) $(BEV3)$(SO_EXT)
+	pyccel $(FLAGS_openmp_pic) $< $(FLAGS)
+
 $(PS)$(SO_EXT) : $(PS).py $(LAC)$(SO_EXT) $(BK)$(SO_EXT) $(BEV2)$(SO_EXT) $(BEV3)$(SO_EXT) $(MEVA)$(SO_EXT)
 	pyccel $< $(FLAGS)
 
 $(KM2)$(SO_EXT) : $(KM2).py
 	pyccel $(FLAGS_openmp_mhd) $< $(FLAGS)
 
 $(KM3)$(SO_EXT) : $(KM3).py
```

### Comparing `struphy-2.0.1/src/struphy/console/compile.py` & `struphy-2.0.2/src/struphy/console/compile.py`

 * *Files 14% similar despite different names*

```diff
@@ -13,14 +13,15 @@
     verbose : bool, optional
         Call pyccel in verbose mode.
     """
 
     import subprocess
     import struphy
     import os
+    import pyccel
 
     libpath = struphy.__path__[0]
 
     if delete:
 
         # (change dir not to be in source path)
         print('\nDeleting .f90 and .so files ...')
@@ -35,34 +36,42 @@
 
         # struphy and psydac (change dir not to be in source path)
         flag_omp_pic = '--openmp'
         flag_omp_mhd = ''
         if no_openmp:
             flag_omp_pic = ''
 
-        flag_verb = ''
+        # pyccel flags
+        flags = ''
+        
+        _li = pyccel.__version__.split('.')
+        _num = int(_li[0])*100 + int(_li[1])*10 + int(_li[2])
+        if _num >= 180:
+            flags += '--conda-warnings off'
+            
         if verbose:
-            flag_verb = '--verbose'
+            flags += ' --verbose'
 
+        # install psydac from wheel if not there
         try:
             import psydac.api
         except:
             print('\nInstalling Psydac ...')
             subprocess.run(['pip',
                             'install',
                             os.path.join(
-                                libpath, 'psydac-0.1-py3-none-any.whl'),
+                                libpath, 'psydac-0.1.2-py3-none-any.whl'),
                             ], check=True)
             print('Done.')
 
         # gvec_to_python (change dir not to be in source path)
         subprocess.run(['compile-gvec-tp'], check=True, cwd=libpath)
 
         print('\nCompiling Struphy and Psydac kernels ...')
         subprocess.run(['make',
                         '-f',
                         'compile_struphy.mk',
-                        'flags=' + flag_verb,
+                        'flags=' + flags,
                         'flags_openmp_pic=' + flag_omp_pic,
                         'flags_openmp_mhd=' + flag_omp_mhd,
                         ], check=True, cwd=libpath)
         print('Done.')
```

### Comparing `struphy-2.0.1/src/struphy/console/example.py` & `struphy-2.0.2/src/struphy/console/example.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/console/main.py` & `struphy-2.0.2/src/struphy/console/main.py`

 * *Files 10% similar despite different names*

```diff
@@ -37,35 +37,61 @@
     version_message += 'MIT license\n'
 
     # path message
     import struphy
     libpath = struphy.__path__[0]
 
     try:
-        with open(os.path.join(libpath, 'io_path.txt'), 'r') as f:
-            io_path = f.readlines()[0]
+        with open(os.path.join(libpath, 'i_path.txt'), 'r') as f:
+            i_path = f.readlines()[0]
     except FileNotFoundError:
-        # setting default io path
-        with open(os.path.join(libpath, 'io_path.txt'), 'w') as f:
-            f.write(libpath)
-            io_path = libpath
+        # setting default input path
+        with open(os.path.join(libpath, 'i_path.txt'), 'w') as f:
+            i_path = os.path.join(libpath, 'io/inp')
+            f.write(i_path)
+
+    try:
+        with open(os.path.join(libpath, 'o_path.txt'), 'r') as f:
+            o_path = f.readlines()[0]
+    except FileNotFoundError:
+        # setting default output path
+        with open(os.path.join(libpath, 'o_path.txt'), 'w') as f:
+            o_path = os.path.join(libpath, 'io/out')
+            f.write(o_path)
+
+    try:
+        with open(os.path.join(libpath, 'b_path.txt'), 'r') as f:
+            b_path = f.readlines()[0]
+    except FileNotFoundError:
+        # setting default output path
+        with open(os.path.join(libpath, 'b_path.txt'), 'w') as f:
+            b_path = os.path.join(libpath, 'io/batch')
+            f.write(b_path)
 
     path_message = f'Struphy installation path: {libpath}\n'
-    path_message += f'default input:             {io_path}/io/inp\n'
-    path_message += f'default output:            {io_path}/io/out\n'
-    path_message += f'template batch scripts:    {io_path}/io/batch'
+    path_message += f'default input:             {i_path}\n'
+    path_message += f'default output:            {o_path}\n'
+    path_message += f'template batch scripts:    {b_path}'
 
     parser.add_argument('-v', '--version', action='version',
                         version=version_message)
     parser.add_argument('-p', '--path', action='version',
                         version=path_message, help='default installations and i/o paths')
-    parser.add_argument('--set-io',
+    parser.add_argument('--set-i',
+                        type=str,
+                        metavar='PATH',
+                        help='make PATH the new default Input folder (type "." to use current working directory)',)
+    parser.add_argument('--set-o',
+                        type=str,
+                        metavar='PATH',
+                        help='make PATH the new default Output folder (type "." to use current working directory)',)
+    parser.add_argument('--set-b',
                         type=str,
                         metavar='PATH',
-                        help='make PATH the new default I/O folder and copy templates there (type "." to use current working directory)',)
+                        help='make PATH the new default Batch folder (type "." to use current working directory)',)
 
     # create sub-commands and save name of sub-command into variable "command"
     subparsers = parser.add_subparsers(title='available commands',
                                        metavar='COMMAND',
                                        dest='command')
 
     # 1. "compile" sub-command
@@ -261,14 +287,20 @@
 
     parser_profile.add_argument('--print-callers',
                                 type=str,
                                 metavar='STR',
                                 help='string STR that identifies functions for which to print callers (default=None)',
                                 default=None)
 
+    parser_profile.add_argument('--savefig-dir',
+                                type=str,
+                                metavar='DIR',
+                                help='output directory relative to current Out path (default=None)',
+                                default=None,)
+
     # 5. "pproc" sub-command
     parser_pproc = subparsers.add_parser(
         'pproc',
         help='post process data of a finished Struphy run',
         description='Post-process data of a finished Struphy run to prepare for diagnostics.')
 
     parser_pproc.add_argument('-d', '--dirr',
@@ -349,52 +381,91 @@
                              help='run code tests',
                              action='store_true')
 
     # parse argument
     args = parser.parse_args()
 
     # if no arguments are passed, print help and exit
-    if args.command is None and args.set_io is None:
+    if args.command is None and args.set_i is None and args.set_o is None and args.set_b is None:
         parser.print_help()
         exit()
 
-    # set default io path
-    if args.set_io:
-        if args.set_io == '.':
-            io_path = os.getcwd()
+    # set default in path
+    if args.set_i:
+        if args.set_i == '.':
+            i_path = os.getcwd()
+
+        elif args.set_i == 'd':
+            i_path = os.path.join(libpath, 'io/inp')
+
+        else:
+            i_path = args.set_i
+            try:
+                os.mkdir(i_path)
+            except:
+                pass
+
+        i_path = os.path.abspath(i_path)
+
+        with open(os.path.join(libpath, 'i_path.txt'), 'w') as f:
+            f.write(i_path)
+    
+        print(f'New default Input path has been set:')
+        import subprocess
+        subprocess.run(['struphy', '-p'])
+
+        exit()
+
+    # set default out path
+    if args.set_o:
+        if args.set_o == '.':
+            o_path = os.getcwd()
+
+        elif args.set_o == 'd':
+            o_path = os.path.join(libpath, 'io/out')
+
         else:
-            io_path = args.set_io
+            o_path = args.set_o
             try:
-                os.mkdir(io_path)
+                os.mkdir(o_path)
             except:
                 pass
 
-        io_path = os.path.abspath(io_path)
+        o_path = os.path.abspath(o_path)
+
+        with open(os.path.join(libpath, 'o_path.txt'), 'w') as f:
+            f.write(o_path)
+    
+        print(f'New default Out path has been set:')
+        import subprocess
+        subprocess.run(['struphy', '-p'])
+
+        exit()
+
+    # set default out path
+    if args.set_b:
+        if args.set_b == '.':
+            b_path = os.getcwd()
+
+        elif args.set_b == 'd':
+            b_path = os.path.join(libpath, 'io/batch')
+
+        else:
+            b_path = args.set_b
+            try:
+                os.mkdir(b_path)
+            except:
+                pass
 
-        with open(os.path.join(libpath, 'io_path.txt'), 'w') as f:
-            f.write(io_path)
+        b_path = os.path.abspath(b_path)
 
-        io_dir = os.path.join(io_path, 'io/')
-        try:
-            os.mkdir(io_dir)
-            os.mkdir(os.path.join(io_dir, 'out/'))
-        except:
-            pass
-
-        from distutils.dir_util import copy_tree
-        copy_tree(os.path.join(libpath, 'io/inp/'),
-                  os.path.join(io_dir, 'inp/'))
-        copy_tree(os.path.join(libpath, 'io/batch/'),
-                  os.path.join(io_dir, 'batch/'))
-        
-        # remove tests and examples input folders
-        shutil.rmtree(os.path.join(io_dir, 'inp/tests/'))
-        shutil.rmtree(os.path.join(io_dir, 'inp/examples/'))
+        with open(os.path.join(libpath, 'b_path.txt'), 'w') as f:
+            f.write(b_path)
 
-        print(f'New default I/O path has been set:')
+        print(f'New default Batch path has been set:')
         import subprocess
         subprocess.run(['struphy', '-p'])
 
         exit()
 
     # handle argument dependencies in "sub-command"
     if args.command == 'test':
@@ -411,15 +482,17 @@
 
     # load sub-command function (see functions below)
     func = locals()['struphy_' + args.command]
 
     # transform parser Namespace object to dictionary and remove "command" key
     kwargs = vars(args)
     kwargs.pop('command')
-    kwargs.pop('set_io')
+    kwargs.pop('set_i')
+    kwargs.pop('set_o')
+    kwargs.pop('set_b')
 
     # start sub-command function with all parameters of that function
     func(**kwargs)
 
 
 class NoSubparsersMetavarFormatter(HelpFormatter):
     """
```

### Comparing `struphy-2.0.1/src/struphy/console/pproc.py` & `struphy-2.0.2/src/struphy/console/pproc.py`

 * *Files 10% similar despite different names*

```diff
@@ -18,20 +18,20 @@
     """
     import subprocess
     import os
     import struphy
 
     libpath = struphy.__path__[0]
     
-    with open(os.path.join(libpath, 'io_path.txt')) as f:
-        io_path = f.readlines()[0]
+    with open(os.path.join(libpath, 'o_path.txt')) as f:
+        o_path = f.readlines()[0]
 
     # create absolute path
     if dir_abs is None:
-        dir_abs = os.path.join(io_path, 'io/out', dirr)
+        dir_abs = os.path.join(o_path, dirr)
 
     # loop over output folders and call post-processing .py file
     subprocess.run(['python3',
                     'post_processing/pproc_struphy.py',
                     dir_abs,
                     '-s',
                     str(step),
```

### Comparing `struphy-2.0.1/src/struphy/console/profile.py` & `struphy-2.0.2/src/struphy/post_processing/profile_struphy.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,166 +1,165 @@
-def struphy_profile(dirs, replace, all, n_lines, print_callers):
+import sys
+import pickle
+import yaml
+import numpy as np
+from matplotlib import pyplot as plt
+
+from struphy.post_processing.cprofile_analyser import get_cprofile_data, replace_keys
+
+
+def main():
     """
-    Profile finished Struphy runs.
+    TODO
     """
-
-    import os
-    import pickle
-    import yaml
-    import numpy as np
-    from matplotlib import pyplot as plt
-    from struphy.post_processing.cprofile_analyser import get_cprofile_data, replace_keys
-    import struphy
-
-    libpath = struphy.__path__[0]
-    
-    with open(os.path.join(libpath, 'io_path.txt')) as f:
-        io_path = f.readlines()[0]
-
-    # absolute paths
-    abs_paths = []
-    for d in dirs:
-        abs_paths += [os.path.join(io_path, 'io/out/', d)]
-
-    # define the function filter
-    list_of_funcs = ['assemble_',
-                     'propagator',
-                     'accumulate',
-                     '_fill',
-                     'pusher',
-                     'update_ghost_regions',
-                     'solver',
-                     'class ',
-                     'stencil',
-                     'block',
-                     'integrate_in_time']
+    print(sys.argv)
 
     # check --all option
-    if all:
+    if sys.argv[1] == 'true':
         list_of_funcs = None
     else:
-        print('\nKeyword search enabled with the following filter:')
-        print('-------------------------------------------------')
+        list_of_funcs = ['assemble_',
+                         'propagator',
+                         'accumulate',
+                         '_fill',
+                         'pusher',
+                         'update_ghost_regions',
+                         'solver',
+                         'class ',
+                         'stencil',
+                         'block',
+                         'integrate_in_time']
+        print('\nKeyword search enabled with keywords:')
+        print('-------------------------------------')
         print(list_of_funcs)
-
+        
     print('\nLoad profiling data:')
     print('--------------------')
 
+    # replace propagator keys or not
+    do_replace_keys = sys.argv[2] == 'true'
+
+    # plot n_lines most time consuming calls in profiling analysis
+    n_lines = int(sys.argv[3])
+
     # load data
     sim_names = []
     dicts_pre = []
     nproc = []
     Nel = []
-    for path in abs_paths:
+    for path in sys.argv[4:]:
 
         print('')
-        get_cprofile_data(path, print_callers)
-
-        sim_names += [path.split('/')[-1]]
+        get_cprofile_data(path)
+        
+        sim_names += [path.split('/')[-2]]
 
-        with open(os.path.join(path, 'profile_dict.sav'), 'rb') as f:
+        with open(path + 'profile_dict.sav', 'rb') as f:
             dicts_pre += [pickle.load(f)]
 
-        with open(os.path.join(path, 'meta.txt'), 'r') as f:
+        with open(path + 'meta.txt', 'r') as f:
             lines = f.readlines()
 
         nproc += [int(lines[4].split()[-1])]
 
-        with open(os.path.join(path, 'parameters.yml'), 'r') as f:
+        with open(path + 'parameters.yml', 'r') as f:
             params = yaml.load(f, Loader=yaml.FullLoader)
 
         Nel += [params['grid']['Nel']]
 
     # Nicer key names for output:
     dicts = []
     for d in dicts_pre:
 
         tmp = {}
         for key, val in d.items():
-            # tmp[key] = float(val['cumtime'])
+            #tmp[key] = float(val['cumtime'])
             tmp[key] = val
 
-        if replace:
+        if do_replace_keys:
             tmp2 = replace_keys(tmp)
         else:
             tmp2 = tmp
 
         dicts += [tmp2]
 
     # loop over keys (should be same in each dict)
     d_saved = {}
-    print('simulation'.ljust(20) + '#proc'.ljust(7) + 'pos'.ljust(5) + 'function'.ljust(70) +
-          'ncalls'.ljust(15) + 'totime'.ljust(15) + 'percall'.ljust(15) + 'cumtime'.ljust(15))
+    print('simulation'.ljust(20) + '#proc'.ljust(7) + 'pos'.ljust(5) + 'function'.ljust(70) + 'ncalls'.ljust(15) + 'totime'.ljust(15) + 'percall'.ljust(15) + 'cumtime'.ljust(15))
     print('-'*154)
     for position, key in enumerate(dicts[0].keys()):
 
         if list_of_funcs == None:
 
             for dict, sim_name, n, dim in zip(dicts, sim_names, nproc, Nel):
 
-                string = f'{sim_name}'.ljust(
-                    20) + f'{n}'.ljust(7) + f'{position:2d}'.ljust(5) + str(key.ljust(70))
+                string = f'{sim_name}'.ljust(20) + f'{n}'.ljust(7) + f'{position:2d}'.ljust(5) + str(key.ljust(70))
                 for value in dict[key].values():
                     string += str(value).ljust(15)
                     # if len(str(value)) < 7:
                     #     string += '\t\t'
                     # else:
                     #     string += '\t'
                 print(string)
             print('')
 
             if position == 50:
-                break
+
+                exit()
 
         elif any(func in key for func in list_of_funcs) and 'dependencies_' not in key and '_dot' not in key:
 
             d_saved[key] = {'mpi_size': [], 'Nel': [], 'time': []}
 
             for dict, sim_name, n, dim in zip(dicts, sim_names, nproc, Nel):
 
-                string = f'{sim_name}'.ljust(
-                    20) + f'{n}'.ljust(7) + f'{position:2d}'.ljust(5) + str(key.ljust(70))
+                string = f'{sim_name}'.ljust(20) + f'{n}'.ljust(7) + f'{position:2d}'.ljust(5) + str(key.ljust(70))
                 for value in dict[key].values():
                     string += str(value).ljust(15)
-                    # string += '\t\t'
+                    #string += '\t\t'
                 print(string)
 
                 d_saved[key]['mpi_size'] += [n]
                 d_saved[key]['Nel'] += [dim]
-                d_saved[key]['time'] += [dict[key]['cumtime']]
+                d_saved[key]['time'] += [dict[key]]
             print('')
 
             if position >= 200:
-                break
+                exit()
 
     # save profiling date in each sim path
-    for path in abs_paths:
-        with open(os.path.join(path, 'comparison_dict.sav'), 'w+b') as f:
+    for path in sys.argv[4:]:
+        with open(path + 'comparison_dict.sav', 'w+b') as f:
             pickle.dump(d_saved, f)
 
     # plot results
     fig = plt.figure(figsize=(10, 10))
     for n, (key, val) in enumerate(d_saved.items()):
         if n < n_lines and '__init__' not in key and 'mass' not in key and 'set_backend' not in key:
+            #print(key, val)
 
             # strong scaling plot
-            if np.all([Nel == val['Nel'][0] for Nel in val['Nel']]):
+            if all([Nel == val['Nel'][0] for Nel in val['Nel']]):
                 plt.loglog(val['mpi_size'], val['time'], label=key)
                 plt.xlabel('mpi_size')
                 plt.ylabel('time [s]')
                 plt.title('Strong scaling for Nel=' +
                           str(val['Nel'][0]) + ' cells')
                 plt.legend(loc='lower left')
-                plt.loglog(val['mpi_size'], float(val['time'][0])/2 **
+                plt.loglog(val['mpi_size'], val['time'][0]/2 **
                            np.arange(len(val['time'])), 'k--', alpha=0.3)
             # weak scaling plot
             else:
                 plt.plot(val['mpi_size'], val['time'], label=key)
                 plt.xlabel('mpi_size')
                 plt.ylabel('time [s]')
                 plt.title('Weak scaling for cells/mpi_size=' +
                           str(np.prod(val['Nel'][0])/val['mpi_size'][0]) + '=const.')
                 plt.legend(loc='upper left')
-                # plt.loglog(val['mpi_size'], val['time'][0]*np.ones_like(val['time']), 'k--', alpha=0.3)
+                #plt.loglog(val['mpi_size'], val['time'][0]*np.ones_like(val['time']), 'k--', alpha=0.3)
                 plt.xscale('log')
 
     plt.show()
+
+
+if __name__ == '__main__':
+    main()
```

### Comparing `struphy-2.0.1/src/struphy/console/run.py` & `struphy-2.0.2/src/struphy/console/run.py`

 * *Files 3% similar despite different names*

```diff
@@ -56,27 +56,33 @@
     import shutil
     import os
     import glob
     import struphy
 
     libpath = struphy.__path__[0]
     
-    with open(os.path.join(libpath, 'io_path.txt')) as f:
-        io_path = f.readlines()[0]
+    with open(os.path.join(libpath, 'i_path.txt')) as f:
+        i_path = f.readlines()[0]
+
+    with open(os.path.join(libpath, 'o_path.txt')) as f:
+        o_path = f.readlines()[0]
+
+    with open(os.path.join(libpath, 'b_path.txt')) as f:
+        b_path = f.readlines()[0]
 
     # create absolute i/o paths
     if input_abs is None:
-        input_abs = os.path.join(io_path, 'io/inp/', input)
+        input_abs = os.path.join(i_path, input)
 
     if output_abs is None:
-        output_abs = os.path.join(io_path, 'io/out/', output)
+        output_abs = os.path.join(o_path, output)
 
     if batch_abs is None:
         if batch is not None:
-            batch_abs = os.path.join(io_path, 'io/batch/', batch)
+            batch_abs = os.path.join(b_path, batch)
 
     # take existing parameter file for restart
     if restart:
         input_abs = os.path.join(output_abs, 'parameters.yml')
 
     # run in normal or debug mode
     if batch_abs is None:
```

### Comparing `struphy-2.0.1/src/struphy/console/test.py` & `struphy-2.0.2/src/struphy/console/test.py`

 * *Files 8% similar despite different names*

```diff
@@ -95,33 +95,51 @@
 
         # test LinearMHDVlasovPC
         subprocess.run(['struphy', 'run', 'LinearMHDVlasovPC',
                         '-i', os.path.join(libpath, 'io/inp/tests/params_hybridmhdvlasovpc.yml'),
                         '-o', 'sim_test_8',
                         '--mpi', '2'], check=True)
 
+        # test VlasovMaxwell
+        subprocess.run(['struphy', 'run', 'VlasovMaxwell',
+                        '-i', os.path.join(libpath, 'io/inp/tests/params_vlasovmaxwell.yml'),
+                        '-o', 'sim_test_9',
+                        '--mpi', '2'], check=True)
+
+        subprocess.run(['struphy', 'pproc',
+                        '-d', 'sim_test_9'], check=True)
+
         # test LinearVlasovMaxwell
         subprocess.run(['struphy', 'run', 'LinearVlasovMaxwell',
                         '-i', os.path.join(libpath, 'io/inp/tests/params_linvlasovmaxwell.yml'),
-                        '-o', 'sim_test_9',
+                        '-o', 'sim_test_10',
                         '--mpi', '2'], check=True)
 
         subprocess.run(['struphy', 'pproc',
-                        '-d', 'sim_test_9'], check=True)
+                        '-d', 'sim_test_10'], check=True)
 
         # test DeltaFVlasovMaxwell
         subprocess.run(['struphy', 'run', 'DeltaFVlasovMaxwell',
                         '-i', os.path.join(libpath, 'io/inp/tests/params_deltafvlasovmaxwell.yml'),
-                        '-o', 'sim_test_10',
+                        '-o', 'sim_test_11',
                         '--mpi', '2'], check=True)
 
         subprocess.run(['struphy', 'pproc',
-                        '-d', 'sim_test_10'], check=True)
+                        '-d', 'sim_test_11'], check=True)
 
         # test ColdPlasma
         subprocess.run(['struphy', 'run', 'ColdPlasma',
                         '-i', os.path.join(libpath, 'io/inp/tests/params_coldplasma.yml'),
-                        '-o', 'sim_test_11',
+                        '-o', 'sim_test_12',
                         '--mpi', '2'], check=True)
 
         subprocess.run(['struphy', 'pproc',
-                        '-d', 'sim_test_11'], check=True)
+                        '-d', 'sim_test_12'], check=True)
+
+        # test ColdPlasmaVlasov
+        subprocess.run(['struphy', 'run', 'ColdPlasmaVlasov',
+                        '-i', os.path.join(libpath, 'io/inp/tests/params_coldplasmavlasov.yml'),
+                        '-o', 'sim_test_13',
+                        '--mpi', '2'], check=True)
+
+        subprocess.run(['struphy', 'pproc',
+                        '-d', 'sim_test_13'], check=True)
```

### Comparing `struphy-2.0.1/src/struphy/console/units.py` & `struphy-2.0.2/src/struphy/console/units.py`

 * *Files 8% similar despite different names*

```diff
@@ -17,20 +17,20 @@
     import os
     import yaml
     import struphy
     from struphy.models import fluid, kinetic, hybrid, toy
 
     libpath = struphy.__path__[0]
     
-    with open(os.path.join(libpath, 'io_path.txt')) as f:
-        io_path = f.readlines()[0]
+    with open(os.path.join(libpath, 'i_path.txt')) as f:
+        i_path = f.readlines()[0]
 
     # create absolute i/o paths
     if input_abs is None:
-        input_abs = os.path.join(io_path, 'io/inp/', input)
+        input_abs = os.path.join(i_path, input)
 
     # load simulation parameters
     with open(input_abs) as file:
         params = yaml.load(file, Loader=yaml.FullLoader)
 
     # load model class
     objs = [fluid, kinetic, hybrid, toy]
```

### Comparing `struphy-2.0.1/src/struphy/diagnostics/console_diagn.py` & `struphy-2.0.2/src/struphy/diagnostics/console_diagn.py`

 * *Files 1% similar despite different names*

```diff
@@ -45,18 +45,18 @@
     actions = args.actions
     foldername = args.f[0]
     time = args.t[0]
     do_log = args.log
     scalars_plot = args.scalars[0]
 
     libpath = struphy.__path__[0]
-    with open(os.path.join(libpath, 'io_path.txt')) as f:
-        io_path = f.readlines()[0]
+    with open(os.path.join(libpath, 'o_path.txt')) as f:
+        o_path = f.readlines()[0]
 
-    path = os.path.join(io_path, 'io/out', foldername)
+    path = os.path.join(o_path, foldername)
 
     grid_slices = {'e1': args.e1[0], 'e2': args.e2[0], 'e3': args.e3[0],
                    'v1': args.v1[0], 'v2': args.v2[0], 'v3': args.v3[0]}
 
     # Get fields
     file = h5py.File(os.path.join(path, 'data/', 'data_proc0.hdf5'), 'r')
     saved_scalars = file['scalar']
```

### Comparing `struphy-2.0.1/src/struphy/diagnostics/continuous_spectra.py` & `struphy-2.0.2/src/struphy/diagnostics/continuous_spectra.py`

 * *Files 2% similar despite different names*

```diff
@@ -206,20 +206,20 @@
                         default=3)
 
     args = parser.parse_args()
     
     import struphy
     libpath = struphy.__path__[0]
     
-    with open(os.path.join(libpath, 'io_path.txt')) as f:
-        io_path = f.readlines()[0]
+    with open(os.path.join(libpath, 'o_path.txt')) as f:
+        o_path = f.readlines()[0]
     
     # create absolute input folder path
     if args.input_abs is None:
-        input_path = os.path.join(io_path, 'io/out', args.input)
+        input_path = os.path.join(o_path, args.input)
     else:
         input_path = args.input_abs
         
     # absolute path of .npy spectrum and toroidal mode number
     spec_path = os.path.join(input_path, args.name)
     n_tor = int(os.path.split(spec_path)[-1][-6:-4])
```

### Comparing `struphy-2.0.1/src/struphy/diagnostics/diagn_tools.py` & `struphy-2.0.2/src/struphy/diagnostics/diagn_tools.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/diagnostics/paraview/mesh_creator.py` & `struphy-2.0.2/src/struphy/diagnostics/paraview/mesh_creator.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/diagnostics/paraview/vtk_writer.py` & `struphy-2.0.2/src/struphy/diagnostics/paraview/vtk_writer.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/dispersion_relations/analytic.py` & `struphy-2.0.2/src/struphy/dispersion_relations/analytic.py`

 * *Files 0% similar despite different names*

```diff
@@ -272,20 +272,20 @@
 class ColdPlasma1D(DispersionRelations1D):
     r'''Dispersion relation for cold plasma model for homogeneous background :math:`(n_0,\mathbf B_0)`
     and wave propagation along z-axis :math:`(\mathbf k = k \mathbf e_z)` in Struphy units
     (see ``ColdPlasma`` in :ref:`models`):
 
     .. math::
 
-        \left[ \left( \omega^2 - |k|^2 \right) \mathbb I + \mathbf k \otimes \mathbf k + i \frac{\omega \alpha}{\varepsilon_c} \sigma_c \right] \mathbf E = 0\,,
+        \left[ \left( \omega^2 - |k|^2 \right) \mathbb I + \mathbf k \otimes \mathbf k + i \frac{\alpha^2}{\varepsilon_c} \omega \sigma_c \right] \mathbf E = 0\,,
 
-    where :math:`\left( \omega^2 - |k|^2 \right) \mathbb I + \mathbf k \otimes \mathbf k + i \frac{\omega \alpha}{\varepsilon_c} \sigma_c = \epsilon`
+    where :math:`\left( \omega^2 - |k|^2 \right) \mathbb I + \mathbf k \otimes \mathbf k + i \frac{\alpha^2}{\varepsilon_c} \omega \sigma_c = \epsilon`
     is the dielectric tensor, :math:`\alpha` is the plasma frequency in units of the electron cyclotron frequency, 
     :math:`1/\varepsilon_c` is the electron cyclotron frequency in struphy units,
-    and :math:`\sigma_c = \left( \mathbb I - i Q / \varepsilon_c \omega \right)^{-1} i \alpha n_0 / \varepsilon_c \omega`,
+    and :math:`\sigma_c = \left( \mathbb I - i Q / \varepsilon_c \omega \right)^{-1} i n_0 / \varepsilon_c \omega`,
     with :math:`Q` being an operator which, if applied to vector :math:`\mathbf v`, returns :math:`\mathbf v \times \mathbf B_0`.
     '''
 
     def __init__(self, **params):
 
         # set default parameters
         params_default = {'B0x': 0.,
```

### Comparing `struphy-2.0.1/src/struphy/dispersion_relations/base.py` & `struphy-2.0.2/src/struphy/dispersion_relations/base.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/derivatives.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/derivatives.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/kernels_2d.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/kernels_2d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/kernels_3d.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/kernels_3d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/kernels_projectors_global.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/kernels_projectors_global.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/kernels_projectors_global_mhd.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/kernels_projectors_global_mhd.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/MHD_eigenvalues_cylinder_1D.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/MHD_eigenvalues_cylinder_1D.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/control_variate.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/control_variate.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/kernels_control_variate.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/kernels_control_variate.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fB_massless_control_variate.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fB_massless_control_variate.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fB_massless_kernels_control_variate.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fB_massless_kernels_control_variate.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_control_variate.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_control_variate.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_cv_kernel_2.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_cv_kernel_2.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_kernels_control_variate.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_kernels_control_variate.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_control_variate.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_control_variate.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_cvker.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_cvker.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_kernels_control_variate.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_kernels_control_variate.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/emw_operators.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/emw_operators.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/inner_products_1d.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/inner_products_1d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/inner_products_2d.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/inner_products_2d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/inner_products_3d.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/inner_products_3d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/l2_error_1d.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/l2_error_1d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/l2_error_2d.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/l2_error_2d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/l2_error_3d.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/l2_error_3d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/mass_matrices_3d_pre.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/mass_matrices_3d_pre.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_arrays.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_arrays.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_bb_kernel.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_bb_kernel.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_bv_kernel.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_bv_kernel.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_massless_linear_operators.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_massless_linear_operators.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_vv_kernel.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_vv_kernel.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/mhd_operators_MF.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/mhd_operators_MF.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/mhd_operators_MF_for_tests.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/mhd_operators_MF_for_tests.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/kernels_projectors_local.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/kernels_projectors_local.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/kernels_projectors_local_mhd.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/kernels_projectors_local_mhd.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/mhd_operators_3d_local.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/mhd_operators_3d_local.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/projectors_local.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/projectors_local.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_L2_projector_kernel.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_L2_projector_kernel.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_function_projectors_L2.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_function_projectors_L2.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_function_projectors_local.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_function_projectors_local.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_local_projector_kernel.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_local_projector_kernel.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/mass_matrices_1d.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/mass_matrices_1d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/mass_matrices_2d.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/mass_matrices_2d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/mass_matrices_3d.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/mass_matrices_3d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/mhd_axisymmetric_main.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/mhd_axisymmetric_main.py`

 * *Files 1% similar despite different names*

```diff
@@ -199,25 +199,28 @@
                         help='output directory, absolute path')    
 
     args = parser.parse_args()
     
     import struphy
     libpath = struphy.__path__[0]
     
-    with open(os.path.join(libpath, 'io_path.txt')) as f:
-        io_path = f.readlines()[0]
+    with open(os.path.join(libpath, 'i_path.txt')) as f:
+        i_path = f.readlines()[0]
+
+    with open(os.path.join(libpath, 'o_path.txt')) as f:
+        o_path = f.readlines()[0]
     
     # create absolute i/o paths
     if args.input_abs is None:
-        input_abs = os.path.join(io_path, 'io/inp', args.input)
+        input_abs = os.path.join(i_path, args.input)
     else:
         input_abs = args.input_abs
         
     if args.output_abs is None:
-        output_abs = os.path.join(io_path, 'io/out', args.output)
+        output_abs = os.path.join(o_path, args.output)
     else:
         output_abs = args.output_abs
         
     # create output folder (if it does not already exist)
     if not os.path.exists(output_abs):
         os.mkdir(output_abs)
         print('\nCreated folder ' + output_abs)
```

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/mhd_axisymmetric_pproc.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/mhd_axisymmetric_pproc.py`

 * *Files 5% similar despite different names*

```diff
@@ -32,20 +32,20 @@
                         help='upper range of squared eigenfrequency')
 
     args = parser.parse_args()
     
     import struphy
     libpath = struphy.__path__[0]
     
-    with open(os.path.join(libpath, 'io_path.txt')) as f:
-        io_path = f.readlines()[0]
+    with open(os.path.join(libpath, 'o_path.txt')) as f:
+        o_path = f.readlines()[0]
     
     # create absolute input folder path
     if args.input_abs is None:
-        input_path = os.path.join(io_path, 'io/out', args.input)
+        input_path = os.path.join(o_path, args.input)
     else:
         input_path = args.input_abs
         
     # load spectrum and restrict to range
     if args.n < 0:
         n_tor_str = str(args.n)
     else:
```

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/mhd_operators.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/mhd_operators.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/mhd_operators_core.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/mhd_operators_core.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/projectors_global.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/projectors_global.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/eigenvalue_solvers/spline_space.py` & `struphy-2.0.2/src/struphy/eigenvalue_solvers/spline_space.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/examples/TAE_tokamak.py` & `struphy-2.0.2/src/struphy/examples/TAE_tokamak.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,16 +10,16 @@
     
     import os
     import subprocess
     import struphy
 
     libpath = struphy.__path__[0]
     
-    with open(os.path.join(libpath, 'io_path.txt')) as f:
-        io_path = f.readlines()[0]
+    with open(os.path.join(libpath, 'o_path.txt')) as f:
+        o_path = f.readlines()[0]
 
     # name of simulation output folder
     out_name = 'sim_example_TAE_tokamak'
     
     # run MHD eigenvalue solver
     subprocess.run(['python3',
                     os.path.join(libpath, 'eigenvalue_solvers/mhd_axisymmetric_main.py'),
@@ -42,15 +42,15 @@
                     check=True, cwd=libpath)
     
     # run the model
     subprocess.run(['struphy', 
                     'run', 
                     'LinearMHD',
                     '--input-abs',
-                    os.path.join(io_path, 'io/out', out_name, 'parameters.yml'),
+                    os.path.join(o_path, out_name, 'parameters.yml'),
                     '-o',
                     out_name,
                     '--mpi',
                     str(n_procs)], check=True)
     
     # perform post-processing
     subprocess.run(['struphy',
@@ -78,19 +78,19 @@
     from struphy.dispersion_relations.analytic import MhdContinousSpectraCylinder
     from struphy.eigenvalue_solvers.spline_space import Spline_space_1d, Tensor_spline_space
     
     import struphy
 
     libpath = struphy.__path__[0]
     
-    with open(os.path.join(libpath, 'io_path.txt')) as f:
-        io_path = f.readlines()[0]
+    with open(os.path.join(libpath, 'o_path.txt')) as f:
+        o_path = f.readlines()[0]
     
     out_name = 'sim_example_TAE_tokamak'
-    out_path = os.path.join(io_path, 'io/out', out_name)
+    out_path = os.path.join(o_path, out_name)
 
     # load simulation parameters
     with open(os.path.join(out_path, 'parameters.yml')) as file:
         params = yaml.load(file, Loader=yaml.FullLoader)
 
     # load grid data
     Nel = params['grid']['Nel']
```

### Comparing `struphy-2.0.1/src/struphy/examples/_draw_parallel.py` & `struphy-2.0.2/src/struphy/examples/_draw_parallel.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/examples/_mhd_eigenvalues_cylinder.py` & `struphy-2.0.2/src/struphy/examples/_mhd_eigenvalues_cylinder.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/examples/_mhd_eigenvalues_slab.py` & `struphy-2.0.2/src/struphy/examples/_mhd_eigenvalues_slab.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/examples/_sendrecv.py` & `struphy-2.0.2/src/struphy/examples/_sendrecv.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/examples/gc_orbits_tokamak.py` & `struphy-2.0.2/src/struphy/examples/gc_orbits_tokamak.py`

 * *Files 2% similar despite different names*

```diff
@@ -47,20 +47,20 @@
     
     from struphy.models.setup import setup_domain_mhd
     from struphy.fields_background.mhd_equil.equils import EQDSKequilibrium
     
     import struphy
     libpath = struphy.__path__[0]
     
-    with open(os.path.join(libpath, 'io_path.txt')) as f:
-        io_path = f.readlines()[0]
+    with open(os.path.join(libpath, 'o_path.txt')) as f:
+        o_path = f.readlines()[0]
     
     # output path
     out_name = 'sim_example_gc_orbits_tokamak'
-    out_path = os.path.join(io_path, 'io/out', out_name)
+    out_path = os.path.join(o_path, out_name)
     
     # load simulation parameters
     with open(os.path.join(out_path, 'parameters.yml')) as file:
         params = yaml.load(file, Loader=yaml.FullLoader)
 
     # create domain and MHD equilibrium
     domain, mhd_equil = setup_domain_mhd(params)
```

### Comparing `struphy-2.0.1/src/struphy/examples/linearextendedmhd.py` & `struphy-2.0.2/src/struphy/examples/linearextendedmhd.py`

 * *Files 1% similar despite different names*

```diff
@@ -43,19 +43,19 @@
     
     from struphy.diagnostics.diagn_tools import fourier_1d
     
     import struphy
 
     libpath = struphy.__path__[0]
     
-    with open(os.path.join(libpath, 'io_path.txt')) as f:
-        io_path = f.readlines()[0]
+    with open(os.path.join(libpath, 'o_path.txt')) as f:
+        o_path = f.readlines()[0]
     
     out_name = 'sim_example_linearextendedmhd'
-    out_path = os.path.join(io_path, 'io/out', out_name)
+    out_path = os.path.join(o_path, out_name)
     
     # read in parameters for analytical dispersion relation
     with open(os.path.join(out_path, 'parameters.yml')) as file:
         params = yaml.load(file, Loader=yaml.FullLoader)
 
     
     # parameters for dispersion relation
```

### Comparing `struphy-2.0.1/src/struphy/examples/linearmhd.py` & `struphy-2.0.2/src/struphy/examples/linearmhd.py`

 * *Files 1% similar despite different names*

```diff
@@ -43,19 +43,19 @@
     
     from struphy.diagnostics.diagn_tools import fourier_1d
     
     import struphy
 
     libpath = struphy.__path__[0]
     
-    with open(os.path.join(libpath, 'io_path.txt')) as f:
-        io_path = f.readlines()[0]
+    with open(os.path.join(libpath, 'o_path.txt')) as f:
+        o_path = f.readlines()[0]
     
     out_name = 'sim_example_linearmhd'
-    out_path = os.path.join(io_path, 'io/out', out_name)
+    out_path = os.path.join(o_path, out_name)
     
     # read in parameters for analytical dispersion relation
     with open(os.path.join(out_path, 'parameters.yml')) as file:
         params = yaml.load(file, Loader=yaml.FullLoader)
 
     # parameters for dispersion relation
     B0x = params['mhd_equilibrium']['HomogenSlab']['B0x']
```

### Comparing `struphy-2.0.1/src/struphy/examples/linearmhdvlasov_cc.py` & `struphy-2.0.2/src/struphy/examples/linearmhdvlasov_cc.py`

 * *Files 0% similar despite different names*

```diff
@@ -44,19 +44,19 @@
     import numpy as np
     import matplotlib.pyplot as plt
     
     import struphy
 
     libpath = struphy.__path__[0]
     
-    with open(os.path.join(libpath, 'io_path.txt')) as f:
-        io_path = f.readlines()[0]
+    with open(os.path.join(libpath, 'o_path.txt')) as f:
+        o_path = f.readlines()[0]
     
     out_name = 'sim_example_linearmhdvlasovcc'
-    out_path = os.path.join(io_path, 'io/out', out_name)
+    out_path = os.path.join(o_path, out_name)
 
     # load data
     file = h5py.File(os.path.join(out_path, 'data/', 'data_proc0.hdf5'), 'r')
 
     t  = file['time/value'][:]
     eu = file['scalar/en_U'][:]
     eb = file['scalar/en_B'][:]
```

### Comparing `struphy-2.0.1/src/struphy/examples/linearmhdvlasov_pc.py` & `struphy-2.0.2/src/struphy/examples/linearmhdvlasov_pc.py`

 * *Files 2% similar despite different names*

```diff
@@ -44,19 +44,19 @@
     import numpy as np
     import matplotlib.pyplot as plt
     
     import struphy
 
     libpath = struphy.__path__[0]
     
-    with open(os.path.join(libpath, 'io_path.txt')) as f:
-        io_path = f.readlines()[0]
+    with open(os.path.join(libpath, 'o_path.txt')) as f:
+        o_path = f.readlines()[0]
     
     out_name = 'sim_example_linearmhdvlasovpc'
-    out_path = os.path.join(io_path, 'io/out', out_name)
+    out_path = os.path.join(o_path, out_name)
 
     # load data
     file = h5py.File(os.path.join(out_path, 'data/', 'data_proc0.hdf5'), 'r')
 
     t  = file['time/value'][:]
     eu = file['scalar/en_U'][:]
     eb = file['scalar/en_B'][:]
```

### Comparing `struphy-2.0.1/src/struphy/examples/maxwell.py` & `struphy-2.0.2/src/struphy/examples/maxwell.py`

 * *Files 1% similar despite different names*

```diff
@@ -43,20 +43,20 @@
     
     from struphy.diagnostics.diagn_tools import fourier_1d
     
     import struphy
 
     libpath = struphy.__path__[0]
     
-    with open(os.path.join(libpath, 'io_path.txt')) as f:
-        io_path = f.readlines()[0]
+    with open(os.path.join(libpath, 'o_path.txt')) as f:
+        o_path = f.readlines()[0]
     
     # output path
     out_name = 'sim_example_maxwell'
-    out_path = os.path.join(io_path, 'io/out', out_name) 
+    out_path = os.path.join(o_path, out_name) 
     
     # code name
     with open(os.path.join(out_path, 'meta.txt'), 'r') as f:
         lines = f.readlines()
 
     code = lines[3].split()[-1]
```

### Comparing `struphy-2.0.1/src/struphy/examples/orbits_tokamak.py` & `struphy-2.0.2/src/struphy/examples/orbits_tokamak.py`

 * *Files 1% similar despite different names*

```diff
@@ -47,20 +47,20 @@
     
     from struphy.models.setup import setup_domain_mhd
     from struphy.fields_background.mhd_equil.equils import EQDSKequilibrium
     
     import struphy
     libpath = struphy.__path__[0]
     
-    with open(os.path.join(libpath, 'io_path.txt')) as f:
-        io_path = f.readlines()[0]
+    with open(os.path.join(libpath, 'o_path.txt')) as f:
+        o_path = f.readlines()[0]
     
     # output path
     out_name = 'sim_example_orbits_tokamak'
-    out_path = os.path.join(io_path, 'io/out', out_name)
+    out_path = os.path.join(o_path, out_name)
     
     # load simulation parameters
     with open(os.path.join(out_path, 'parameters.yml')) as file:
         params = yaml.load(file, Loader=yaml.FullLoader)
 
     # create domain and MHD equilibrium
     domain, mhd_equil = setup_domain_mhd(params)
```

### Comparing `struphy-2.0.1/src/struphy/fields_background/electric_equil/analytical.py` & `struphy-2.0.2/src/struphy/fields_background/electric_equil/analytical.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/fields_background/electric_equil/base.py` & `struphy-2.0.2/src/struphy/fields_background/electric_equil/base.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/fields_background/mhd_equil/base.py` & `struphy-2.0.2/src/struphy/fields_background/mhd_equil/base.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/fields_background/mhd_equil/eqdsk/data/AUGNLED_g031213.00830.high` & `struphy-2.0.2/src/struphy/fields_background/mhd_equil/eqdsk/data/AUGNLED_g031213.00830.high`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/fields_background/mhd_equil/eqdsk/readeqdsk.py` & `struphy-2.0.2/src/struphy/fields_background/mhd_equil/eqdsk/readeqdsk.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/fields_background/mhd_equil/equils.py` & `struphy-2.0.2/src/struphy/fields_background/mhd_equil/equils.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E1D6_M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat` & `struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E1D6_M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E1D6_M6N6/parameter.ini` & `struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E1D6_M6N6/parameter.ini`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E4D6_M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat` & `struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E4D6_M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E4D6_M6N6/parameter.ini` & `struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E4D6_M6N6/parameter.ini`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/oldBC_E40D5M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat` & `struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/oldBC_E40D5M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/oldBC_E40D5M6N6/parameter.ini` & `struphy-2.0.2/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/oldBC_E40D5M6N6/parameter.ini`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/geometry/base.py` & `struphy-2.0.2/src/struphy/geometry/base.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/geometry/domains.py` & `struphy-2.0.2/src/struphy/geometry/domains.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/geometry/kernels.py` & `struphy-2.0.2/src/struphy/geometry/kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/geometry/map_eval.py` & `struphy-2.0.2/src/struphy/geometry/map_eval.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/geometry/mappings_fast.py` & `struphy-2.0.2/src/struphy/geometry/mappings_fast.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/geometry/transform.py` & `struphy-2.0.2/src/struphy/geometry/transform.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/geometry/utilities.py` & `struphy-2.0.2/src/struphy/geometry/utilities.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/initial/eigenfunctions.py` & `struphy-2.0.2/src/struphy/initial/eigenfunctions.py`

 * *Files 11% similar despite different names*

```diff
@@ -8,162 +8,184 @@
 
 from psydac.api.discretization import discretize
 
 
 class InitialMHDAxisymHdivEigFun:
     r"""
     Defines the initial condition via a 2-form MHD velocity field eigenfunction on the logical domain and setting the magnetic field and pressure to zero.
-    
+
     Parameters
     ----------
     derham : struphy.psydac_api.psydac_derham.Derham
         Discrete Derham complex.
-    
+
     **params
         Parameters for loading and selecting the desired eigenfunction.
 
         * spec : str, path of the .npy eigenspectrum relative to <install_path>/io/out/
         * spec_abs : str, absolute path of the .npy eigenspectrum
         * eig_freq_upper : float, upper search limit of squared eigenfrequency
         * eig_freq_lower : float, lower search limit of squared eigenfrequency
         * kind : str, whether to use real (r) or imaginary (i) part of eigenfunction
         * scaling : float, scaling factor that is multiplied with the eigenfunction
     """
-    
+
     def __init__(self, derham, **params):
-        
+
         import struphy
         libpath = struphy.__path__[0]
-        
-        with open(os.path.join(libpath, 'io_path.txt')) as f:
-            io_path = f.readlines()[0]
-        
+
+        with open(os.path.join(libpath, 'o_path.txt')) as f:
+            o_path = f.readlines()[0]
+
         params_default = {'spec': 'sim_1/spec_n_-1.npy',
                           'spec_abs': None,
-                          'eig_freq_upper': 0.02, 
+                          'eig_freq_upper': 0.02,
                           'eig_freq_lower': 0.03,
                           'kind': 'r',
                           'scaling': 1.}
-        
+
         params = set_defaults(params, params_default)
-        
+
         # absolute path of spectrum
         if params['spec_abs'] is None:
-            spec_path = os.path.join(io_path, 'io/out', params['spec'])
+            spec_path = os.path.join(o_path, params['spec'])
         else:
             spec_path = params['spec_abs']
-        
+
         # load eigenvector for velocity field
         omega2, U2_eig = np.split(np.load(spec_path), [1], axis=0)
         omega2 = omega2.flatten()
 
         # find eigenvector corresponding to given squared eigenfrequency range
-        mode = np.where((np.real(omega2) < params['eig_freq_upper']) & 
+        mode = np.where((np.real(omega2) < params['eig_freq_upper']) &
                         (np.real(omega2) > params['eig_freq_lower']))[0]
-        
+
         assert mode.size == 1
         mode = mode[0]
-        
+
         nnz_pol = derham.B['2'].dim_nz_pol
         nnz_tor = derham.B['2'].dim_nz_tor
-        
+
         eig_vec_1 = U2_eig[0*nnz_pol[0] + 0*nnz_pol[1] + 0*nnz_pol[2]:1*nnz_pol[0] + 0*nnz_pol[1] + 0*nnz_pol[2], mode]
         eig_vec_2 = U2_eig[1*nnz_pol[0] + 0*nnz_pol[1] + 0*nnz_pol[2]:1*nnz_pol[0] + 1*nnz_pol[1] + 0*nnz_pol[2], mode]
         eig_vec_3 = U2_eig[1*nnz_pol[0] + 1*nnz_pol[1] + 0*nnz_pol[2]:1*nnz_pol[0] + 1*nnz_pol[1] + 1*nnz_pol[2], mode]
 
         del omega2, U2_eig
 
         # project toroidal Fourier modes
         domain_log = Line('L', bounds=(0, 1))
         derham_sym = Derham(domain_log)
-        
-        domain_log_h = discretize(domain_log, ncells=[derham.Nel[2]], periodic=[True])
-        derham_1d = discretize(derham_sym, domain_log_h, degree=[derham.p[2]], quad_order=[derham.quad_order[2]])
-        
+
+        domain_log_h = discretize(
+            domain_log, ncells=[derham.Nel[2]], periodic=[True])
+        derham_1d = discretize(derham_sym, domain_log_h, degree=[
+                               derham.p[2]], quad_order=[derham.quad_order[2]])
+
         p0, p1 = derham_1d.projectors(nquads=[derham.nq_pr[2]])
-        
+
         n_tor = int(os.path.split(spec_path)[-1][-6:-4])
-        
-        N_cos = p0(lambda phi : np.cos(2*np.pi*n_tor*phi)).coeffs.toarray()
-        N_sin = p0(lambda phi : np.sin(2*np.pi*n_tor*phi)).coeffs.toarray()
 
-        D_cos = p1(lambda phi : np.cos(2*np.pi*n_tor*phi)).coeffs.toarray()
-        D_sin = p1(lambda phi : np.sin(2*np.pi*n_tor*phi)).coeffs.toarray()
+        N_cos = p0(lambda phi: np.cos(2*np.pi*n_tor*phi)).coeffs.toarray()
+        N_sin = p0(lambda phi: np.sin(2*np.pi*n_tor*phi)).coeffs.toarray()
+
+        D_cos = p1(lambda phi: np.cos(2*np.pi*n_tor*phi)).coeffs.toarray()
+        D_sin = p1(lambda phi: np.sin(2*np.pi*n_tor*phi)).coeffs.toarray()
 
         # select real part or imaginary part
         assert params['kind'] == 'r' or params['kind'] == 'i'
-        
+
         if params['kind'] == 'r':
-            eig_vec_1 = (np.outer(np.real(eig_vec_1), D_cos) - np.outer(np.imag(eig_vec_1), D_sin)).flatten()
-            eig_vec_2 = (np.outer(np.real(eig_vec_2), D_cos) - np.outer(np.imag(eig_vec_2), D_sin)).flatten()
-            eig_vec_3 = (np.outer(np.real(eig_vec_3), N_cos) - np.outer(np.imag(eig_vec_3), N_sin)).flatten()
+            eig_vec_1 = (np.outer(np.real(eig_vec_1), D_cos) -
+                         np.outer(np.imag(eig_vec_1), D_sin)).flatten()
+            eig_vec_2 = (np.outer(np.real(eig_vec_2), D_cos) -
+                         np.outer(np.imag(eig_vec_2), D_sin)).flatten()
+            eig_vec_3 = (np.outer(np.real(eig_vec_3), N_cos) -
+                         np.outer(np.imag(eig_vec_3), N_sin)).flatten()
         else:
-            eig_vec_1 = (np.outer(np.imag(eig_vec_1), D_cos) + np.outer(np.real(eig_vec_1), D_sin)).flatten()
-            eig_vec_2 = (np.outer(np.imag(eig_vec_2), D_cos) + np.outer(np.real(eig_vec_2), D_sin)).flatten()
-            eig_vec_3 = (np.outer(np.imag(eig_vec_3), N_cos) + np.outer(np.real(eig_vec_3), N_sin)).flatten()
-            
+            eig_vec_1 = (np.outer(np.imag(eig_vec_1), D_cos) +
+                         np.outer(np.real(eig_vec_1), D_sin)).flatten()
+            eig_vec_2 = (np.outer(np.imag(eig_vec_2), D_cos) +
+                         np.outer(np.real(eig_vec_2), D_sin)).flatten()
+            eig_vec_3 = (np.outer(np.imag(eig_vec_3), N_cos) +
+                         np.outer(np.real(eig_vec_3), N_sin)).flatten()
+
         # set coefficients in full space
         eigvec_1_ten = np.zeros(derham.nbasis['2'][0], dtype=float)
         eigvec_2_ten = np.zeros(derham.nbasis['2'][1], dtype=float)
         eigvec_3_ten = np.zeros(derham.nbasis['2'][2], dtype=float)
-        
+
         bc1_1 = 1 if derham.bc[0][0] == 'd' else 0
         bc1_2 = 1 if derham.bc[0][1] == 'd' else 0
-        
+
         bc2_1 = 1 if derham.bc[1][0] == 'd' else 0
         bc2_2 = 1 if derham.bc[1][1] == 'd' else 0
-        
+
         bc3_1 = 1 if derham.bc[2][0] == 'd' else 0
         bc3_2 = 1 if derham.bc[2][1] == 'd' else 0
-        
+
         if derham.polar_ck == -1:
-        
-            n_v2_0 = [[derham.nbasis['2'][0][0] - bc1_1 - bc1_2, derham.nbasis['2'][0][1], derham.nbasis['2'][0][2]],
-                      [derham.nbasis['2'][1][0], derham.nbasis['2'][1][1] - bc2_1 - bc2_2, derham.nbasis['2'][1][2]], 
-                      [derham.nbasis['2'][2][0], derham.nbasis['2'][2][1], derham.nbasis['2'][2][2] - bc3_1 - bc3_2]] 
 
-            eigvec_1_ten[bc1_1:derham.nbasis['2'][0][0] - bc1_2, :, :] = eig_vec_1.reshape(n_v2_0[0])
-            eigvec_2_ten[:, bc2_1:derham.nbasis['2'][1][1] - bc2_2, :] = eig_vec_2.reshape(n_v2_0[1])
-            eigvec_3_ten[:, :, bc3_1:derham.nbasis['2'][2][2] - bc3_2] = eig_vec_3.reshape(n_v2_0[2])
+            n_v2_0 = [[derham.nbasis['2'][0][0] - bc1_1 - bc1_2, derham.nbasis['2'][0][1], derham.nbasis['2'][0][2]],
+                      [derham.nbasis['2'][1][0], derham.nbasis['2'][1]
+                          [1] - bc2_1 - bc2_2, derham.nbasis['2'][1][2]],
+                      [derham.nbasis['2'][2][0], derham.nbasis['2'][2][1], derham.nbasis['2'][2][2] - bc3_1 - bc3_2]]
+
+            eigvec_1_ten[bc1_1:derham.nbasis['2'][0][0] -
+                         bc1_2, :, :] = eig_vec_1.reshape(n_v2_0[0])
+            eigvec_2_ten[:, bc2_1:derham.nbasis['2'][1]
+                         [1] - bc2_2, :] = eig_vec_2.reshape(n_v2_0[1])
+            eigvec_3_ten[:, :, bc3_1:derham.nbasis['2'][2]
+                         [2] - bc3_2] = eig_vec_3.reshape(n_v2_0[2])
 
             self._eigvec_1 = eigvec_1_ten*params['scaling']
             self._eigvec_2 = eigvec_2_ten*params['scaling']
             self._eigvec_3 = eigvec_3_ten*params['scaling']
-            
+
         else:
-            
+
             # split into polar/tensor product parts
-            eig_vec_1 = np.split(eig_vec_1, [derham.Vh_pol['2'].n_polar[0]*nnz_tor[0],])
-            eig_vec_2 = np.split(eig_vec_2, [derham.Vh_pol['2'].n_polar[1]*nnz_tor[1],])
-            eig_vec_3 = np.split(eig_vec_3, [derham.Vh_pol['2'].n_polar[2]*nnz_tor[2],])
-            
+            eig_vec_1 = np.split(eig_vec_1,
+                                 [derham.Vh_pol['2'].n_polar[0] * nnz_tor[0],])
+            eig_vec_2 = np.split(eig_vec_2,
+                                 [derham.Vh_pol['2'].n_polar[1] * nnz_tor[1],])
+            eig_vec_3 = np.split(eig_vec_3,
+                                 [derham.Vh_pol['2'].n_polar[2] * nnz_tor[2],])
+
             # reshape polar coeffs
-            eig_vec_1[0] = eig_vec_1[0].reshape(derham.Vh_pol['2'].n_polar[0], nnz_tor[0])
-            eig_vec_2[0] = eig_vec_2[0].reshape(derham.Vh_pol['2'].n_polar[1], nnz_tor[1])
-            eig_vec_3[0] = eig_vec_3[0].reshape(derham.Vh_pol['2'].n_polar[2], nnz_tor[2])
-            
+            eig_vec_1[0] = eig_vec_1[0].reshape(
+                derham.Vh_pol['2'].n_polar[0], nnz_tor[0])
+            eig_vec_2[0] = eig_vec_2[0].reshape(
+                derham.Vh_pol['2'].n_polar[1], nnz_tor[1])
+            eig_vec_3[0] = eig_vec_3[0].reshape(
+                derham.Vh_pol['2'].n_polar[2], nnz_tor[2])
+
             # reshape tensor product coeffs
-            n_v2_0 = [[derham.nbasis['2'][0][0] - derham.Vh_pol['2'].n_rings[0] - bc1_2, 
-                       derham.nbasis['2'][0][1], 
+            n_v2_0 = [[derham.nbasis['2'][0][0] - derham.Vh_pol['2'].n_rings[0] - bc1_2,
+                       derham.nbasis['2'][0][1],
                        derham.nbasis['2'][0][2]],
-                      [derham.nbasis['2'][1][0] - derham.Vh_pol['2'].n_rings[1], 
-                       derham.nbasis['2'][1][1], 
-                       derham.nbasis['2'][1][2]], 
-                      [derham.nbasis['2'][2][0] - derham.Vh_pol['2'].n_rings[2], 
-                       derham.nbasis['2'][2][1], 
-                       derham.nbasis['2'][2][2]]] 
-            
-            eigvec_1_ten[derham.Vh_pol['2'].n_rings[0]:derham.nbasis['2'][0][0] - bc1_2, :, :] = eig_vec_1[1].reshape(n_v2_0[0])
-            eigvec_2_ten[derham.Vh_pol['2'].n_rings[1]:, :, :] = eig_vec_2[1].reshape(n_v2_0[1])
-            eigvec_3_ten[derham.Vh_pol['2'].n_rings[2]:, :, :] = eig_vec_3[1].reshape(n_v2_0[2])
-            
-            self._eigvec_1 = [eig_vec_1[0]*params['scaling'], eigvec_1_ten*params['scaling']]
-            self._eigvec_2 = [eig_vec_2[0]*params['scaling'], eigvec_2_ten*params['scaling']]
-            self._eigvec_3 = [eig_vec_3[0]*params['scaling'], eigvec_3_ten*params['scaling']]
-        
-    
+                      [derham.nbasis['2'][1][0] - derham.Vh_pol['2'].n_rings[1],
+                       derham.nbasis['2'][1][1],
+                       derham.nbasis['2'][1][2]],
+                      [derham.nbasis['2'][2][0] - derham.Vh_pol['2'].n_rings[2],
+                       derham.nbasis['2'][2][1],
+                       derham.nbasis['2'][2][2]]]
+
+            eigvec_1_ten[derham.Vh_pol['2'].n_rings[0]:
+                         derham.nbasis['2'][0][0] - bc1_2, :, :] = eig_vec_1[1].reshape(n_v2_0[0])
+            eigvec_2_ten[derham.Vh_pol['2'].n_rings[1]:, :, :] = \
+                eig_vec_2[1].reshape(n_v2_0[1])
+            eigvec_3_ten[derham.Vh_pol['2'].n_rings[2]:, :, :] = \
+                eig_vec_3[1].reshape(n_v2_0[2])
+
+            self._eigvec_1 = [eig_vec_1[0] * params['scaling'],
+                              eigvec_1_ten * params['scaling']]
+            self._eigvec_2 = [eig_vec_2[0] * params['scaling'],
+                              eigvec_2_ten * params['scaling']]
+            self._eigvec_3 = [eig_vec_3[0] * params['scaling'],
+                              eigvec_3_ten * params['scaling']]
+
     @property
     def u2(self):
         """ List of eigenvectors
         """
         return self._eigvec_1, self._eigvec_2, self._eigvec_3
-
```

### Comparing `struphy-2.0.1/src/struphy/io/batch/batch_cobra.sh` & `struphy-2.0.2/src/struphy/io/batch/batch_cobra.sh`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/io/batch/p_016.sh` & `struphy-2.0.2/src/struphy/io/batch/p_016.sh`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/io/batch/p_032.sh` & `struphy-2.0.2/src/struphy/io/batch/p_032.sh`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/io/batch/p_064.sh` & `struphy-2.0.2/src/struphy/io/batch/p_064.sh`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/io/batch/p_128.sh` & `struphy-2.0.2/src/struphy/io/batch/p_128.sh`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/io/batch/p_256.sh` & `struphy-2.0.2/src/struphy/io/batch/p_256.sh`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/io/batch/p_512.sh` & `struphy-2.0.2/src/struphy/io/batch/p_512.sh`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/io/inp/examples/params_TAE_tokamak.yml` & `struphy-2.0.2/src/struphy/io/inp/examples/params_TAE_tokamak.yml`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/io/inp/examples/params_gc_orbits_tokamak.yml` & `struphy-2.0.2/src/struphy/io/inp/examples/params_gc_orbits_tokamak.yml`

 * *Files 11% similar despite different names*

```diff
@@ -52,15 +52,15 @@
             A : 1 # mass number in units of proton mass
             Z : 1 # signed charge number in units of elementary charge
         markers :
             type    : full_f # full_f, control_variate, or delta_f
             ppc     : null
             Np      : 4 # alternative if ppc = null (total number of markers, must be larger or equal than # MPI processes)
             eps     : 2.0 # MPI send/receive buffer (0.1 <= eps <= 1.0)
-            bc_type : [periodic, periodic, periodic] # marker boundary conditions: remove, reflect or periodic
+            bc_type : [remove, periodic, periodic] # marker boundary conditions: remove, reflect or periodic
             loading :
                 type    : pseudo_random # particle loading mechanism 
                 seed    : 1608 # seed for random number generator
                 moments : [0., 0., 1., 1.] # moments of Gaussian s3, see background/moms_spec
                 spatial : uniform # uniform or disc
                 initial : [[.501, 0.001, 0.001,  1.935 , -1.72], # counter-passing particle
                            [.501, 0.001, 0.001, -1.935 , -1.72], # co-passing particle
@@ -69,12 +69,17 @@
 
         init :
             type : Maxwellian5DUniform
             Maxwellian5DUniform:
                 n : 0.05
         save_data :
             n_markers : 4 # number of markers to be save during simulation
-        push_algos :
+        push_algos1 :
+            integrator : implicit # explicit or implicit
+            method : discrete_gradients # possible choices: discrete_gradients, discrete_gradients_faster, discrete_gradients_Itoh_Newton, forward_euler, heun2, rk2, heun3, rk4
+            maxiter : 5
+            tol : 1.e-10
+        push_algos2 :
             integrator : implicit # explicit or implicit
             method : discrete_gradients_Itoh_Newton # possible choices: discrete_gradients, discrete_gradients_faster, discrete_gradients_Itoh_Newton, forward_euler, heun2, rk2, heun3, rk4
             maxiter : 5
             tol : 1.e-10
```

### Comparing `struphy-2.0.1/src/struphy/io/inp/examples/params_hybridmhdvlasovcc.yml` & `struphy-2.0.2/src/struphy/io/inp/examples/params_hybridmhdvlasovcc.yml`

 * *Files 1% similar despite different names*

```diff
@@ -54,15 +54,15 @@
                 comps :
                     n3 : False                # components to be initialized (for scalar fields: no list)
                     uv : [False, True, False] # components to be initialized (for scalar fields: no list)
                     p3 : False                # components to be initialized (for scalar fields: no list)
                 ls : [0] # Integer mode numbers in x or eta_1 (depending on coords)
                 ms : [0] # Integer mode numbers in y or eta_2 (depending on coords)
                 ns : [-1] # Integer mode numbers in z or eta_3 (depending on coords)
-                amp : [0.0001] # amplitudes of each mode
+                amps : [0.0001] # amplitudes of each mode
                 Lx : 1.
                 Ly : 1.
                 Lz : 10.
             InitialMHDSlab :
                 a  : 1.
                 R0 : 1.
                 m  : 0
```

### Comparing `struphy-2.0.1/src/struphy/io/inp/examples/params_hybridmhdvlasovpc.yml` & `struphy-2.0.2/src/struphy/io/inp/examples/params_hybridmhdvlasovpc.yml`

 * *Files 0% similar despite different names*

```diff
@@ -54,15 +54,15 @@
                 comps :
                     n3 : False                # components to be initialized (for scalar fields: no list)
                     uv : [False, True, False] # components to be initialized (for scalar fields: no list)
                     p3 : False                # components to be initialized (for scalar fields: no list)
                 ls : [0] # Integer mode numbers in x or eta_1 (depending on coords)
                 ms : [0] # Integer mode numbers in y or eta_2 (depending on coords)
                 ns : [-1] # Integer mode numbers in z or eta_3 (depending on coords)
-                amp : [0.0001] # amplitudes of each mode
+                amps : [0.0001] # amplitudes of each mode
                 Lx : 1.
                 Ly : 1.
                 Lz : 10.
             InitialMHDSlab :
                 a  : 1.
                 R0 : 1.
                 m  : 0
```

### Comparing `struphy-2.0.1/src/struphy/io/inp/examples/params_linearextendedmhd.yml` & `struphy-2.0.2/src/struphy/io/inp/examples/params_linearextendedmhd.yml`

 * *Files 2% similar despite different names*

```diff
@@ -52,14 +52,15 @@
                 comps :
                     n3 : False              # components to be initialized (for scalar fields: no list)
                     u2 : [True, True, True] # components to be initialized (for scalar fields: no list)
                     pi3 : False              # components to be initialized (for scalar fields: no list)
                     pe3 : False             # components to be initialized (for scalar fields: no list)
                 variation_in : e3 # noise variation (logical space): e1, e2, e3 (1d), e1e2, e1e3, e2e3 (2d), e1e2e3 (3d)
                 amp : 0.1 # noise amplitude
+                seed : 1234    # seed for random number generator
 
 solvers :
     solver_1 :
         type : PConjugateGradient
         pc : MassMatrixPreconditioner # null or name of preconditioner class
         tol : 1.e-8
         maxiter : 3000
```

### Comparing `struphy-2.0.1/src/struphy/io/inp/examples/params_linearmhd.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/params_linearmhd.yml`

 * *Files 8% similar despite different names*

```diff
@@ -1,68 +1,69 @@
 grid :
-    Nel      : [3, 3, 64] # number of grid cells, >p
-    p        : [2, 2, 3]  # spline degree
+    Nel      : [4, 4, 32] # number of grid cells, >p
+    p        : [2, 2, 3]  # spline degree, 
     spl_kind : [True, True, True] # spline type: True=periodic, False=clamped
     bc       : [[null, null], [null, null], [null, null]] # boundary conditions for N-splines (homogeneous Dirichlet='d')
     dims_mask : [True, True, True] # True if the dimension is to be used in the mpi domain decomposition (=default for each dimension).
     nq_el    : [6, 6, 6] # quadrature points per grid cell
     nq_pr    : [4, 4, 4] # quadrature points per histopolation cell (for commuting projectors)
     polar_ck : -1 # C^k smoothness at polar singularity at eta_1=0 (default: -1 --> standard tensor product, 1 : polar splines)
 
 units :
     x : 1. # length scale unit in m
     B : 1. # magnetic field unit in T
     n : 1. # number density unit of fluid species in 1 x 10^20 m^(-3)
 
-time :
+time : 
     dt         : 0.15 # time step
-    Tend       : 180. # simulation time interval is [0, Tend]
+    Tend       : 1.5 # simulation time interval is [0, Tend]
     split_algo : LieTrotter # LieTrotter | Strang
 
-geometry :
-    type : Cuboid # mapping F (possible types seen below)
-    Cuboid :
+geometry : 
+    type : Cuboid # mapping F (possible types seen below)  
+    Cuboid : 
         l1 : 0. # start of interval in eta1
         r1 : 1. # end of interval in eta1, r1>l1
         l2 : 0. # start of interval in eta2
         r2 : 1. # end of interval in eta2, r2>l2
         l3 : 0. # start of interval in eta3
         r3 : 60. # end of interval in eta3, r3>l3
 
-mhd_equilibrium :
+mhd_equilibrium : 
     type : HomogenSlab # (possible choices seen below)
     HomogenSlab :
         B0x  : 0. # magnetic field in x
         B0y  : 1. # magnetic field in y
         B0z  : 1. # magnetic field in z
         beta : 100. # plasma beta = 2*p*mu_0/B^2
         n0   : 1. # number density
 
-em_fields :
+em_fields : 
     init :
         type : null # initialization
 
 fluid :
     mhd :
         phys_params:
             A : 1  # mass number in units of proton mass
             Z : 1 # signed charge number in units of elementary charge
         mhd_u_space : H1vec # Hdiv | H1vec
         init :
-            type : noise # initialization
+            type : noise # initial conditions (possible types seen below)
             noise :
-                comps :
+                comps : 
                     n3 : False              # components to be initialized (for scalar fields: no list)
                     uv : [True, True, True] # components to be initialized (for scalar fields: no list)
                     p3 : False              # components to be initialized (for scalar fields: no list)
                 variation_in : e3 # noise variation (logical space): e1, e2, e3 (1d), e1e2, e1e3, e2e3 (2d), e1e2e3 (3d)
                 amp : 0.1 # noise amplitude
+                seed : 1234    # seed for random number generator
 
 solvers :
-    solver_1 :
+    solver_1 : 
         type : PConjugateGradient
         pc : MassMatrixPreconditioner # null or name of preconditioner class
         tol : 1.e-8
         maxiter : 3000
         info : False
         verbose : False
     solver_2 :
```

### Comparing `struphy-2.0.1/src/struphy/io/inp/examples/params_linvlasovmaxwell_landau.yml` & `struphy-2.0.2/src/struphy/io/inp/examples/params_linvlasovmaxwell_landau.yml`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/io/inp/examples/params_linvlasovmaxwell_streaming_weibel.yml` & `struphy-2.0.2/src/struphy/io/inp/examples/params_linvlasovmaxwell_streaming_weibel.yml`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/io/inp/examples/params_linvlasovmaxwell_weibel.yml` & `struphy-2.0.2/src/struphy/io/inp/examples/params_linvlasovmaxwell_weibel.yml`

 * *Files 3% similar despite different names*

```diff
@@ -59,15 +59,14 @@
     init :
         type : ModesCos # initial conditions (possible types seen below)
         ModesCos :
             coords : 'physical' # in which coordinates (logical or physical)
             comps :
                 e_field : [False, False, False]  # components to be initialized (for scalar fields: no list)
                 b_field : [False, False, True] # components to be initialized (for scalar fields: no list)
-            # variation_in : e1 # noise variation (logical space): e1, e2, e3 (1d), e1e2, e1e3, e2e3 (2d), e1e2e3 (3d)
             ls : [1.]
             ms : [0]
             ns : [0.]
             amp : [-0.0001] # amplitudes of each mode
             Lx : 5.026548245743669
 
 kinetic :
```

### Comparing `struphy-2.0.1/src/struphy/io/inp/examples/params_maxwell.yml` & `struphy-2.0.2/src/struphy/io/inp/examples/params_maxwell.yml`

 * *Files 2% similar despite different names*

```diff
@@ -32,14 +32,15 @@
         type : noise
         noise :
             comps :
                 e1 : [True, True, False]   # components to be initialized (for scalar fields: no list)
                 b2: [False, False, False] # components to be initialized (for scalar fields: no list)
             variation_in : e3 # noise variation (logical space): e1, e2, e3 (1d), e1e2, e1e3, e2e3 (2d), e1e2e3 (3d)
             amp : 0.1 # noise amplitude
+            seed : 1234    # seed for random number generator
 
 solvers :
     solver_1 :
         type : PConjugateGradient
         pc : MassMatrixPreconditioner # null or name of preconditioner class
         tol : 1.e-8
         maxiter : 3000
```

### Comparing `struphy-2.0.1/src/struphy/io/inp/examples/params_orbits_tokamak.yml` & `struphy-2.0.2/src/struphy/io/inp/examples/params_orbits_tokamak.yml`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/io/inp/parameters.yml` & `struphy-2.0.2/src/struphy/io/inp/parameters.yml`

 * *Files 3% similar despite different names*

```diff
@@ -2,16 +2,16 @@
 
 # 1. Strings can either be set as e.g. 'Cuboid' or Cuboid, i.e. with or without quotes - both works
 # 2. The parameter null will be transformed to Python's None type
 # 3. For available geometries, please check out https://struphy.pages.mpcdf.de/struphy/sections/domains.html
 # 4. For available MHD equilibria, please check out https://struphy.pages.mpcdf.de/struphy/sections/mhd_equils.html
 
 grid :
-    Nel       : [16, 32, 32] # number of grid cells, >p
-    p         : [2, 3, 4]  # spline degree
+    Nel       : [8, 16, 4] # number of grid cells, >p
+    p         : [3, 4, 2]  # spline degree
     spl_kind  : [False, True, True] # spline type: True=periodic, False=clamped
     bc        : [[null, null], [null, null], [null, null]] # boundary conditions for N-splines (homogeneous Dirichlet='d')
     dims_mask : [True, True, True] # True if the dimension is to be used in the mpi domain decomposition (=default for each dimension).
     nq_el     : [2, 2, 2] # quadrature points per grid cell
     nq_pr     : [2, 2, 2] # quadrature points per histopolation cell (for commuting projectors)
     polar_ck  : -1 # C^k smoothness at polar singularity at eta_1=0 (default: -1 --> standard tensor product, 1 : polar splines)
 
@@ -53,41 +53,42 @@
     init :
         type : ModesSin # type of initial condition (possible types seen below)
         noise : 
             comps :
                 e1 : [True, False, False]  # components to be initialized (for scalar fields: no list)
                 b2 : [False, False, False] # components to be initialized (for scalar fields: no list)
             variation_in : e3 # noise variation (logical space): e1, e2, e3 (1d), e1e2, e1e3, e2e3 (2d), e1e2e3 (3d)
-            amp : 0.1   # noise amplitude
+            amp : 0.0001   # noise amplitude
+            seed : 1234    # seed for random number generator
         ModesSin : 
             coords : 'logical' # in which coordinates (logical or physical)
             comps :
                 e1 : [True, False, False]  # components to be initialized (for scalar fields: no list)
                 b2 : [False, False, False] # components to be initialized (for scalar fields: no list)
             ls : [0] # Integer mode numbers in x or eta_1 (depending on coords)
             ms : [0] # Integer mode numbers in y or eta_2 (depending on coords)
             ns : [1] # Integer mode numbers in z or eta_3 (depending on coords)
-            amp : [0.001] # amplitudes of each mode
+            amps : [0.0001] # amplitudes of each mode
         ModesCos :
             coords : 'logical' # in which coordinates (logical or physical)
             comps :
                 e1 : [True, False, False]  # components to be initialized (for scalar fields: no list)
                 b2 : [False, False, False] # components to be initialized (for scalar fields: no list)
             ls : [0] # Integer mode numbers in x or eta_1 (depending on coords)
             ms : [0] # Integer mode numbers in y or eta_2 (depending on coords)
             ns : [1] # Integer mode numbers in z or eta_3 (depending on coords)
-            amp : [0.001] # amplitudes of each mode
+            amps : [0.001] # amplitudes of each mode
         TorusModesSin :
             coords : 'logical' # in which coordinates (logical or physical)
             comps :
                 e1 : [True, False, False]  # components to be initialized (for scalar fields: no list)
                 b2 : [False, False, False] # components to be initialized (for scalar fields: no list)
             ms : [1] # poloidal mode numbers
             ns : [0] # toroidal mode numbers
-            amp : [0.001] # amplitudes of each mode
+            amps : [0.001] # amplitudes of each mode
             pfuns : ['sin'] # profile function in eta1-direction ('sin' or 'exp')
             pfun_params : [null] # Provides [r_0, sigma] parameters for each "exp" profile fucntion, and null for "sin"
         InitialMHDSlab :
             a  : 1. # minor radius (Lx=a, Ly=2*pi*a)
             R0 : 3. # major radius (Lz=2*pi*R0)
             m  : 0  # poloidal (y) mode number
             n  : 1  # toroidal (z) mode number
@@ -112,43 +113,44 @@
             noise :
                 comps :
                     n3 : False               # components to be initialized (for scalar fields: no list)
                     uv : [True, True, True]  # components to be initialized (for scalar fields: no list)
                     p3 : False               # components to be initialized (for scalar fields: no list)
                 variation_in : e3 # noise variation (logical space): e1, e2, e3 (1d), e1e2, e1e3, e2e3 (2d), e1e2e3 (3d)
                 amp : 0.1   # noise amplitude
+                seed : 1234    # seed for random number generator
             ModesSin :
                 coords : 'logical' # in which coordinates (logical or physical)
                 comps :
                     n3 : False              # components to be initialized (for scalar fields: no list)
                     uv : [True, True, True] # components to be initialized (for scalar fields: no list)
                     p3 : False              # components to be initialized (for scalar fields: no list)
                 ls : [0] # Integer mode numbers in x or eta_1 (depending on coords)
                 ms : [0] # Integer mode numbers in y or eta_2 (depending on coords)
                 ns : [1] # Integer mode numbers in z or eta_3 (depending on coords)
-                amp : [0.001] # amplitudes of each mode
+                amps : [0.0001] # amplitudes of each mode
             ModesCos :
                 coords : 'logical' # in which coordinates (logical or physical)
                 comps :
                     n3 : False               # components to be initialized (for scalar fields: no list)
                     uv : [True, True, True]  # components to be initialized (for scalar fields: no list)
                     p3 : False               # components to be initialized (for scalar fields: no list)
                 ls : [0] # Integer mode numbers in x or eta_1 (depending on coords)
                 ms : [0] # Integer mode numbers in y or eta_2 (depending on coords)
                 ns : [1] # Integer mode numbers in z or eta_3 (depending on coords)
-                amp : [0.001] # amplitudes of each mode
+                amps : [0.001] # amplitudes of each mode
             TorusModesSin :
                 coords : 'logical' # in which coordinates (logical or physical)
                 comps :
                     n3 : False              # components to be initialized (for scalar fields: no list)
                     uv : [True, True, True] # components to be initialized (for scalar fields: no list)
                     p3 : False              # components to be initialized (for scalar fields: no list)
                 ms : [1] # poloidal mode numbers
                 ns : [0] # toroidal mode numbers
-                amp : [0.001] # amplitudes of each mode
+                amps : [0.001] # amplitudes of each mode
                 pfuns : ['sin'] # profile function in eta1-direction ('sin' or 'exp')
                 pfun_params : [null] # Provides [r_0, sigma] parameters for each "exp" profile fucntion, and null for "sin"
             InitialMHDSlab :
                 a  : 1. # minor radius (Lx=a, Ly=2*pi*a)
                 R0 : 3. # major radius (Lz=2*pi*R0)
                 m  : 0  # poloidal (y) mode number
                 n  : 1  # toroidal (z) mode number
@@ -159,15 +161,15 @@
                 spec_abs : null # absolute path of .npy spectrum (is used instead of "spec", if "spec_abs" is not null)
                 eig_freq_upper : 0.15 # upper search limit of squared eigenfrequency to identify eigenfunction
                 eig_freq_lower : 0.14 # lower search limit of squared eigenfrequency to identify eigenfunction
                 kind : r # real (r) or imaginary (i) part of eigenfunction
                 scaling : 1. # scaling factor to scale the amplitude of the eigenfunction     
 
 kinetic :
-    hot_ions :
+    energetic_ions :
         phys_params :
             A : 1  # mass number in units of proton mass
             Z : 1 # signed charge number in units of elementary charge
         markers :
             type    : full_f # full_f, control_variate, or delta_f
             ppc     : 100  # number of markers per 3d grid cell
             Np      : 3 # alternative if ppc = null (total number of markers, must be larger or equal than # MPI processes)
@@ -179,25 +181,25 @@
                 moments       : [0., 0., 0., 1., 1., 1.] # moments of Gaussian s3, see background/moms_spec
                 spatial       : uniform # uniform or disc
                 dir_particles : 'path_to_particles' # directory of particles if loaded externally
         init :
             type : Maxwellian6DPerturbed
             Maxwellian6DPerturbed :
                 n :
-                    n0 : 1.
+                    n0 : 0.05
                     perturbation :
                         l : [0]
                         m : [0]
                         n : [0]
                         amps_sin : [0.]
                         amps_cos : [0.]
                 u1 :
                     u10 : 0.
                 u2 :
-                    u20 : 0.
+                    u20 : 2.5
                 u3 :
                     u30 : 0.
                 vth1 :
                     vth10 : 1.
                 vth2 :
                     vth20 : 1.
                 vth3 :
@@ -234,7 +236,21 @@
     solver_2 :
         type : PConjugateGradient
         pc : MassMatrixPreconditioner # null or name of preconditioner class
         tol : 1.e-8
         maxiter : 3000
         info : False
         verbose : False
+    solver_3 :
+        type : PConjugateGradient
+        pc : MassMatrixPreconditioner # null or name of preconditioner class
+        tol : 1.e-14
+        maxiter : 3000
+        info : False
+        verbose : False
+    solver_4 :
+        type : PBiConjugateGradientStab
+        pc : MassMatrixPreconditioner # null or name of preconditioner class
+        tol : 1.e-14
+        maxiter : 3000
+        info : False
+        verbose : False
```

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/params_cc_linmhd_5d.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/params_cc_linmhd_5d.yml`

 * *Files 2% similar despite different names*

```diff
@@ -61,14 +61,15 @@
             noise :
                 comps : 
                     n3 : False
                     uv : [True, True, True]
                     p3 : False
                 variation_in : e3 # noise variation (logical space): e1, e2, e3 (1d), e1e2, e1e3, e2e3 (2d), e1e2e3 (3d)
                 amp : 0.0001   # noise amplitude
+                seed : 1234    # seed for random number generator
 
 kinetic :
     energetic_ions :
         markers :
             type    : full_f # full_f or delta_f
             Np      : 4 # alternative if ppc = null (total number of markers, must be larger or equal than # MPI processes)
             eps     : 1.0 # MPI send/receive buffer (0.1 <= eps <= 1.0)
```

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/params_coldplasma.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/params_coldplasma.yml`

 * *Files 5% similar despite different names*

```diff
@@ -42,45 +42,47 @@
         type : noise
         noise :
             comps :
                 e1 : [True, False, False]   # components to be initialized (for scalar fields: no list)
                 b2 : [False, False, False]   # components to be initialized (for scalar fields: no list)
             variation_in : e3 # noise variation (logical space): e1, e2, e3 (1d), e1e2, e1e3, e2e3 (2d), e1e2e3 (3d)
             amp : 1.0 # noise amplitude
+            seed : 1234    # seed for random number generator
 
 fluid :
     electrons :
         phys_params:
             A : 0.00054858  # mass number in units of proton mass
             Z : -1 # signed charge number in units of elementary charge
         init :
             type : noise # initialization
             noise :
                 comps :
                     j1 : [False, False, False] # components to be initialized (for scalar fields: no list)
                 variation_in : e3 # noise variation (logical space): e1, e2, e3 (1d), e1e2, e1e3, e2e3 (2d), e1e2e3 (3d)
                 amp : 0.1 # noise amplitude
+                seed : 1234    # seed for random number generator
 
 solvers :
-    solver_1 :
+    solver_maxwell :
         type : PConjugateGradient
         pc : MassMatrixPreconditioner # null or name of preconditioner class
         tol : 1.e-10
         maxiter : 3000
         info : False
         verbose : False
 
-    solver_2 :
+    solver_ohmcold :
         type : PConjugateGradient
         pc : MassMatrixPreconditioner # null or name of preconditioner class
         tol : 1.e-10
         maxiter : 3000
         info : False
         verbose : False
 
-    solver_3 :
+    solver_jxbcold :
         type : PBiConjugateGradientStab
         pc : MassMatrixPreconditioner # null or name of preconditioner class
         tol : 1.e-10
         maxiter : 3000
         info : False
         verbose : False
```

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/params_deltafvlasovmaxwell.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/params_deltafvlasovmaxwell.yml`

 * *Files 2% similar despite different names*

```diff
@@ -49,15 +49,15 @@
             coords : 'logical' # in which coordinates (logical or physical)
             comps :
                 e_field : [False, False, False]  # components to be initialized
                 b_field : [False, False, True] # components to be initialized
             ls : [1] # Integer mode numbers in x or eta_1 (depending on coords)
             ms : [0] # Integer mode numbers in y or eta_2 (depending on coords)
             ns : [0] # Integer mode numbers in z or eta_3 (depending on coords)
-            amp : [0.01] # amplitudes of each mode
+            amps : [0.01] # amplitudes of each mode
 
 kinetic :
     electrons :
         phys_params:
             A : 0.0005446170214876324  # electron mass number in units of proton mass
             Z : -1 # signed charge number in units of elementary charge
         markers :
@@ -107,15 +107,15 @@
         push_algos :
             vxb : analytic # possible choices: analytic, implicit
             eta : rk4 # possible choices: forward_euler, heun2, rk2, heun3, rk4
 
 solvers :
     solver_poisson :
         type : PConjugateGradient
-        pc : null # MassMatrixPreconditioner # null or name of preconditioner class
+        pc : MassMatrixPreconditioner # MassMatrixPreconditioner # null or name of preconditioner class
         tol : 1.e-10
         maxiter : 3000
         info : False
         verbose : False
     solver_ew :
         type : PConjugateGradient
         pc : MassMatrixPreconditioner # null or name of preconditioner class
```

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/params_hybrid_fA.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/params_hybrid_fA.yml`

 * *Files 1% similar despite different names*

```diff
@@ -41,37 +41,38 @@
     init :
         type : noise # initial conditions (possible types seen below)
         noise :
             comps :
                 a1 : [True, True, True]  # components to be initialized (for scalar fields: no list)
             variation_in : e1e2e3 # noise variation (logical space): e1, e2, e3 (1d), e1e2, e1e3, e2e3 (2d), e1e2e3 (3d)
             amp : 0.   # noise amplitude
+            seed : 1234    # seed for random number generator
         ModesSin : 
             coords : 'logical' # in which coordinates (logical or physical)
             comps :
                 a1 : [True, True, True]  # components to be initialized (for scalar fields: no list)
             ls : [0] # Integer mode numbers in x or eta_1 (depending on coords)
             ms : [0] # Integer mode numbers in y or eta_2 (depending on coords)
             ns : [1] # Integer mode numbers in z or eta_3 (depending on coords)
-            amp : [0.001] # amplitudes of each mode
+            amps : [0.001] # amplitudes of each mode
         ModesCos :
             coords : 'logical' # in which coordinates (logical or physical)
             comps :
                 a1 : [True, True, True]  # components to be initialized (for scalar fields: no list)
             ls : [0] # Integer mode numbers in x or eta_1 (depending on coords)
             ms : [0] # Integer mode numbers in y or eta_2 (depending on coords)
             ns : [1] # Integer mode numbers in z or eta_3 (depending on coords)
-            amp : [0.001] # amplitudes of each mode
+            amps : [0.001] # amplitudes of each mode
         TorusModesSin :
             coords : 'logical' # in which coordinates (logical or physical)
             comps :
                 a1 : [True, True, True]  # components to be initialized (for scalar fields: no list)
             ms : [1] # poloidal mode numbers
             ns : [0] # toroidal mode numbers
-            amp : [0.001] # amplitudes of each mode
+            amps : [0.001] # amplitudes of each mode
             pfuns : ['sin'] # profile function in eta1-direction ('sin' or 'exp')
             pfun_params : [null] # Provides [r_0, sigma] parameters for each "exp" profile fucntion, and null for "sin"
         InitialMHDSlab :
             a  : 1. # minor radius (Lx=a, Ly=2*pi*a)
             R0 : 3. # major radius (Lz=2*pi*R0)
             m  : 0  # poloidal (y) mode number
             n  : 1  # toroidal (z) mode number
```

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/params_hybridmhdvlasovcc.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/params_hybridmhdvlasovcc.yml`

 * *Files 0% similar despite different names*

```diff
@@ -54,15 +54,15 @@
                 comps : 
                     n3 : False                # components to be initialized (for scalar fields: no list)
                     uv : [False, True, False] # components to be initialized (for scalar fields: no list)
                     p3 : False                # components to be initialized (for scalar fields: no list)
                 ls : [0] # Integer mode numbers in x or eta_1 (depending on coords)
                 ms : [0] # Integer mode numbers in y or eta_2 (depending on coords)
                 ns : [-1] # Integer mode numbers in z or eta_3 (depending on coords)
-                amp : [0.001] # amplitudes of each mode
+                amps : [0.001] # amplitudes of each mode
                 Lx : 1.
                 Ly : 6.283185307
                 Lz : 6.283185307
             InitialMHDSlab :
                 a  : 1.
                 R0 : 1.
                 m  : 0
```

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/params_hybridmhdvlasovcc_control.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/params_hybridmhdvlasovcc_control.yml`

 * *Files 0% similar despite different names*

```diff
@@ -54,15 +54,15 @@
                 comps : 
                     n3 : False                # components to be initialized (for scalar fields: no list)
                     uv : [False, True, False] # components to be initialized (for scalar fields: no list)
                     p3 : False                # components to be initialized (for scalar fields: no list)
                 ls : [0] # Integer mode numbers in x or eta_1 (depending on coords)
                 ms : [0] # Integer mode numbers in y or eta_2 (depending on coords)
                 ns : [-1] # Integer mode numbers in z or eta_3 (depending on coords)
-                amp : [0.0001] # amplitudes of each mode
+                amps : [0.0001] # amplitudes of each mode
                 Lx : 1.
                 Ly : 1.
                 Lz : 10.
             InitialMHDSlab : 
                 a  : 1.
                 R0 : 1.
                 m  : 0
```

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/params_hybridmhdvlasovcc_gvec.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/params_hybridmhdvlasovcc_gvec.yml`

 * *Files 0% similar despite different names*

```diff
@@ -52,15 +52,15 @@
                 comps : 
                     n3 : False                # components to be initialized (for scalar fields: no list)
                     uv : [False, True, False] # components to be initialized (for scalar fields: no list)
                     p3 : False                # components to be initialized (for scalar fields: no list)
                 ls : [0] # Integer mode numbers in x or eta_1 (depending on coords)
                 ms : [0] # Integer mode numbers in y or eta_2 (depending on coords)
                 ns : [-1] # Integer mode numbers in z or eta_3 (depending on coords)
-                amp : [0.001] # amplitudes of each mode
+                amps : [0.001] # amplitudes of each mode
                 Lx : 1.
                 Ly : 6.283185307
                 Lz : 6.283185307
             InitialMHDSlab : 
                 a  : 1.
                 R0 : 1.
                 m  : 0
```

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/params_hybridmhdvlasovpc.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/params_hybridmhdvlasovpc.yml`

 * *Files 0% similar despite different names*

```diff
@@ -54,15 +54,15 @@
                 comps :
                     n3 : False                # components to be initialized (for scalar fields: no list)
                     uv : [False, True, False] # components to be initialized (for scalar fields: no list)
                     p3 : False                # components to be initialized (for scalar fields: no list)
                 ls : [0] # Integer mode numbers in x or eta_1 (depending on coords)
                 ms : [0] # Integer mode numbers in y or eta_2 (depending on coords)
                 ns : [-1] # Integer mode numbers in z or eta_3 (depending on coords)
-                amp : [0.0001] # amplitudes of each mode
+                amps : [0.0001] # amplitudes of each mode
                 Lx : 1.
                 Ly : 1.
                 Lz : 10.
             InitialMHDSlab :
                 a  : 1.
                 R0 : 1.
                 m  : 0
```

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/params_linearmhd.yml` & `struphy-2.0.2/src/struphy/io/inp/examples/params_linearmhd.yml`

 * *Files 5% similar despite different names*

```diff
@@ -1,68 +1,69 @@
 grid :
-    Nel      : [4, 4, 32] # number of grid cells, >p
-    p        : [2, 2, 3]  # spline degree, 
+    Nel      : [3, 3, 64] # number of grid cells, >p
+    p        : [2, 2, 3]  # spline degree
     spl_kind : [True, True, True] # spline type: True=periodic, False=clamped
     bc       : [[null, null], [null, null], [null, null]] # boundary conditions for N-splines (homogeneous Dirichlet='d')
     dims_mask : [True, True, True] # True if the dimension is to be used in the mpi domain decomposition (=default for each dimension).
     nq_el    : [6, 6, 6] # quadrature points per grid cell
     nq_pr    : [4, 4, 4] # quadrature points per histopolation cell (for commuting projectors)
     polar_ck : -1 # C^k smoothness at polar singularity at eta_1=0 (default: -1 --> standard tensor product, 1 : polar splines)
 
 units :
     x : 1. # length scale unit in m
     B : 1. # magnetic field unit in T
     n : 1. # number density unit of fluid species in 1 x 10^20 m^(-3)
 
-time : 
+time :
     dt         : 0.15 # time step
-    Tend       : 1.5 # simulation time interval is [0, Tend]
+    Tend       : 180. # simulation time interval is [0, Tend]
     split_algo : LieTrotter # LieTrotter | Strang
 
-geometry : 
-    type : Cuboid # mapping F (possible types seen below)  
-    Cuboid : 
+geometry :
+    type : Cuboid # mapping F (possible types seen below)
+    Cuboid :
         l1 : 0. # start of interval in eta1
         r1 : 1. # end of interval in eta1, r1>l1
         l2 : 0. # start of interval in eta2
         r2 : 1. # end of interval in eta2, r2>l2
         l3 : 0. # start of interval in eta3
         r3 : 60. # end of interval in eta3, r3>l3
 
-mhd_equilibrium : 
+mhd_equilibrium :
     type : HomogenSlab # (possible choices seen below)
     HomogenSlab :
         B0x  : 0. # magnetic field in x
         B0y  : 1. # magnetic field in y
         B0z  : 1. # magnetic field in z
         beta : 100. # plasma beta = 2*p*mu_0/B^2
         n0   : 1. # number density
 
-em_fields : 
+em_fields :
     init :
         type : null # initialization
 
 fluid :
     mhd :
         phys_params:
             A : 1  # mass number in units of proton mass
             Z : 1 # signed charge number in units of elementary charge
         mhd_u_space : H1vec # Hdiv | H1vec
         init :
-            type : noise # initial conditions (possible types seen below)
+            type : noise # initialization
             noise :
-                comps : 
+                comps :
                     n3 : False              # components to be initialized (for scalar fields: no list)
                     uv : [True, True, True] # components to be initialized (for scalar fields: no list)
                     p3 : False              # components to be initialized (for scalar fields: no list)
                 variation_in : e3 # noise variation (logical space): e1, e2, e3 (1d), e1e2, e1e3, e2e3 (2d), e1e2e3 (3d)
                 amp : 0.1 # noise amplitude
+                seed : 1234    # seed for random number generator
 
 solvers :
-    solver_1 : 
+    solver_1 :
         type : PConjugateGradient
         pc : MassMatrixPreconditioner # null or name of preconditioner class
         tol : 1.e-8
         maxiter : 3000
         info : False
         verbose : False
     solver_2 :
```

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/params_linearmhd_gvec.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/params_linearmhd_gvec.yml`

 * *Files 2% similar despite different names*

```diff
@@ -51,14 +51,15 @@
             noise :
                 comps :
                     n3 : False              # components to be initialized (for scalar fields: no list)
                     uv : [True, True, True] # components to be initialized (for scalar fields: no list)
                     p3 : False              # components to be initialized (for scalar fields: no list)
                 variation_in : e3 # noise variation (logical space): e1, e2, e3 (1d), e1e2, e1e3, e2e3 (2d), e1e2e3 (3d)
                 amp : 0.1   # noise amplitude
+                seed : 1234    # seed for random number generator
 
 solvers :
     solver_1 :
         type : PConjugateGradient
         pc : MassMatrixPreconditioner # null or name of preconditioner class
         tol : 1.e-8
         maxiter : 3000
```

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/params_linvlasovmaxwell.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/params_linvlasovmaxwell.yml`

 * *Files 2% similar despite different names*

```diff
@@ -47,14 +47,15 @@
         type : noise # initial conditions (possible types seen below)
         noise :
             comps :
                 e_field : [True, False, False]  # components to be initialized (for scalar fields: no list)
                 b_field : [False, True, True] # components to be initialized (for scalar fields: no list)
             variation_in : e3 # noise variation (logical space): e1, e2, e3 (1d), e1e2, e1e3, e2e3 (2d), e1e2e3 (3d)
             amp : 0.1   # noise amplitude
+            seed : 1234    # seed for random number generator
 
 kinetic :
     electrons :
         phys_params:
             A : 0.0005446170214876324  # electron mass number in units of proton mass
             Z : -1 # signed charge number in units of elementary charge
         markers :
@@ -111,15 +112,15 @@
         push_algos :
             vxb : analytic # possible choices: analytic, implicit
             eta : rk4 # possible choices: forward_euler, heun2, rk2, heun3, rk4
 
 solvers :
     solver_poisson :
         type : PConjugateGradient
-        pc : null # MassMatrixPreconditioner # null or name of preconditioner class
+        pc : MassMatrixPreconditioner # MassMatrixPreconditioner # null or name of preconditioner class
         tol : 1.e-10
         maxiter : 3000
         info : False
         verbose : False
     solver_ew :
         type : PConjugateGradient
         pc : MassMatrixPreconditioner # null or name of preconditioner class
```

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/params_maxwell_1.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/params_maxwell_1.yml`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 grid :
-    Nel      : [32, 32, 32] # number of grid cells, >p
+    Nel      : [16, 8, 4] # number of grid cells, >p
     p        : [3, 2, 1]  # spline degree
     spl_kind : [True, True, True] # spline type: True=periodic, False=clamped
     bc       : [[null, null], [null, null], [null, null]] # boundary conditions for N-splines (homogeneous Dirichlet='d')
     dims_mask : [True, True, True] # True if the dimension is to be used in the mpi domain decomposition (=default for each dimension).
     nq_el    : [2, 2, 2] # quadrature points per grid cell
     nq_pr    : [2, 2, 2] # quadrature points per histopolation cell (for commuting projectors)
     polar_ck : -1 # C^k smoothness at polar singularity at eta_1=0 (default: -1 --> standard tensor product, 1 : polar splines)
@@ -30,15 +30,15 @@
         TorusModesSin :
             coords : 'logical' # in which coordinates (logical or physical)
             comps :
                 e1 : [True, True, False]   # components to be initialized (for scalar fields: no list)
                 b2 : [False, False, False] # components to be initialized (for scalar fields: no list)
             ms : [1] # poloidal mode numbers
             ns : [0] # toroidal mode numbers
-            amp : [0.001] # amplitudes
+            amps : [0.001] # amplitudes
             pfuns : ['sin'] # profile function in eta1-direction ('sin' or 'exp')
             pfun_params : [null] # Provides [r_0, sigma] parameters for each "exp" profile fucntion, and null for "sin"
 
 solvers :
     solver_1 : 
         type : PConjugateGradient
         pc : MassMatrixPreconditioner # null or name of preconditioner class
```

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/params_maxwell_2.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/params_maxwell_2.yml`

 * *Files 0% similar despite different names*

```diff
@@ -31,15 +31,15 @@
         TorusModesSin : 
             coords : 'logical' # in which coordinates (logical or physical)
             comps :
                 e1 : [True, True, False]   # components to be initialized (for scalar fields: no list)
                 b2 : [False, False, False] # components to be initialized (for scalar fields: no list)
             ms : [3] # poloidal mode numbers
             ns : [1] # toroidal mode numbers
-            amp : [0.001] # amplitudes
+            amps : [0.001] # amplitudes
             pfuns : ['sin'] # profile function in eta1-direction ('sin' or 'exp')
             pfun_params : [null] # Provides [r_0, sigma] parameters for each "exp" profile fucntion, and null for "sin"
 
 solvers :
     solver_1 : 
         type : PConjugateGradient
         pc : MassMatrixPreconditioner # null or name of preconditioner class
```

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/strscl.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/strscl.yml`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/wkscl_1.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/wkscl_1.yml`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/wkscl_2.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/wkscl_2.yml`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/wkscl_3.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/wkscl_3.yml`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/wkscl_4.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/wkscl_4.yml`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/wkscl_5.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/wkscl_5.yml`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/wkscl_6.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/wkscl_6.yml`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/wkscl_7.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/wkscl_7.yml`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/io/inp/tests/wkscl_8.yml` & `struphy-2.0.2/src/struphy/io/inp/tests/wkscl_8.yml`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/kinetic_background/background_eval.py` & `struphy-2.0.2/src/struphy/kinetic_background/background_eval.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/kinetic_background/base.py` & `struphy-2.0.2/src/struphy/kinetic_background/base.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/kinetic_background/f0_kernels.py` & `struphy-2.0.2/src/struphy/kinetic_background/f0_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/kinetic_background/maxwellians.py` & `struphy-2.0.2/src/struphy/kinetic_background/maxwellians.py`

 * *Files 2% similar despite different names*

```diff
@@ -16,29 +16,31 @@
                       - \frac{(v_2 - u_2)^2}{2v_{\mathrm{th},2}^2}
                       - \frac{(v_3 - u_3)^2}{2v_{\mathrm{th},3}^2}\right].
 
     Parameters
     ----------
     **params
         Keyword arguments (n= , u1=, etc.) defining the moments of the 6d Maxwellian.
-        
+
     Note
     ----
     In the parameter .yml, use the following in the section ``kinetic/<species>``::
 
         init :
             type : Maxwellian6DUniform
             Maxwellian6DUniform :
                 n : 1.0
                 u1 : 0.0
                 u2 : 0.0
                 u3 : 0.0
                 vth1 : 1.0
                 vth2 : 1.0
                 vth3 : 1.0
+
+    Can use ``background :`` instead of ``init :``.
     """
 
     def __init__(self, **params):
 
         # default parameters
         params_default = {'n': 1.,
                           'u1': 0.,
@@ -123,28 +125,28 @@
     r"""
     6d Maxwellian distribution function defined on :math:`[0, 1]^3 \times \mathbb R^3`, 
     with logical position and Cartesian velocity coordinates, with sin/cos perturbed velocity moments.
 
     .. math::
 
         f(\boldsymbol{\eta}, \mathbf v) = \frac{n(\boldsymbol{\eta})}{(2\pi)^{3/2}(v_{\mathrm{th},x}\,v_{\mathrm{th},y}\,v_{\mathrm{th},z})(\boldsymbol{\eta})}\,\exp\left[-\frac{(v_x-u_x(\boldsymbol{\eta}))^2}{2v_{\mathrm{th},x}(\boldsymbol{\eta})^2}-\frac{(v_y-u_y(\boldsymbol{\eta}))^2}{2v_{\mathrm{th},y}(\boldsymbol{\eta})^2}-\frac{(v_z-u_z(\boldsymbol{\eta}))^2}{2v_{\mathrm{th},z}(\boldsymbol{\eta})^2}\right]\,, 
-        
+
     with perturbations of the form
-    
+
     .. math::
-    
+
         n(\boldsymbol{\eta})= n_0 + \sum_i\left\lbrace A_i\sin\left[2\pi(l_i\,\eta_1+m_i\,\eta_2+n_i\,\eta_3)\right] + B_i\cos\left[2\pi(l_i\,\eta_1+m_i\,\eta_2+n_i\,\eta_3)\right] \right\rbrace\,,
 
     and similarly for the other moments :math:`u_x(\boldsymbol{\eta}),u_y(\boldsymbol{\eta})`, etc.
 
     Parameters
     ----------
     **params
         Keyword arguments defining the moments of the 6d Maxwellian. For each moment, a dictionary of the form {'n0' : float, 'perturbation' : {'l' : list, 'm' : list, 'n' : list, 'amps_sin' : list, 'amps_cos' : list}} must be passed.
-    
+
     Note
     ----
     In the parameter .yml, use the following in the section ``kinetic/<species>``::
 
         init :
             type : Maxwellian6DPerturbed
             Maxwellian6DPerturbed :
@@ -164,14 +166,16 @@
                     u30 : 0.
                 vth1 :
                     vth10 : 1.
                 vth2 :
                     vth20 : 1.
                 vth3 :
                     vth30 : 1.
+
+    Can use ``background :`` instead of ``init :``.
     """
 
     def __init__(self, **params):
 
         moment_keys = ['n', 'u1', 'u2', 'u3', 'vth1', 'vth2', 'vth3']
 
         backgr_keys = ['n0', 'u01', 'u02', 'u03', 'vth01', 'vth02', 'vth03']
@@ -431,28 +435,30 @@
 
         n(\eta_1) = c_3\exp\left[-\frac{c_2}{c_1}\tanh\left(\frac{\eta_1 - c_0}{c_2}\right)\right]\,.
 
     Parameters
     ----------
     **params
         Keyword arguments defining the moments of the 6d Maxwellian. For the density profile a dictionary of the form {'c0' : float, 'c1' : float, 'c2' : float, 'c3' : float} must be passed.
-    
+
     Note
     ----
     In the parameter .yml, use the following in the section ``kinetic/<species>``::
 
         init :
             type : Maxwellian6DITPA
             Maxwellian6DITPA :
                 n : 
                     c0: 0.5
                     c1: 0.5
                     c2: 0.5
                     c3: 0.5
                 vth : 1.0
+
+    Can use ``background :`` instead of ``init :``.
     """
 
     def __init__(self, **params):
 
         # set default ITPA default parameters if not given
         if 'n' not in params.keys():
             params['n'] = {}
@@ -557,27 +563,29 @@
 
         f(v_\parallel, v_\perp) = \frac{n}{2\pi\,v_{\mathrm{th},\parallel}\,v_{\mathrm{th},\perp}}\exp\left[-\frac{(v_\parallel-u_\parallel)^2}{2v_{\mathrm{th},\parallel}^2} - \frac{(v_\perp-u_\perp)^2}{2v_{\mathrm{th},\perp}^2}\right]\,.
 
     Parameters
     ----------
     **params
         Keyword arguments (n= , u_parallel=, etc.) defining the moments of the 6d Maxwellian.
-        
+
     Note
     ----
     In the parameter .yml, use the following in the section ``kinetic/<species>``::
 
         init :
             type : Maxwellian5DUniform
             Maxwellian5DUniform :
                 n : 1.0
                 u_parallel : 0.0
                 u_perp : 0.0
                 vth_parallel : 1.0
                 vth_perp : 1.0
+
+    Can use ``background :`` instead of ``init :``.
     """
 
     def __init__(self, **params):
 
         # default parameters
         params_default = {'n': 1.,
                           'u_parallel': 0.,
```

### Comparing `struphy-2.0.1/src/struphy/kinetic_background/moments_kernels.py` & `struphy-2.0.2/src/struphy/kinetic_background/moments_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/linear_algebra/core.py` & `struphy-2.0.2/src/struphy/linear_algebra/core.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/linear_algebra/iterative_solvers.py` & `struphy-2.0.2/src/struphy/linear_algebra/iterative_solvers.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/linear_algebra/linalg_kron.py` & `struphy-2.0.2/src/struphy/linear_algebra/linalg_kron.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/linear_algebra/schur_solver.py` & `struphy-2.0.2/src/struphy/linear_algebra/schur_solver.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/linear_algebra/stencil_dot_kernels.py` & `struphy-2.0.2/src/struphy/linear_algebra/stencil_dot_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/linear_algebra/stencil_transpose_kernels.py` & `struphy-2.0.2/src/struphy/linear_algebra/stencil_transpose_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/models/base.py` & `struphy-2.0.2/src/struphy/models/base.py`

 * *Files 4% similar despite different names*

```diff
@@ -33,14 +33,19 @@
     ----
     All Struphy models are subclasses of ``StruphyModel`` and should be added to ``struphy/models/models.py``.  
     """
 
     def __init__(self, params, comm, **species):
 
         from struphy.models.setup import setup_domain_mhd, setup_electric_background, setup_derham
+
+        from struphy.polar.basic import PolarVector
+        from struphy.propagators.base import Propagator
+        from struphy.propagators import propagators_fields, propagators_coupling, propagators_markers
+        from struphy.psydac_api.basis_projection_ops import BasisProjectionOperators
         from struphy.psydac_api.mass import WeightedMassOperators
 
         self._params = params
         self._comm = comm
         self._species = species
 
         # initialize model variable dictionaries
@@ -76,76 +81,92 @@
             params['grid'], comm=comm, domain=self.domain, mpi_dims_mask=dims_mask)
 
         # create weighted mass operators
         self._mass_ops = WeightedMassOperators(
             self.derham, self.domain, eq_mhd=self.mhd_equil)
 
         # allocate memory for variables
+        self._pointer = {}
         self._allocate_variables()
 
         # store plasma parameters
         if comm.Get_rank() == 0:
             self._pparams = self.print_plasma_params()
             print('\nOPERATOR ASSEMBLY:')
         else:
             self._pparams = self.print_plasma_params(verbose=False)
 
+        # expose propagator modules
+        self._prop = Propagator
+        self._prop_fields = propagators_fields
+        self._prop_coupling = propagators_coupling
+        self._prop_markers = propagators_markers
+
+        # set propagators base class attributes (available to all propagators)
+        self.prop.derham = self.derham
+        self.prop.domain = self.domain
+        self.prop.mass_ops = self.mass_ops
+        self.prop.basis_ops = BasisProjectionOperators(
+            self.derham, self.domain, eq_mhd=self.mhd_equil)
+
+        self._propagators = []
+        self._scalar_quantities = {}
+
     @classmethod
     @abstractmethod
     def bulk_species(cls):
         '''Name of the bulk species of the plasma. Must be a key of self.fluid or self.kinetic, or None.'''
         pass
 
     @classmethod
     @abstractmethod
     def timescale(cls):
         '''String that sets the time scale unit of the model. 
         Must be one of "alfvn", "cyclotron" or "light".'''
         pass
 
-    @property
-    @abstractmethod
-    def propagators(self):
-        '''List of :ref:`propagators` used in the time stepping of the model.'''
-        pass
-
-    @property
-    @abstractmethod
-    def scalar_quantities(self):
-        '''Dictionary of scalar quantities to be saved during simulation. 
-        Must be initialized as empty np.array of size 1::
-
-        The time series self._scalar_quantities['time'] = np.empty(1, dtype=float) must be contained.'''
-        pass
-
     @abstractmethod
     def update_scalar_quantities(self):
-        ''' Specify an update rule for each item in scalar_quantities.
+        ''' Specify an update rule for each item in scalar_quantities using :meth:`update_scalar`.
         '''
         pass
 
     @property
     def params(self):
         '''Model parameters from :code:`parameters.yml`.'''
         return self._params
 
     @property
     def pparams(self):
         '''Plasma parameters for each species.'''
         return self._pparams
 
     @property
+    def eq_params(self):
+        '''Parameters appearing in model equation due to Struphy normalization.
+        '''
+        return self._eq_params
+
+    @property
     def comm(self):
         '''MPI communicator.'''
         return self._comm
 
     @property
     def species(self):
         '''Species dictionary.'''
         return self._species
+    
+    @property
+    def pointer(self):
+        '''Dictionary pointing to the data structures of the species (Stencil/BlockVector or "Particle" class).
+        
+        The keys are the keys from the "species" property. 
+        In case of a fluid species, the keys are like "species_variable".'''
+        return self._pointer
 
     @property
     def em_fields(self):
         '''Dictionary of electromagnetic field/potential variables.'''
         return self._em_fields
 
     @property
@@ -181,24 +202,85 @@
     @property
     def units(self):
         '''All Struphy units.
         '''
         return self._units
 
     @property
-    def eq_params(self):
-        '''Parameters appearing in model equation due to Struphy normalization.
-        '''
-        return self._eq_params
-
-    @property
     def mass_ops(self):
         '''WeighteMassOperators object, see :ref:`mass_ops`.'''
         return self._mass_ops
 
+    @property
+    def prop(self):
+        '''Class :class:`struphy.propagators.base.Propagator`.'''
+        return self._prop
+
+    @property
+    def prop_fields(self):
+        '''Module :mod:`struphy.propagators.propagators_fields`.'''
+        return self._prop_fields
+
+    @property
+    def prop_coupling(self):
+        '''Module :mod:`struphy.propagators.propagators_coupling`.'''
+        return self._prop_coupling
+
+    @property
+    def prop_markers(self):
+        '''Module :mod:`struphy.propagators.propagators_markers`.'''
+        return self._prop_markers
+
+    @property
+    def propagators(self):
+        '''A list of propagator instances for the model.'''
+        return self._propagators
+
+    @property
+    def scalar_quantities(self):
+        '''A dictionary of scalar quantities to be saved during the simulation.'''
+        return self._scalar_quantities
+
+    def add_propagator(self, prop_instance):
+        '''Add a propagator to a Struphy model.
+
+        Parameters
+        ----------
+            prop_instance : obj
+                An instance of :class:`struphy.propagator.base.Propagator`.
+        '''
+        assert isinstance(prop_instance, self.prop)
+        self._propagators += [prop_instance]
+
+    def add_scalar(self, name):
+        '''Add a scalar that should be saved during the simulation.
+
+        Parameters
+        ----------
+            name : str
+                Dictionary key of the scalar.
+        '''
+        assert isinstance(name, str)
+        self._scalar_quantities[name] = np.empty(1, dtype=float)
+
+    def update_scalar(self, name, value):
+        '''Add a scalar that should be saved during the simulation.
+
+        Parameters
+        ----------
+            name : str
+                Dictionary key of the scalar.
+
+            value : float
+                Value to be saved.
+        '''
+        assert isinstance(name, str)
+        assert isinstance(value, float)
+        self._scalar_quantities[name][0] = value
+
     def integrate(self, dt, split_algo='LieTrotter'):
         """
         Advance the model by a time step dt.
 
         Parameters
         ----------
         dt : float
@@ -285,30 +367,54 @@
         if len(self.em_fields) > 0:
 
             for key, val in self.em_fields.items():
                 if 'params' not in key:
                     val['obj'].initialize_coeffs(
                         self.em_fields['params']['init'], domain=self.domain)
 
+                    if self.comm.Get_rank() == 0:
+                        _type = self.em_fields['params']['init']['type']
+                        print(f'EM field "{key}" was initialized with:')
+                        print('type:'.ljust(25), _type)
+                        if _type is not None:
+                            for key, val in self.em_fields['params']['init'][_type].items():
+                                print((key + ':').ljust(25), val)
+
         # initialize fields
         if len(self.fluid) > 0:
 
-            for val in self.fluid.values():
+            for species, val in self.fluid.items():
 
                 for variable, subval in val.items():
                     if 'params' not in variable:
                         subval['obj'].initialize_coeffs(
                             val['params']['init'], domain=self.domain)
 
+                if self.comm.Get_rank() == 0:
+                    _type = val['params']['init']['type']
+                    print(f'Fluid species "{species}" was initialized with:')
+                    print('type:'.ljust(25), _type)
+                    if _type is not None:
+                        for key, val in val['params']['init'][_type].items():
+                            print((key + ':').ljust(25), val)
+
         # initialize particles
         if len(self.kinetic) > 0:
 
-            for val in self.kinetic.values():
-                val['obj'].draw_markers()
+            for species, val in self.kinetic.items():
 
+                if self.comm.Get_rank() == 0:
+                    _type = val['params']['init']['type']
+                    print(f'Kinetic species "{species}" was initialized with:')
+                    print('type:'.ljust(25), _type)
+                    if _type is not None:
+                        for key, par in val['params']['init'][_type].items():
+                            print((key + ':').ljust(25), par)
+
+                val['obj'].draw_markers()
                 val['obj'].mpi_sort_markers(do_test=True)
 
                 typ = val['params']['markers']['type']
                 if typ == 'full_f':
                     val['obj'].initialize_weights(val['params']['init'])
                 elif typ == 'delta_f':
                     val['obj'].initialize_weights(val['params']['init'])
@@ -705,25 +811,29 @@
         # allocate memory for FE coeffs of electromagnetic fields/potentials
         if 'em_fields' in self.params:
 
             for key, val in self.em_fields.items():
 
                 if 'params' not in key:
                     val['obj'] = Field(key, val['space'], self.derham)
+                    
+                    self._pointer[key] = val['obj'].vector
 
         # allocate memory for FE coeffs of fluid variables
         if 'fluid' in self.params:
 
             for species, val in self.fluid.items():
 
                 for variable, subval in val.items():
 
                     if 'params' not in variable:
                         subval['obj'] = Field(
                             variable, subval['space'], self.derham)
+                        
+                        self._pointer[species + '_' + variable] = subval['obj'].vector
 
         # marker arrays and plasma parameters of kinetic species
         if 'kinetic' in self.params:
 
             for species, val in self.kinetic.items():
 
                 if self.params['kinetic'][species]['markers']['type'] in ['control_variate', 'delta_f']:
@@ -736,14 +846,16 @@
                                            **val['params']['phys_params'],
                                            **val['params']['markers'],
                                            comm=self.derham.comm,
                                            domain_array=self.derham.domain_array,
                                            domain=self.domain,
                                            mhd_equil=self.mhd_equil,
                                            units_basic=self.units)
+                
+                self._pointer[species] = val['obj']
 
                 # for storing markers
                 n_markers = val['params']['save_data']['n_markers']
                 assert n_markers <= val['obj'].n_mks
                 if n_markers > 0:
                     val['kinetic_data'] = {}
                     val['kinetic_data']['markers'] = np.zeros(
@@ -933,15 +1045,16 @@
                 tmp = getattr(maxwellians, tmp_type)(**tmp_params)
 
                 # density (m)
                 pparams[species]['density'] = np.mean(tmp.n(
                     eta1mg, eta2mg, eta3mg) * np.abs(det_tmp)) * units['x']**3 / plasma_volume * units['n']
                 # thermal speeds (m/s)
                 vth = tmp.vth(eta1mg, eta2mg, eta3mg) * \
-                    np.abs(det_tmp) * units['x']**3 / plasma_volume * units['v']
+                    np.abs(det_tmp) * units['x']**3 / \
+                    plasma_volume * units['v']
                 thermal_speed = 0.
                 for dir in range(val['obj'].vdim):
                     pparams[species]['vth' + str(dir + 1)] = np.mean(vth[dir])
                     thermal_speed += pparams[species]['vth' + str(dir + 1)]
                 # TODO: here it is assumed that background density parameter is called "n",
                 # and that background thermal speeds are called "vthn"; make this a convention?
                 pparams[species]['v_th'] = thermal_speed / \
```

### Comparing `struphy-2.0.1/src/struphy/models/hybrid.py` & `struphy-2.0.2/src/struphy/models/hybrid.py`

 * *Files 22% similar despite different names*

```diff
@@ -73,38 +73,27 @@
 
         if u_space == 'Hdiv':
             u_name = 'u2'
         else:
             u_name = 'uv'
 
         self._u_space = u_space
+        self._un = 'mhd_' + u_name
 
         # initialize base class
         super().__init__(params, comm,
                          b2='Hdiv',
                          mhd={'n3': 'L2', u_name: self._u_space, 'p3': 'L2'},
                          energetic_ions='Particles6D')
 
         from struphy.polar.basic import PolarVector
-        from struphy.propagators.base import Propagator
-        from struphy.propagators import propagators_fields, propagators_coupling, propagators_markers
         from struphy.kinetic_background import maxwellians as kin_ana
-        from struphy.psydac_api.basis_projection_ops import BasisProjectionOperators
         from mpi4py.MPI import SUM, IN_PLACE
 
-        # pointers to em-field variables
-        self._b = self.em_fields['b2']['obj'].vector
-
-        # pointers to fluid variables
-        self._n = self.fluid['mhd']['n3']['obj'].vector
-        self._u = self.fluid['mhd'][u_name]['obj'].vector
-        self._p = self.fluid['mhd']['p3']['obj'].vector
-
-        # pointer to energetic ions
-        self._e_ions = self.kinetic['energetic_ions']['obj']
+        # prelim
         e_ions_params = self.kinetic['energetic_ions']['params']
 
         # extract necessary parameters
         solver_params_1 = params['solvers']['solver_1']
         solver_params_2 = params['solvers']['solver_2']
         solver_params_3 = params['solvers']['solver_3']
         solver_params_4 = params['solvers']['solver_4']
@@ -145,135 +134,121 @@
         else:
             self._ones[:] = 1.
 
         # add control variate to mass_ops object
         if control:
             self.mass_ops.weights['f0'] = f0
 
-        # set propagators base class attributes (available to all propagators)
-        Propagator.derham = self.derham
-        Propagator.domain = self.domain
-        Propagator.mass_ops = self.mass_ops
-        Propagator.basis_ops = BasisProjectionOperators(
-            self.derham, self.domain, eq_mhd=self.mhd_equil)
-
         # Initialize propagators/integrators used in splitting substeps
-        self._propagators = []
-
-        # updates u
-        self._propagators += [propagators_fields.CurrentCoupling6DDensity(
-            self._u,
-            particles=self._e_ions,
+        self.add_propagator(self.prop_fields.CurrentCoupling6DDensity(
+            self.pointer[self._un],
+            particles=self.pointer['energetic_ions'],
             u_space=self._u_space,
             b_eq=self._b_eq,
-            b_tilde=self._b,
+            b_tilde=self.pointer['b2'],
             f0=f0,
             **solver_params_1,
-            **self._coupling_params)]
-
-        # updates u and b
-        self._propagators += [propagators_fields.ShearAlfvn(
-            self._u,
-            self._b,
-            u_space=self._u_space,
-            **solver_params_2)]
-
-        # updates u and v (and weights for control variate)
-        self._propagators += [propagators_coupling.CurrentCoupling6DCurrent(
-            self._e_ions,
-            self._u,
+            **self._coupling_params))
+        self.add_propagator(self.prop_fields.ShearAlfvn(
+            self.pointer[self._un],
+            self.pointer['b2'],
+            u_space=self._u_space,
+            **solver_params_2))
+        self.add_propagator(self.prop_coupling.CurrentCoupling6DCurrent(
+            self.pointer['energetic_ions'],
+            self.pointer[self._un],
             u_space=self._u_space,
             b_eq=self._b_eq,
-            b_tilde=self._b,
+            b_tilde=self.pointer['b2'],
             f0=f0,
             **solver_params_3,
-            **self._coupling_params)]
-
-        # updates eta (and weights for control variate)
-        self._propagators += [propagators_markers.PushEta(
-            self._e_ions,
+            **self._coupling_params))
+        self.add_propagator(self.prop_markers.PushEta(
+            self.pointer['energetic_ions'],
             algo=e_ions_params['push_algos']['eta'],
             bc_type=e_ions_params['markers']['bc_type'],
-            f0=f0)]
-
-        # updates v (and weights for control variate)
-        self._propagators += [propagators_markers.PushVxB(
-            self._e_ions,
+            f0=f0))
+        self.add_propagator(self.prop_markers.PushVxB(
+            self.pointer['energetic_ions'],
             algo=e_ions_params['push_algos']['vxb'],
             scale_fac=self._coupling_params['kappa'],
             b_eq=self._b_eq,
-            b_tilde=self._b,
-            f0=f0)]
-
-        # updates u and p
-        self._propagators += [propagators_fields.Magnetosonic(
-            self._n,
-            self._u,
-            self._p,
+            b_tilde=self.pointer['b2'],
+            f0=f0))
+        self.add_propagator(self.prop_fields.Magnetosonic(
+            self.pointer['mhd_n3'],
+            self.pointer[self._un],
+            self.pointer['mhd_p3'],
             u_space=self._u_space,
-            b=self._b,
-            **solver_params_4)]
+            b=self.pointer['b2'],
+            **solver_params_4))
 
         # Scalar variables to be saved during simulation:
-        self._scalar_quantities = {}
+        self.add_scalar('en_U')
+        self.add_scalar('en_p')
+        self.add_scalar('en_B')
+        self.add_scalar('en_f')
+        self.add_scalar('en_B_tot')
+        self.add_scalar('en_tot')
+
+        # temporary vectors for scalar quantities
+        if self._u_space == 'Hdiv':
+            self._tmp_u = self.derham.Vh['2'].zeros()
+        else:
+            self._tmp_u = self.derham.Vh['v'].zeros()
 
-        self._scalar_quantities['en_U'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_p'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_B'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_f'] = np.empty(1, dtype=float)
-        # self._scalar_quantities['en_p_eq'] = np.empty(1, dtype=float)
-        # self._scalar_quantities['en_B_eq'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_B_tot'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_tot'] = np.empty(1, dtype=float)
+        self._tmp_b1 = self.derham.Vh['2'].zeros()
+        self._tmp_b2 = self.derham.Vh['2'].zeros()
+        self._tmp = np.empty(1, dtype=float)
 
         # MPI operations needed for scalar variables
         self._mpi_sum = SUM
         self._mpi_in_place = IN_PLACE
 
-    @property
-    def propagators(self):
-        return self._propagators
-
-    @property
-    def scalar_quantities(self):
-        return self._scalar_quantities
-
     def update_scalar_quantities(self):
 
+        # perturbed fields
         if self._u_space == 'Hdiv':
-            self._scalar_quantities['en_U'][0] = self._u.dot(
-                self._mass_ops.M2n.dot(self._u))/2
+            self._mass_ops.M2n.dot(self.pointer[self._un], out=self._tmp_u)
         else:
-            self._scalar_quantities['en_U'][0] = self._u.dot(
-                self._mass_ops.Mvn.dot(self._u))/2
+            self._mass_ops.Mvn.dot(self.pointer[self._un], out=self._tmp_u)
 
-        self._scalar_quantities['en_p'][0] = self._p.dot(self._ones)/(5/3 - 1)
-        self._scalar_quantities['en_B'][0] = self._b.dot(
-            self._mass_ops.M2.dot(self._b))/2
+        self._mass_ops.M2.dot(self.pointer['b2'], out=self._tmp_b1)
 
-        # self._scalar_quantities['en_p_eq'][0] = self._p_eq.dot(
-        #     self._ones)/(5/3 - 1)
-        # self._scalar_quantities['en_B_eq'][0] = self._b_eq.dot(
-        #     self._mass_ops.M2.dot(self._b_eq, apply_bc=False))/2
+        en_U = self.pointer[self._un].dot(self._tmp_u)/2
+        en_B = self.pointer['b2'].dot(self._tmp_b1)/2
+        en_p = self.pointer['mhd_p3'].dot(self._ones)/(5/3 - 1)
+
+        self.update_scalar('en_U', en_U)
+        self.update_scalar('en_B', en_B)
+        self.update_scalar('en_p', en_p)
+
+        # total magnetic field
+        self._mass_ops.M2.dot(self._b_eq, apply_bc=False, out=self._tmp_b1)
+
+        self._b_eq.copy(out=self._tmp_b1)
+        self._tmp_b1 += self.pointer['b2']
+
+        self._mass_ops.M2.dot(self._tmp_b1, apply_bc=False, out=self._tmp_b2)
+
+        en_Btot = self._tmp_b1.dot(self._tmp_b2)/2
 
-        self._scalar_quantities['en_B_tot'][0] = (
-            self._b_eq + self._b).dot(self._mass_ops.M2.dot(self._b_eq + self._b, apply_bc=False))/2
+        self.update_scalar('en_B_tot', en_Btot)
 
-        self._scalar_quantities['en_f'][0] = self._coupling_params['Ah']/self._coupling_params['Ab']*self._e_ions.markers_wo_holes[:, 6].dot(
-            self._e_ions.markers_wo_holes[:, 3]**2 +
-            self._e_ions.markers_wo_holes[:, 4]**2 +
-            self._e_ions.markers_wo_holes[:, 5]**2)/(2*self._e_ions.n_mks)
+        # particles
+        self._tmp[0] = self._coupling_params['Ah']/self._coupling_params['Ab']*self.pointer['energetic_ions'].markers_wo_holes[:, 6].dot(
+            self.pointer['energetic_ions'].markers_wo_holes[:, 3]**2 +
+            self.pointer['energetic_ions'].markers_wo_holes[:, 4]**2 +
+            self.pointer['energetic_ions'].markers_wo_holes[:, 5]**2)/(2*self.pointer['energetic_ions'].n_mks)
 
         self.derham.comm.Allreduce(
-            self._mpi_in_place, self._scalar_quantities['en_f'], op=self._mpi_sum)
+            self._mpi_in_place, self._tmp, op=self._mpi_sum)
 
-        self._scalar_quantities['en_tot'][0] = self._scalar_quantities['en_U'][0]
-        self._scalar_quantities['en_tot'][0] += self._scalar_quantities['en_p'][0]
-        self._scalar_quantities['en_tot'][0] += self._scalar_quantities['en_B'][0]
-        self._scalar_quantities['en_tot'][0] += self._scalar_quantities['en_f'][0]
+        self.update_scalar('en_f', self._tmp[0])
+        self.update_scalar('en_tot', en_U + en_B + en_p + self._tmp[0])
 
 
 class LinearMHDVlasovPC(StruphyModel):
     r'''Hybrid (Linear ideal MHD + Full-orbit Vlasov) equations with **pressure coupling scheme**. 
 
     :ref:`normalization`:
 
@@ -349,38 +324,27 @@
 
         if u_space == 'Hdiv':
             u_name = 'u2'
         else:
             u_name = 'uv'
 
         self._u_space = u_space
+        self._un = 'mhd_' + u_name
 
         # initialize base class
         super().__init__(params, comm,
                          b2='Hdiv',
                          mhd={'n3': 'L2', u_name: self._u_space, 'p3': 'L2'},
                          energetic_ions='Particles6D')
 
         from struphy.polar.basic import PolarVector
-        from struphy.propagators.base import Propagator
-        from struphy.propagators import propagators_fields, propagators_coupling, propagators_markers
         from struphy.kinetic_background import maxwellians as kin_ana
-        from struphy.psydac_api.basis_projection_ops import BasisProjectionOperators
         from mpi4py.MPI import SUM, IN_PLACE
 
-        # pointers to em-field variables
-        self._b = self.em_fields['b2']['obj'].vector
-
-        # pointers to fluid variables
-        self._n = self.fluid['mhd']['n3']['obj'].vector
-        self._u = self.fluid['mhd'][u_name]['obj'].vector
-        self._p = self.fluid['mhd']['p3']['obj'].vector
-
-        # pointer to kinetic variables
-        self._e_ions = self.kinetic['energetic_ions']['obj']
+        # prelim
         ions_params = self.kinetic['energetic_ions']['params']
 
         # extract necessary parameters
         solver_params_1 = params['solvers']['solver_1']
         solver_params_2 = params['solvers']['solver_2']
         solver_params_3 = params['solvers']['solver_3']
 
@@ -420,122 +384,111 @@
         else:
             self._ones[:] = 1.
 
         # add control variate to mass_ops object
         if control:
             self.mass_ops.weights['f0'] = f0
 
-        # set propagators base class attributes (available to all propagators)
-        Propagator.derham = self.derham
-        Propagator.domain = self.domain
-        Propagator.mass_ops = self.mass_ops
-        Propagator.basis_ops = BasisProjectionOperators(
-            self.derham, self.domain, eq_mhd=self.mhd_equil)
-
         # Initialize propagators/integrators used in splitting substeps
-        self._propagators = []
-
-        # updates u and b
-        self._propagators += [propagators_fields.ShearAlfvn(
-            self._u,
-            self._b,
-            u_space=self._u_space,
-            **solver_params_1,)]
-
-        self._propagators += [propagators_coupling.PressureCoupling6D(
-            self._e_ions,
-            self._u,
+        self.add_propagator(self.prop_fields.ShearAlfvn(
+            self.pointer[self._un],
+            self.pointer['b2'],
+            u_space=self._u_space,
+            **solver_params_1,))
+        self.add_propagator(self.prop_coupling.PressureCoupling6D(
+            self.pointer['energetic_ions'],
+            self.pointer[self._un],
             u_space=self._u_space,
             use_perp_model=ions_params['use_perp_model'],
             **solver_params_2,
-            **self._coupling_params)]
-
-        # updates eta
-        self._propagators += [propagators_markers.PushEtaPC(
-            self._e_ions,
-            u_mhd=self._u,
+            **self._coupling_params))
+        self.add_propagator(self.prop_markers.PushEtaPC(
+            self.pointer['energetic_ions'],
+            u_mhd=self.pointer[self._un],
             u_space=self._u_space,
             bc_type=ions_params['markers']['bc_type'],
-            use_perp_model=ions_params['use_perp_model'])]
-
-        # updates v
-        self._propagators += [propagators_markers.PushVxB(
-            self._e_ions,
+            use_perp_model=ions_params['use_perp_model']))
+        self.add_propagator(self.prop_markers.PushVxB(
+            self.pointer['energetic_ions'],
             algo=ions_params['push_algos']['vxb'],
             scale_fac=self._coupling_params['kappa'],
             b_eq=self._b_eq,
-            b_tilde=self._b,
-            f0=f0)]
-
-        # updates u and p
-        self._propagators += [propagators_fields.Magnetosonic(
-            self._n,
-            self._u,
-            self._p,
+            b_tilde=self.pointer['b2'],
+            f0=f0))
+        self.add_propagator(self.prop_fields.Magnetosonic(
+            self.pointer['mhd_n3'],
+            self.pointer[self._un],
+            self.pointer['mhd_p3'],
             u_space=self._u_space,
-            b=self._b,
-            **solver_params_3)]
+            b=self.pointer['b2'],
+            **solver_params_3))
 
         # Scalar variables to be saved during simulation:
-        self._scalar_quantities = {}
+        self.add_scalar('en_U')
+        self.add_scalar('en_p')
+        self.add_scalar('en_B')
+        self.add_scalar('en_f')
+        self.add_scalar('en_B_tot')
+        self.add_scalar('en_tot')
+
+        # temporary vectors for scalar quantities
+        if self._u_space == 'Hdiv':
+            self._tmp_u = self.derham.Vh['2'].zeros()
+        else:
+            self._tmp_u = self.derham.Vh['v'].zeros()
 
-        self._scalar_quantities['en_U'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_p'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_B'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_f'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_p_eq'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_B_eq'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_B_tot'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_tot'] = np.empty(1, dtype=float)
+        self._tmp_b1 = self.derham.Vh['2'].zeros()
+        self._tmp_b2 = self.derham.Vh['2'].zeros()
+        self._tmp = np.empty(1, dtype=float)
 
         # MPI operations needed for scalar variables
         self._mpi_sum = SUM
         self._mpi_in_place = IN_PLACE
 
-    @property
-    def propagators(self):
-        return self._propagators
-
-    @property
-    def scalar_quantities(self):
-        return self._scalar_quantities
-
     def update_scalar_quantities(self):
 
+        # perturbed fields
         if self._u_space == 'Hdiv':
-            self._scalar_quantities['en_U'][0] = self._u.dot(
-                self._mass_ops.M2n.dot(self._u))/2
+            self._mass_ops.M2n.dot(self.pointer[self._un], out=self._tmp_u)
         else:
-            self._scalar_quantities['en_U'][0] = self._u.dot(
-                self._mass_ops.Mvn.dot(self._u))/2
+            self._mass_ops.Mvn.dot(self.pointer[self._un], out=self._tmp_u)
+
+        self._mass_ops.M2.dot(self.pointer['b2'], out=self._tmp_b1)
+
+        en_U = self.pointer[self._un].dot(self._tmp_u)/2
+        en_B = self.pointer['b2'].dot(self._tmp_b1)/2
+        en_p = self.pointer['mhd_p3'].dot(self._ones)/(5/3 - 1)
 
-        self._scalar_quantities['en_p'][0] = self._p.dot(self._ones)/(5/3 - 1)
-        self._scalar_quantities['en_B'][0] = self._b.dot(
-            self._mass_ops.M2.dot(self._b))/2
-
-        self._scalar_quantities['en_p_eq'][0] = self._p_eq.dot(
-            self._ones)/(5/3 - 1)
-        self._scalar_quantities['en_B_eq'][0] = self._b_eq.dot(
-            self._mass_ops.M2.dot(self._b_eq, apply_bc=False))/2
-
-        self._scalar_quantities['en_B_tot'][0] = (
-            self._b_eq + self._b).dot(self._mass_ops.M2.dot(self._b_eq + self._b, apply_bc=False))/2
-
-        self._scalar_quantities['en_f'][0] = self._coupling_params['Ah']/self._coupling_params['Ab']*self._e_ions.markers_wo_holes[:, 6].dot(
-            self._e_ions.markers_wo_holes[:, 3]**2 +
-            self._e_ions.markers_wo_holes[:, 4]**2 +
-            self._e_ions.markers_wo_holes[:, 5]**2)/(2*self._e_ions.n_mks)
+        self.update_scalar('en_U', en_U)
+        self.update_scalar('en_B', en_B)
+        self.update_scalar('en_p', en_p)
+
+        # total magnetic field
+        self._mass_ops.M2.dot(self._b_eq, apply_bc=False, out=self._tmp_b1)
+
+        self._b_eq.copy(out=self._tmp_b1)
+        self._tmp_b1 += self.pointer['b2']
+
+        self._mass_ops.M2.dot(self._tmp_b1, apply_bc=False, out=self._tmp_b2)
+
+        en_Btot = self._tmp_b1.dot(self._tmp_b2)/2
+
+        self.update_scalar('en_B_tot', en_Btot)
+
+        # particles
+        self._tmp[0] = self._coupling_params['Ah']/self._coupling_params['Ab']*self.pointer['energetic_ions'].markers_wo_holes[:, 6].dot(
+            self.pointer['energetic_ions'].markers_wo_holes[:, 3]**2 +
+            self.pointer['energetic_ions'].markers_wo_holes[:, 4]**2 +
+            self.pointer['energetic_ions'].markers_wo_holes[:, 5]**2)/(2*self.pointer['energetic_ions'].n_mks)
 
         self.derham.comm.Allreduce(
-            self._mpi_in_place, self._scalar_quantities['en_f'], op=self._mpi_sum)
+            self._mpi_in_place, self._tmp, op=self._mpi_sum)
 
-        self._scalar_quantities['en_tot'][0] = self._scalar_quantities['en_U'][0]
-        self._scalar_quantities['en_tot'][0] += self._scalar_quantities['en_p'][0]
-        self._scalar_quantities['en_tot'][0] += self._scalar_quantities['en_B'][0]
-        self._scalar_quantities['en_tot'][0] += self._scalar_quantities['en_f'][0]
+        self.update_scalar('en_f', self._tmp[0])
+        self.update_scalar('en_tot', en_U + en_B + en_p + self._tmp[0])
 
 
 class LinearMHDDriftkineticCC(StruphyModel):
     r'''Hybrid (Linear ideal MHD + Driftkinetic) equations with **current coupling scheme**. 
 
     :ref:`normalization`: 
 
@@ -621,38 +574,27 @@
 
         if u_space == 'Hdiv':
             u_name = 'u2'
         else:
             u_name = 'uv'
 
         self._u_space = u_space
+        self._un = 'mhd_' + u_name
 
         # initialize base class
         super().__init__(params, comm,
                          b2='Hdiv',
                          mhd={'n3': 'L2', u_name: self._u_space, 'p3': 'L2'},
                          energetic_ions='Particles5D')
 
         from struphy.polar.basic import PolarVector
-        from struphy.propagators.base import Propagator
-        from struphy.propagators import propagators_fields, propagators_coupling, propagators_markers
         from struphy.kinetic_background import maxwellians as kin_ana
-        from struphy.psydac_api.basis_projection_ops import BasisProjectionOperators
-        from mpi4py.MPI import SUM
-
-        # pointers to em-field variables
-        self._b = self.em_fields['b2']['obj'].vector
-
-        # pointers to fluid variables
-        self._n = self.fluid['mhd']['n3']['obj'].vector
-        self._u = self.fluid['mhd'][u_name]['obj'].vector
-        self._p = self.fluid['mhd']['p3']['obj'].vector
+        from mpi4py.MPI import SUM, IN_PLACE
 
-        # pointer to kinetic variables
-        self._e_ions = self.kinetic['energetic_ions']['obj']
+        # prelim
         ions_params = self.kinetic['energetic_ions']['params']
 
         # extract necessary parameters
         solver_params_1 = params['solvers']['solver_1']
         solver_params_2 = params['solvers']['solver_2']
         solver_params_3 = params['solvers']['solver_3']
         solver_params_4 = params['solvers']['solver_4']
@@ -697,333 +639,389 @@
         self._ones = self._p_eq.space.zeros()
 
         # transposed extraction operator PolarVector --> BlockVector (identity map in case of no polar splines)
         self._E0T = self.derham.E['0'].transpose()
         self._EvT = self.derham.E['v'].transpose()
         self._E2T = self.derham.E['2'].transpose()
 
-        # temporary vectors to avoid memory allocation
-        self._b_full1 = self._b_eq.space.zeros()
-        self._b_full2 = self._E2T.codomain.zeros()
-        self._PBb1 = self._abs_b.space.zeros()
-        self._PBb2 = self._E0T.codomain.zeros()
-
         if isinstance(self._ones, PolarVector):
             self._ones.tp[:] = 1.
         else:
             self._ones[:] = 1.
 
         # add control variate to mass_ops object
         if control:
             self.mass_ops.weights['f0'] = f0
 
-        # set propagators base class attributes (available to all propagators)
-        Propagator.derham = self.derham
-        Propagator.domain = self.domain
-        Propagator.mass_ops = self.mass_ops
-        Propagator.basis_ops = BasisProjectionOperators(
-            self.derham, self.domain, eq_mhd=self.mhd_equil)
-
         # Initialize propagators/integrators used in splitting substeps
-        self._propagators = []
-        # # updates u and p
-        # self._propagators += [propagators_fields.MagnetosonicCurrentCoupling5D(
-        #     self._n,
-        #     self._u,
-        #     self._p,
-        #     b=self._b,
-        #     particles=self._e_ions,
-        #     unit_b1=self._unit_b1,
-        #     f0=f0,
-        #     u_space=self._u_space,
-        #     **solver_params_2,
-        #     **self._coupling_params)]
-
-        # update H
-        self._propagators += [propagators_markers.StepPushDriftKinetic1(
-            self._e_ions,
+        self.add_propagator(self.prop_markers.StepPushDriftKinetic1(
+            self.pointer['energetic_ions'],
             kappa=kappa,
-            b=self._b,
+            b=self.pointer['b2'],
             b_eq=self._b_eq,
             unit_b1=self._unit_b1,
             unit_b2=self._unit_b2,
             abs_b=self._abs_b,
-            integrator=ions_params['push_algos']['integrator'],
-            method='discrete_gradients',
-            maxiter=ions_params['push_algos']['maxiter'],
-            tol=ions_params['push_algos']['tol'])]
-
-        # update H and v parallel
-        self._propagators += [propagators_markers.StepPushDriftKinetic2(
-            self._e_ions,
+            integrator=ions_params['push_algos1']['integrator'],
+            method=ions_params['push_algos1']['method'],
+            maxiter=ions_params['push_algos1']['maxiter'],
+            tol=ions_params['push_algos1']['tol']))
+        self.add_propagator(self.prop_markers.StepPushDriftKinetic2(
+            self.pointer['energetic_ions'],
             kappa=kappa,
-            b=self._b,
+            b=self.pointer['b2'],
             b_eq=self._b_eq,
             unit_b1=self._unit_b1,
             unit_b2=self._unit_b2,
             abs_b=self._abs_b,
-            method='discrete_gradients_Itoh_Newton',
-            integrator=ions_params['push_algos']['integrator'],
-            maxiter=ions_params['push_algos']['maxiter'],
-            tol=ions_params['push_algos']['tol'])]
-        
-        # update u and H
-        self._propagators += [propagators_coupling.CurrentCoupling5DCurrent2(
-            self._e_ions,
-            self._u,
-            b=self._b,
+            integrator=ions_params['push_algos2']['integrator'],
+            method=ions_params['push_algos2']['method'],
+            maxiter=ions_params['push_algos2']['maxiter'],
+            tol=ions_params['push_algos2']['tol']))
+        self.add_propagator(self.prop_coupling.CurrentCoupling5DCurrent2(
+            self.pointer['energetic_ions'],
+            self.pointer[self._un],
+            b=self.pointer['b2'],
             b_eq=self._b_eq,
             unit_b1=self._unit_b1,
             unit_b2=self._unit_b2,
             abs_b=self._abs_b,
             f0=f0,
             u_space=self._u_space,
             **solver_params_4,
             **self._coupling_params,
             integrator='explicit',
-            method='rk4')]
-
-        # updates u and b
-        self._propagators += [propagators_fields.ShearAlfvnCurrentCoupling5D(
-            self._u,
-            self._b,
-            particles=self._e_ions,
+            method='rk4'))
+        self.add_propagator(self.prop_fields.ShearAlfvnCurrentCoupling5D(
+            self.pointer[self._un],
+            self.pointer['b2'],
+            particles=self.pointer['energetic_ions'],
             b_eq=self._b_eq,
             f0=f0,
             u_space=self._u_space,
             **solver_params_1,
-            **self._coupling_params)]
-        
-        # update u and v parallel
-        self._propagators += [propagators_coupling.CurrentCoupling5DCurrent1(
-            self._e_ions,
-            self._u,
-            b=self._b,
+            **self._coupling_params))
+        self.add_propagator(self.prop_coupling.CurrentCoupling5DCurrent1(
+            self.pointer['energetic_ions'],
+            self.pointer[self._un],
+            b=self.pointer['b2'],
             b_eq=self._b_eq,
             unit_b1=self._unit_b1,
             f0=f0,
             u_space=self._u_space,
             **solver_params_3,
-            **self._coupling_params)]
-
-        # update u
-        self._propagators += [propagators_fields.CurrentCoupling5DDensity(
-            self._u,
-            particles=self._e_ions,
-            u_space=self._u_space,
-            b_eq=self._b_eq,
-            b_tilde=self._b,
-            f0=f0,
-            **solver_params_5,
-            **self._coupling_params)]
+            **self._coupling_params))
 
         # Scalar variables to be saved during simulation
-        self._scalar_quantities = {}
-        self._scalar_quantities['en_U'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_p'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_B'] = np.empty(1, dtype=float)
-        # self._scalar_quantities['en_p_eq'] = np.empty(1, dtype=float)
-        # self._scalar_quantities['en_B_eq'] = np.empty(1, dtype=float)
-        # self._scalar_quantities['en_B_tot'] = np.empty(1, dtype=float)
+        self.add_scalar('en_U')
+        self.add_scalar('en_p')
+        self.add_scalar('en_B')
+        self.add_scalar('en_fv')
+        self.add_scalar('en_fB')
+        self.add_scalar('en_fv_lost')
+        self.add_scalar('en_fB_lost')
+        self.add_scalar('en_tot')
+
+        # things needed in update_scalar_quantities
+        self._mpi_sum = SUM
+        self._mpi_in_place = IN_PLACE
+
+        # temporaries
+        self._b_full1 = self._b_eq.space.zeros()
+        self._b_full2 = self._E2T.codomain.zeros()
+        self._PBb1 = self._abs_b.space.zeros()
+        self._PBb2 = self._E0T.codomain.zeros()
+
         self._en_fv_loc = np.empty(1, dtype=float)
-        self._scalar_quantities['en_fv'] = np.empty(1, dtype=float)
         self._en_fB_loc = np.empty(1, dtype=float)
-        self._scalar_quantities['en_fB'] = np.empty(1, dtype=float)
         self._en_fv_loc_lost = np.empty(1, dtype=float)
-        self._scalar_quantities['en_fv_lost'] = np.empty(1, dtype=float)
         self._en_fB_loc_lost = np.empty(1, dtype=float)
-        self._scalar_quantities['en_fB_lost'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_tot'] = np.empty(1, dtype=float)
 
-        # things needed in update_scalar_quantities
-        self._mpi_sum = SUM
-        self._prop = Propagator
+        if self._u_space == 'Hcurl':
+            self._tmp_u = self.derham.Vh['1'].zeros()
+        elif self._u_space == 'Hdiv':
+            self._tmp_u = self.derham.Vh['2'].zeros()
+        else:
+            self._tmp_u = self.derham.Vh['v'].zeros()
 
-    @property
-    def propagators(self):
-        return self._propagators
-
-    @property
-    def scalar_quantities(self):
-        return self._scalar_quantities
+        self._tmp_b = self.derham.Vh['2'].zeros()
 
     def update_scalar_quantities(self):
 
         if self._u_space == 'Hcurl':
-            self._scalar_quantities['en_U'][0] = self._u.dot(
-                self._mass_ops.M1n.dot(self._u))/2
-
+            self._mass_ops.M1n.dot(self.pointer[self._un], out=self._tmp_u)
+            en_U = self.pointer[self._un].dot(self._tmp_u)/2
         elif self._u_space == 'Hdiv':
-            self._scalar_quantities['en_U'][0] = self._u.dot(
-                self._mass_ops.M2n.dot(self._u))/2
-
+            self._mass_ops.M2n.dot(self.pointer[self._un], out=self._tmp_u)
+            en_U = self.pointer[self._un].dot(self._tmp_u)/2
         else:
-            self._scalar_quantities['en_U'][0] = self._u.dot(
-                self._mass_ops.Mvn.dot(self._u))/2
+            self._mass_ops.Mvn.dot(self.pointer[self._un], out=self._tmp_u)
+            en_U = self.pointer[self._un].dot(self._tmp_u)/2
 
-        self._scalar_quantities['en_p'][0] = self._p.toarray().sum()/(5/3 - 1)
-        self._scalar_quantities['en_B'][0] = self._b.dot(
-            self._mass_ops.M2.dot(self._b))/2
+        en_p = self.pointer['mhd_p3'].toarray().sum()/(5/3 - 1)
+        self._mass_ops.M2.dot(self.pointer['b2'], out=self._tmp_b)
+        en_B = self.pointer['b2'].dot(self._tmp_b)/2
+
+        self.update_scalar('en_U', en_U)
+        self.update_scalar('en_p', en_p)
+        self.update_scalar('en_B', en_B)
 
         # self._scalar_quantities['en_p_eq'][0] = self._p_eq.dot(
         #     self._ones)/(5/3 - 1)
         # self._scalar_quantities['en_B_eq'][0] = self._b_eq.dot(
         #     self._mass_ops.M2.dot(self._b_eq, apply_bc=False))/2
 
         # calculate particle kinetic energy
-        self._en_fv_loc = self._e_ions.markers[~self._e_ions.holes, 5].dot(
-            self._e_ions.markers[~self._e_ions.holes, 3]**2) / (2*self._e_ions.n_mks)
-        self.derham.comm.Reduce(
-            self._en_fv_loc, self._scalar_quantities['en_fv'], op=self._mpi_sum, root=0)
-
-        self._en_fv_loc_lost = self._e_ions.lost_markers[:self._e_ions.n_lost_markers, 5].dot(
-            self._e_ions.lost_markers[:self._e_ions.n_lost_markers, 3]**2) / (2.*self._e_ions.n_mks)
-        self.derham.comm.Reduce(
-            self._en_fv_loc_lost, self._scalar_quantities['en_fv_lost'], op=self._mpi_sum, root=0)
+        self._en_fv_loc[0] = self.pointer['energetic_ions'].markers[~self.pointer['energetic_ions'].holes, 5].dot(
+            self.pointer['energetic_ions'].markers[~self.pointer['energetic_ions'].holes, 3]**2) / (2*self.pointer['energetic_ions'].n_mks)
+        self.derham.comm.Allreduce(
+            self._mpi_in_place, self._en_fv_loc, op=self._mpi_sum)
+
+        self.update_scalar('en_fv', self._en_fv_loc[0])
+
+        self._en_fv_loc_lost = self.pointer['energetic_ions'].lost_markers[:self.pointer['energetic_ions'].n_lost_markers, 5].dot(
+            self.pointer['energetic_ions'].lost_markers[:self.pointer['energetic_ions'].n_lost_markers, 3]**2) / (2.*self.pointer['energetic_ions'].n_mks)
+        self.derham.comm.Allreduce(
+            self._mpi_in_place, self._en_fv_loc_lost, op=self._mpi_sum)
 
+        self.update_scalar('en_fv_lost', self._en_fv_loc_lost[0])
 
         # sum up total magnetic field b_full1 = b_eq + b_tilde (in-place)
         self._b_eq.copy(out=self._b_full1)
-        self._b_full1 += self._b
+        self._b_full1 += self.pointer['b2']
         self._b_full1.update_ghost_regions()
 
         # self._scalar_quantities['en_B_tot'][0] = (self._b_full1).dot(
         #     self._mass_ops.M2.dot(self._b_full1, apply_bc=False))/2.
 
         # absolute value of parallel magnetic field
         self._prop.basis_ops.PB.dot(self._b_full1, out=self._PBb1)
         self._E0T.dot(self._PBb1, out=self._PBb2)
         self._PBb2.update_ghost_regions()
 
-        self._e_ions.save_magnetic_energy(self._derham, self._PBb2)
-        self._en_fB_loc = self._e_ions.markers[~self._e_ions.holes, 5].dot(
-            self._e_ions.markers[~self._e_ions.holes, 8])/self._e_ions.n_mks
-        self.derham.comm.Reduce(
-            self._en_fB_loc, self._scalar_quantities['en_fB'], op=self._mpi_sum, root=0)
-        
-        self._en_fB_loc_lost = self._e_ions.lost_markers[:self._e_ions.n_lost_markers, 5].dot(
-            self._e_ions.lost_markers[:self._e_ions.n_lost_markers, 8]) / self._e_ions.n_mks
-        self.derham.comm.Reduce(
-            self._en_fB_loc_lost, self._scalar_quantities['en_fB_lost'], op=self._mpi_sum, root=0)
+        self.pointer['energetic_ions'].save_magnetic_energy(
+            self._derham, self._PBb2)
+        self._en_fB_loc[0] = self.pointer['energetic_ions'].markers[~self.pointer['energetic_ions'].holes, 5].dot(
+            self.pointer['energetic_ions'].markers[~self.pointer['energetic_ions'].holes, 8])/self.pointer['energetic_ions'].n_mks
+        self.derham.comm.Allreduce(
+            self._mpi_in_place, self._en_fB_loc, op=self._mpi_sum)
+
+        self.update_scalar('en_fB', self._en_fB_loc[0])
+
+        self._en_fB_loc_lost[0] = self.pointer['energetic_ions'].lost_markers[:self.pointer['energetic_ions'].n_lost_markers, 5].dot(
+            self.pointer['energetic_ions'].lost_markers[:self.pointer['energetic_ions'].n_lost_markers, 8]) / self.pointer['energetic_ions'].n_mks
+        self.derham.comm.Allreduce(
+            self._mpi_in_place, self._en_fB_loc_lost, op=self._mpi_sum)
 
+        self.update_scalar('en_fB_lost', self._en_fB_loc_lost[0])
 
         # # calculate particle magnetic energy
-        # self._e_ions.save_magnetic_energy(self._derham, self._E0T.dot(
+        # self.pointer['energetic_ions'].save_magnetic_energy(self._derham, self._E0T.dot(
         #     self.derham.P['0'](self.mhd_equil.absB0)))
 
-        # self._en_fB_loc = self._e_ions.markers[~self._e_ions.holes, 5].dot(
-        #     self._e_ions.markers[~self._e_ions.holes, 8]) / self._e_ions.n_mks
+        # self._en_fB_loc = self.pointer['energetic_ions'].markers[~self.pointer['energetic_ions'].holes, 5].dot(
+        #     self.pointer['energetic_ions'].markers[~self.pointer['energetic_ions'].holes, 8]) / self.pointer['energetic_ions'].n_mks
         # self.derham.comm.Reduce(
         #     self._en_fB_loc, self._scalar_quantities['en_fB'], op=self._mpi_sum, root=0)
 
+        self.update_scalar('en_tot', en_U + en_p + en_B +
+                           self._en_fv_loc[0] + self._en_fv_loc_lost[0] + self._en_fB_loc[0] + self._en_fB_loc_lost[0])
+
+        print('Number of lost markers:',
+              self.pointer['energetic_ions'].n_lost_markers)
+
 
-        self._scalar_quantities['en_tot'][0] = self._scalar_quantities['en_U'][0]
-        self._scalar_quantities['en_tot'][0] += self._scalar_quantities['en_p'][0]
-        self._scalar_quantities['en_tot'][0] += self._scalar_quantities['en_B'][0]
-        self._scalar_quantities['en_tot'][0] += self._scalar_quantities['en_fv'][0]
-        self._scalar_quantities['en_tot'][0] += self._scalar_quantities['en_fB'][0]
-        self._scalar_quantities['en_tot'][0] += self._scalar_quantities['en_fv_lost'][0]
-        self._scalar_quantities['en_tot'][0] += self._scalar_quantities['en_fB_lost'][0]
+class ColdPlasmaVlasov(StruphyModel):
+    r'''Cold plasma hybrid model
 
-        print('Number of lost markers:', self._e_ions.n_lost_markers)
+    Normalization:
 
-# class ColdPlasmaVlasov(StruphyModel):
-#     r'''Cold plasma model
+    .. math::
 
-#     Normalization:
+        &c = \frac{\hat \omega}{\hat k} = \frac{\hat E}{\hat B}\,, \quad \alpha = \frac{\hat \Omega_\textnormal{pc}}{\hat \Omega_\textnormal{cc}}\,, \quad \varepsilon_\textnormal{c} = \frac{\hat{\omega}}{\hat \Omega_\textnormal{cc}}\,, \quad \varepsilon_\textnormal{h} = \frac{\hat{\omega}}{\hat \Omega_\textnormal{ch}}\,,
 
-#     .. math::
+        &\hat j_\textnormal{c} = q_\textnormal{c} c \hat n_\textnormal{c}\,, \quad \hat j_\textnormal{h} = q_\textnormal{h} c \hat n_\textnormal{c}\,, \quad \hat f = \frac{\hat n_\textnormal{c}}{c^3} \,, \quad \nu = \frac{q_\textnormal{h}}{q_\textnormal{c}}\,,
 
-#         &c = \frac{\hat \omega}{\hat k} = \frac{\hat E}{\hat B}\,,
+    where :math:`c` is the vacuum speed of light, :math:`\hat \Omega_\textnormal{cc}` the cold electron cyclotron frequency,
+    :math:`\hat \Omega_\textnormal{pc}` the cold electron plasma frequency,  :math:`\hat \Omega_\textnormal{ch}` the hot electron cyclotron frequency,
+    and :math:`\hat \Omega_\textnormal{ph}` the hot electron plasma frequency.
+    Implemented equations:
 
-#         &\hat \omega = \Omega_{ce}\,,
+    .. math::
 
-#         &\alpha = \frac{\Omega_{pe}}{\Omega_{ce}}\,,
+        &\partial_t f + \mathbf{v} \cdot \, \nabla f + \frac{1}{\varepsilon_\textnormal{h}}\left( \mathbf{E} + \mathbf{v} \times \left( \mathbf{B} + \mathbf{B}_0 \right) \right)
+            \cdot \frac{\partial f}{\partial \mathbf{v}} = 0 \,,
 
-#         &\hat j_c = \varepsilon_0 \Omega_{pe} \hat E\,,
+        &\frac{\partial \mathbf B}{\partial t} + \nabla\times\mathbf E = 0\,,
 
-#         &\hat v = \frac{\Omega_{ce}}{\hat k} = c\,,
+        &-\frac{\partial \mathbf E}{\partial t} + \nabla\times\mathbf B =
+        \frac{\alpha^2}{\varepsilon_\textnormal{c}} \left( \mathbf j_\textnormal{c} + \nu  \int_{\mathbb{R}^3} \mathbf{v} f \, \text{d}^3 \mathbf{v} \right) \,,
 
-#     where :math:`c` is the vacuum speed of light, :math:`\Omega_{ce}` the electron cyclotron frequency,
-#     :math:`\Omega_{pe}` the plasma frequency and :math:`\varepsilon_0` the vacuum dielectric constant.
-#     Implemented equations:
+        &\frac{1}{n_0} \frac{\partial \mathbf j_\textnormal{c}}{\partial t} = \frac{1}{\varepsilon_\textnormal{c}} \mathbf E + \frac{1}{\varepsilon_\textnormal{c} n_0} \mathbf j_\textnormal{c} \times \mathbf B_0\,.
 
-#     .. math::
+    where :math:`(n_0,\mathbf B_0)` denotes a (inhomogeneous) background.
 
-#         &\frac{\partial \mathbf B}{\partial t} + \nabla\times\mathbf E = 0\,,
+    At initial time the Poisson equation is solved once to weakly satisfy the Gauss law
 
-#         &-\frac{\partial \mathbf E}{\partial t} + \nabla\times\mathbf B =
-#         \alpha\left(\mathbf j_c + \frac{\hat n_h}{n_0 \left(x\right)} \alpha \mathbf j_h\right)\,,
+    .. math::
 
-#         &\frac{\partial \mathbf j_c}{\partial t} = \alpha \mathbf E + \mathbf j_c \times \mathbf B\,,
+        \begin{align}
+            \nabla \cdot \mathbf{E} & = \nu \frac{\alpha^2}{\varepsilon_\textnormal{c}} \int_{\mathbb{R}^3} f \, \text{d}^3 \mathbf{v}
+        \end{align}
 
-#         &\frac{\partial f_h}{\partial t} + v \cdot \nabla f_h
-#         + \left(\mathbf E + \mathbf v \times B\right) \cdot \nabla_v f_h = 0\,.
+    Parameters
+    ----------
+    params : dict
+        Simulation parameters, see from :ref:`params_yml`.
 
+    comm : mpi4py.MPI.Intracomm
+        MPI communicator used for parallelization.
 
-#     Parameters
-#     ----------
-#         params : dict
-#             Simulation parameters, see from :ref:`params_yml`.
-#     '''
+    Note
+    ----------
+    If hot and cold particles are of the same species (:math:`Z_\textnormal{c} = Z_\textnormal{h} \,, A_\textnormal{c} = A_\textnormal{h}`) then :math:`\varepsilon_\textnormal{c} = \varepsilon_\textnormal{h}` and :math:`\nu = 1`.
+    '''
 
-#     def __init__(self, params, comm):
+    @classmethod
+    def bulk_species(cls):
+        return 'coldelectrons'
 
-#         from struphy.propagators import propagators_fields
-#         from struphy.psydac_api.mass import WeightedMassOperators
-#         from struphy.propagators import propagators_fields
+    @classmethod
+    def timescale(cls):
+        return 'light'
 
-#         super().__init__(params, comm, e1='Hcurl', b2='Hdiv',
-#                          electron={'j1': 'Hcurl'}, hot_electrons='Particles6D')
+    def __init__(self, params, comm):
 
-#         # pointers to em-fields variables
-#         self._e = self.em_fields['e1']['obj'].vector
-#         self._b = self.em_fields['b2']['obj'].vector
+        super().__init__(params, comm, e1='Hcurl', b2='Hdiv',
+                         coldelectrons={'j1': 'Hcurl'}, hotelectrons='Particles6D')
 
-#         # pointers to  fluid variables
-#         self._j = self.fluid['electrons']['j1']['obj'].vector
+        from mpi4py.MPI import SUM, IN_PLACE
 
-#         # extract necessary parameters
-#         maxwell_solver = params['solvers']['solver_1']
-#         cold_solver = params['solvers']['solver_2']
+        # Get rank and size
+        self._rank = comm.Get_rank()
 
-#         # Define callable for weighted mass matrices
-#         proton_mass = 1.6726219237e-27
-#         electron_mass = self.fluid['electrons']['plasma_params']['M'] * proton_mass
-#         vacuum_permittivity = 8.854187813e-12
-#         prefactor = (electron_mass / vacuum_permittivity)**0.5
+        # prelim
+        electron_params = params['kinetic']['hotelectrons']
 
-#         def call_alpha(e1, e2, e3):
-#             return prefactor * self.mhd_equil.n0(e1, e2, e3, sqeez_out=False)**0.5 / self.mhd_equil.absB0(e1, e2, e3, sqeez_out=False)
+        # get poisson solver parameters
+        self._poisson_params = params['solvers']['solver_poisson']
 
-#         def call_M1alpha(e1, e2, e3, m, n):
-#             return self.domain.Ginv(e1, e2, e3)[:, :, :, m, n] * self.domain.sqrt_g(e1, e2, e3)*call_alpha(e1, e2, e3)
+        # model parameters
+        self._alpha = np.abs(self.eq_params['coldelectrons']['alpha_unit'])
+        self._epsilon_cold = self.eq_params['coldelectrons']['epsilon_unit']
+        self._epsilon_hot = self.eq_params['hotelectrons']['epsilon_unit']
+
+        self._nu = electron_params['phys_params']['Z'] / \
+            params['fluid']['coldelectrons']['phys_params']['Z']
+
+        # Initialize background magnetic field from MHD equilibrium
+        self._b_background = self.derham.P['2']([self.mhd_equil.b2_1,
+                                                 self.mhd_equil.b2_2,
+                                                 self.mhd_equil.b2_3])
+
+        self.add_propagator(self.prop_fields.Maxwell(
+            self.pointer['e1'],
+            self.pointer['b2'],
+            **params['solvers']['solver_maxwell']))
+        self.add_propagator(self.prop_fields.OhmCold(
+            self.pointer['coldelectrons_j1'],
+            self.pointer['e1'],
+            **params['solvers']['solver_ohmcold'],
+            alpha=self._alpha,
+            epsilon=self._epsilon_cold))
+        self.add_propagator(self.prop_fields.JxBCold(
+            self.pointer['coldelectrons_j1'],
+            **params['solvers']['solver_jxbcold'],
+            alpha=self._alpha,
+            epsilon=self._epsilon_cold))
+        self.add_propagator(self.prop_markers.PushEta(
+            self.pointer['hotelectrons'],
+            algo=electron_params['push_algos']['eta'],
+            bc_type=electron_params['markers']['bc_type'],
+            f0=None))
+        self.add_propagator(self.prop_markers.PushVxB(
+            self.pointer['hotelectrons'],
+            algo=electron_params['push_algos']['vxb'],
+            scale_fac=1/self._epsilon_cold,
+            b_eq=self._b_background,
+            b_tilde=self.pointer['b2'],
+            f0=None))
+        self.add_propagator(self.prop_coupling.VlasovMaxwell(
+            self.pointer['e1'],
+            self.pointer['hotelectrons'],
+            c1=self._nu * self._alpha**2/self._epsilon_cold,
+            c2=1/self._epsilon_hot,
+            **params['solvers']['solver_vlasovmaxwell']))
 
-#         # Assemble necessary mass matrices
-#         self._mass_ops = WeightedMassOperators(
-#             self.derham, self.domain, alpha=call_M1alpha)
+        # Scalar variables to be saved during simulation
+        self.add_scalar('en_E')
+        self.add_scalar('en_B')
+        self.add_scalar('en_J')
+        self.add_scalar('en_f')
+        self.add_scalar('en_tot')
 
-#         # Initialize propagators/integrators used in splitting substeps
-#         self._propagators = []
-#         self._propagators += [propagators_fields.Maxwell(
-#             self._e, self._b, self.derham, self._mass_ops, maxwell_solver)]
-#         self._propagators += [propagators_fields.OhmCold(
-#             self._j, self._e, self._mass_ops, cold_solver)]
+        # MPI operations needed for scalar variables
+        self._mpi_sum = SUM
+        self._mpi_in_place = IN_PLACE
 
-#         # Scalar variables to be saved during simulation
-#         self._scalar_quantities['time'] = np.empty(1, dtype=float)
-#         self._scalar_quantities['en_E'] = np.empty(1, dtype=float)
-#         self._scalar_quantities['en_B'] = np.empty(1, dtype=float)
-#         self._scalar_quantities['en_tot'] = np.empty(1, dtype=float)
+        # temporaries
+        self._tmp1 = self.pointer['e1'].space.zeros()
+        self._tmp2 = self.pointer['b2'].space.zeros()
+        self._tmp = np.empty(1, dtype=float)
+
+    def initialize_from_params(self):
+
+        from struphy.pic.particles_to_grid import AccumulatorVector
+        from psydac.linalg.stencil import StencilVector
+
+        # Initialize fields and particles
+        super().initialize_from_params()
+
+        # Accumulate charge density
+        charge_accum = AccumulatorVector(
+            self.derham, self.domain, "H1", "vlasov_maxwell_poisson")
+        charge_accum.accumulate(self.pointer['hotelectrons'])
+
+        # Locally subtract mean charge for solvability with periodic bc
+        if np.all(charge_accum.vectors[0].space.periods):
+            charge_accum._vectors[0][:] -= np.mean(charge_accum.vectors[0].toarray()[
+                                                   charge_accum.vectors[0].toarray() != 0])
+
+        # Instantiate Poisson solver
+        _phi = StencilVector(self.derham.Vh['0'])
+        poisson_solver = self.prop_fields.ImplicitDiffusion(
+            _phi,
+            sigma=0,
+            phi_n=self._nu * self._alpha**2 /
+            self._epsilon_cold * charge_accum.vectors[0],
+            x0=self._nu * self._alpha**2 /
+            self._epsilon_cold * charge_accum.vectors[0],
+            **self._poisson_params)
+
+        # Solve with dt=1. and compute electric field
+        poisson_solver(1.)
+        self.derham.grad.dot(-_phi, out=self.pointer['e1'])
 
-#     @property
-#     def propagators(self):
-#         return self._propagators
+    def update_scalar_quantities(self):
+
+        self._mass_ops.M1.dot(self.pointer['e1'], out=self._tmp1)
+        self._mass_ops.M2.dot(self.pointer['b2'], out=self._tmp2)
+        en_E = .5 * self.pointer['e1'].dot(self._tmp1)
+        en_B = .5 * self.pointer['b2'].dot(self._tmp2)
+        self._mass_ops.M1ninv.dot(
+            self.pointer['coldelectrons_j1'], out=self._tmp1)
+        en_J = .5 * self._alpha**2 * \
+            self.pointer['coldelectrons_j1'].dot(self._tmp1)
+        self.update_scalar('en_E', en_E)
+        self.update_scalar('en_B', en_B)
+        self.update_scalar('en_J', en_J)
+
+        # nu alpha^2 eps_h / eps_c / 2 / N * sum_p w_p v_p^2
+        self._tmp[0] = self._nu * self._alpha**2 * self._epsilon_hot / self._epsilon_cold / \
+            (2 * self.pointer['hotelectrons'].n_mks) * np.dot(self.pointer['hotelectrons'].markers_wo_holes[:, 3]**2 + self.pointer['hotelectrons'].markers_wo_holes[:, 4]
+                                                              ** 2 + self.pointer['hotelectrons'].markers_wo_holes[:, 5]**2, self.pointer['hotelectrons'].markers_wo_holes[:, 6])
+        self.derham.comm.Allreduce(
+            self._mpi_in_place, self._tmp, op=self._mpi_sum)
+        self.update_scalar('en_f', self._tmp[0])
 
-#     def update_scalar_quantities(self, time):
-#         self._scalar_quantities['time'][0] = time
-#         self._scalar_quantities['en_E'][0] = .5 * \
-#             self._e.dot(self._mass_ops.M1.dot(self._e))
-#         self._scalar_quantities['en_B'][0] = .5 * \
-#             self._b.dot(self._mass_ops.M2.dot(self._b))
-#         self._scalar_quantities['en_tot'][0] = self._scalar_quantities['en_E'][0]
-#         self._scalar_quantities['en_tot'][0] += self._scalar_quantities['en_B'][0]
+        # en_tot =en_E + en_B + en_J + en_w
+        self.update_scalar('en_tot', en_E + en_B + en_J + self._tmp[0])
```

### Comparing `struphy-2.0.1/src/struphy/models/kinetic.py` & `struphy-2.0.2/src/struphy/models/kinetic.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,11 +1,187 @@
 import numpy as np
 from struphy.models.base import StruphyModel
 
 
+class VlasovMaxwell(StruphyModel):
+    r'''Vlasov Maxwell equations with Poisson splitting.
+
+    :ref:`normalization`:
+
+    .. math::
+
+        \begin{align}
+            c & = \frac{\hat \omega}{\hat k} = \frac{\hat E}{\hat B} = \hat v \,, \qquad  \hat f = \frac{\hat n}{c^3} \,.
+        \end{align}
+
+    Implemented equations:
+
+    .. math::
+
+        \begin{align}
+            &\partial_t f + \mathbf{v} \cdot \, \nabla f + \frac{1}{\varepsilon}\left( \mathbf{E} + \mathbf{v} \times \left( \mathbf{B} + \mathbf{B}_0 \right) \right)
+            \cdot \frac{\partial f}{\partial \mathbf{v}} = 0 \,,
+            \\[2mm]
+            &\frac{\partial \mathbf{E}}{\partial t} = \nabla \times \mathbf{B} -
+            \frac{\alpha^2}{\varepsilon} \int_{\mathbb{R}^3} \mathbf{v} f \, \text{d}^3 \mathbf{v} \,,
+            \\
+            &\frac{\partial \mathbf{B}}{\partial t} = - \nabla \times \mathbf{E} \,,
+        \end{align}
+
+    where
+
+    .. math::
+
+        \alpha = \frac{\hat \Omega_\textnormal{p}}{\hat \Omega_\textnormal{c}}\,,\qquad \varepsilon = \frac{\hat \omega}{\hat \Omega_\textnormal{c}} \,,\qquad \textnormal{with} \qquad \hat\Omega_\textnormal{p} = \sqrt{\frac{\hat n (Ze)^2}{\epsilon_0 A m_\textnormal{H}}} \,,\qquad \hat \Omega_{\textnormal{c}} = \frac{Ze \hat B}{A m_\textnormal{H}}\,.
+
+    At initial time the Poisson equation is solved once to weakly satisfy the Gauss law
+
+    .. math::
+
+        \begin{align}
+            \nabla \cdot \mathbf{E} & = \frac{\alpha^2}{\varepsilon} \int_{\mathbb{R}^3} f \, \text{d}^3 \mathbf{v}
+        \end{align}
+
+    Parameters
+    ----------
+    params : dict
+        Simulation parameters, see from :ref:`params_yml`.
+
+    comm : mpi4py.MPI.Intracomm
+        MPI communicator used for parallelization.
+    '''
+
+    @classmethod
+    def bulk_species(cls):
+        return 'electrons'
+
+    @classmethod
+    def timescale(cls):
+        return 'light'
+
+    def __init__(self, params, comm):
+
+        super().__init__(params, comm,
+                         e1='Hcurl', b2='Hdiv',
+                         electrons='Particles6D')
+
+        from mpi4py.MPI import SUM, IN_PLACE
+
+        # Get rank and size
+        self._rank = comm.Get_rank()
+
+        # prelim
+        electron_params = params['kinetic']['electrons']
+
+        # model parameters
+        self._alpha = self.eq_params['electrons']['alpha_unit']
+        self._epsilon = self.eq_params['electrons']['epsilon_unit']
+
+        # Get Poisson solver params parameters
+        self._poisson_params = params['solvers']['solver_poisson']
+
+        # ====================================================================================
+        # Initialize background magnetic field from MHD equilibrium
+        self._b_background = self.derham.P['2']([self.mhd_equil.b2_1,
+                                                 self.mhd_equil.b2_2,
+                                                 self.mhd_equil.b2_3])
+
+        # Initialize propagators/integrators used in splitting substeps
+        self.add_propagator(self.prop_fields.Maxwell(
+            self.pointer['e1'],
+            self.pointer['b2'],
+            **params['solvers']['solver_maxwell']))
+        
+        self.add_propagator(self.prop_markers.PushEta(
+            self.pointer['electrons'],
+            algo=electron_params['push_algos']['eta'],
+            bc_type=electron_params['markers']['bc_type'],
+            f0=None))
+        
+        self.add_propagator(self.prop_markers.PushVxB(
+            self.pointer['electrons'],
+            algo=electron_params['push_algos']['vxb'],
+            scale_fac=1/self._epsilon,
+            b_eq=self._b_background,
+            b_tilde=self.pointer['b2'],
+            f0=None))
+        
+        self.add_propagator(self.prop_coupling.VlasovMaxwell(
+            self.pointer['e1'],
+            self.pointer['electrons'],
+            c1=self._alpha**2/self._epsilon,
+            c2=1/self._epsilon,
+            **params['solvers']['solver_vlasovmaxwell']))
+
+        # Scalar variables to be saved during the simulation
+        self.add_scalar('en_E')
+        self.add_scalar('en_B')
+        self.add_scalar('en_f')
+        self.add_scalar('en_tot')
+
+        # MPI operations needed for scalar variables
+        self._mpi_sum = SUM
+        self._mpi_in_place = IN_PLACE
+
+        # temporaries
+        self._tmp1 = self.derham.Vh['1'].zeros()
+        self._tmp2 = self.derham.Vh['2'].zeros()
+        self._tmp = np.empty(1, dtype=float)
+
+    def initialize_from_params(self):
+
+        from struphy.pic.particles_to_grid import AccumulatorVector
+        from psydac.linalg.stencil import StencilVector
+
+        # Initialize fields and particles
+        super().initialize_from_params()
+
+        # Accumulate charge density
+        charge_accum = AccumulatorVector(
+            self.derham, self.domain, "H1", "vlasov_maxwell_poisson")
+        charge_accum.accumulate(self.pointer['electrons'])
+
+        # Locally subtract mean charge for solvability with periodic bc
+        if np.all(charge_accum.vectors[0].space.periods):
+            charge_accum._vectors[0][:] -= np.mean(charge_accum.vectors[0].toarray()[
+                                                   charge_accum.vectors[0].toarray() != 0])
+
+        # Instantiate Poisson solver
+        _phi = StencilVector(self.derham.Vh['0'])
+        poisson_solver = self.prop_fields.ImplicitDiffusion(
+            _phi,
+            sigma=1e-11,
+            phi_n=self._alpha**2 / self._epsilon * charge_accum.vectors[0],
+            x0=self._alpha**2 / self._epsilon * charge_accum.vectors[0],
+            **self._poisson_params)
+
+        # Solve with dt=1. and compute electric field
+        poisson_solver(1.)
+        self.derham.grad.dot(-_phi, out=self.pointer['e1'])
+
+    def update_scalar_quantities(self):
+        self._mass_ops.M1.dot(self.pointer['e1'], out=self._tmp1)
+        self._mass_ops.M2.dot(self.pointer['b2'], out=self._tmp2)
+        en_E = self.pointer['e1'].dot(self._tmp1) / 2.
+        en_B = self.pointer['b2'].dot(self._tmp2) / 2.
+        self.update_scalar('en_E', en_E)
+        self.update_scalar('en_B', en_B)
+
+        # alpha^2 / 2 / N * sum_p w_p v_p^2
+        self._tmp[0] = self._alpha**2 / (2 * self.pointer['electrons'].n_mks) * \
+            np.dot(self.pointer['electrons'].markers_wo_holes[:, 3]**2 + self.pointer['electrons'].markers_wo_holes[:, 4] ** 2 +
+                   self.pointer['electrons'].markers_wo_holes[:, 5]**2, self.pointer['electrons'].markers_wo_holes[:, 6])
+        self.derham.comm.Allreduce(
+            self._mpi_in_place, self._tmp, op=self._mpi_sum)
+        self.update_scalar('en_f', self._tmp[0])
+
+        # en_tot = en_w + en_e + en_b
+        self.update_scalar('en_tot', en_E + en_B + self._tmp[0])
+
+
 class LinearVlasovMaxwell(StruphyModel):
     r'''Linearized Vlasov Maxwell equations with a Maxwellian background distribution function :math:`f_0`.
 
     :ref:`normalization`:
 
     .. math::
 
@@ -64,45 +240,35 @@
 
     def __init__(self, params, comm):
 
         super().__init__(params, comm,
                          e_field='Hcurl', b_field='Hdiv',
                          electrons='Particles6D')
 
-        from struphy.propagators.base import Propagator
-        from struphy.propagators import propagators_fields, propagators_coupling, propagators_markers
         from struphy.kinetic_background import maxwellians as kin_ana
         from mpi4py.MPI import SUM, IN_PLACE
 
-        # pointers to em-field variables
-        self._e = self.em_fields['e_field']['obj'].vector
-        self._b = self.em_fields['b_field']['obj'].vector
-
-        self._en_e_tmp = self._e.space.zeros()
-        self._en_b_tmp = self._b.space.zeros()
-
         # Get rank and size
         self._rank = comm.Get_rank()
 
-        # pointer to electrons
-        self._electrons = self.kinetic['electrons']['obj']
+        # prelim
         electron_params = params['kinetic']['electrons']
 
         # kinetic background
         assert electron_params['background']['type'] == 'Maxwellian6DUniform', \
             AssertionError(
                 "The background distribution function must be a uniform Maxwellian!")
 
         self._maxwellian_params = electron_params['background']['Maxwellian6DUniform']
         assert self._maxwellian_params['u1'] == 0., "No shifts in velocity space possible!"
         assert self._maxwellian_params['u2'] == 0., "No shifts in velocity space possible!"
         assert self._maxwellian_params['u3'] == 0., "No shifts in velocity space possible!"
-        self.kinetic['electrons']['obj']._f_backgr = getattr(
+        self.pointer['electrons']._f_backgr = getattr(
             kin_ana, 'Maxwellian6DUniform')(**self._maxwellian_params)
-        self._f0 = self._electrons.f_backgr
+        self._f0 = self.pointer['electrons'].f_backgr
 
         # Get coupling strength
         self.alpha = self.eq_params['electrons']['alpha_unit']
         self.kappa = 1. / self.eq_params['electrons']['epsilon_unit']
 
         # Get Poisson solver params
         self._poisson_params = params['solvers']['solver_poisson']
@@ -114,95 +280,84 @@
                                                  self.mhd_equil.b2_3])
 
         # Create pointers to background electric potential and field
         self._phi_background = self.derham.P['0'](self.electric_equil.phi0)
         self._e_background = self.derham.grad.dot(self._phi_background)
         # ====================================================================================
 
-        # set propagators base class attributes (available to all propagators)
-        Propagator.derham = self.derham
-        Propagator.domain = self.domain
-        Propagator.mass_ops = self.mass_ops
-
         # Initialize propagators/integrators used in splitting substeps
-        self._propagators = []
-
-        self._propagators += [propagators_markers.PushEta(
-            self._electrons,
+        self.add_propagator(self.prop_markers.PushEta(
+            self.pointer['electrons'],
             algo=electron_params['push_algos']['eta'],
             bc_type=electron_params['markers']['bc_type'],
-            f0=None)]  # no conventional weights update here, thus f0=None
+            f0=None))  # no conventional weights update here, thus f0=None
         if self._rank == 0:
             print("Added Step PushEta\n")
 
         # Only add StepVinEfield if e-field is non-zero, otherwise it is more expensive
         if np.all(self._e_background[0]._data < 1e-14) and np.all(self._e_background[1]._data < 1e-14) and np.all(self._e_background[2]._data < 1e-14):
-            self._propagators += [propagators_markers.StepVinEfield(
-                self._electrons,
+            self.add_propagator(self.prop_markers.StepVinEfield(
+                self.pointer['electrons'],
                 e_field=self._e_background,
-                kappa=self.kappa)]
+                kappa=self.kappa))
             if self._rank == 0:
                 print("Added Step VinEfield\n")
 
         # Only add VxB Step if b-field is non-zero, otherwise it is more expensive
         b_bckgr_params = params['mhd_equilibrium'][params['mhd_equilibrium']['type']]
         if (b_bckgr_params['B0x'] != 0.) or (b_bckgr_params['B0y'] != 0.) or (b_bckgr_params['B0z'] != 0.):
-            self._propagators += [propagators_markers.PushVxB(
-                self._electrons,
+            self.add_propagator(self.prop_markers.PushVxB(
+                self.pointer['electrons'],
                 algo=electron_params['push_algos']['vxb'],
                 scale_fac=1.,
                 b_eq=self._b_background,
                 b_tilde=None,
-                f0=None)]  # no conventional weights update here, thus f0=None
+                f0=None))  # no conventional weights update here, thus f0=None
             if self._rank == 0:
                 print("Added Step VxB\n")
 
-        self._propagators += [propagators_coupling.EfieldWeightsImplicit(
-            self._e,
-            self._electrons,
+        self.add_propagator(self.prop_coupling.EfieldWeightsImplicit(
+            self.pointer['e_field'],
+            self.pointer['electrons'],
             alpha=self.alpha,
             kappa=self.kappa,
             f0=self._f0,
-            **params['solvers']['solver_ew']
-        )]
+            **params['solvers']['solver_ew']))
         if self._rank == 0:
             print("\nAdded Step EfieldWeights\n")
 
-        self._propagators += [propagators_fields.Maxwell(
-            self._e,
-            self._b,
-            **params['solvers']['solver_eb'])]
+        self.add_propagator(self.prop_fields.Maxwell(
+            self.pointer['e_field'],
+            self.pointer['b_field'],
+            **params['solvers']['solver_eb']))
         if self._rank == 0:
             print("\nAdded Step Maxwell\n")
 
         # Scalar variables to be saved during the simulation
-        self._scalar_quantities = {}
-        self._scalar_quantities['en_e'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_b'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_w'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_e1'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_e2'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_b3'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_tot'] = np.empty(1, dtype=float)
+        self.add_scalar('en_e')
+        self.add_scalar('en_b')
+        self.add_scalar('en_w')
+        self.add_scalar('en_e1')
+        self.add_scalar('en_e2')
+        self.add_scalar('en_b3')
+        self.add_scalar('en_tot')
 
         # MPI operations needed for scalar variables
         self._mpi_sum = SUM
         self._mpi_in_place = IN_PLACE
 
-    @property
-    def propagators(self):
-        return self._propagators
-
-    @property
-    def scalar_quantities(self):
-        return self._scalar_quantities
+        # temporaries
+        self._en_e_tmp = self.pointer['e_field'].space.zeros()
+        self._en_b_tmp = self.pointer['b_field'].space.zeros()
+        self._tmp = np.empty(1, dtype=float)
 
     def initialize_from_params(self):
-        from struphy.propagators import solvers
+
         from struphy.pic.particles_to_grid import AccumulatorVector
+        from psydac.linalg.stencil import StencilVector
 
         # Get physical properties of the Maxwellian
         init_type = self.kinetic['electrons']['params']['init']['type']
         if init_type == 'Maxwellian6DUniform':
             sigma1 = self.kinetic['electrons']['params']['init'][init_type]['vth1']
             sigma2 = self.kinetic['electrons']['params']['init'][init_type]['vth2']
             sigma3 = self.kinetic['electrons']['params']['init'][init_type]['vth3']
@@ -226,15 +381,15 @@
             self.kinetic['electrons']['params']['init'][init_type]['vth1'] = vth1
             self.kinetic['electrons']['params']['init'][init_type]['vth2'] = vth2
             self.kinetic['electrons']['params']['init'][init_type]['vth3'] = vth3
         elif init_type == 'Maxwellian6DPerturbed':
             self.kinetic['electrons']['params']['init'][init_type]['vth1']['vth01'] = vth1
             self.kinetic['electrons']['params']['init'][init_type]['vth2']['vth02'] = vth2
             self.kinetic['electrons']['params']['init'][init_type]['vth3']['vth03'] = vth3
-        
+
         # Take smaller width of the two gaussians for markers drawing in order to avoid
         # small values for f0 and hence division by zero
         self.kinetic['electrons']['params']['markers']['loading']['moments'][3] = \
             min(vth1, sigma1)
         self.kinetic['electrons']['params']['markers']['loading']['moments'][4] = \
             min(vth2, sigma2)
         self.kinetic['electrons']['params']['markers']['loading']['moments'][5] = \
@@ -244,96 +399,102 @@
         super().initialize_from_params()
 
         # edges = self.kinetic['electrons']['bin_edges']['e1']
         # # edges = [self.kinetic['electrons']['bin_edges']['v1_v2'][1]]
         # components = [False] * 6
         # components[0] = True
 
-        # self._electrons.show_distribution_function(components, edges, self.domain)
+        # self.pointer['electrons'].show_distribution_function(components, edges, self.domain)
 
         # Correct initialization of weights by dividing by sqrt(f_0)
-        self._electrons.markers[~self._electrons.holes, 6] /= \
-            (np.sqrt(self._f0(*self._electrons.markers_wo_holes[:, :6].T)))
+        self.pointer['electrons'].markers[~self.pointer['electrons'].holes, 6] /= \
+            (np.sqrt(
+                self._f0(*self.pointer['electrons'].markers_wo_holes[:, :6].T)))
 
         # # Set v3 = 0
-        # self._electrons.markers[~self._electrons.holes, 5] = 0.
+        # self.pointer['electrons'].markers[~self.pointer['electrons'].holes, 5] = 0.
 
-        # self._electrons.show_distribution_function(components, edges, self.domain)
+        # self.pointer['electrons'].show_distribution_function(components, edges, self.domain)
         # exit()
 
         # evaluate f0
-        f0_values = self._f0(self._electrons.markers[:, 0],
-                             self._electrons.markers[:, 1],
-                             self._electrons.markers[:, 2],
-                             self._electrons.markers[:, 3],
-                             self._electrons.markers[:, 4],
-                             self._electrons.markers[:, 5])
+        f0_values = self._f0(self.pointer['electrons'].markers[:, 0],
+                             self.pointer['electrons'].markers[:, 1],
+                             self.pointer['electrons'].markers[:, 2],
+                             self.pointer['electrons'].markers[:, 3],
+                             self.pointer['electrons'].markers[:, 4],
+                             self.pointer['electrons'].markers[:, 5])
 
         # Accumulate charge density
         charge_accum = AccumulatorVector(self.derham,
                                          self.domain,
                                          "H1",
                                          "linear_vlasov_maxwell_poisson")
-        charge_accum.accumulate(self._electrons, f0_values,
+        charge_accum.accumulate(self.pointer['electrons'], f0_values,
                                 np.array(
                                     list(self._maxwellian_params.values())),
                                 self.alpha, self.kappa)
 
-        # Subtract the charge local to each process
-        charge_accum._vectors[0][:, :, :] -= \
-            np.sum(charge_accum.vectors[0].toarray()) / \
-            charge_accum.vectors[0].toarray().size
-
-        # Then solve Poisson equation
-        poisson_solver = solvers.PoissonSolver(
-            rho=charge_accum.vectors[0],
+        # Locally subtract mean charge for solvability with periodic bc
+        if np.all(charge_accum.vectors[0].space.periods):
+            charge_accum._vectors[0][:] -= np.mean(charge_accum.vectors[0].toarray()[
+                                                   charge_accum.vectors[0].toarray() != 0])
+
+        # Instantiate Poisson solver
+        _phi = StencilVector(self.derham.Vh['0'])
+        poisson_solver = self.prop_fields.ImplicitDiffusion(
+            _phi,
+            sigma=0.,
+            phi_n=charge_accum.vectors[0],
+            x0=charge_accum.vectors[0],
             **self._poisson_params)
-        poisson_solver(0.)
-        self.derham.grad.dot(-poisson_solver._phi, out=self._e)
+
+        # Solve with dt=1. and compute electric field
+        poisson_solver(1.)
+        self.derham.grad.dot(-_phi, out=self.pointer['e_field'])
 
     def update_scalar_quantities(self):
         # 0.5 * e^T * M_1 * e
-        self._mass_ops.M1.dot(self._e, out=self._en_e_tmp)
-        self._scalar_quantities['en_e'][0] = self._e.dot(
-            self._en_e_tmp) / 2.
+        self._mass_ops.M1.dot(self.pointer['e_field'], out=self._en_e_tmp)
+        en_E = self.pointer['e_field'].dot(self._en_e_tmp) / 2.
+        self.update_scalar('en_e', en_E)
 
         # 0.5 * |e_1|^2
-        self._scalar_quantities['en_e1'][0] = self._e._blocks[0].dot(
-            self._en_e_tmp._blocks[0]) / 2.
+        self.update_scalar('en_e1', self.pointer['e_field']._blocks[0].dot(
+            self._en_e_tmp._blocks[0]) / 2.)
 
         # 0.5 * |e_2|^2
-        self._scalar_quantities['en_e2'][0] = self._e._blocks[1].dot(
-            self._en_e_tmp._blocks[1]) / 2.
+        self.update_scalar('en_e2', self.pointer['e_field']._blocks[1].dot(
+            self._en_e_tmp._blocks[1]) / 2.)
 
         # 0.5 * b^T * M_2 * b
-        self._mass_ops.M2.dot(self._b, out=self._en_b_tmp)
-        self._scalar_quantities['en_b'][0] = self._b.dot(
-            self._en_b_tmp) / 2.
+        self._mass_ops.M2.dot(self.pointer['b_field'], out=self._en_b_tmp)
+        en_B = self.pointer['b_field'].dot(self._en_b_tmp) / 2.
+        self.update_scalar('en_b', en_B)
 
         # 0.5 * |b_3|^2
-        self._scalar_quantities['en_b3'][0] = self._b._blocks[2].dot(
-            self._en_b_tmp._blocks[2]) / 2.
+        self.update_scalar('en_b3', self.pointer['b_field']._blocks[2].dot(
+            self._en_b_tmp._blocks[2]) / 2.)
 
         # alpha^2 / (2N) * (v_th_1 * v_th_2 * v_th_3)^(2/3) * sum_p s_0 * w_p^2
-        self._scalar_quantities['en_w'][0] = \
-            self.alpha**2 / (2 * self._electrons.n_mks) * \
-            (self._maxwellian_params['vth1'] * \
-            self._maxwellian_params['vth2'] * \
-            self._maxwellian_params['vth3'])**(2/3) * \
-            np.dot(self._electrons.markers_wo_holes[:, 6]**2,  # w_p^2
-                   self._electrons.markers_wo_holes[:, 7])  # s_{0,p}
+        self._tmp[0] = \
+            self.alpha**2 / (2 * self.pointer['electrons'].n_mks) * \
+            (self._maxwellian_params['vth1'] *
+             self._maxwellian_params['vth2'] *
+             self._maxwellian_params['vth3'])**(2/3) * \
+            np.dot(self.pointer['electrons'].markers_wo_holes[:, 6]**2,  # w_p^2
+                   self.pointer['electrons'].markers_wo_holes[:, 7])  # s_{0,p}
 
         self.derham.comm.Allreduce(
-            self._mpi_in_place, self._scalar_quantities['en_w'], op=self._mpi_sum)
+            self._mpi_in_place, self._tmp, op=self._mpi_sum)
+
+        self.update_scalar('en_w', self._tmp[0])
 
         # en_tot = en_w + en_e + en_b
-        self._scalar_quantities['en_tot'][0] = \
-            self._scalar_quantities['en_w'][0] + \
-            self._scalar_quantities['en_e'][0] + \
-            self._scalar_quantities['en_b'][0]
+        self.update_scalar('en_tot', self._tmp[0] + en_E + en_B)
 
 
 class DeltaFVlasovMaxwell(StruphyModel):
     r'''Vlasov Maxwell with Maxwellian background and delta-f method.
 
     :ref:`normalization`:
 
@@ -388,38 +549,31 @@
 
     def __init__(self, params, comm):
 
         super().__init__(params, comm,
                          e_field='Hcurl', b_field='Hdiv',
                          electrons='Particles6D')
 
-        from struphy.propagators.base import Propagator
-        from struphy.propagators import propagators_fields, propagators_coupling, propagators_markers
         from struphy.kinetic_background import maxwellians as kin_ana
         from mpi4py.MPI import SUM, IN_PLACE
 
-        # pointers to em-field variables
-        self._e = self.em_fields['e_field']['obj'].vector
-        self._b = self.em_fields['b_field']['obj'].vector
-
         # Get rank and size
         self._rank = comm.Get_rank()
 
-        # pointer to electrons
-        self._electrons = self.kinetic['electrons']['obj']
+        # prelim
         electron_params = params['kinetic']['electrons']
 
         # kinetic background
         assert electron_params['background']['type'] == 'Maxwellian6DUniform', \
             "The background distribution function must be a uniform Maxwellian!"
 
         self._maxwellian_params = electron_params['background']['Maxwellian6DUniform']
-        self.kinetic['electrons']['obj']._f_backgr = getattr(
+        self.pointer['electrons']._f_backgr = getattr(
             kin_ana, 'Maxwellian6DUniform')(**self._maxwellian_params)
-        self._f0 = self._electrons.f_backgr
+        self._f0 = self.pointer['electrons'].f_backgr
 
         # Get coupling strength
         self.alpha = self.eq_params['electrons']['alpha_unit']
         self.kappa = 1. / self.eq_params['electrons']['epsilon_unit']
 
         # Get Poisson solver params
         self._poisson_params = params['solvers']['solver_poisson']
@@ -431,153 +585,150 @@
                                                  self.mhd_equil.b2_3])
 
         # Create pointers to background electric potential and field
         self._phi_background = self.derham.P['0'](self.electric_equil.phi0)
         self._e_background = self.derham.grad.dot(self._phi_background)
         # ====================================================================================
 
-        # set propagators base class attributes (available to all propagators)
-        Propagator.derham = self.derham
-        Propagator.domain = self.domain
-        Propagator.mass_ops = self.mass_ops
-
         # Initialize propagators/integrators used in splitting substeps
-        self._propagators = []
-
-        self._propagators += [propagators_markers.PushEta(
-            self._electrons,
+        self.add_propagator(self.prop_markers.PushEta(
+            self.pointer['electrons'],
             algo=electron_params['push_algos']['eta'],
             bc_type=electron_params['markers']['bc_type'],
-            f0=None)]  # no conventional weights update here, thus f0=None
+            f0=None))  # no conventional weights update here, thus f0=None
         if self._rank == 0:
             print("Added Step PushEta\n")
 
         # Only add StepVinEfield if e-field is non-zero, otherwise it is more expensive
-        self._propagators += [propagators_markers.StepVinEfield(
-            self._electrons,
-            e_field=self._e_background + self._e,
-            kappa=self.kappa)]
+        self.add_propagator(self.prop_markers.StepVinEfield(
+            self.pointer['electrons'],
+            e_field=self._e_background + self.pointer['e_field'],
+            kappa=self.kappa))
         if self._rank == 0:
             print("Added Step VinEfield\n")
 
-        self._propagators += [propagators_markers.PushVxB(
-            self._electrons,
+        self.add_propagator(self.prop_markers.PushVxB(
+            self.pointer['electrons'],
             algo=electron_params['push_algos']['vxb'],
             scale_fac=1.,
-            b_eq=self._b_background + self._b,
+            b_eq=self._b_background + self.pointer['b_field'],
             b_tilde=None,
-            f0=None)]  # no conventional weights update here, thus f0=None
+            f0=None))  # no conventional weights update here, thus f0=None
         if self._rank == 0:
             print("\nAdded Step VxB\n")
 
-        self._propagators += [propagators_coupling.EfieldWeightsExplicit(
-            self._e,
-            self._electrons,
+        self.add_propagator(self.prop_coupling.EfieldWeightsExplicit(
+            self.pointer['e_field'],
+            self.pointer['electrons'],
             alpha=self.alpha,
             kappa=self.kappa,
             f0=self._f0,
-            **params['solvers']['solver_ew']
-        )]
+            **params['solvers']['solver_ew']))
         if self._rank == 0:
             print("\nAdded Step EfieldWeights\n")
 
-        self._propagators += [propagators_fields.Maxwell(
-            self._e,
-            self._b,
-            **params['solvers']['solver_eb'])]
+        self.add_propagator(self.prop_fields.Maxwell(
+            self.pointer['e_field'],
+            self.pointer['b_field'],
+            **params['solvers']['solver_eb']))
         if self._rank == 0:
             print("\nAdded Step Maxwell\n")
 
         # Scalar variables to be saved during simulation
-        self._scalar_quantities = {}
-        self._scalar_quantities['en_e'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_b'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_w'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_tot'] = np.empty(1, dtype=float)
+        self.add_scalar('en_e')
+        self.add_scalar('en_b')
+        self.add_scalar('en_w')
+        self.add_scalar('en_tot')
 
         # MPI operations needed for scalar variables
         self._mpi_sum = SUM
         self._mpi_in_place = IN_PLACE
 
-    @property
-    def propagators(self):
-        return self._propagators
-
-    @property
-    def scalar_quantities(self):
-        return self._scalar_quantities
+        # temporaries
+        self._en_e_tmp = self.pointer['e_field'].space.zeros()
+        self._en_b_tmp = self.pointer['b_field'].space.zeros()
+        self._tmp = np.empty(1, dtype=float)
 
     def initialize_from_params(self):
-        from struphy.propagators import solvers
+
         from struphy.pic.particles_to_grid import AccumulatorVector
+        from psydac.linalg.stencil import StencilVector
 
         # Initialize fields and particles
         super().initialize_from_params()
 
-        f0_values = self._f0(*self._electrons.markers_wo_holes[:, :6].T)
+        f0_values = self._f0(
+            *self.pointer['electrons'].markers_wo_holes[:, :6].T)
 
         # Correct initialization of weights: w_p = f_0 * (1 - log(f_0)) / (N * s_0) - w_p^0 * log(f_0) / N
-        self._electrons.markers[~self._electrons.holes, 6] = \
-            f0_values * (1 - np.log(f0_values)) / (self._electrons.n_mks * self._electrons.markers_wo_holes[:, 7]) - \
-            self._electrons.markers_wo_holes[:, 8] * \
-            np.log(f0_values) / self._electrons.n_mks
+        self.pointer['electrons'].markers[~self.pointer['electrons'].holes, 6] = \
+            f0_values * (1 - np.log(f0_values)) / (self.pointer['electrons'].n_mks * self.pointer['electrons'].markers_wo_holes[:, 7]) - \
+            self.pointer['electrons'].markers_wo_holes[:, 8] * \
+            np.log(f0_values) / self.pointer['electrons'].n_mks
 
         # evaluate f0
-        f0_values = self._f0(self._electrons.markers[:, 0],
-                             self._electrons.markers[:, 1],
-                             self._electrons.markers[:, 2],
-                             self._electrons.markers[:, 3],
-                             self._electrons.markers[:, 4],
-                             self._electrons.markers[:, 5])
+        f0_values = self._f0(self.pointer['electrons'].markers[:, 0],
+                             self.pointer['electrons'].markers[:, 1],
+                             self.pointer['electrons'].markers[:, 2],
+                             self.pointer['electrons'].markers[:, 3],
+                             self.pointer['electrons'].markers[:, 4],
+                             self.pointer['electrons'].markers[:, 5])
 
         # Accumulate charge density
         charge_accum = AccumulatorVector(
             self.derham, self.domain, "H1", "delta_f_vlasov_maxwell_poisson")
-        charge_accum.accumulate(self._electrons, f0_values,
+        charge_accum.accumulate(self.pointer['electrons'], f0_values,
                                 np.array(
                                     list(self._maxwellian_params.values())),
                                 self.alpha, self.kappa)
 
-        # Subtract the charge local to each process
-        charge_accum._vectors[0][:, :, :] -= \
-            np.sum(charge_accum.vectors[0].toarray()) / \
-            charge_accum.vectors[0].toarray().size
-
-        # Then solve Poisson equation
-        poisson_solver = solvers.PoissonSolver(
-            rho=charge_accum.vectors[0], **self._poisson_params)
-        poisson_solver(0.)
-        self.derham.grad.dot(-poisson_solver._phi, out=self._e)
+        # Locally subtract mean charge for solvability with periodic bc
+        if np.all(charge_accum.vectors[0].space.periods):
+            charge_accum._vectors[0][:] -= np.mean(charge_accum.vectors[0].toarray()[
+                                                   charge_accum.vectors[0].toarray() != 0])
+
+        # Instantiate Poisson solver
+        _phi = StencilVector(self.derham.Vh['0'])
+        poisson_solver = self.prop_fields.ImplicitDiffusion(
+            _phi,
+            sigma=0.,
+            phi_n=charge_accum.vectors[0],
+            x0=charge_accum.vectors[0],
+            **self._poisson_params)
+
+        # Solve with dt=1. and compute electric field
+        poisson_solver(1.)
+        self.derham.grad.dot(-_phi, out=self.pointer['e_field'])
 
     def update_scalar_quantities(self):
+        # 0.5 * e^T * M_1 * e
+        self._mass_ops.M1.dot(self.pointer['e_field'], out=self._en_e_tmp)
+        en_E = self.pointer['e_field'].dot(self._en_e_tmp) / 2.
+        self.update_scalar('en_e', en_E)
 
-        # e^T * M_1 * e
-        self._scalar_quantities['en_e'][0] = self._e.dot(
-            self._mass_ops.M1.dot(self._e)) / 2.
-
-        # b^T * M_2 * b
-        self._scalar_quantities['en_b'][0] = self._b.dot(
-            self._mass_ops.M2.dot(self._b)) / 2.
+        # 0.5 * b^T * M_2 * b
+        self._mass_ops.M2.dot(self.pointer['b_field'], out=self._en_b_tmp)
+        en_B = self.pointer['b_field'].dot(self._en_b_tmp) / 2.
+        self.update_scalar('en_b', en_B)
 
         # alpha^2 * v_th_1^2 * v_th_2^2 * v_th_3^2 * sum_p w_p
-        self._scalar_quantities['en_w'][0] = \
+        self._tmp[0] = \
             self.alpha**2 * \
             self._maxwellian_params['vth1']**2 * \
             self._maxwellian_params['vth2']**2 * \
             self._maxwellian_params['vth3']**2 * \
-            np.sum(self._electrons.markers_wo_holes[:, 6])
+            np.sum(self.pointer['electrons'].markers_wo_holes[:, 6])
 
         self.derham.comm.Allreduce(
-            self._mpi_in_place, self._scalar_quantities['en_w'], op=self._mpi_sum)
+            self._mpi_in_place, self._tmp, op=self._mpi_sum)
+
+        self.update_scalar('en_w', self._tmp[0])
 
         # en_tot = en_w + en_e + en_b
-        self._scalar_quantities['en_tot'][0] = \
-            self._scalar_quantities['en_w'][0] + \
-            self._scalar_quantities['en_e'][0] + \
-            self._scalar_quantities['en_b'][0]
+        self.update_scalar('en_tot', self._tmp[0] + en_E + en_B)
 
 
 class VlasovMasslessElectrons(StruphyModel):
     r'''Hybrid (kinetic ions + massless electrons) equations with quasi-neutrality condition. 
     Unknowns: distribution function for ions, and vector potential.
 
     Normalization:
```

### Comparing `struphy-2.0.1/src/struphy/models/main.py` & `struphy-2.0.2/src/struphy/models/main.py`

 * *Files 3% similar despite different names*

```diff
@@ -50,15 +50,15 @@
                             size)
 
     # instantiate STRUPHY model (will only allocate model objects and associated memory)
     objs = [fluid, kinetic, hybrid, toy]
     for obj in objs:
         try:
             model_class = getattr(obj, model_name)
-        except AttributeError: 
+        except AttributeError:
             pass
 
     model = model_class(params, comm)
 
     # data object for saving (will either create new hdf5 files if restart==False or open existing files if restart==True)
     data = DataContainer(path_out, comm=comm)
 
@@ -73,14 +73,17 @@
         key_time_restart = 'restart/time/' + key
         data.add_data({key_time: val})
         data.add_data({key_time_restart: val})
 
     # start a new simulation (set initial conditions according to parameter file)
     time_params = params['time']
 
+    if rank == 0:
+        print('\nINITIAL CONDITIONS:')
+
     if not restart:
         model.initialize_from_params()
         total_steps = str(
             int(round(time_params['Tend']/time_params['dt'])))
 
     # restart of an existing simulation (overwrite time quantities and load restart data from hdf5 files)
     else:
@@ -91,15 +94,15 @@
             int(round((time_params['Tend'] - time_state['value'][0])/time_params['dt'])))
 
         model.initialize_from_restart(data)
 
     # list of model methods for diagnostics
     model_updates = []
     for method in dir(model):
-        if 'update' in method:
+        if 'update' in method and method != 'update_scalar':
             model_updates.append(getattr(model, method))
 
     # initial diagnostic data (will be saved in hdf5 file)
     for method in model_updates:
         method()
 
     # prepare hdf5 file structure
@@ -136,15 +139,17 @@
             if rank == 0:
                 print('wall-clock time of simulation [sec]: ',
                       end_simulation - start_simulation)
                 print()
             break
 
         # integrate the model for a time step dt
+        t0 = time.time()
         model.integrate(time_params['dt'], time_params['split_algo'])
+        t1 = time.time()
 
         # update time and index (round time to 10 decimals for a clean time grid!)
         time_state['value'][0] = round(
             time_state['value'][0] + time_params['dt'], 10)
         time_state['index'][0] += 1
 
         # update diagnostics data and save data
@@ -170,16 +175,18 @@
             # save data (everything but restart data)
             data.save_data(keys=save_keys_all)
 
             # print current time and scalar quantities to screen
             if rank == 0:
                 step = str(time_state['index'][0]).zfill(len(total_steps))
 
-                message = 'time: {0:12.8f}/{1:12.8f}'.format(time_state['value'][0], time_params['Tend'])
-                message += ' | ' + 'time step: ' + step + '/' + str(total_steps) 
+                message = 'time step: ' + step + '/' + str(total_steps) 
+                message += ' | ' + 'time: {0:10.5f}/{1:10.5f}'.format(
+                    time_state['value'][0], time_params['Tend'])
+                message += ' | ' + 'wall clock [s]: {0:8.4f} | last step duration [s]: {1:8.4f}'.format(run_time_now*60, t1 - t0)
 
                 print(message, end='\n')
                 model.print_scalar_quantities()
                 print()
     # ===================================================================
 
     with open(path_out + '/meta.txt', 'a') as f:
@@ -190,39 +197,42 @@
 if __name__ == '__main__':
 
     import argparse
     import os
     import struphy
 
     libpath = struphy.__path__[0]
-    
-    with open(os.path.join(libpath, 'io_path.txt')) as f:
-        io_path = f.readlines()[0]
+
+    with open(os.path.join(libpath, 'i_path.txt')) as f:
+        i_path = f.readlines()[0]
+
+    with open(os.path.join(libpath, 'o_path.txt')) as f:
+        o_path = f.readlines()[0]
 
     parser = argparse.ArgumentParser(description='Run an Struphy model.')
 
     # model
     parser.add_argument('model',
                         type=str,
                         metavar='model',
                         help='the name of the model to run (default=Maxwell)')
 
     # input (absolute path)
     parser.add_argument('-i', '--input',
                         type=str,
                         metavar='FILE',
                         help='absolute path of parameter file (.yml) (default=<struphy_path>/io/inp/parameters.yml)',
-                        default=os.path.join(io_path, 'io/inp/parameters.yml'))
+                        default=os.path.join(i_path, 'parameters.yml'))
 
     # output (absolute path)
     parser.add_argument('-o', '--output',
                         type=str,
                         metavar='DIR',
                         help='absolute path of output folder (default=<struphy_path>/io/out/sim_1)',
-                        default=os.path.join(io_path, 'io/out/sim_1'))
+                        default=os.path.join(o_path, 'sim_1'))
 
     # restart
     parser.add_argument('-r', '--restart',
                         help='restart the simulation in the output folder specified under -o',
                         action='store_true')
 
     # runtime
```

### Comparing `struphy-2.0.1/src/struphy/models/output_handling.py` & `struphy-2.0.2/src/struphy/models/output_handling.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/models/setup.py` & `struphy-2.0.2/src/struphy/models/setup.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,26 +1,25 @@
 import numpy as np
 
 
 def derive_units(Z_bulk=1, A_bulk=1., x=1., B=1., n=1., time_scale='alfvn'):
-    """
-    Computes Struphy units used in Struphy model implementations.
-    
+    """ Computes Struphy units used in Struphy model implementations.
+
     Input units from parameter file:
-    
+
         * Length (m)
         * Magnetic field (T)
         * number density (10^20 1/m^3)
-        
+
     Velocity unit must be defined in each model as one of "light", "alfvn" or "cyclotron":
-    
+
         * Velocity (m/s)
-        
+
     Derived units using mass and charge number of bulk species:
-    
+
         * Time (s)
         * Mass density (kg/m^3)
         * Pressure (Pa)
 
     Parameters
     ---------
     Z_bulk : int
@@ -68,35 +67,37 @@
     units['n'] = n * 1e20
     # velocity (m/s)
     if time_scale == 'light':
         units['v'] = 1*c
     elif time_scale == 'alfvn':
         units['v'] = units['B'] / np.sqrt(units['n'] * A_bulk * mH * mu0)
     elif time_scale == 'cyclotron':
-        units['v'] = Z_bulk * e * units['B'] / (A_bulk * mH) / (2*np.pi) * units['x']
+        units['v'] = Z_bulk * e * units['B'] / \
+            (A_bulk * mH) / (2*np.pi) * units['x']
     # time (s)
     units['t'] = units['x'] / units['v']
     # pressure (Pa)
     units['p'] = A_bulk * mH * units['n'] * units['x']**3 / \
-        (units['x'] * units['t']**2) # this is equal to B^2/(mu0*n) if time_scale='alfvn'
+        (units['x'] * units['t'] **
+         2)  # this is equal to B^2/(mu0*n) if time_scale='alfvn'
     # mass density (kg/m^3)
     units['rho'] = A_bulk * mH * units['n']
 
     return units
 
 
 def setup_domain_mhd(params, units=None):
     """
     Creates the domain object and MHD equilibrium for a given parameter file.
 
     Parameters
     ----------
     params : dict
         The full simulation parameter dictionary.
-        
+
     units : dict
         All Struphy units.
 
     Returns
     -------
     domain : struphy.geometry.base.Domain
         The Struphy domain object for evaluating the mapping F : [0, 1]^3 --> R^3 and the corresponding metric coefficients.
@@ -269,15 +270,15 @@
         Maximum run time of simulation in minutes. Will finish the time integration once this limit is reached.
 
     mpi_rank : int
         The rank of the calling process.
 
     mpi_size : int
         Total number of MPI processes of the run.
-        
+
     Returns
     -------
     params : dict
         The simulation parameters.
     """
 
     import os
@@ -292,15 +293,15 @@
     if mpi_rank == 0:
         print('\nPREPARATION AND CLEAN-UP:')
 
         # create output folder if it does not exit
         if not os.path.exists(path_out):
             os.mkdir(path_out)
             print('Created folder ' + path_out)
-            
+
         # create data folder in output folder if it does not exist
         if not os.path.exists(os.path.join(path_out, 'data/')):
             os.mkdir(os.path.join(path_out, 'data/'))
             print('Created folder ' + os.path.join(path_out, 'data/'))
 
         # clean output folder if it already exists
         else:
@@ -326,15 +327,15 @@
             # remove .png files (if NOT a restart)
             if not restart:
                 files = glob.glob(os.path.join(path_out, '*.png'))
                 for n, file in enumerate(files):
                     os.remove(file)
                     if n < 10:  # print only ten statements in case of many processes
                         print('Removed existing file ' + file)
-                        
+
                 files = glob.glob(os.path.join(path_out, 'data', '*.hdf5'))
                 for n, file in enumerate(files):
                     os.remove(file)
                     if n < 10:  # print only ten statements in case of many processes
                         print('Removed existing file ' + file)
 
     # save "parameters" dictionary as .yml file
@@ -369,15 +370,15 @@
         print('python version:'.ljust(25), sysconfig.get_python_version())
         print('model:'.ljust(25), model_name)
         print('MPI processes:'.ljust(25), mpi_size)
         print('parameter file:'.ljust(25), parameters_path)
         print('output folder:'.ljust(25), path_out)
         print('restart:'.ljust(25), restart)
         print('max wall-clock [min]:'.ljust(25), max_sim_time)
-        
+
         # print domain info
         print('\nDOMAIN:')
         print(f'type:'.ljust(25), params['geometry']['type'])
         for key, val in params['geometry'][params['geometry']['type']].items():
             if key not in {'cx', 'cy', 'cz'}:
                 print((key + ':').ljust(25), val)
 
@@ -385,15 +386,15 @@
         print('\nGRID:')
         print(f'number of elements:'.ljust(25), params['grid']['Nel'])
         print(f'spline degrees:'.ljust(25), params['grid']['p'])
         print(f'periodic bcs:'.ljust(25), params['grid']['spl_kind'])
         print(f'hom. Dirichlet bc:'.ljust(25), params['grid']['bc'])
         print(f'GL quad pts (L2):'.ljust(25), params['grid']['nq_el'])
         print(f'GL quad pts (hist):'.ljust(25), params['grid']['nq_pr'])
-        
+
         # print time info
         print('\nTIME:')
         print(f'time step:'.ljust(25), params['time']['dt'])
         print(f'final time:'.ljust(25), params['time']['Tend'])
         print(f'splitting algo:'.ljust(25), params['time']['split_algo'])
 
         # write meta data to output folder
```

### Comparing `struphy-2.0.1/src/struphy/models/toy.py` & `struphy-2.0.2/src/struphy/models/toy.py`

 * *Files 23% similar despite different names*

```diff
@@ -36,65 +36,42 @@
     def timescale(cls):
         return 'light'
 
     def __init__(self, params, comm):
 
         super().__init__(params, comm, e1='Hcurl', b2='Hdiv')
 
-        from struphy.propagators.base import Propagator
-        from struphy.propagators import propagators_fields
-
-        # Pointers to em-field variables
-        self._e = self.em_fields['e1']['obj'].vector
-        self._b = self.em_fields['b2']['obj'].vector
-
         # extract necessary parameters
         solver_params = params['solvers']['solver_1']
 
-        # set propagators base class attributes
-        Propagator.derham = self.derham
-        Propagator.domain = self.domain
-        Propagator.mass_ops = self.mass_ops
-
         # Initialize propagators/integrators used in splitting substeps
-        self._propagators = []
-        self._propagators += [propagators_fields.Maxwell(
-            self._e,
-            self._b,
-            **solver_params)]
+        self.add_propagator(self.prop_fields.Maxwell(
+            self.pointer['e1'],
+            self.pointer['b2'],
+            **solver_params))
 
         # Scalar variables to be saved during simulation
-        self._scalar_quantities = {}
-        self._scalar_quantities['en_E'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_B'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_tot'] = np.empty(1, dtype=float)
+        self.add_scalar('en_E')
+        self.add_scalar('en_B')
+        self.add_scalar('en_tot')
 
         # temporary vectors for scalar quantities
         self._tmp_e = self.derham.Vh['1'].zeros()
         self._tmp_b = self.derham.Vh['2'].zeros()
 
-    @property
-    def propagators(self):
-        return self._propagators
-
-    @property
-    def scalar_quantities(self):
-        return self._scalar_quantities
-
     def update_scalar_quantities(self):
-        self._mass_ops.M1.dot(self._e, out=self._tmp_e)
-        self._mass_ops.M2.dot(self._b, out=self._tmp_b)
+        self._mass_ops.M1.dot(self.pointer['e1'], out=self._tmp_e)
+        self._mass_ops.M2.dot(self.pointer['b2'], out=self._tmp_b)
 
-        en_E = self._e.dot(self._tmp_e)/2
-        en_B = self._b.dot(self._tmp_b)/2
+        en_E = self.pointer['e1'].dot(self._tmp_e)/2
+        en_B = self.pointer['b2'].dot(self._tmp_b)/2
 
-        self._scalar_quantities['en_E'][0] = en_E
-        self._scalar_quantities['en_B'][0] = en_B
-
-        self._scalar_quantities['en_tot'][0] = en_E + en_B
+        self.update_scalar('en_E', en_E)
+        self.update_scalar('en_B', en_B)
+        self.update_scalar('en_tot', en_E + en_B)
 
 
 class Vlasov(StruphyModel):
     r'''Vlasov equation in static background magnetic field.
 
     :ref:`normalization`:
 
@@ -125,78 +102,59 @@
     def timescale(cls):
         return 'cyclotron'
 
     def __init__(self, params, comm):
 
         super().__init__(params, comm, ions='Particles6D')
 
-        from struphy.propagators.base import Propagator
-        from struphy.propagators import propagators_markers
         from mpi4py.MPI import SUM, IN_PLACE
 
-        # pointer to ions
-        self._ions = self.kinetic['ions']['obj']
+        # prelim
         ions_params = self.kinetic['ions']['params']
-
         print(
-            f'Total number of markers : {self._ions.n_mks}, shape of markers array on rank {self.derham.comm.Get_rank()} : {self._ions.markers.shape}')
+            f'Total number of markers : {self.pointer["ions"].n_mks}, shape of markers array on rank {self.derham.comm.Get_rank()} : {self.pointer["ions"].markers.shape}')
 
         # project magnetic background
         self._b_eq = self.derham.P['2']([self.mhd_equil.b2_1,
                                          self.mhd_equil.b2_2,
                                          self.mhd_equil.b2_3])
 
-        # set propagators base class attributes
-        Propagator.derham = self.derham
-        Propagator.domain = self.domain
-        Propagator.mass_ops = self.mass_ops
-
         # Initialize propagators/integrators used in splitting substeps
-        self._propagators = []
-
-        self._propagators += [propagators_markers.PushVxB(
-            self._ions,
+        self.add_propagator(self.prop_markers.PushVxB(
+            self.pointer['ions'],
             algo=ions_params['push_algos']['vxb'],
             scale_fac=1.,
             b_eq=self._b_eq,
             b_tilde=None,
-            f0=None)]
-
-        self._propagators += [propagators_markers.PushEta(
-            self._ions,
+            f0=None))
+        self.add_propagator(self.prop_markers.PushEta(
+            self.pointer['ions'],
             algo=ions_params['push_algos']['eta'],
             bc_type=ions_params['markers']['bc_type'],
-            f0=None)]
+            f0=None))
 
         # Scalar variables to be saved during simulation
-        self._scalar_quantities = {}
-        
-        self._scalar_quantities['en_f'] = np.empty(1, dtype=float)
+        self.add_scalar('en_f')
 
         # MPI operations needed for scalar variables
         self._mpi_sum = SUM
         self._mpi_in_place = IN_PLACE
-
-    @property
-    def propagators(self):
-        return self._propagators
-
-    @property
-    def scalar_quantities(self):
-        return self._scalar_quantities
+        self._tmp = np.empty(1, dtype=float)
 
     def update_scalar_quantities(self):
-        
-        self._scalar_quantities['en_f'][0] = self._ions.markers_wo_holes[:, 6].dot(
-            self._ions.markers_wo_holes[:, 3]**2 +
-            self._ions.markers_wo_holes[:, 4]**2 +
-            self._ions.markers_wo_holes[:, 5]**2)/(2*self._ions.n_mks)
+
+        self._tmp[0] = self.pointer['ions'].markers_wo_holes[:, 6].dot(
+            self.pointer['ions'].markers_wo_holes[:, 3]**2 +
+            self.pointer['ions'].markers_wo_holes[:, 4]**2 +
+            self.pointer['ions'].markers_wo_holes[:, 5]**2) / (2*self.pointer['ions'].n_mks)
 
         self.derham.comm.Allreduce(
-            self._mpi_in_place, self._scalar_quantities['en_f'], op=self._mpi_sum)
+            self._mpi_in_place, self._tmp, op=self._mpi_sum)
+
+        self.update_scalar('en_f', self._tmp[0])
 
 
 class DriftKinetic(StruphyModel):
     r'''Drift-kinetic equation in static background magnetic field (guiding-center motion). 
 
     :ref:`normalization`:
 
@@ -239,20 +197,17 @@
     def timescale(cls):
         return 'alfvn'
 
     def __init__(self, params, comm):
 
         super().__init__(params, comm, ions='Particles5D')
 
-        from struphy.propagators.base import Propagator
-        from struphy.propagators import propagators_markers
         from mpi4py.MPI import SUM, IN_PLACE
 
-        # pointer to ions
-        self._ions = self.kinetic['ions']['obj']
+        # prelim
         ions_params = self.kinetic['ions']['params']
 
         # project magnetic background
         self._b_eq = self.derham.P['2']([self.mhd_equil.b2_1,
                                          self.mhd_equil.b2_2,
                                          self.mhd_equil.b2_3])
 
@@ -265,106 +220,65 @@
         self._unit_b2 = self.derham.P['2']([self.mhd_equil.unit_b2_1,
                                             self.mhd_equil.unit_b2_2,
                                             self.mhd_equil.unit_b2_3])
 
         self._E0T = self.derham.E['0'].transpose()
         self._EvT = self.derham.E['v'].transpose()
 
-        ee = 1.602176634e-19  # elementary charge (C)
-        mH = 1.67262192369e-27  # proton mass (kg)
-
-        Ah = params['kinetic']['ions']['phys_params']['A']
-        Zh = params['kinetic']['ions']['phys_params']['Z']
-
-        omega_ch = (Zh*ee*self.units_basic['B'])/(Ah*mH)
-        kappa = omega_ch*self.units_basic['t']
-
+        kappa = 1. / self.eq_params['ions']['epsilon_unit']
         if abs(kappa - 1) < 1e-6:
             kappa = 1.
 
-        # set propagators base class attributes
-        Propagator.derham = self.derham
-        Propagator.domain = self.domain
-
         # Initialize propagators/integrators used in splitting substeps
-        self._propagators = []
-        self._propagators += [propagators_markers.StepPushGuidingCenter1(
-            self._ions,
+        self.add_propagator(self.prop_markers.StepPushGuidingCenter1(
+            self.pointer['ions'],
             kappa=kappa,
             b_eq=self._b_eq,
             unit_b1=self._unit_b1,
             unit_b2=self._unit_b2,
             abs_b=self._abs_b,
-            integrator=ions_params['push_algos']['integrator'],
-            method='discrete_gradients',
-            maxiter=ions_params['push_algos']['maxiter'],
-            tol=ions_params['push_algos']['tol'])]
-        self._propagators += [propagators_markers.StepPushGuidingCenter2(
-            self._ions,
+            integrator=ions_params['push_algos1']['integrator'],
+            method=ions_params['push_algos1']['method'],
+            maxiter=ions_params['push_algos1']['maxiter'],
+            tol=ions_params['push_algos1']['tol']))
+        self.add_propagator(self.prop_markers.StepPushGuidingCenter2(
+            self.pointer['ions'],
             kappa=kappa,
             b_eq=self._b_eq,
             unit_b1=self._unit_b1,
             unit_b2=self._unit_b2,
             abs_b=self._abs_b,
-            method='discrete_gradients_Itoh_Newton',
-            integrator=ions_params['push_algos']['integrator'],
-            maxiter=ions_params['push_algos']['maxiter'],
-            tol=ions_params['push_algos']['tol'])]
+            integrator=ions_params['push_algos2']['integrator'],
+            method=ions_params['push_algos2']['method'],
+            maxiter=ions_params['push_algos2']['maxiter'],
+            tol=ions_params['push_algos2']['tol']))
 
         # Scalar variables to be saved during simulation
-        self._scalar_quantities = {}
-        self._en_fv_loc = np.empty(1, dtype=float)
-        self._scalar_quantities['en_fv'] = np.empty(1, dtype=float)
-        self._en_fB_loc = np.empty(1, dtype=float)
-        self._scalar_quantities['en_fB'] = np.empty(1, dtype=float)
-        self._en_fv_loc_lost = np.empty(1, dtype=float)
-        self._scalar_quantities['en_fv_lost'] = np.empty(1, dtype=float)
-        self._en_fB_loc_lost = np.empty(1, dtype=float)
-        self._scalar_quantities['en_fB_lost'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_tot'] = np.empty(1, dtype=float)
+        self.add_scalar('en_fv')
+        self.add_scalar('en_fB')
+        self.add_scalar('en_tot')
 
         # MPI operations needed for scalar variables
         self._mpi_sum = SUM
-
-    @property
-    def propagators(self):
-        return self._propagators
-
-    @property
-    def scalar_quantities(self):
-        return self._scalar_quantities
+        self._mpi_in_place = IN_PLACE
+        self._en_fv_loc = np.empty(1, dtype=float)
+        self._en_fB_loc = np.empty(1, dtype=float)
 
     def update_scalar_quantities(self):
-
         # particles' kinetic energy
-        self._en_fv_loc = self._ions.markers[~self._ions.holes, 5].dot(
-            self._ions.markers[~self._ions.holes, 3]**2) / (2.*self._ions.n_mks)
-        self.derham.comm.Reduce(
-            self._en_fv_loc, self._scalar_quantities['en_fv'], op=self._mpi_sum, root=0)
-    
-        self._en_fv_loc_lost = self._ions.lost_markers[:self._ions.n_lost_markers, 5].dot(
-            self._ions.lost_markers[:self._ions.n_lost_markers, 3]**2) / (2.*self._ions.n_mks)
-        self.derham.comm.Reduce(
-            self._en_fv_loc_lost, self._scalar_quantities['en_fv_lost'], op=self._mpi_sum, root=0)
+        self._en_fv_loc[0] = self.pointer['ions'].markers[~self.pointer['ions'].holes, 5].dot(
+            self.pointer['ions'].markers[~self.pointer['ions'].holes, 3]**2) / (2.*self.pointer['ions'].n_mks)
+        self.derham.comm.Allreduce(
+            self._mpi_in_place, self._en_fv_loc, op=self._mpi_sum)
 
         # particles' magnetic energy
-        self._ions.save_magnetic_energy(self._derham,
-            self._E0T.dot(self.derham.P['0'](self.mhd_equil.absB0)))
+        self.pointer['ions'].save_magnetic_energy(self._derham,
+                                        self._E0T.dot(self.derham.P['0'](self.mhd_equil.absB0)))
+
+        self._en_fB_loc[0] = self.pointer['ions'].markers[~self.pointer['ions'].holes, 5].dot(
+            self.pointer['ions'].markers[~self.pointer['ions'].holes, 8]) / self.pointer['ions'].n_mks
+        self.derham.comm.Allreduce(
+            self._mpi_in_place, self._en_fB_loc, op=self._mpi_sum)
 
-        self._en_fB_loc = self._ions.markers[~self._ions.holes, 5].dot(
-            self._ions.markers[~self._ions.holes, 8]) / self._ions.n_mks
-        self.derham.comm.Reduce(
-            self._en_fB_loc, self._scalar_quantities['en_fB'], op=self._mpi_sum, root=0)
-        
-        self._en_fB_loc_lost = self._ions.lost_markers[:self._ions.n_lost_markers, 5].dot(
-            self._ions.lost_markers[:self._ions.n_lost_markers, 8]) / self._ions.n_mks
-        self.derham.comm.Reduce(
-            self._en_fB_loc_lost, self._scalar_quantities['en_fB_lost'], op=self._mpi_sum, root=0)
-
-        self._scalar_quantities['en_tot'][0] = self._scalar_quantities['en_fv'][0]
-        self._scalar_quantities['en_tot'][0] += self._scalar_quantities['en_fB'][0]
-        self._scalar_quantities['en_tot'][0] += self._scalar_quantities['en_fv_lost'][0]
-        self._scalar_quantities['en_tot'][0] += self._scalar_quantities['en_fB_lost'][0]
-
-        # print(self._ions.markers[~self._ions.holes,0:9])
-        print('Number of lost markers:', self._ions.n_lost_markers)
-        # print(self._ions.lost_markers[:self._ions.n_lost_markers,:])
+        self.update_scalar('en_fv', self._en_fv_loc[0])
+        self.update_scalar('en_fB', self._en_fB_loc[0])
+        self.update_scalar('en_tot', self._en_fv_loc[0] + self._en_fB_loc[0])
```

### Comparing `struphy-2.0.1/src/struphy/pic/accum_kernels.py` & `struphy-2.0.2/src/struphy/pic/accum_kernels_gc.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,1444 +1,33 @@
 from pyccel.decorators import stack_array
 
-from numpy import zeros, empty, sqrt, shape, floor, log
+from numpy import zeros, empty, shape
 
 import struphy.geometry.map_eval as map_eval
 import struphy.b_splines.bsplines_kernels as bsp
 import struphy.b_splines.bspline_evaluation_3d as eval_3d
 import struphy.linear_algebra.core as linalg
 import struphy.pic.mat_vec_filler as mvf
-import struphy.pic.filler_kernels as fk
-
-
-def _docstring():
-    '''
-    MODULE DOCSTRING for :ref:`accumulators`.
-
-    The module contains model-specific accumulation routines (pyccelized), to be defined by the user.
-
-    Naming conventions:
-        - use the model name, all lower-case letters (e.g. lin_vlasov_maxwell)
-        - in case of multiple accumulations in one model, attach _1, _2, etc. 
-
-    Arguments have to be passed in the following order (copy and paste from existing accum_kernels function):
-
-    - First, the marker info:
-        - markers: 'float[:,:]',          # positions [0:3,], velocities [3:6,], and weights [6,] of the markers
-
-    - then, the Derham spline bases info:
-        - pn: 'int[:]',                   # N-spline degree in each direction
-        - tn1: 'float[:]',                # N-spline knot vector 
-        - tn2: 'float[:]',
-        - tn3: 'float[:]',    
-
-    - then, the mpi.comm info of all spaces:
-        - starts0: 'int[:]'               # start indices of current process of elements in space V0
-        - starts1: 'int[:,:]'             # start indices of current process of elements in space V1 in format (component, direction)
-        - starts2: 'int[:,:]'             # start indices of current process of elements in space V2 in format (component, direction)
-        - starts3: 'int[:]'               # start indices of current process of elements in space V3
-
-    - then, the mapping info:
-        - kind_map: 'int',                # mapping identifier 
-        - params_map: 'float[:]',         # mapping parameters
-        - p_map: 'int[:]',                # spline degree
-        - t1_map: 'float[:]',             # knot vector 
-        - t2_map: 'float[:]',             
-        - t3_map: 'float[:]', 
-        - ind1_map: int[:,:],             # Indices of non-vanishing splines in format (number of mapping grid cells, p_map + 1)       
-        - ind2_map: int[:,:], 
-        - ind3_map: int[:,:],            
-        - cx: 'float[:,:,:]',             # control points for Fx
-        - cy: 'float[:,:,:]',             # control points for Fy
-        - cz: 'float[:,:,:]',             # control points for Fz                         
-
-    - then, the data objects (number depends on model, but at least one matrix has to be passed)
-        - mat11: 'float[:,:,:,:,:,:]',    # _data attribute of StencilMatrix
-        - optional:
-
-            - mat12: 'float[:,:,:,:,:,:]',
-            - mat13: 'float[:,:,:,:,:,:]',
-            - mat21: 'float[:,:,:,:,:,:]',
-            - mat22: 'float[:,:,:,:,:,:]',
-            - mat23: 'float[:,:,:,:,:,:]',
-            - mat31: 'float[:,:,:,:,:,:]',
-            - mat32: 'float[:,:,:,:,:,:]',
-            - mat33: 'float[:,:,:,:,:,:]',
-            - vec1: 'float[:,:,:]',           # _data attribute of StencilVector
-            - vec2: 'float[:,:,:]',
-            - vec3: 'float[:,:,:]'
-
-    - optional: additional parameters, for example
-        - b2_1: 'float[:,:,:]',           # spline coefficients of b2_1
-        - b2_2: 'float[:,:,:]',           # spline coefficients of b2_2
-        - b2_3: 'float[:,:,:]'            # spline coefficients of b2_3
-        - f0_params: 'float[:]',          # parameters of equilibrium background
-    '''
-
-    print('This is just the docstring function.')
-
-
-@stack_array('cell_left', 'point_left', 'point_right', 'cell_number', 'temp1', 'temp4', 'compact', 'grids_shapex', 'grids_shapey', 'grids_shapez')
-def hybrid_fA_density(markers: 'float[:,:]', n_markers_tot: 'int',
-                          pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                          starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                          kind_map: 'int', params_map: 'float[:]',
-                          p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                          ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                          cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                          mat: 'float[:,:,:,:,:,:]', Nel: 'int[:]', quad: 'int[:]', quad_pts_x: 'float[:]', quad_pts_y: 'float[:]', quad_pts_z: 'float[:]',
-                          p_shape: 'int[:]', p_size: 'float[:]'):  # model specific argument
-    r"""
-    Accumulates the values of density at quadrature points with the filling functions
-
-    .. math::
-        n = \sum_p w_p S(x - x_p)
-
-    Parameters
-    ----------
-        To do 
-    Note
-    ----
-        The above parameter list contains only the model specific input arguments.
-    """
-
-    # allocate
-    cell_left    = empty(3, dtype=int)
-    point_left   = zeros(3, dtype=float)
-    point_right  = zeros(3, dtype=float)
-    cell_number  = empty(3, dtype=int)
-
-    temp1        = zeros(3, dtype=float)
-    temp4        = zeros(3, dtype=float)
-
-    compact      = zeros(3, dtype=float)
-    compact[0]   = (p_shape[0]+1.0)*p_size[0]
-    compact[1]   = (p_shape[1]+1.0)*p_size[1]
-    compact[2]   = (p_shape[2]+1.0)*p_size[2]
-
-    grids_shapex = zeros(p_shape[0] + 2, dtype=float)
-    grids_shapey = zeros(p_shape[1] + 2, dtype=float)
-    grids_shapez = zeros(p_shape[2] + 2, dtype=float)
-
-    df           = zeros((3, 3), dtype=float)
-    
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    #$ omp parallel private (df, det_df, cell_left, point_left, point_right, cell_number, temp1, temp4, compact, grids_shapex, grids_shapey, grids_shapez, n_markers, ip, eta1, eta2, eta3, weight, ie1, ie2, ie3, il1, il2, il3, jl1, jl2, jl3, i1, i2, i3, value_x, value_y, value_z, span1, span2, span3)
-    #$ omp for reduction ( + : mat)
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        # marker positions
-        eta1 = markers[ip, 0]
-        eta2 = markers[ip, 1]
-        eta3 = markers[ip, 2]
-
-        # evaluate Jacobian, result in df
-        map_eval.df(eta1, eta2, eta3,
-                    kind_map, params_map,
-                    t1_map, t2_map, t3_map, p_map,
-                    ind1_map, ind2_map, ind3_map,
-                    cx, cy, cz,
-                    df)
-
-        # metric coeffs
-        det_df = linalg.det(df)
-
-        weight = markers[ip, 6]/(p_size[0]*p_size[1]*p_size[2])/n_markers_tot/det_df
-        
-        ie1 = int(eta1*Nel[0])
-        ie2 = int(eta2*Nel[1])
-        ie3 = int(eta3*Nel[2])
-
-        #the points here are still not put in the periodic box [0, 1] x [0, 1] x [0, 1]
-        point_left[0]  = eta1 - 0.5*compact[0]
-        point_right[0] = eta1 + 0.5*compact[0]
-        point_left[1]  = eta2 - 0.5*compact[1]
-        point_right[1] = eta2 + 0.5*compact[1]
-        point_left[2]  = eta3 - 0.5*compact[2]
-        point_right[2] = eta3 + 0.5*compact[2]
-
-        cell_left[0] = int(floor(point_left[0]*Nel[0]))
-        cell_left[1] = int(floor(point_left[1]*Nel[1]))
-        cell_left[2] = int(floor(point_left[2]*Nel[2]))
-
-        cell_number[0] = int(floor(point_right[0]*Nel[0])) - cell_left[0] + 1
-        cell_number[1] = int(floor(point_right[1]*Nel[1])) - cell_left[1] + 1
-        cell_number[2] = int(floor(point_right[2]*Nel[2])) - cell_left[2] + 1
-
-        for i in range(p_shape[0] + 1):
-            grids_shapex[i] = point_left[0] + i * p_size[0]
-        grids_shapex[p_shape[0] + 1] = point_right[0]
-
-        for i in range(p_shape[1] + 1):
-            grids_shapey[i] = point_left[1] + i * p_size[1]
-        grids_shapey[p_shape[1] + 1] = point_right[1]
-
-        for i in range(p_shape[2] + 1):
-            grids_shapez[i] = point_left[2] + i * p_size[2]
-        grids_shapez[p_shape[2] + 1] = point_right[2]
-
-        span1 = int(eta1*Nel[0]) + pn[0]
-        span2 = int(eta2*Nel[1]) + pn[1]
-        span3 = int(eta3*Nel[2]) + pn[2]
-
-        # =========== kernel part (periodic bundary case) ==========
-        mvf.hybrid_density(Nel, pn, cell_left, cell_number, span1, span2, span3, starts0, ie1, ie2, ie3, temp1, temp4, quad, quad_pts_x, quad_pts_y, quad_pts_z, compact, eta1, eta2, eta3, mat, weight, p_shape, p_size, grids_shapex, grids_shapey, grids_shapez)
-    #$ omp end parallel
-
-
-@stack_array('df', 'df_t', 'df_inv', 'df_inv_times_v', 'filling_m', 'filling_v')
-def hybrid_fA_Arelated(markers: 'float[:,:]', n_markers_tot: 'int',
-                          pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                          starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                          kind_map: 'int', params_map: 'float[:]',
-                          p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                          ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                          cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                          mat11: 'float[:,:,:,:,:,:]',
-                          mat12: 'float[:,:,:,:,:,:]',
-                          mat13: 'float[:,:,:,:,:,:]',
-                          mat22: 'float[:,:,:,:,:,:]',
-                          mat23: 'float[:,:,:,:,:,:]',
-                          mat33: 'float[:,:,:,:,:,:]',
-                          vec1: 'float[:,:,:]',
-                          vec2: 'float[:,:,:]',
-                          vec3: 'float[:,:,:]'):  # model specific argument
-    r"""
-    Accumulates into V1 with the filling functions
-
-    .. math::
-
-        A_p^{\mu, \nu} &= f_0(\eta_p, v_p) * [ DF^{-1}(\eta_p) * v_p ]_\mu * [ DF^{-1}(\eta_p) * v_p ]_\nu    
-
-        B_p^\mu &= \sqrt{f_0(\eta_p, v_p)} * w_p * [ DF^{-1}(\eta_p) * v_p ]_\mu  
-
-    Parameters
-    ----------
-        f0_spec : int
-            Specifier for kinetic background, see :ref:`kinetic_backgrounds`  
-
-        moms_spec : array[int]
-            Specifier for the seven moments n0, u0x, u0y, u0z, vth0x, vth0y, vth0z (in this order).
-            Is 0 for constant moment, for more see :meth:`struphy.kinetic_background.moments_kernels.moments`.
-
-        f0_params : array[float]
-            Parameters needed to specify the moments; the order is specified in :ref:`kinetic_moments` for the respective functions available.
-
-    Note
-    ----
-        The above parameter list contains only the model specific input arguments.
-    """
-
-    # allocate for metric coeffs
-    df = empty((3, 3), dtype=float)
-    df_inv = empty((3, 3), dtype=float)
-
-    # allocate for filling
-    df_inv_times_v = empty(3, dtype=float)
-    filling_m = empty((3, 3), dtype=float)
-    filling_v = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    #$ omp parallel private (ip, eta1, eta2, eta3, v, df, df_inv, df_inv_times_v, weight, filling_m, filling_v)
-    #$ omp for reduction ( + : mat11, mat12, mat13, mat21, mat22, mat23, mat31, mat32, mat33, vec1, vec2, vec3)
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        # marker positions
-        eta1 = markers[ip, 0]
-        eta2 = markers[ip, 1]
-        eta3 = markers[ip, 2]
-
-        # evaluate background
-        v = markers[ip, 3:6]
-
-        # evaluate Jacobian, result in df
-        map_eval.df(eta1, eta2, eta3,
-                    kind_map, params_map,
-                    t1_map, t2_map, t3_map, p_map,
-                    ind1_map, ind2_map, ind3_map,
-                    cx, cy, cz,
-                    df)
-
-        # filling functions
-        linalg.matrix_inv(df, df_inv)
-        linalg.matrix_vector(df_inv, v, df_inv_times_v)
-
-        weight = markers[ip, 6]
-
-        # filling_m
-        filling_m[0,0] = weight / n_markers_tot * (df_inv[0,0]*df_inv[0,0] + df_inv[0,1]*df_inv[0,1] + df_inv[0,2]*df_inv[0,2])
-        filling_m[0,1] = weight / n_markers_tot * (df_inv[0,0]*df_inv[1,0] + df_inv[0,1]*df_inv[1,1] + df_inv[0,2]*df_inv[1,2])
-        filling_m[0,2] = weight / n_markers_tot * (df_inv[0,0]*df_inv[2,0] + df_inv[0,1]*df_inv[2,1] + df_inv[0,2]*df_inv[2,2])
-
-        filling_m[1,1] = weight / n_markers_tot * (df_inv[1,0]*df_inv[1,0] + df_inv[1,1]*df_inv[1,1] + df_inv[1,2]*df_inv[1,2])
-        filling_m[1,2] = weight / n_markers_tot * (df_inv[1,0]*df_inv[2,0] + df_inv[1,1]*df_inv[2,1] + df_inv[1,2]*df_inv[2,2])
-
-        filling_m[2,2] = weight / n_markers_tot * (df_inv[2,0]*df_inv[2,0] + df_inv[2,1]*df_inv[2,1] + df_inv[2,2]*df_inv[2,2])
-
-        # filling_v
-        filling_v[:] = weight / n_markers_tot * df_inv_times_v
-
-        # call the appropriate matvec filler
-        mvf.m_v_fill_b_v1_symm(pn, tn1, tn2, tn3, starts1,
-                               eta1, eta2, eta3,
-                               mat11, mat12, mat13, mat22, mat23, mat33,
-                               filling_m[0, 0], filling_m[0, 1], filling_m[0, 2],
-                               filling_m[1, 1], filling_m[1, 2], filling_m[2, 2],
-                               vec1, vec2, vec3,
-                               filling_v[0], filling_v[1], filling_v[2])
-
-    #$ omp end parallel
-
-
-@stack_array('bn1', 'bn2', 'bn3')
-def linear_vlasov_maxwell_poisson(markers: 'float[:,:]', n_markers_tot: 'int',
-                                  pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                                  starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                                  kind_map: 'int', params_map: 'float[:]',
-                                  p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                                  ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                                  cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                  vec: 'float[:,:,:]',
-                                  f0_values: 'float[:]',  # model specific argument
-                                  f0_params: 'float[:]',  # model specific argument
-                                  alpha: 'float',  # model specific argument
-                                  kappa: 'float'):  # model specific argument
-    r"""
-    Accumulates the charge density in V0 
-
-    .. math::
-
-        \rho_p^\mu &= \alpha^2 \sqrt{f_0(\mathbf{\eta}_p, \mathbf{v}_p)} w_p [ DF^{-1}(\mathbf{\eta}_p) \mathbf{v}_p ]_\mu \,.
-
-    Parameters
-    ----------
-        f0_values ; array[float]
-            Value of f0 for each particle.
-
-        f0_params : array[float]
-            Parameters needed to specify the moments; the order is specified in :ref:`kinetic_moments` for the respective functions available.
-
-        alpha : float
-            = Omega_c / Omega_p ; Parameter determining the coupling strength between particles and fields
-
-    Note
-    ----
-        The above parameter list contains only the model specific input arguments.
-    """
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    # non-vanishing B-splines at particle position
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    #$ omp parallel private (ip, eta1, eta2, eta3, f0, filling)
-    #$ omp for reduction ( + :vec)
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        # marker positions
-        eta1 = markers[ip, 0]
-        eta2 = markers[ip, 1]
-        eta3 = markers[ip, 2]
-
-        f0 = f0_values[ip]
-
-        # filling = alpha^2 * kappa * w_p * sqrt{f_0} / N
-        filling = alpha**2 * kappa * markers[ip, 6] * sqrt(f0) / n_markers_tot
-
-        # spans (i.e. index for non-vanishing B-spline basis functions)
-        span1 = bsp.find_span(tn1, pn[0], eta1)
-        span2 = bsp.find_span(tn2, pn[1], eta2)
-        span3 = bsp.find_span(tn3, pn[2], eta3)
-
-        # compute bn, bd, i.e. values for non-vanishing B-/splines at position eta
-        bsp.b_splines_slim(tn1, pn[0], eta1, span1, bn1)
-        bsp.b_splines_slim(tn2, pn[1], eta2, span2, bn2)
-        bsp.b_splines_slim(tn3, pn[2], eta3, span3, bn3)
-
-        # call the appropriate matvec filler
-        fk.fill_vec(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3,
-                    starts0, vec, filling)
-
-    #$ omp end parallel
-
-
-@stack_array('df', 'df_t', 'df_inv', 'v', 'df_inv_times_v', 'filling_m', 'filling_v')
-def linear_vlasov_maxwell(markers: 'float[:,:]', n_markers_tot: 'int',
-                          pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                          starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                          kind_map: 'int', params_map: 'float[:]',
-                          p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                          ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                          cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                          mat11: 'float[:,:,:,:,:,:]',
-                          mat12: 'float[:,:,:,:,:,:]',
-                          mat13: 'float[:,:,:,:,:,:]',
-                          mat22: 'float[:,:,:,:,:,:]',
-                          mat23: 'float[:,:,:,:,:,:]',
-                          mat33: 'float[:,:,:,:,:,:]',
-                          vec1: 'float[:,:,:]',
-                          vec2: 'float[:,:,:]',
-                          vec3: 'float[:,:,:]',
-                          f0_values: 'float[:]',  # model specific argument
-                          f0_params: 'float[:]',  # model specific argument
-                          alpha: 'float',  # model specific argument
-                          kappa: 'float'):  # model specific argument
-    r"""
-    Accumulates into V1 with the filling functions
-
-    .. math::
-
-        A_p^{\mu, \nu} &= \frac{\alpha^2 \kappa^2}{v_{\text{th}}^2} \frac{1}{N\, s_0} f_0(\mathbf{\eta}_p, \mathbf{v}_p)
-            [ DF^{-1}(\mathbf{\eta}_p) v_p ]_\mu [ DF^{-1}(\mathbf{\eta}_p) \mathbf{v}_p ]_\nu \,,
-
-        B_p^\mu &= \alpha^2 \kappa \sqrt{f_0(\mathbf{\eta}_p, \mathbf{v}_p)} w_p [ DF^{-1}(\mathbf{\eta}_p) \mathbf{v}_p ]_\mu \,.
-
-    Parameters
-    ----------
-        f0_values ; array[float]
-            Value of f0 for each particle.
-
-        f0_params : array[float]
-            Parameters needed to specify the moments; the order is specified in :ref:`kinetic_moments` for the respective functions available.
-
-        alpha : float
-            = Omega_p / Omega_c ; Parameter determining the coupling strength between particles and fields
-
-        kappa : float
-            = 2 * pi * Omega_c / omega ; Parameter determining the coupling strength between particles and fields
-
-    Note
-    ----
-        The above parameter list contains only the model specific input arguments.
-    """
-
-    # allocate for metric coeffs
-    df = empty((3, 3), dtype=float)
-    df_inv = empty((3, 3), dtype=float)
-
-    # allocate for filling
-    v = empty(3, dtype=float)
-    df_inv_v = empty(3, dtype=float)
-    filling_m = empty((3, 3), dtype=float)
-    filling_v = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    #$ omp parallel private (ip, eta1, eta2, eta3, f0, df, df_inv, v, df_inv_times_v, filling_m, filling_v)
-    #$ omp for reduction ( + : mat11, mat12, mat13, mat22, mat23, mat33, vec1, vec2, vec3)
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        # marker positions
-        eta1 = markers[ip, 0]
-        eta2 = markers[ip, 1]
-        eta3 = markers[ip, 2]
-
-        # get velocity
-        v[0] = markers[ip, 3] / f0_params[4]**2
-        v[1] = markers[ip, 4] / f0_params[5]**2
-        v[2] = markers[ip, 5] / f0_params[6]**2
-
-        f0 = f0_values[ip]
-
-        # evaluate Jacobian, result in df
-        map_eval.df(eta1, eta2, eta3,
-                    kind_map, params_map,
-                    t1_map, t2_map, t3_map, p_map,
-                    ind1_map, ind2_map, ind3_map,
-                    cx, cy, cz,
-                    df)
-
-        # invert Jacobian matrix
-        linalg.matrix_inv(df, df_inv)
-
-        # compute DF^{-1} v
-        linalg.matrix_vector(df_inv, v, df_inv_v)
-
-        # filling_m = alpha^2 * kappa^2 * f0 / (N * s_0) * (v_th_1 * v_th_2 * v_th_3)^2/3) * (DF^{-1} \V_th v_p)_mu * (DF^{-1} \V_th v_p)_nu
-        linalg.outer(df_inv_v, df_inv_v, filling_m)
-        filling_m[:, :] *= alpha**2 * kappa**2 * f0 * (f0_params[4] * f0_params[5] * f0_params[6])**(2/3) / (n_markers_tot * markers[ip, 7])
-
-        # filling_v = alpha^2 * kappa / N * (v_th_1 * v_th_2 * v_th_3)^2/3) * w_p * sqrt{f_0} DL^{-1} * \V_th * v_p
-        filling_v[:] = alpha**2 * kappa * sqrt(f0) * markers[ip, 6] * df_inv_v[:] / n_markers_tot * (f0_params[4] * f0_params[5] * f0_params[6])**(2/3)
-
-        # call the appropriate matvec filler
-        mvf.m_v_fill_b_v1_symm(pn,
-                               tn1, tn2, tn3,
-                               starts1,
-                               eta1, eta2, eta3,
-                               mat11, mat12, mat13, mat22, mat23, mat33,
-                               filling_m[0, 0], filling_m[0, 1], filling_m[0, 2],
-                               filling_m[1, 1], filling_m[1, 2], filling_m[2, 2],
-                               vec1, vec2, vec3,
-                               filling_v[0], filling_v[1], filling_v[2])
-
-    #$ omp end parallel
-
-
-def delta_f_vlasov_maxwell_poisson(markers: 'float[:,:]', n_markers_tot: 'int',
-                                   pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                                   starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                                   kind_map: 'int', params_map: 'float[:]',
-                                   p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                                   ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                                   cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                   vec: 'float[:,:,:]',
-                                   f0_values: 'float[:]',  # model specific argument
-                                   f0_params: 'float[:]',  # model specific argument
-                                   alpha: 'float',  # model specific argument
-                                   kappa: 'float'):  # model specific argument
-    r"""
-    Accumulates the charge density in V0 
-
-    .. math::
-
-        \rho_p^\mu &= \alpha^2 \sqrt{f_0(\mathbf{\eta}_p, \mathbf{v}_p)} w_p [ DF^{-1}(\mathbf{\eta}_p) \mathbf{v}_p ]_\mu \,.
-
-    Parameters
-    ----------
-        f0_values ; array[float]
-            Value of f0 for each particle.
-
-        f0_params : array[float]
-            Parameters needed to specify the moments; the order is specified in :ref:`kinetic_moments` for the respective functions available.
-
-        alpha : float
-            = Omega_c / Omega_p ; Parameter determining the coupling strength between particles and fields
-
-    Note
-    ----
-        The above parameter list contains only the model specific input arguments.
-    """
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    #$ omp parallel private (ip, eta1, eta2, eta3, f0, filling)
-    #$ omp for reduction ( + :vec)
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        # marker positions
-        eta1 = markers[ip, 0]
-        eta2 = markers[ip, 1]
-        eta3 = markers[ip, 2]
-
-        f0 = f0_values[ip]
-
-        # filling = alpha^2 * kappa * (1 / (N * s_0) * (f_0 / log(f_0) - f_0) - w_p / log(f_0))
-        filling = alpha**2 * kappa * ((f0 / log(f0) - f0) / (n_markers_tot * markers[ip, 7]) - markers[ip, 6] / log(f0))  * f0_params[4]**2 * f0_params[5]**2 * f0_params[6]**2
-
-        # call the appropriate matvec filler
-        mvf.scalar_fill_b_v0(pn, tn1, tn2, tn3,
-                             starts0, eta1, eta2, eta3,
-                             vec, filling)
-
-    #$ omp end parallel
-
-
-@stack_array('df', 'df_t', 'df_inv', 'v', 'df_inv_times_v', 'filling_v')
-def delta_f_vlasov_maxwell(markers: 'float[:,:]', n_markers_tot: 'int',
-                           pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                           starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                           kind_map: 'int', params_map: 'float[:]',
-                           p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                           ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                           cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                           vec1: 'float[:,:,:]',
-                           vec2: 'float[:,:,:]',
-                           vec3: 'float[:,:,:]',
-                           f0_values: 'float[:]',  # model specific argument
-                           f0_params: 'float[:]',  # model specific argument
-                           alpha: 'float',  # model specific argument
-                           kappa: 'float'):  # model specific argument
-    r"""
-    Accumulates into V1 with the filling functions
-
-    .. math::
-
-        A_p^{\mu, \nu} &= \frac{\alpha^2}{v_{\text{th}}^2} \frac{1}{N\, s_0} f_0(\mathbf{\eta}_p, \mathbf{v}_p)
-            [ DF^{-1}(\mathbf{\eta}_p) v_p ]_\mu [ DF^{-1}(\mathbf{\eta}_p) \mathbf{v}_p ]_\nu \,,
-
-        B_p^\mu &= \alpha^2 \sqrt{f_0(\mathbf{\eta}_p, \mathbf{v}_p)} w_p [ DF^{-1}(\mathbf{\eta}_p) \mathbf{v}_p ]_\mu \,.
-
-    Parameters
-    ----------
-        f0_values ; array[float]
-            Value of f0 for each particle.
-
-        f0_params : array[float]
-            Parameters needed to specify the moments; the order is specified in :ref:`kinetic_moments` for the respective functions available.
-
-        alpha : float
-            = Omega_c / Omega_p ; Parameter determining the coupling strength between particles and fields
-
-    Note
-    ----
-        The above parameter list contains only the model specific input arguments.
-    """
-
-    # allocate for metric coeffs
-    df = empty((3, 3), dtype=float)
-    df_inv = empty((3, 3), dtype=float)
-
-    # allocate for filling
-    v = empty(3, dtype=float)
-    df_inv_times_v = empty(3, dtype=float)
-    filling_v = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    #$ omp parallel private (ip, eta1, eta2, eta3, f0, df, df_inv, v, df_inv_times_v, filling_v)
-    #$ omp for reduction ( + : mat11, mat12, mat13, mat22, mat23, mat33, vec1, vec2, vec3)
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        # marker positions
-        eta1 = markers[ip, 0]
-        eta2 = markers[ip, 1]
-        eta3 = markers[ip, 2]
-
-        f0 = f0_values[ip]
-
-        # evaluate Jacobian, result in df
-        map_eval.df(eta1, eta2, eta3,
-                    kind_map, params_map,
-                    t1_map, t2_map, t3_map, p_map,
-                    ind1_map, ind2_map, ind3_map,
-                    cx, cy, cz,
-                    df)
-
-        # compute shifted and stretched velocity
-        v[0] = (markers[ip, 3] - f0_params[1]) / f0_params[4]**2
-        v[1] = (markers[ip, 4] - f0_params[2]) / f0_params[5]**2
-        v[2] = (markers[ip, 5] - f0_params[3]) / f0_params[6]**2
-
-        # filling functions
-        linalg.matrix_inv(df, df_inv)
-        linalg.matrix_vector(df_inv, v, df_inv_times_v)
-
-        # filling_v = alpha^2 / (N * s_0) * (f_0 / ln(f_0) - f_0) * DL^{-1} * \V_th * (v_p - u)
-        filling_v[:] = alpha**2 * kappa / (n_markers_tot * markers[ip, 7]) * (f0 / log(f0) - f0 ) * df_inv_times_v[:] * f0_params[4]**2 * f0_params[5]**2 * f0_params[6]**2
-
-        # call the appropriate matvec filler
-        mvf.vec_fill_b_v1(pn, tn1, tn2, tn3, starts1,
-                          eta1, eta2, eta3,
-                          vec1, vec2, vec3,
-                          filling_v[0], filling_v[1], filling_v[2])
-
-    #$ omp end parallel
 
 
 @stack_array('g_inv', 'tmp1', 'tmp2', 'b', 'b_prod', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3')
-def cc_lin_mhd_6d_1(markers: 'float[:,:]', n_markers_tot: 'int',
-                    pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                    starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                    kind_map: 'int', params_map: 'float[:]',
-                    p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                    ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                    cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                    mat12: 'float[:,:,:,:,:,:]',
-                    mat13: 'float[:,:,:,:,:,:]',
-                    mat23: 'float[:,:,:,:,:,:]',
-                    b2_1: 'float[:,:,:]',   # model specific argument
-                    b2_2: 'float[:,:,:]',   # model specific argument
-                    b2_3: 'float[:,:,:]',   # model specific argument
-                    basis_u : 'int', scale_mat : 'float'):  # model specific argument
-    r"""Accumulates into V1 with the filling functions
-
-    .. math::
-
-        A_p^{\mu, \nu} = w_p * [ G^{-1}(\eta_p) * B2_{\times}(\eta_p) * G^{-1}(\eta_p) ]_{\mu, \nu}     
-
-    where :math:`B2_{\times} * a := B2 \times a` for :math:`a \in \mathbb R^3`. 
-
-    Parameters
-    ----------
-        b2_1, b2_2, b2_3 : array[float]
-            FE coefficients c_ijk of the magnetic field as a 2-form.
-
-    Note
-    ----
-        The above parameter list contains only the model specific input arguments.
-    """
-
-    # allocate for magnetic field evaluation
-    b = empty(3, dtype=float)
-    b_prod = zeros((3, 3), dtype=float) 
-
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-    
-    # allocate for metric coefficients
-    df       = empty((3, 3), dtype=float)
-    df_inv   = empty((3, 3), dtype=float)
-    df_inv_t = empty((3, 3), dtype=float)
-    g_inv    = empty((3, 3), dtype=float)
-
-    # allocate some temporary buffers for filling
-    tmp1 = empty((3, 3), dtype=float)
-    tmp2 = empty((3, 3), dtype=float)
-
-    # get local number of markers
-    n_markers_loc = shape(markers)[0]
-    
-    #$ omp parallel firstprivate(b_prod) private(ip, eta1, eta2, eta3, span1, span2, span3, bn1, bn2, bn3, bd1, bd2, bd3, b, df, det_df, weight, df_inv, df_inv_t, g_inv, tmp1, tmp2, filling_m12, filling_m13, filling_m23) 
-    #$ omp for reduction ( + : mat12, mat13, mat23)
-    for ip in range(n_markers_loc):
-        
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        # marker positions
-        eta1 = markers[ip, 0]
-        eta2 = markers[ip, 1]
-        eta3 = markers[ip, 2]
-
-        # b-field evaluation
-        span1 = bsp.find_span(tn1, pn[0], eta1)
-        span2 = bsp.find_span(tn2, pn[1], eta2)
-        span3 = bsp.find_span(tn3, pn[2], eta3)
-
-        bsp.b_d_splines_slim(tn1, pn[0], eta1, span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], eta2, span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], eta3, span3, bn3, bd3)
-
-        b[0] = eval_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b2_1, starts2[0])
-        b[1] = eval_3d.eval_spline_mpi_kernel(
-            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2_2, starts2[1])
-        b[2] = eval_3d.eval_spline_mpi_kernel(
-            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b2_3, starts2[2])
-
-        # operator bx() as matrix
-        b_prod[0, 1] = -b[2]
-        b_prod[0, 2] = +b[1]
-        b_prod[1, 0] = +b[2]
-        b_prod[1, 2] = -b[0]
-        b_prod[2, 0] = -b[1]
-        b_prod[2, 1] = +b[0]
-
-        # evaluate Jacobian matrix and Jacobian determinant
-        map_eval.df(eta1, eta2, eta3,
-                    kind_map, params_map,
-                    t1_map, t2_map, t3_map, p_map,
-                    ind1_map, ind2_map, ind3_map,
-                    cx, cy, cz,
-                    df)
-        
-        det_df = linalg.det(df)
-
-        # marker weight
-        weight = markers[ip, 6]
-        
-        if basis_u == 0:
-        
-            # filling functions
-            filling_m12 = - weight * b_prod[0, 1] * scale_mat
-            filling_m13 = - weight * b_prod[0, 2] * scale_mat
-            filling_m23 = - weight * b_prod[1, 2] * scale_mat
-
-            # call the appropriate matvec filler
-            mvf.mat_fill_v0vec_asym(pn, span1, span2, span3,
-                                 bn1, bn2, bn3,
-                                 starts0,
-                                 mat12, mat13, mat23,
-                                 filling_m12, filling_m13, filling_m23)
-        
-        elif basis_u == 1:
-        
-            # filling functions
-            linalg.matrix_inv_with_det(df, det_df, df_inv)
-            linalg.transpose(df_inv, df_inv_t)
-            linalg.matrix_matrix(df_inv, df_inv_t, g_inv)
-            linalg.matrix_matrix(g_inv, b_prod, tmp1)
-            linalg.matrix_matrix(tmp1, g_inv, tmp2)
-
-            filling_m12 = - weight * tmp2[0, 1] * scale_mat
-            filling_m13 = - weight * tmp2[0, 2] * scale_mat
-            filling_m23 = - weight * tmp2[1, 2] * scale_mat
-
-            # call the appropriate matvec filler
-            mvf.mat_fill_v1_asym(pn, span1, span2, span3,
-                                 bn1, bn2, bn3,
-                                 bd1, bd2, bd3,
-                                 starts1,
-                                 mat12, mat13, mat23,
-                                 filling_m12, filling_m13, filling_m23)
-            
-        elif basis_u == 2:
-            
-            # filling functions
-            filling_m12 = - weight * b_prod[0, 1] * scale_mat / det_df**2
-            filling_m13 = - weight * b_prod[0, 2] * scale_mat / det_df**2
-            filling_m23 = - weight * b_prod[1, 2] * scale_mat / det_df**2
-
-            # call the appropriate matvec filler
-            mvf.mat_fill_v2_asym(pn, span1, span2, span3,
-                                 bn1, bn2, bn3,
-                                 bd1, bd2, bd3,
-                                 starts1,
-                                 mat12, mat13, mat23,
-                                 filling_m12, filling_m13, filling_m23)
-            
-    #$ omp end parallel
-    
-    mat12 /= n_markers_tot
-    mat13 /= n_markers_tot
-    mat23 /= n_markers_tot
-
-
-@stack_array('df', 'df_t', 'df_inv', 'g', 'g_inv', 'filling_m', 'filling_v', 'tmp1', 'tmp1_t', 'tmp2', 'tmp3', 'tmp_v', 'df_inv_times_v', 'b', 'b_prod', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3')
-def cc_lin_mhd_6d_2(markers: 'float[:,:]', n_markers_tot: 'int',
-                    pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                    starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                    kind_map: 'int', params_map: 'float[:]',
-                    p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                    ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                    cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                    mat11: 'float[:,:,:,:,:,:]',
-                    mat12: 'float[:,:,:,:,:,:]',
-                    mat13: 'float[:,:,:,:,:,:]',
-                    mat22: 'float[:,:,:,:,:,:]',
-                    mat23: 'float[:,:,:,:,:,:]',
-                    mat33: 'float[:,:,:,:,:,:]',
-                    vec1: 'float[:,:,:]',
-                    vec2: 'float[:,:,:]',
-                    vec3: 'float[:,:,:]',
-                    b2_1: 'float[:,:,:]',   # model specific argument
-                    b2_2: 'float[:,:,:]',   # model specific argument
-                    b2_3: 'float[:,:,:]',   # model specific argument
-                    basis_u : 'int', scale_mat : 'float', scale_vec : 'float'): # model specific argument
-    r"""Accumulates into V1 with the filling functions
-
-    .. math::
-
-        A_p^{\mu, \nu} &= w_p * [ G^{-1}(\eta_p) * B2_{\times}(\eta_p) * G^{-1}(\eta_p) * B2_{\times}(\eta_p)^\top * G^{-1}(\eta_p) ]_{\mu, \nu}
-
-        B_p^\mu &= w_p * [ G^{-1}(\eta_p) * B2_{\times}(\eta_p) * DF^{-1}(\eta_p) * v_p ]_\mu
-
-    where :math:`B2_{\times} * a := B2 \times a` for :math:`a \in \mathbb R^3`.
-
-    Parameters
-    ----------
-        b2_1, b2_2, b2_3 : array[float]
-            FE coefficients c_ijk of the magnetic field as a 2-form.
-
-    Note
-    ----
-        The above parameter list contains only the model specific input arguments.
-    """
-
-    # allocate for magnetic field evaluation
-    b = empty(3, dtype=float)
-    b_prod = zeros((3, 3), dtype=float)
-
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-    
-    # allocate for metric coeffs
-    df       = empty((3, 3), dtype=float)
-    df_inv   = empty((3, 3), dtype=float)
-    df_inv_t = empty((3, 3), dtype=float)
-    g_inv    = empty((3, 3), dtype=float)
-
-    # allocate for filling
-    filling_m = empty((3, 3), dtype=float)
-    filling_v = empty(3, dtype=float)
-
-    tmp1   = empty((3, 3), dtype=float)
-    tmp2   = empty((3, 3), dtype=float)
-    
-    tmp_t  = empty((3, 3), dtype=float)
-    tmp_m  = empty((3, 3), dtype=float)
-
-    tmp_v = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers_loc = shape(markers)[0]
-    
-    #$ omp parallel firstprivate(b_prod) private(ip, eta1, eta2, eta3, span1, span2, span3, bn1, bn2, bn3, bd1, bd2, bd3, b, df, det_df, weight, v, df_inv, df_inv_t, g_inv, tmp1, tmp2, tmp_t, tmp_m, tmp_v, filling_m, filling_v) 
-    #$ omp for reduction ( + : mat12, mat13, mat23)
-    for ip in range(n_markers_loc):
-        
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        # marker positions
-        eta1 = markers[ip, 0]
-        eta2 = markers[ip, 1]
-        eta3 = markers[ip, 2]
-
-        # b-field evaluation
-        span1 = bsp.find_span(tn1, pn[0], eta1)
-        span2 = bsp.find_span(tn2, pn[1], eta2)
-        span3 = bsp.find_span(tn3, pn[2], eta3)
-
-        bsp.b_d_splines_slim(tn1, pn[0], eta1, span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], eta2, span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], eta3, span3, bn3, bd3)
-
-        b[0] = eval_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b2_1, starts2[0])
-        b[1] = eval_3d.eval_spline_mpi_kernel(
-            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2_2, starts2[1])
-        b[2] = eval_3d.eval_spline_mpi_kernel(
-            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b2_3, starts2[2])
-
-        # operator bx() as matrix
-        b_prod[0, 1] = -b[2]
-        b_prod[0, 2] = +b[1]
-        b_prod[1, 0] = +b[2]
-        b_prod[1, 2] = -b[0]
-        b_prod[2, 0] = -b[1]
-        b_prod[2, 1] = +b[0]
-
-        # evaluate Jacobian, result in df
-        map_eval.df(eta1, eta2, eta3,
-                    kind_map, params_map,
-                    t1_map, t2_map, t3_map, p_map,
-                    ind1_map, ind2_map, ind3_map,
-                    cx, cy, cz,
-                    df)
-        
-        det_df = linalg.det(df)
-        
-        # marker weight and velocity
-        weight = markers[ip, 6]
-        v = markers[ip, 3:6]
-        
-        if basis_u == 0:
-            
-            # needed metric coefficients
-            linalg.matrix_inv_with_det(df, det_df, df_inv)
-            linalg.transpose(df_inv, df_inv_t)
-            linalg.matrix_matrix(df_inv, df_inv_t, g_inv)
-            
-            # filling functions tmp_m = tmp1 * tmp1^T and tmp_v = tmp1 * v, where tmp1 = B^x * DF^(-1)
-            linalg.matrix_matrix(b_prod, df_inv, tmp1)
-            
-            linalg.transpose(tmp1, tmp_t)
-            
-            linalg.matrix_matrix(tmp1, tmp_t, tmp_m)
-            linalg.matrix_vector(tmp1, v, tmp_v)
-
-            filling_m[:, :] = weight * tmp_m * scale_mat
-            filling_v[:] = weight * tmp_v * scale_vec
-
-            # call the appropriate matvec filler
-            mvf.m_v_fill_v0vec_symm(pn, span1, span2, span3,
-                                    bn1, bn2, bn3,
-                                    starts0,
-                                    mat11, mat12, mat13, 
-                                    mat22, mat23, 
-                                    mat33, 
-                                    filling_m[0, 0], filling_m[0, 1], filling_m[0, 2], 
-                                    filling_m[1, 1], filling_m[1, 2], 
-                                    filling_m[2, 2],
-                                    vec1, vec2, vec3,
-                                    filling_v[0], filling_v[1], filling_v[2])
-        
-        elif basis_u == 1:
-            
-            # needed metric coefficients
-            linalg.matrix_inv_with_det(df, det_df, df_inv)
-            linalg.transpose(df_inv, df_inv_t)
-            linalg.matrix_matrix(df_inv, df_inv_t, g_inv)
-            
-            # filling functions tmp_m = tmp2 * tmp2^T and tmp_v = tmp2 * v, where tmp2 = G^(-1) * B^x * DF^(-1)
-            linalg.matrix_matrix(g_inv, b_prod, tmp1)
-            linalg.matrix_matrix(tmp1, df_inv, tmp2)
-            
-            linalg.transpose(tmp2, tmp_t)
-            
-            linalg.matrix_matrix(tmp2, tmp_t, tmp_m)
-            linalg.matrix_vector(tmp2, v, tmp_v)
-
-            filling_m[:, :] = weight * tmp_m * scale_mat
-            filling_v[:] = weight * tmp_v * scale_vec
-
-            # call the appropriate matvec filler
-            mvf.m_v_fill_v1_symm(pn, span1, span2, span3,
-                                 bn1, bn2, bn3,
-                                 bd1, bd2, bd3,
-                                 starts1,
-                                 mat11, mat12, mat13, 
-                                 mat22, mat23, 
-                                 mat33, 
-                                 filling_m[0, 0], filling_m[0, 1], filling_m[0, 2], 
-                                 filling_m[1, 1], filling_m[1, 2], 
-                                 filling_m[2, 2],
-                                 vec1, vec2, vec3,
-                                 filling_v[0], filling_v[1], filling_v[2])
-            
-        elif basis_u == 2:
-            
-            # needed metric coefficients
-            linalg.matrix_inv_with_det(df, det_df, df_inv)
-            linalg.transpose(df_inv, df_inv_t)
-            linalg.matrix_matrix(df_inv, df_inv_t, g_inv)
-            
-            # filling functions tmp_m = tmp1 * tmp1^T and tmp_v = tmp1 * v, where tmp1 = B^x * DF^(-1) / det(DF)
-            linalg.matrix_matrix(b_prod, df_inv, tmp1)
-            
-            linalg.transpose(tmp1, tmp_t)
-            
-            linalg.matrix_matrix(tmp1, tmp_t, tmp_m)
-            linalg.matrix_vector(tmp1, v, tmp_v)
-
-            filling_m[:, :] = weight * tmp_m * scale_mat / det_df**2
-            filling_v[:] = weight * tmp_v * scale_vec / det_df
-
-            # call the appropriate matvec filler
-            mvf.m_v_fill_v2_symm(pn, span1, span2, span3,
-                                 bn1, bn2, bn3,
-                                 bd1, bd2, bd3,
-                                 starts2,
-                                 mat11, mat12, mat13, 
-                                 mat22, mat23, 
-                                 mat33, 
-                                 filling_m[0, 0], filling_m[0, 1], filling_m[0, 2], 
-                                 filling_m[1, 1], filling_m[1, 2], 
-                                 filling_m[2, 2],
-                                 vec1, vec2, vec3,
-                                 filling_v[0], filling_v[1], filling_v[2])
-            
-    #$ omp end parallel
-    
-    mat11 /= n_markers_tot
-    mat12 /= n_markers_tot
-    mat13 /= n_markers_tot
-    mat22 /= n_markers_tot
-    mat23 /= n_markers_tot
-    mat33 /= n_markers_tot
-    
-    vec1 /= n_markers_tot
-    vec2 /= n_markers_tot
-    vec3 /= n_markers_tot
-
-
-@stack_array('df', 'df_t', 'df_inv', 'filling_m', 'filling_v', 'tmp1', 'tmp_v', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3')
-def pc_lin_mhd_6d_full(markers: 'float[:,:]', n_markers_tot: 'int',
-                       pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                       starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                       kind_map: 'int', params_map: 'float[:]',
-                       p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                       ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                       cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                       mat11_11: 'float[:,:,:,:,:,:]',
-                       mat12_11: 'float[:,:,:,:,:,:]',
-                       mat13_11: 'float[:,:,:,:,:,:]',
-                       mat22_11: 'float[:,:,:,:,:,:]',
-                       mat23_11: 'float[:,:,:,:,:,:]',
-                       mat33_11: 'float[:,:,:,:,:,:]',
-                       mat11_12: 'float[:,:,:,:,:,:]',
-                       mat12_12: 'float[:,:,:,:,:,:]',
-                       mat13_12: 'float[:,:,:,:,:,:]',
-                       mat22_12: 'float[:,:,:,:,:,:]',
-                       mat23_12: 'float[:,:,:,:,:,:]',
-                       mat33_12: 'float[:,:,:,:,:,:]',
-                       mat11_13: 'float[:,:,:,:,:,:]',
-                       mat12_13: 'float[:,:,:,:,:,:]',
-                       mat13_13: 'float[:,:,:,:,:,:]',
-                       mat22_13: 'float[:,:,:,:,:,:]',
-                       mat23_13: 'float[:,:,:,:,:,:]',
-                       mat33_13: 'float[:,:,:,:,:,:]',
-                       mat11_22: 'float[:,:,:,:,:,:]',
-                       mat12_22: 'float[:,:,:,:,:,:]',
-                       mat13_22: 'float[:,:,:,:,:,:]',
-                       mat22_22: 'float[:,:,:,:,:,:]',
-                       mat23_22: 'float[:,:,:,:,:,:]',
-                       mat33_22: 'float[:,:,:,:,:,:]',
-                       mat11_23: 'float[:,:,:,:,:,:]',
-                       mat12_23: 'float[:,:,:,:,:,:]',
-                       mat13_23: 'float[:,:,:,:,:,:]',
-                       mat22_23: 'float[:,:,:,:,:,:]',
-                       mat23_23: 'float[:,:,:,:,:,:]',
-                       mat33_23: 'float[:,:,:,:,:,:]',
-                       mat11_33: 'float[:,:,:,:,:,:]',
-                       mat12_33: 'float[:,:,:,:,:,:]',
-                       mat13_33: 'float[:,:,:,:,:,:]',
-                       mat22_33: 'float[:,:,:,:,:,:]',
-                       mat23_33: 'float[:,:,:,:,:,:]',
-                       mat33_33: 'float[:,:,:,:,:,:]',
-                       vec1_1: 'float[:,:,:]',
-                       vec2_1: 'float[:,:,:]',
-                       vec3_1: 'float[:,:,:]',
-                       vec1_2: 'float[:,:,:]',
-                       vec2_2: 'float[:,:,:]',
-                       vec3_2: 'float[:,:,:]',
-                       vec1_3: 'float[:,:,:]',
-                       vec2_3: 'float[:,:,:]',
-                       vec3_3: 'float[:,:,:]',
-                       scale_mat : 'float', scale_vec : 'float'):
-
-    r"""Accumulates into V1 with the filling functions
-
-    .. math::
-
-        V_{p,i} A_p^{\mu, \nu} V_{p,j} &= w_p * [ DF^{-1}(\eta_p) DF^{-\top}(\eta_p) ]_{\mu, \nu} * V_{p,i} * V_{p,j}
-        
-        V_{p,i} B_p^\mu &= w_p * [DF^{-1}(\eta_p)]_\mu * V_{p,i}
-
-    Parameters
-    ----------
-
-    Note
-    ----
-        The above parameter list contains only the model specific input arguments.
-    """
-
-    # allocate for metric coeffs
-    df = empty((3, 3), dtype=float)
-    df_t = empty((3, 3), dtype=float)
-    df_inv = empty((3, 3), dtype=float)
-    df_inv_t = empty((3, 3), dtype=float)
-
-    # allocate for filling
-    filling_m = empty((3, 3), dtype=float)
-    filling_v = empty(3, dtype=float)
-
-    tmp1 = empty((3, 3), dtype=float)
-
-    tmp_v = empty(3, dtype=float)
-
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-    
-    for ip in range(n_markers):
-        
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        # marker positions
-        eta1 = markers[ip, 0]
-        eta2 = markers[ip, 1]
-        eta3 = markers[ip, 2]
-        
-        # b-field evaluation
-        span1 = bsp.find_span(tn1, pn[0], eta1)
-        span2 = bsp.find_span(tn2, pn[1], eta2)
-        span3 = bsp.find_span(tn3, pn[2], eta3)
-
-        bsp.b_d_splines_slim(tn1, pn[0], eta1, span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], eta2, span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], eta3, span3, bn3, bd3)
-
-        # evaluate Jacobian, result in df
-        map_eval.df(eta1, eta2, eta3,
-                    kind_map, params_map,
-                    t1_map, t2_map, t3_map, p_map,
-                    ind1_map, ind2_map, ind3_map,
-                    cx, cy, cz,
-                    df)
-
-        # Avoid second computation of df, use linear_algebra.core routines to get g_inv:
-        linalg.matrix_inv(df, df_inv)
-        linalg.transpose(df, df_t)
-        linalg.transpose(df_inv, df_inv_t)
-
-        # filling functions
-        v = markers[ip, 3:6]
-        
-        linalg.matrix_matrix(df_inv, df_inv_t, tmp1)
-        linalg.matrix_vector(df_inv, v, tmp_v)
-
-        weight = markers[ip, 8]
-        
-        filling_m[:,:] = weight * tmp1 / n_markers_tot * scale_mat
-        filling_v[:] = weight * tmp_v / n_markers_tot * scale_vec
-
-        # call the appropriate matvec filler
-        mvf.m_v_fill_v1_pressure_full(pn, span1, span2, span3,
-                                      bn1, bn2, bn3,
-                                      bd1, bd2, bd3,
-                                      starts1,
-                                      mat11_11, mat12_11, mat13_11, 
-                                      mat22_11, mat23_11, 
-                                      mat33_11,
-                                      mat11_12, mat12_12, mat13_12, 
-                                      mat22_12, mat23_12, 
-                                      mat33_12,
-                                      mat11_13, mat12_13, mat13_13, 
-                                      mat22_13, mat23_13, 
-                                      mat33_13,
-                                      mat11_22, mat12_22, mat13_22, 
-                                      mat22_22, mat23_22, 
-                                      mat33_22,
-                                      mat11_23, mat12_23, mat13_23, 
-                                      mat22_23, mat23_23, 
-                                      mat33_23,
-                                      mat11_33, mat12_33, mat13_33, 
-                                      mat22_33, mat23_33, 
-                                      mat33_33, 
-                                      filling_m[0, 0], filling_m[0, 1], filling_m[0, 2], 
-                                      filling_m[1, 1], filling_m[1, 2], 
-                                      filling_m[2, 2],
-                                      vec1_1, vec2_1, vec3_1,
-                                      vec1_2, vec2_2, vec3_2,
-                                      vec1_3, vec2_3, vec3_3,
-                                      filling_v[0], filling_v[1], filling_v[2],
-                                      v[0], v[1], v[2])
-
-
-@stack_array('df', 'df_inv_t', 'df_inv', 'filling_m', 'filling_v', 'tmp1', 'tmp_v', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3')
-def pc_lin_mhd_6d(markers: 'float[:,:]', n_markers_tot: 'int',
-                  pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                  starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                  kind_map: 'int', params_map: 'float[:]',
-                  p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                  ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                  cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                  mat11_11: 'float[:,:,:,:,:,:]',
-                  mat12_11: 'float[:,:,:,:,:,:]',
-                  mat13_11: 'float[:,:,:,:,:,:]',
-                  mat22_11: 'float[:,:,:,:,:,:]',
-                  mat23_11: 'float[:,:,:,:,:,:]',
-                  mat33_11: 'float[:,:,:,:,:,:]',
-                  mat11_12: 'float[:,:,:,:,:,:]',
-                  mat12_12: 'float[:,:,:,:,:,:]',
-                  mat13_12: 'float[:,:,:,:,:,:]',
-                  mat22_12: 'float[:,:,:,:,:,:]',
-                  mat23_12: 'float[:,:,:,:,:,:]',
-                  mat33_12: 'float[:,:,:,:,:,:]',
-                  mat11_13: 'float[:,:,:,:,:,:]',
-                  mat12_13: 'float[:,:,:,:,:,:]',
-                  mat13_13: 'float[:,:,:,:,:,:]',
-                  mat22_13: 'float[:,:,:,:,:,:]',
-                  mat23_13: 'float[:,:,:,:,:,:]',
-                  mat33_13: 'float[:,:,:,:,:,:]',
-                  mat11_22: 'float[:,:,:,:,:,:]',
-                  mat12_22: 'float[:,:,:,:,:,:]',
-                  mat13_22: 'float[:,:,:,:,:,:]',
-                  mat22_22: 'float[:,:,:,:,:,:]',
-                  mat23_22: 'float[:,:,:,:,:,:]',
-                  mat33_22: 'float[:,:,:,:,:,:]',
-                  mat11_23: 'float[:,:,:,:,:,:]',
-                  mat12_23: 'float[:,:,:,:,:,:]',
-                  mat13_23: 'float[:,:,:,:,:,:]',
-                  mat22_23: 'float[:,:,:,:,:,:]',
-                  mat23_23: 'float[:,:,:,:,:,:]',
-                  mat33_23: 'float[:,:,:,:,:,:]',
-                  mat11_33: 'float[:,:,:,:,:,:]',
-                  mat12_33: 'float[:,:,:,:,:,:]',
-                  mat13_33: 'float[:,:,:,:,:,:]',
-                  mat22_33: 'float[:,:,:,:,:,:]',
-                  mat23_33: 'float[:,:,:,:,:,:]',
-                  mat33_33: 'float[:,:,:,:,:,:]',
-                  vec1_1: 'float[:,:,:]',
-                  vec2_1: 'float[:,:,:]',
-                  vec3_1: 'float[:,:,:]',
-                  vec1_2: 'float[:,:,:]',
-                  vec2_2: 'float[:,:,:]',
-                  vec3_2: 'float[:,:,:]',
-                  vec1_3: 'float[:,:,:]',
-                  vec2_3: 'float[:,:,:]',
-                  vec3_3: 'float[:,:,:]',
-                  scale_mat : 'float', scale_vec : 'float'):
-    r"""Accumulates into V1 with the filling functions
-
-    .. math::
-
-        {V_{p,i}}_\perp A_p^{\mu, \nu} {V_{p,j}}_\perp &= w_p * [ DF^{-1}(\eta_p) DF^{-\top}(\eta_p) ]_{\mu, \nu} * {V_{p,i}}_\perp * {V_{p,j}}_\perp
-        
-        {V_{p,i}}_\perp B_p^\mu &= w_p * [DF^{-1}(\eta_p)]_\mu * {V_{p,i}}_\perp
-
-    Parameters
-    ----------
-
-    Note
-    ----
-        The above parameter list contains only the model specific input arguments.
-    """
-
-    # allocate for metric coeffs
-    df = empty((3, 3), dtype=float)
-    df_inv = empty((3, 3), dtype=float)
-    df_inv_t = empty((3, 3), dtype=float)
-
-    # allocate for filling
-    filling_m = empty((3, 3), dtype=float)
-    filling_v = empty(3, dtype=float)
-
-    tmp1 = empty((3, 3), dtype=float)
-
-    tmp_v = empty(3, dtype=float)
-
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-    
-    for ip in range(n_markers):
-        
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        # marker positions
-        eta1 = markers[ip, 0]
-        eta2 = markers[ip, 1]
-        eta3 = markers[ip, 2]
-
-        # marker weight and velocity
-        weight = markers[ip, 6]
-        v = markers[ip, 3:6]
-        
-        # evaluation
-        span1 = bsp.find_span(tn1, pn[0], eta1)
-        span2 = bsp.find_span(tn2, pn[1], eta2)
-        span3 = bsp.find_span(tn3, pn[2], eta3)
-
-        bsp.b_d_splines_slim(tn1, pn[0], eta1, span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], eta2, span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], eta3, span3, bn3, bd3)
-
-        # evaluate Jacobian, result in df
-        map_eval.df(eta1, eta2, eta3,
-                    kind_map, params_map,
-                    t1_map, t2_map, t3_map, p_map,
-                    ind1_map, ind2_map, ind3_map,
-                    cx, cy, cz,
-                    df)
-
-        det_df = linalg.det(df)
-
-        # Avoid second computation of df, use linear_algebra.core routines to get g_inv:
-        linalg.matrix_inv_with_det(df, det_df, df_inv)
-        linalg.transpose(df_inv, df_inv_t)
-        
-        linalg.matrix_matrix(df_inv, df_inv_t, tmp1)
-        linalg.matrix_vector(df_inv, v, tmp_v)
-        
-        filling_m[:,:] = weight * tmp1 * scale_mat
-        filling_v[:] = weight * tmp_v * scale_vec
-
-        # call the appropriate matvec filler
-        mvf.m_v_fill_v1_pressure(pn, span1, span2, span3,
-                                 bn1, bn2, bn3,
-                                 bd1, bd2, bd3,
-                                 starts1,
-                                 mat11_11, mat12_11, mat13_11, 
-                                 mat22_11, mat23_11, 
-                                 mat33_11,
-                                 mat11_12, mat12_12, mat13_12, 
-                                 mat22_12, mat23_12, 
-                                 mat33_12,
-                                 mat11_22, mat12_22, mat13_22, 
-                                 mat22_22, mat23_22, 
-                                 mat33_22,
-                                 filling_m[0, 0], filling_m[0, 1], filling_m[0, 2], 
-                                 filling_m[1, 1], filling_m[1, 2], 
-                                 filling_m[2, 2],
-                                 vec1_1, vec2_1, vec3_1,
-                                 vec1_2, vec2_2, vec3_2,
-                                 filling_v[0], filling_v[1], filling_v[2],
-                                 v[0], v[1])
-
-    #$ omp end parallel
-    
-    mat11_11 /= n_markers_tot
-    mat12_11 /= n_markers_tot
-    mat13_11 /= n_markers_tot
-    mat22_11 /= n_markers_tot
-    mat23_11 /= n_markers_tot
-    mat33_11 /= n_markers_tot
-    mat11_12 /= n_markers_tot
-    mat12_12 /= n_markers_tot
-    mat13_12 /= n_markers_tot
-    mat22_12 /= n_markers_tot
-    mat23_12 /= n_markers_tot
-    mat33_12 /= n_markers_tot
-    mat11_22 /= n_markers_tot
-    mat12_22 /= n_markers_tot
-    mat13_22 /= n_markers_tot
-    mat22_22 /= n_markers_tot
-    mat23_22 /= n_markers_tot
-    mat33_22 /= n_markers_tot
-    
-    vec1_1 /= n_markers_tot
-    vec2_1 /= n_markers_tot
-    vec3_1 /= n_markers_tot
-    vec1_2 /= n_markers_tot
-    vec2_2 /= n_markers_tot
-    vec3_2 /= n_markers_tot
-
-@stack_array('g_inv', 'tmp1', 'tmp2', 'b', 'b_prod', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3')
 def cc_lin_mhd_5d_D(markers: 'float[:,:]', n_markers_tot: 'int',
                     pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                     starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
                     kind_map: 'int', params_map: 'float[:]',
                     p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
                     ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
                     cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
                     mat12: 'float[:,:,:,:,:,:]',
                     mat13: 'float[:,:,:,:,:,:]',
                     mat23: 'float[:,:,:,:,:,:]',
                     b2_1: 'float[:,:,:]',   # model specific argument
                     b2_2: 'float[:,:,:]',   # model specific argument
                     b2_3: 'float[:,:,:]',   # model specific argument
-                    basis_u : 'int', scale_mat : 'float'):  # model specific argument
+                    basis_u: 'int', scale_mat: 'float'):  # model specific argument
     r"""
     """
 
     # allocate for magnetic field evaluation
     b = empty(3, dtype=float)
     b_prod = zeros((3, 3), dtype=float)
 
@@ -1447,18 +36,18 @@
     bn3 = empty(pn[2] + 1, dtype=float)
 
     bd1 = empty(pn[0], dtype=float)
     bd2 = empty(pn[1], dtype=float)
     bd3 = empty(pn[2], dtype=float)
 
     # allocate for metric coefficients
-    df       = empty((3, 3), dtype=float)
-    df_inv   = empty((3, 3), dtype=float)
+    df = empty((3, 3), dtype=float)
+    df_inv = empty((3, 3), dtype=float)
     df_inv_t = empty((3, 3), dtype=float)
-    g_inv    = empty((3, 3), dtype=float)
+    g_inv = empty((3, 3), dtype=float)
 
     # allocate some temporary buffers for filling
     tmp1 = empty((3, 3), dtype=float)
     tmp2 = empty((3, 3), dtype=float)
 
     # get local number of markers
     n_markers_loc = shape(markers)[0]
@@ -1501,34 +90,34 @@
         # evaluate Jacobian matrix and Jacobian determinant
         map_eval.df(eta1, eta2, eta3,
                     kind_map, params_map,
                     t1_map, t2_map, t3_map, p_map,
                     ind1_map, ind2_map, ind3_map,
                     cx, cy, cz,
                     df)
-        
+
         det_df = linalg.det(df)
 
         # marker weight
         weight = markers[ip, 5]
 
         if basis_u == 0:
 
             # filling functions
             filling_m12 = - weight * b_prod[0, 1] * scale_mat
             filling_m13 = - weight * b_prod[0, 2] * scale_mat
             filling_m23 = - weight * b_prod[1, 2] * scale_mat
 
             # call the appropriate matvec filler
             mvf.mat_fill_v0vec_asym(pn, span1, span2, span3,
-                                 bn1, bn2, bn3,
-                                 starts0,
-                                 mat12, mat13, mat23,
-                                 filling_m12, filling_m13, filling_m23)
-            
+                                    bn1, bn2, bn3,
+                                    starts0,
+                                    mat12, mat13, mat23,
+                                    filling_m12, filling_m13, filling_m23)
+
         elif basis_u == 1:
 
             # filling functions
             linalg.matrix_inv_with_det(df, det_df, df_inv)
             linalg.transpose(df_inv, df_inv_t)
             linalg.matrix_matrix(df_inv, df_inv_t, g_inv)
             linalg.matrix_matrix(g_inv, b_prod, tmp1)
@@ -1541,34 +130,35 @@
             # call the appropriate matvec filler
             mvf.mat_fill_v1_asym(pn, span1, span2, span3,
                                  bn1, bn2, bn3,
                                  bd1, bd2, bd3,
                                  starts1,
                                  mat12, mat13, mat23,
                                  filling_m12, filling_m13, filling_m23)
-            
+
         elif basis_u == 2:
 
             # filling functions
             filling_m12 = - weight * b_prod[0, 1] * scale_mat / det_df**2
             filling_m13 = - weight * b_prod[0, 2] * scale_mat / det_df**2
             filling_m23 = - weight * b_prod[1, 2] * scale_mat / det_df**2
 
             # call the appropriate matvec filler
             mvf.mat_fill_v2_asym(pn, span1, span2, span3,
                                  bn1, bn2, bn3,
                                  bd1, bd2, bd3,
                                  starts1,
                                  mat12, mat13, mat23,
                                  filling_m12, filling_m13, filling_m23)
-            
+
     mat12 /= n_markers_tot
     mat13 /= n_markers_tot
     mat23 /= n_markers_tot
 
+
 @stack_array('df', 'df_t', 'df_inv', 'g_inv', 'filling_m', 'filling_v', 'tmp', 'tmp1', 'tmp2', 'tmp_m', 'tmp_v', 'b', 'b_prod', 'b_star', 'norm_b1', 'curl_norm_b', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3')
 def cc_lin_mhd_5d_J1(markers: 'float[:,:]', n_markers_tot: 'int',
                      pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                      starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
                      kind_map: 'int', params_map: 'float[:]',
                      p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
                      ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
@@ -1580,26 +170,25 @@
                      mat23: 'float[:,:,:,:,:,:]',
                      mat33: 'float[:,:,:,:,:,:]',
                      vec1: 'float[:,:,:]',
                      vec2: 'float[:,:,:]',
                      vec3: 'float[:,:,:]',
                      kappa: float,                  # model specific argument
                      b1: 'float[:,:,:]',            # model specific argument
-                     b2: 'float[:,:,:]',            # model specific argument 
-                     b3: 'float[:,:,:]',            # model specific argument 
-                     norm_b11: 'float[:,:,:]',      # model specific argument    
+                     b2: 'float[:,:,:]',            # model specific argument
+                     b3: 'float[:,:,:]',            # model specific argument
+                     norm_b11: 'float[:,:,:]',      # model specific argument
                      norm_b12: 'float[:,:,:]',      # model specific argument
                      norm_b13: 'float[:,:,:]',      # model specific argument
                      curl_norm_b1: 'float[:,:,:]',  # model specific argument
                      curl_norm_b2: 'float[:,:,:]',  # model specific argument
                      curl_norm_b3: 'float[:,:,:]',  # model specific argument
-                     basis_u : 'int',               # model specific argument
-                     scale_mat : 'float',           # model specific argument
-                     scale_vec : 'float'):          # model specific argument
-
+                     basis_u: 'int',               # model specific argument
+                     scale_mat: 'float',           # model specific argument
+                     scale_vec: 'float'):          # model specific argument
     r"""Accumulates into V1 with the filling functions
 
     .. math::
 
         A_p^{\mu, \nu} &= w_p * [G^{-1}(\eta_p) * B2_{\times}(\eta_p) * B2_{\times}(\eta_p)^\top * G^{-1}(\eta_p) * v^2_{\parallel,p} * \left( 1/B^*_\parallel \right)^2 * |1/\sqrt{g} \hat \nabla \times \hat b^1_0|_p^2]_{\mu, \nu}
 
         B_p^\mu &= w_p *[ G^{-1}(\eta_p) * B2_{\times}(\eta_p)* v^2_{\parallel,p} * \left( 1/B^*_\parallel \right)]_\mu
@@ -1632,37 +221,37 @@
     bn1 = empty(pn[0] + 1, dtype=float)
     bn2 = empty(pn[1] + 1, dtype=float)
     bn3 = empty(pn[2] + 1, dtype=float)
 
     bd1 = empty(pn[0], dtype=float)
     bd2 = empty(pn[1], dtype=float)
     bd3 = empty(pn[2], dtype=float)
-    
+
     # allocate for metric coeffs
-    df       = empty((3, 3), dtype=float)
-    df_inv   = empty((3, 3), dtype=float)
+    df = empty((3, 3), dtype=float)
+    df_inv = empty((3, 3), dtype=float)
     df_inv_t = empty((3, 3), dtype=float)
-    g_inv    = empty((3, 3), dtype=float)
+    g_inv = empty((3, 3), dtype=float)
 
     # allocate for filling
     filling_m = empty((3, 3), dtype=float)
     filling_v = empty(3, dtype=float)
 
-    tmp   = empty((3, 3), dtype=float)
-    tmp1  = empty((3, 3), dtype=float)
-    tmp2  = empty((3, 3), dtype=float)
+    tmp = empty((3, 3), dtype=float)
+    tmp1 = empty((3, 3), dtype=float)
+    tmp2 = empty((3, 3), dtype=float)
     tmp_m = empty((3, 3), dtype=float)
 
     tmp_v = empty(3, dtype=float)
 
     # get number of markers
     n_markers_loc = shape(markers)[0]
-    
+
     for ip in range(n_markers_loc):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         # marker positions
         eta1 = markers[ip, 0]
         eta2 = markers[ip, 1]
@@ -1684,31 +273,40 @@
         # evaluate Jacobian, result in df
         map_eval.df(eta1, eta2, eta3,
                     kind_map, params_map,
                     t1_map, t2_map, t3_map, p_map,
                     ind1_map, ind2_map, ind3_map,
                     cx, cy, cz,
                     df)
-        
+
         det_df = linalg.det(df)
 
         # b; 2form
-        b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
+        b[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
+        b[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
+        b[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
 
         # norm_b1; 1form
-        norm_b1[0] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
+        norm_b1[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
+        norm_b1[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
+        norm_b1[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
 
         # curl_norm_b; 2form
-        curl_norm_b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
+        curl_norm_b[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
+        curl_norm_b[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
+        curl_norm_b[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
 
         # b_star; 2form in H1vec
         b_star[:] = (b + curl_norm_b*v/kappa)/det_df
 
         # calculate abs_b_star_para
         abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
 
@@ -1725,130 +323,141 @@
 
         if basis_u == 0:
 
             linalg.matrix_matrix(b_prod, tmp, tmp1)
             linalg.matrix_matrix(tmp1, -b_prod, tmp_m)
             linalg.matrix_vector(b_prod, curl_norm_b, tmp_v)
 
-            filling_m[:, :] = weight * tmp_m * v**2 / abs_b_star_para**2 / det_df**2 * scale_mat
-            filling_v[:] = weight * tmp_v * v**2 / abs_b_star_para / det_df * scale_vec
+            filling_m[:, :] = weight * tmp_m * v**2 / \
+                abs_b_star_para**2 / det_df**2 * scale_mat
+            filling_v[:] = weight * tmp_v * v**2 / \
+                abs_b_star_para / det_df * scale_vec
 
             # call the appropriate matvec filler
             mvf.m_v_fill_v0vec_symm(pn, span1, span2, span3,
                                     bn1, bn2, bn3,
                                     starts0,
-                                    mat11, mat12, mat13, 
-                                    mat22, mat23, 
-                                    mat33, 
-                                    filling_m[0, 0], filling_m[0, 1], filling_m[0, 2], 
-                                    filling_m[1, 1], filling_m[1, 2], 
+                                    mat11, mat12, mat13,
+                                    mat22, mat23,
+                                    mat33,
+                                    filling_m[0, 0], filling_m[0,
+                                                               1], filling_m[0, 2],
+                                    filling_m[1, 1], filling_m[1, 2],
                                     filling_m[2, 2],
                                     vec1, vec2, vec3,
                                     filling_v[0], filling_v[1], filling_v[2])
-        
+
         elif basis_u == 1:
-            
+
             # needed metric coefficients
             linalg.matrix_inv_with_det(df, det_df, df_inv)
             linalg.transpose(df_inv, df_inv_t)
             linalg.matrix_matrix(df_inv, df_inv_t, g_inv)
             linalg.matrix_matrix(g_inv, b_prod, tmp1)
             linalg.matrix_vector(tmp1, curl_norm_b, tmp_v)
 
             linalg.matrix_matrix(tmp1, tmp, tmp2)
             linalg.matrix_matrix(tmp2, -b_prod, tmp1)
             linalg.matrix_matrix(tmp1, g_inv, tmp_m)
 
-            filling_m[:, :] = weight * tmp_m * v**2 / abs_b_star_para**2 / det_df**2 * scale_mat
-            filling_v[:] = weight * tmp_v * v**2 / abs_b_star_para / det_df * scale_vec
+            filling_m[:, :] = weight * tmp_m * v**2 / \
+                abs_b_star_para**2 / det_df**2 * scale_mat
+            filling_v[:] = weight * tmp_v * v**2 / \
+                abs_b_star_para / det_df * scale_vec
 
             # call the appropriate matvec filler
             mvf.m_v_fill_v1_symm(pn, span1, span2, span3,
                                  bn1, bn2, bn3,
                                  bd1, bd2, bd3,
                                  starts1,
-                                 mat11, mat12, mat13, 
-                                 mat22, mat23, 
-                                 mat33, 
-                                 filling_m[0, 0], filling_m[0, 1], filling_m[0, 2], 
-                                 filling_m[1, 1], filling_m[1, 2], 
+                                 mat11, mat12, mat13,
+                                 mat22, mat23,
+                                 mat33,
+                                 filling_m[0, 0], filling_m[0,
+                                                            1], filling_m[0, 2],
+                                 filling_m[1, 1], filling_m[1, 2],
                                  filling_m[2, 2],
                                  vec1, vec2, vec3,
                                  filling_v[0], filling_v[1], filling_v[2])
-            
+
         elif basis_u == 2:
-            
+
             linalg.matrix_matrix(b_prod, tmp, tmp1)
             linalg.matrix_matrix(tmp1, -b_prod, tmp_m)
             linalg.matrix_vector(b_prod, curl_norm_b, tmp_v)
 
-            filling_m[:, :] = weight * tmp_m * v**2 / abs_b_star_para**2 / det_df**4 * scale_mat
-            filling_v[:] = weight * tmp_v * v**2 / abs_b_star_para / det_df**2 * scale_vec
+            filling_m[:, :] = weight * tmp_m * v**2 / \
+                abs_b_star_para**2 / det_df**4 * scale_mat
+            filling_v[:] = weight * tmp_v * v**2 / \
+                abs_b_star_para / det_df**2 * scale_vec
 
             # call the appropriate matvec filler
             mvf.m_v_fill_v2_symm(pn, span1, span2, span3,
                                  bn1, bn2, bn3,
                                  bd1, bd2, bd3,
                                  starts2,
-                                 mat11, mat12, mat13, 
-                                 mat22, mat23, 
-                                 mat33, 
-                                 filling_m[0, 0], filling_m[0, 1], filling_m[0, 2], 
-                                 filling_m[1, 1], filling_m[1, 2], 
+                                 mat11, mat12, mat13,
+                                 mat22, mat23,
+                                 mat33,
+                                 filling_m[0, 0], filling_m[0,
+                                                            1], filling_m[0, 2],
+                                 filling_m[1, 1], filling_m[1, 2],
                                  filling_m[2, 2],
                                  vec1, vec2, vec3,
                                  filling_v[0], filling_v[1], filling_v[2])
-    
+
     mat11 /= n_markers_tot
     mat12 /= n_markers_tot
     mat13 /= n_markers_tot
     mat22 /= n_markers_tot
     mat23 /= n_markers_tot
     mat33 /= n_markers_tot
-    
+
     vec1 /= n_markers_tot
     vec2 /= n_markers_tot
     vec3 /= n_markers_tot
 
 
 def cc_lin_mhd_5d_J2_dg(markers: 'float[:,:]', n_markers_tot: 'int',
-                    pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                    starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                    kind_map: 'int', params_map: 'float[:]',
-                    p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                    ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                    cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                    mat11: 'float[:,:,:,:,:,:]',
-                    mat12: 'float[:,:,:,:,:,:]',
-                    mat13: 'float[:,:,:,:,:,:]',
-                    mat22: 'float[:,:,:,:,:,:]',
-                    mat23: 'float[:,:,:,:,:,:]',
-                    mat33: 'float[:,:,:,:,:,:]',
-                    vec1: 'float[:,:,:]',
-                    vec2: 'float[:,:,:]',
-                    vec3: 'float[:,:,:]',
-                    kappa: float,               # model specific argument
-                    b1: 'float[:,:,:]',           # model specific argument
-                    b2: 'float[:,:,:]',           # model specific argument
-                    b3: 'float[:,:,:]',           # model specific argument
-                    norm_b11: 'float[:,:,:]',     # model specific argument    
-                    norm_b12: 'float[:,:,:]',     # model specific argument
-                    norm_b13: 'float[:,:,:]',     # model specific argument
-                    norm_b21: 'float[:,:,:]',     # model specific argument    
-                    norm_b22: 'float[:,:,:]',     # model specific argument
-                    norm_b23: 'float[:,:,:]',     # model specific argument
-                    curl_norm_b1: 'float[:,:,:]', # model specific argument
-                    curl_norm_b2: 'float[:,:,:]', # model specific argument
-                    curl_norm_b3: 'float[:,:,:]', # model specific argument
-                    grad_PB1: 'float[:,:,:]',     # model specific argument
-                    grad_PB2: 'float[:,:,:]',     # model specific argument
-                    grad_PB3: 'float[:,:,:]',     # model specific argument
-                    gradI_const: 'float',         # model specific argument
-                    basis_u : 'int', scale_vec : 'float'): # model specific argument
-    
+                        pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
+                        starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
+                        kind_map: 'int', params_map: 'float[:]',
+                        p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
+                        ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
+                        cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
+                        mat11: 'float[:,:,:,:,:,:]',
+                        mat12: 'float[:,:,:,:,:,:]',
+                        mat13: 'float[:,:,:,:,:,:]',
+                        mat22: 'float[:,:,:,:,:,:]',
+                        mat23: 'float[:,:,:,:,:,:]',
+                        mat33: 'float[:,:,:,:,:,:]',
+                        vec1: 'float[:,:,:]',
+                        vec2: 'float[:,:,:]',
+                        vec3: 'float[:,:,:]',
+                        kappa: float,               # model specific argument
+                        b1: 'float[:,:,:]',           # model specific argument
+                        b2: 'float[:,:,:]',           # model specific argument
+                        b3: 'float[:,:,:]',           # model specific argument
+                        norm_b11: 'float[:,:,:]',     # model specific argument
+                        norm_b12: 'float[:,:,:]',     # model specific argument
+                        norm_b13: 'float[:,:,:]',     # model specific argument
+                        norm_b21: 'float[:,:,:]',     # model specific argument
+                        norm_b22: 'float[:,:,:]',     # model specific argument
+                        norm_b23: 'float[:,:,:]',     # model specific argument
+                        # model specific argument
+                        curl_norm_b1: 'float[:,:,:]',
+                        # model specific argument
+                        curl_norm_b2: 'float[:,:,:]',
+                        # model specific argument
+                        curl_norm_b3: 'float[:,:,:]',
+                        grad_PB1: 'float[:,:,:]',     # model specific argument
+                        grad_PB2: 'float[:,:,:]',     # model specific argument
+                        grad_PB3: 'float[:,:,:]',     # model specific argument
+                        gradI_const: 'float',         # model specific argument
+                        basis_u: 'int', scale_vec: 'float'):  # model specific argument
     r"""TODO
     """
     # allocate for particle position
     e_diff = empty(3, dtype=float)
 
     # allocate for magnetic field evaluation
     b = empty(3, dtype=float)
@@ -1863,34 +472,34 @@
     bn1 = empty(pn[0] + 1, dtype=float)
     bn2 = empty(pn[1] + 1, dtype=float)
     bn3 = empty(pn[2] + 1, dtype=float)
 
     bd1 = empty(pn[0], dtype=float)
     bd2 = empty(pn[1], dtype=float)
     bd3 = empty(pn[2], dtype=float)
-    
+
     # allocate for metric coeffs
-    df       = empty((3, 3), dtype=float)
-    df_inv   = empty((3, 3), dtype=float)
+    df = empty((3, 3), dtype=float)
+    df_inv = empty((3, 3), dtype=float)
     df_inv_t = empty((3, 3), dtype=float)
-    g_inv    = empty((3, 3), dtype=float)
+    g_inv = empty((3, 3), dtype=float)
 
     # allocate for filling
     filling_v = empty(3, dtype=float)
 
-    tmp1   = empty((3, 3), dtype=float)
-    tmp2   = empty((3, 3), dtype=float)
+    tmp1 = empty((3, 3), dtype=float)
+    tmp2 = empty((3, 3), dtype=float)
     tmp_v1 = empty(3, dtype=float)
     tmp_v2 = empty(3, dtype=float)
 
     # get number of markers
     n_markers_loc = shape(markers)[0]
-    
+
     for ip in range(n_markers_loc):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         # marker positions
         eta1 = markers[ip, 0]
         eta2 = markers[ip, 1]
@@ -1913,46 +522,61 @@
         # evaluate Jacobian, result in df
         map_eval.df(eta1, eta2, eta3,
                     kind_map, params_map,
                     t1_map, t2_map, t3_map, p_map,
                     ind1_map, ind2_map, ind3_map,
                     cx, cy, cz,
                     df)
-        
+
         det_df = linalg.det(df)
 
         # needed metric coefficients
         linalg.matrix_inv_with_det(df, det_df, df_inv)
         linalg.transpose(df_inv, df_inv_t)
         linalg.matrix_matrix(df_inv, df_inv_t, g_inv)
 
         # b; 2form
-        b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
+        b[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
+        b[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
+        b[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
 
         # norm_b1; 1form
-        norm_b1[0] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
+        norm_b1[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
+        norm_b1[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
+        norm_b1[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
 
         # norm_b2; 2form
-        norm_b2[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, norm_b21, starts2[0])
-        norm_b2[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, norm_b22, starts2[1])
-        norm_b2[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, norm_b23, starts2[2])
+        norm_b2[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, norm_b21, starts2[0])
+        norm_b2[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, norm_b22, starts2[1])
+        norm_b2[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, norm_b23, starts2[2])
 
         # curl_norm_b; 2form
-        curl_norm_b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
+        curl_norm_b[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
+        curl_norm_b[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
+        curl_norm_b[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
 
         # grad_PB; 1form
-        grad_PB[0] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_PB1, starts1[0])
-        grad_PB[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_PB2, starts1[1])
-        grad_PB[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_PB3, starts1[2])
+        grad_PB[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_PB1, starts1[0])
+        grad_PB[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_PB2, starts1[1])
+        grad_PB[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_PB3, starts1[2])
 
         # b_star; 2form transformed into H1vec
         b_star[:] = (b + curl_norm_b*v/kappa)/det_df
 
         # calculate abs_b_star_para
         abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
 
@@ -1968,106 +592,120 @@
         norm_b2_prod[0, 2] = +norm_b2[1]
         norm_b2_prod[1, 0] = +norm_b2[2]
         norm_b2_prod[1, 2] = -norm_b2[0]
         norm_b2_prod[2, 0] = -norm_b2[1]
         norm_b2_prod[2, 1] = +norm_b2[0]
 
         if basis_u == 0:
-            
+
             linalg.matrix_matrix(b_prod, g_inv, tmp1)
             linalg.matrix_matrix(tmp1, norm_b2_prod, tmp2)
             linalg.matrix_matrix(tmp2, g_inv, tmp1)
             linalg.matrix_vector(tmp1, grad_PB, tmp_v1)
             linalg.matrix_vector(tmp1, markers[ip, 15:18], tmp_v2)
 
-            filling_v[:] = (weight*tmp_v1*mu + tmp_v2*gradI_const)/abs_b_star_para * scale_vec
+            filling_v[:] = (weight*tmp_v1*mu + tmp_v2 *
+                            gradI_const)/abs_b_star_para * scale_vec
 
             # call the appropriate matvec filler
             mvf.vec_fill_v0(pn, span1, span2, span3,
                             bn1, bn2, bn3,
                             starts0,
                             vec1, vec2, vec3,
                             filling_v[0], filling_v[1], filling_v[2])
-        
+
         elif basis_u == 1:
-            
+
             linalg.matrix_matrix(g_inv, b_prod, tmp1)
             linalg.matrix_matrix(tmp1, g_inv, tmp2)
             linalg.matrix_matrix(tmp2, norm_b2_prod, tmp1)
             linalg.matrix_matrix(tmp1, g_inv, tmp2)
             linalg.matrix_vector(tmp2, grad_PB, tmp_v1)
             linalg.matrix_vector(tmp2, markers[ip, 15:18], tmp_v2)
 
-            filling_v[:] = (weight*tmp_v1*mu + tmp_v2*gradI_const)/abs_b_star_para * scale_vec
+            filling_v[:] = (weight*tmp_v1*mu + tmp_v2 *
+                            gradI_const)/abs_b_star_para * scale_vec
 
             # call the appropriate matvec filler
             mvf.vec_fill_v1(pn, span1, span2, span3,
                             bn1, bn2, bn3,
                             bd1, bd2, bd3,
                             starts1,
                             vec1, vec2, vec3,
                             filling_v[0], filling_v[1], filling_v[2])
-            
+
         elif basis_u == 2:
-            
+
             linalg.matrix_matrix(b_prod, g_inv, tmp1)
             linalg.matrix_matrix(tmp1, norm_b2_prod, tmp2)
             linalg.matrix_matrix(tmp2, g_inv, tmp1)
             linalg.matrix_vector(tmp1, grad_PB, tmp_v1)
             linalg.matrix_vector(tmp1, markers[ip, 15:18], tmp_v2)
 
-            filling_v[:] = (weight*tmp_v1*mu + tmp_v2*gradI_const)/abs_b_star_para/det_df * scale_vec
+            filling_v[:] = (weight*tmp_v1*mu + tmp_v2*gradI_const) / \
+                abs_b_star_para/det_df * scale_vec
 
             # call the appropriate matvec filler
             mvf.vec_fill_v2(pn, span1, span2, span3,
-                            bn1, bn2, bn3, 
+                            bn1, bn2, bn3,
                             bd1, bd2, bd3,
                             starts2,
                             vec1, vec2, vec3,
                             filling_v[0], filling_v[1], filling_v[2])
-            
+
     vec1 /= n_markers_tot
     vec2 /= n_markers_tot
     vec3 /= n_markers_tot
 
 
 def cc_lin_mhd_5d_J2_dg_prepare(markers: 'float[:,:]', n_markers_tot: 'int',
-                             pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                             starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                             kind_map: 'int', params_map: 'float[:]',
-                             p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                             ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                             cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                             mat11: 'float[:,:,:,:,:,:]',
-                             mat12: 'float[:,:,:,:,:,:]',
-                             mat13: 'float[:,:,:,:,:,:]',
-                             mat22: 'float[:,:,:,:,:,:]',
-                             mat23: 'float[:,:,:,:,:,:]',
-                             mat33: 'float[:,:,:,:,:,:]',
-                             vec1: 'float[:,:,:]',
-                             vec2: 'float[:,:,:]',
-                             vec3: 'float[:,:,:]',
-                             kappa: float,    # model specific argument
-                             b1: 'float[:,:,:]',   # model specific argument
-                             b2: 'float[:,:,:]',   # model specific argument
-                             b3: 'float[:,:,:]',   # model specific argument
-                             norm_b11: 'float[:,:,:]',       # model specific argument    
-                             norm_b12: 'float[:,:,:]',       # model specific argument
-                             norm_b13: 'float[:,:,:]',       # model specific argument
-                             norm_b21: 'float[:,:,:]',       # model specific argument    
-                             norm_b22: 'float[:,:,:]',       # model specific argument
-                             norm_b23: 'float[:,:,:]',       # model specific argument
-                             curl_norm_b1: 'float[:,:,:]',  # model specific argument
-                             curl_norm_b2: 'float[:,:,:]',  # model specific argument
-                             curl_norm_b3: 'float[:,:,:]',  # model specific argument
-                             grad_PB1: 'float[:,:,:]',  # model specific argument
-                             grad_PB2: 'float[:,:,:]',  # model specific argument
-                             grad_PB3: 'float[:,:,:]',  # model specific argument
-                             basis_u : 'int', scale_vec : 'float'): # model specific argument
-    
+                                pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
+                                starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
+                                kind_map: 'int', params_map: 'float[:]',
+                                p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
+                                ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
+                                cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
+                                mat11: 'float[:,:,:,:,:,:]',
+                                mat12: 'float[:,:,:,:,:,:]',
+                                mat13: 'float[:,:,:,:,:,:]',
+                                mat22: 'float[:,:,:,:,:,:]',
+                                mat23: 'float[:,:,:,:,:,:]',
+                                mat33: 'float[:,:,:,:,:,:]',
+                                vec1: 'float[:,:,:]',
+                                vec2: 'float[:,:,:]',
+                                vec3: 'float[:,:,:]',
+                                kappa: float,    # model specific argument
+                                b1: 'float[:,:,:]',   # model specific argument
+                                b2: 'float[:,:,:]',   # model specific argument
+                                b3: 'float[:,:,:]',   # model specific argument
+                                # model specific argument
+                                norm_b11: 'float[:,:,:]',
+                                # model specific argument
+                                norm_b12: 'float[:,:,:]',
+                                # model specific argument
+                                norm_b13: 'float[:,:,:]',
+                                # model specific argument
+                                norm_b21: 'float[:,:,:]',
+                                # model specific argument
+                                norm_b22: 'float[:,:,:]',
+                                # model specific argument
+                                norm_b23: 'float[:,:,:]',
+                                # model specific argument
+                                curl_norm_b1: 'float[:,:,:]',
+                                # model specific argument
+                                curl_norm_b2: 'float[:,:,:]',
+                                # model specific argument
+                                curl_norm_b3: 'float[:,:,:]',
+                                # model specific argument
+                                grad_PB1: 'float[:,:,:]',
+                                # model specific argument
+                                grad_PB2: 'float[:,:,:]',
+                                # model specific argument
+                                grad_PB3: 'float[:,:,:]',
+                                basis_u: 'int', scale_vec: 'float'):  # model specific argument
     r"""Accumulates into V1 with the filling functions
 
     .. math::
 
         A_p^{\mu, \nu} &= w_p * [G^{-1}(\eta_p) * B2_{\times}(\eta_p) * B2_{\times}(\eta_p)^\top * G^{-1}(\eta_p) * v^2_{\parallel,p} * \left( 1/B^*_\parallel \right)^2 * |1/\sqrt{g} \hat \nabla \times \hat b^1_0|_p^2]_{\mu, \nu}
 
         B_p^\mu &= w_p *[ G^{-1}(\eta_p) * B2_{\times}(\eta_p)* v^2_{\parallel,p} * \left( 1/B^*_\parallel \right)]_\mu
@@ -2109,33 +747,33 @@
     bn1 = empty(pn[0] + 1, dtype=float)
     bn2 = empty(pn[1] + 1, dtype=float)
     bn3 = empty(pn[2] + 1, dtype=float)
 
     bd1 = empty(pn[0], dtype=float)
     bd2 = empty(pn[1], dtype=float)
     bd3 = empty(pn[2], dtype=float)
-    
+
     # allocate for metric coeffs
-    df       = empty((3, 3), dtype=float)
-    df_inv   = empty((3, 3), dtype=float)
+    df = empty((3, 3), dtype=float)
+    df_inv = empty((3, 3), dtype=float)
     df_inv_t = empty((3, 3), dtype=float)
-    g_inv    = empty((3, 3), dtype=float)
+    g_inv = empty((3, 3), dtype=float)
 
     # allocate for filling
     filling_v = empty(3, dtype=float)
 
-    tmp1   = empty((3, 3), dtype=float)
-    tmp2   = empty((3, 3), dtype=float)
+    tmp1 = empty((3, 3), dtype=float)
+    tmp2 = empty((3, 3), dtype=float)
     tmp_v = empty(3, dtype=float)
 
     # get number of markers
     n_markers_loc = shape(markers)[0]
-    
+
     for ip in range(n_markers_loc):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         # marker positions
         eta1 = markers[ip, 0]
         eta2 = markers[ip, 1]
@@ -2158,46 +796,61 @@
         # evaluate Jacobian, result in df
         map_eval.df(eta1, eta2, eta3,
                     kind_map, params_map,
                     t1_map, t2_map, t3_map, p_map,
                     ind1_map, ind2_map, ind3_map,
                     cx, cy, cz,
                     df)
-        
+
         det_df = linalg.det(df)
 
         # needed metric coefficients
         linalg.matrix_inv_with_det(df, det_df, df_inv)
         linalg.transpose(df_inv, df_inv_t)
         linalg.matrix_matrix(df_inv, df_inv_t, g_inv)
 
         # b; 2form
-        b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
+        b[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
+        b[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
+        b[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
 
         # norm_b1; 1form
-        norm_b1[0] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
+        norm_b1[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
+        norm_b1[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
+        norm_b1[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
 
         # norm_b2; 2form
-        norm_b2[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, norm_b21, starts2[0])
-        norm_b2[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, norm_b22, starts2[1])
-        norm_b2[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, norm_b23, starts2[2])
+        norm_b2[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, norm_b21, starts2[0])
+        norm_b2[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, norm_b22, starts2[1])
+        norm_b2[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, norm_b23, starts2[2])
 
         # curl_norm_b; 2form
-        curl_norm_b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
+        curl_norm_b[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
+        curl_norm_b[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
+        curl_norm_b[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
 
         # grad_PB; 1form
-        grad_PB[0] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_PB1, starts1[0])
-        grad_PB[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_PB2, starts1[1])
-        grad_PB[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_PB3, starts1[2])
+        grad_PB[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_PB1, starts1[0])
+        grad_PB[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_PB2, starts1[1])
+        grad_PB[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_PB3, starts1[2])
 
         # b_star; 2form transformed into H1vec
         b_star[:] = (b + curl_norm_b*v/kappa)/det_df
 
         # calculate abs_b_star_para
         abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
 
@@ -2213,103 +866,118 @@
         norm_b2_prod[0, 2] = +norm_b2[1]
         norm_b2_prod[1, 0] = +norm_b2[2]
         norm_b2_prod[1, 2] = -norm_b2[0]
         norm_b2_prod[2, 0] = -norm_b2[1]
         norm_b2_prod[2, 1] = +norm_b2[0]
 
         if basis_u == 0:
-            
+
             linalg.matrix_matrix(b_prod, g_inv, tmp1)
             linalg.matrix_matrix(tmp1, norm_b2_prod, tmp2)
             linalg.matrix_matrix(tmp2, g_inv, tmp1)
             linalg.matrix_vector(tmp1, grad_PB, tmp_v)
 
             filling_v[:] = weight * tmp_v * mu / abs_b_star_para * scale_vec
 
             # call the appropriate matvec filler
             mvf.vec_fill_v0(pn, span1, span2, span3,
                             bn1, bn2, bn3,
                             starts0,
                             vec1, vec2, vec3,
                             filling_v[0], filling_v[1], filling_v[2])
-        
+
         elif basis_u == 1:
-            
+
             linalg.matrix_matrix(g_inv, b_prod, tmp1)
             linalg.matrix_matrix(tmp1, g_inv, tmp2)
             linalg.matrix_matrix(tmp2, norm_b2_prod, tmp1)
             linalg.matrix_matrix(tmp1, g_inv, tmp2)
             linalg.matrix_vector(tmp2, grad_PB, tmp_v)
 
-            filling_v[:] =    weight * tmp_v * mu / abs_b_star_para * scale_vec
+            filling_v[:] = weight * tmp_v * mu / abs_b_star_para * scale_vec
 
             # call the appropriate matvec filler
             mvf.vec_fill_v1(pn, span1, span2, span3,
                             bn1, bn2, bn3,
                             bd1, bd2, bd3,
                             starts1,
                             vec1, vec2, vec3,
                             filling_v[0], filling_v[1], filling_v[2])
-            
+
         elif basis_u == 2:
-            
+
             linalg.matrix_matrix(b_prod, g_inv, tmp1)
             linalg.matrix_matrix(tmp1, norm_b2_prod, tmp2)
             linalg.matrix_matrix(tmp2, g_inv, tmp1)
             linalg.matrix_vector(tmp1, grad_PB, tmp_v)
 
-            filling_v[:] =    weight * tmp_v * mu / abs_b_star_para / det_df * scale_vec
+            filling_v[:] = weight * tmp_v * mu / \
+                abs_b_star_para / det_df * scale_vec
 
             # call the appropriate matvec filler
             mvf.vec_fill_v2(pn, span1, span2, span3,
                             bn1, bn2, bn3, bd1, bd2, bd3,
                             starts2,
                             vec1, vec2, vec3,
                             filling_v[0], filling_v[1], filling_v[2])
-            
+
     vec1 /= n_markers_tot
     vec2 /= n_markers_tot
     vec3 /= n_markers_tot
 
 
 def cc_lin_mhd_5d_J2_dg_faster(markers: 'float[:,:]', n_markers_tot: 'int',
-                    pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                    starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                    kind_map: 'int', params_map: 'float[:]',
-                    p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                    ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                    cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                    mat11: 'float[:,:,:,:,:,:]',
-                    mat12: 'float[:,:,:,:,:,:]',
-                    mat13: 'float[:,:,:,:,:,:]',
-                    mat22: 'float[:,:,:,:,:,:]',
-                    mat23: 'float[:,:,:,:,:,:]',
-                    mat33: 'float[:,:,:,:,:,:]',
-                    vec1: 'float[:,:,:]',
-                    vec2: 'float[:,:,:]',
-                    vec3: 'float[:,:,:]',
-                    kappa: float,               # model specific argument
-                    b1: 'float[:,:,:]',           # model specific argument
-                    b2: 'float[:,:,:]',           # model specific argument
-                    b3: 'float[:,:,:]',           # model specific argument
-                    norm_b11: 'float[:,:,:]',     # model specific argument    
-                    norm_b12: 'float[:,:,:]',     # model specific argument
-                    norm_b13: 'float[:,:,:]',     # model specific argument
-                    norm_b21: 'float[:,:,:]',     # model specific argument    
-                    norm_b22: 'float[:,:,:]',     # model specific argument
-                    norm_b23: 'float[:,:,:]',     # model specific argument
-                    curl_norm_b1: 'float[:,:,:]', # model specific argument
-                    curl_norm_b2: 'float[:,:,:]', # model specific argument
-                    curl_norm_b3: 'float[:,:,:]', # model specific argument
-                    grad_PB1: 'float[:,:,:]',     # model specific argument
-                    grad_PB2: 'float[:,:,:]',     # model specific argument
-                    grad_PB3: 'float[:,:,:]',     # model specific argument
-                    gradI_const: 'float',         # model specific argument
-                    basis_u : 'int', scale_vec : 'float'): # model specific argument
-    
+                               pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
+                               starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
+                               kind_map: 'int', params_map: 'float[:]',
+                               p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
+                               ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
+                               cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
+                               mat11: 'float[:,:,:,:,:,:]',
+                               mat12: 'float[:,:,:,:,:,:]',
+                               mat13: 'float[:,:,:,:,:,:]',
+                               mat22: 'float[:,:,:,:,:,:]',
+                               mat23: 'float[:,:,:,:,:,:]',
+                               mat33: 'float[:,:,:,:,:,:]',
+                               vec1: 'float[:,:,:]',
+                               vec2: 'float[:,:,:]',
+                               vec3: 'float[:,:,:]',
+                               kappa: float,               # model specific argument
+                               # model specific argument
+                               b1: 'float[:,:,:]',
+                               # model specific argument
+                               b2: 'float[:,:,:]',
+                               # model specific argument
+                               b3: 'float[:,:,:]',
+                               # model specific argument
+                               norm_b11: 'float[:,:,:]',
+                               # model specific argument
+                               norm_b12: 'float[:,:,:]',
+                               # model specific argument
+                               norm_b13: 'float[:,:,:]',
+                               # model specific argument
+                               norm_b21: 'float[:,:,:]',
+                               # model specific argument
+                               norm_b22: 'float[:,:,:]',
+                               # model specific argument
+                               norm_b23: 'float[:,:,:]',
+                               # model specific argument
+                               curl_norm_b1: 'float[:,:,:]',
+                               # model specific argument
+                               curl_norm_b2: 'float[:,:,:]',
+                               # model specific argument
+                               curl_norm_b3: 'float[:,:,:]',
+                               # model specific argument
+                               grad_PB1: 'float[:,:,:]',
+                               # model specific argument
+                               grad_PB2: 'float[:,:,:]',
+                               # model specific argument
+                               grad_PB3: 'float[:,:,:]',
+                               gradI_const: 'float',         # model specific argument
+                               basis_u: 'int', scale_vec: 'float'):  # model specific argument
     r"""TODO
     """
     # allocate for magnetic field evaluation
     grad_PB = empty(3, dtype=float)
 
     bn1 = empty(pn[0] + 1, dtype=float)
     bn2 = empty(pn[1] + 1, dtype=float)
@@ -2318,31 +986,31 @@
     bd1 = empty(pn[0], dtype=float)
     bd2 = empty(pn[1], dtype=float)
     bd3 = empty(pn[2], dtype=float)
 
     # allocate for filling
     filling_v = empty(3, dtype=float)
 
-    tmp   = empty((3, 3), dtype=float)
+    tmp = empty((3, 3), dtype=float)
     tmp_v1 = empty(3, dtype=float)
     tmp_v2 = empty(3, dtype=float)
 
     # get number of markers
     n_markers_loc = shape(markers)[0]
-    
+
     for ip in range(n_markers_loc):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         # marker positions
-        eta1 = markers[ip, 0] # mid
-        eta2 = markers[ip, 1] # mid
-        eta3 = markers[ip, 2] # mid
+        eta1 = markers[ip, 0]  # mid
+        eta2 = markers[ip, 1]  # mid
+        eta3 = markers[ip, 2]  # mid
 
         # marker weight and velocity
         weight = markers[ip, 5]
         mu = markers[ip, 4]
 
         # b-field evaluation
         span1 = bsp.find_span(tn1, pn[0], eta1)
@@ -2350,105 +1018,125 @@
         span3 = bsp.find_span(tn3, pn[2], eta3)
 
         bsp.b_d_splines_slim(tn1, pn[0], eta1, span1, bn1, bd1)
         bsp.b_d_splines_slim(tn2, pn[1], eta2, span2, bn2, bd2)
         bsp.b_d_splines_slim(tn3, pn[2], eta3, span3, bn3, bd3)
 
         # grad_PB; 1form
-        grad_PB[0] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_PB1, starts1[0])
-        grad_PB[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_PB2, starts1[1])
-        grad_PB[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_PB3, starts1[2])
-
-        tmp[:,:] = ((markers[ip, 18], markers[ip, 19], markers[ip, 20]),
-                    (markers[ip, 19], markers[ip, 21], markers[ip, 22]),
-                    (markers[ip, 20], markers[ip, 22], markers[ip, 23])) 
+        grad_PB[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_PB1, starts1[0])
+        grad_PB[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_PB2, starts1[1])
+        grad_PB[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_PB3, starts1[2])
+
+        tmp[:, :] = ((markers[ip, 18], markers[ip, 19], markers[ip, 20]),
+                     (markers[ip, 19], markers[ip, 21], markers[ip, 22]),
+                     (markers[ip, 20], markers[ip, 22], markers[ip, 23]))
 
         if basis_u == 0:
-            
+
             linalg.matrix_vector(tmp, grad_PB, tmp_v1)
             linalg.matrix_vector(tmp, markers[ip, 15:18], tmp_v2)
 
-            filling_v[:] = (tmp_v1 * mu * scale_vec + tmp_v2*gradI_const) * weight
-            
+            filling_v[:] = (tmp_v1 * mu * scale_vec +
+                            tmp_v2*gradI_const) * weight
+
             # call the appropriate matvec filler
             mvf.vec_fill_v0(pn, span1, span2, span3,
                             bn1, bn2, bn3,
                             starts0,
                             vec1, vec2, vec3,
                             filling_v[0], filling_v[1], filling_v[2])
-        
+
         elif basis_u == 1:
-            
+
             linalg.matrix_vector(tmp, grad_PB, tmp_v1)
             linalg.matrix_vector(tmp, markers[ip, 15:18], tmp_v2)
 
-            filling_v[:] = (tmp_v1 * mu * scale_vec + tmp_v2*gradI_const) * weight
+            filling_v[:] = (tmp_v1 * mu * scale_vec +
+                            tmp_v2*gradI_const) * weight
 
             # call the appropriate matvec filler
             mvf.vec_fill_v1(pn, span1, span2, span3,
                             bn1, bn2, bn3,
                             bd1, bd2, bd3,
                             starts1,
                             vec1, vec2, vec3,
                             filling_v[0], filling_v[1], filling_v[2])
-            
+
         elif basis_u == 2:
-            
+
             linalg.matrix_vector(tmp, grad_PB, tmp_v1)
             linalg.matrix_vector(tmp, markers[ip, 15:18], tmp_v2)
 
-            filling_v[:] = (tmp_v1 * mu * scale_vec + tmp_v2*gradI_const) * weight
+            filling_v[:] = (tmp_v1 * mu * scale_vec +
+                            tmp_v2*gradI_const) * weight
 
             # call the appropriate matvec filler
             mvf.vec_fill_v2(pn, span1, span2, span3,
-                            bn1, bn2, bn3, 
+                            bn1, bn2, bn3,
                             bd1, bd2, bd3,
                             starts2,
                             vec1, vec2, vec3,
                             filling_v[0], filling_v[1], filling_v[2])
-            
+
     vec1 /= n_markers_tot
     vec2 /= n_markers_tot
     vec3 /= n_markers_tot
 
 
 def cc_lin_mhd_5d_J2_dg_prepare_faster(markers: 'float[:,:]', n_markers_tot: 'int',
-                             pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                             starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                             kind_map: 'int', params_map: 'float[:]',
-                             p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                             ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                             cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                             mat11: 'float[:,:,:,:,:,:]',
-                             mat12: 'float[:,:,:,:,:,:]',
-                             mat13: 'float[:,:,:,:,:,:]',
-                             mat22: 'float[:,:,:,:,:,:]',
-                             mat23: 'float[:,:,:,:,:,:]',
-                             mat33: 'float[:,:,:,:,:,:]',
-                             vec1: 'float[:,:,:]',
-                             vec2: 'float[:,:,:]',
-                             vec3: 'float[:,:,:]',
-                             kappa: float,    # model specific argument
-                             b1: 'float[:,:,:]',   # model specific argument
-                             b2: 'float[:,:,:]',   # model specific argument
-                             b3: 'float[:,:,:]',   # model specific argument
-                             norm_b11: 'float[:,:,:]',       # model specific argument    
-                             norm_b12: 'float[:,:,:]',       # model specific argument
-                             norm_b13: 'float[:,:,:]',       # model specific argument
-                             norm_b21: 'float[:,:,:]',       # model specific argument    
-                             norm_b22: 'float[:,:,:]',       # model specific argument
-                             norm_b23: 'float[:,:,:]',       # model specific argument
-                             curl_norm_b1: 'float[:,:,:]',  # model specific argument
-                             curl_norm_b2: 'float[:,:,:]',  # model specific argument
-                             curl_norm_b3: 'float[:,:,:]',  # model specific argument
-                             grad_PB1: 'float[:,:,:]',  # model specific argument
-                             grad_PB2: 'float[:,:,:]',  # model specific argument
-                             grad_PB3: 'float[:,:,:]',  # model specific argument
-                             basis_u : 'int', scale_vec : 'float'): # model specific argument
-    
+                                       pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
+                                       starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
+                                       kind_map: 'int', params_map: 'float[:]',
+                                       p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
+                                       ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
+                                       cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
+                                       mat11: 'float[:,:,:,:,:,:]',
+                                       mat12: 'float[:,:,:,:,:,:]',
+                                       mat13: 'float[:,:,:,:,:,:]',
+                                       mat22: 'float[:,:,:,:,:,:]',
+                                       mat23: 'float[:,:,:,:,:,:]',
+                                       mat33: 'float[:,:,:,:,:,:]',
+                                       vec1: 'float[:,:,:]',
+                                       vec2: 'float[:,:,:]',
+                                       vec3: 'float[:,:,:]',
+                                       kappa: float,    # model specific argument
+                                       # model specific argument
+                                       b1: 'float[:,:,:]',
+                                       # model specific argument
+                                       b2: 'float[:,:,:]',
+                                       # model specific argument
+                                       b3: 'float[:,:,:]',
+                                       # model specific argument
+                                       norm_b11: 'float[:,:,:]',
+                                       # model specific argument
+                                       norm_b12: 'float[:,:,:]',
+                                       # model specific argument
+                                       norm_b13: 'float[:,:,:]',
+                                       # model specific argument
+                                       norm_b21: 'float[:,:,:]',
+                                       # model specific argument
+                                       norm_b22: 'float[:,:,:]',
+                                       # model specific argument
+                                       norm_b23: 'float[:,:,:]',
+                                       # model specific argument
+                                       curl_norm_b1: 'float[:,:,:]',
+                                       # model specific argument
+                                       curl_norm_b2: 'float[:,:,:]',
+                                       # model specific argument
+                                       curl_norm_b3: 'float[:,:,:]',
+                                       # model specific argument
+                                       grad_PB1: 'float[:,:,:]',
+                                       # model specific argument
+                                       grad_PB2: 'float[:,:,:]',
+                                       # model specific argument
+                                       grad_PB3: 'float[:,:,:]',
+                                       basis_u: 'int', scale_vec: 'float'):  # model specific argument
     r"""Accumulates into V1 with the filling functions
 
     .. math::
 
         A_p^{\mu, \nu} &= w_p * [G^{-1}(\eta_p) * B2_{\times}(\eta_p) * B2_{\times}(\eta_p)^\top * G^{-1}(\eta_p) * v^2_{\parallel,p} * \left( 1/B^*_\parallel \right)^2 * |1/\sqrt{g} \hat \nabla \times \hat b^1_0|_p^2]_{\mu, \nu}
 
         B_p^\mu &= w_p *[ G^{-1}(\eta_p) * B2_{\times}(\eta_p)* v^2_{\parallel,p} * \left( 1/B^*_\parallel \right)]_\mu
@@ -2490,33 +1178,33 @@
     bn1 = empty(pn[0] + 1, dtype=float)
     bn2 = empty(pn[1] + 1, dtype=float)
     bn3 = empty(pn[2] + 1, dtype=float)
 
     bd1 = empty(pn[0], dtype=float)
     bd2 = empty(pn[1], dtype=float)
     bd3 = empty(pn[2], dtype=float)
-    
+
     # allocate for metric coeffs
-    df       = empty((3, 3), dtype=float)
-    df_inv   = empty((3, 3), dtype=float)
+    df = empty((3, 3), dtype=float)
+    df_inv = empty((3, 3), dtype=float)
     df_inv_t = empty((3, 3), dtype=float)
-    g_inv    = empty((3, 3), dtype=float)
+    g_inv = empty((3, 3), dtype=float)
 
     # allocate for filling
     filling_v = empty(3, dtype=float)
 
-    tmp1   = empty((3, 3), dtype=float)
-    tmp2   = empty((3, 3), dtype=float)
+    tmp1 = empty((3, 3), dtype=float)
+    tmp2 = empty((3, 3), dtype=float)
     tmp_v = empty(3, dtype=float)
 
     # get number of markers
     n_markers_loc = shape(markers)[0]
-    
+
     for ip in range(n_markers_loc):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         # marker positions
         eta1 = markers[ip, 0]
         eta2 = markers[ip, 1]
@@ -2539,46 +1227,61 @@
         # evaluate Jacobian, result in df
         map_eval.df(eta1, eta2, eta3,
                     kind_map, params_map,
                     t1_map, t2_map, t3_map, p_map,
                     ind1_map, ind2_map, ind3_map,
                     cx, cy, cz,
                     df)
-        
+
         det_df = linalg.det(df)
 
         # needed metric coefficients
         linalg.matrix_inv_with_det(df, det_df, df_inv)
         linalg.transpose(df_inv, df_inv_t)
         linalg.matrix_matrix(df_inv, df_inv_t, g_inv)
 
         # b; 2form
-        b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
+        b[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
+        b[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
+        b[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
 
         # norm_b1; 1form
-        norm_b1[0] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
+        norm_b1[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
+        norm_b1[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
+        norm_b1[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
 
         # norm_b2; 2form
-        norm_b2[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, norm_b21, starts2[0])
-        norm_b2[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, norm_b22, starts2[1])
-        norm_b2[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, norm_b23, starts2[2])
+        norm_b2[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, norm_b21, starts2[0])
+        norm_b2[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, norm_b22, starts2[1])
+        norm_b2[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, norm_b23, starts2[2])
 
         # curl_norm_b; 2form
-        curl_norm_b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
+        curl_norm_b[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
+        curl_norm_b[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
+        curl_norm_b[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
 
         # grad_PB; 1form
-        grad_PB[0] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_PB1, starts1[0])
-        grad_PB[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_PB2, starts1[1])
-        grad_PB[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_PB3, starts1[2])
+        grad_PB[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_PB1, starts1[0])
+        grad_PB[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_PB2, starts1[1])
+        grad_PB[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_PB3, starts1[2])
 
         # b_star; 2form transformed into H1vec
         b_star[:] = (b + curl_norm_b*v/kappa)/det_df
 
         # calculate abs_b_star_para
         abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
 
@@ -2594,79 +1297,80 @@
         norm_b2_prod[0, 2] = +norm_b2[1]
         norm_b2_prod[1, 0] = +norm_b2[2]
         norm_b2_prod[1, 2] = -norm_b2[0]
         norm_b2_prod[2, 0] = -norm_b2[1]
         norm_b2_prod[2, 1] = +norm_b2[0]
 
         if basis_u == 0:
-            
+
             linalg.matrix_matrix(b_prod, g_inv, tmp1)
             linalg.matrix_matrix(tmp1, norm_b2_prod, tmp2)
             linalg.matrix_matrix(tmp2, g_inv, tmp1)
             linalg.matrix_vector(tmp1, grad_PB, tmp_v)
 
             # saving S(H_n)
-            markers[ip, 18:21] = tmp1[0,:]/abs_b_star_para
-            markers[ip, 21:23] = tmp1[1,1:3]/abs_b_star_para
-            markers[ip, 23]    = tmp1[2,2]/abs_b_star_para
+            markers[ip, 18:21] = tmp1[0, :]/abs_b_star_para
+            markers[ip, 21:23] = tmp1[1, 1:3]/abs_b_star_para
+            markers[ip, 23] = tmp1[2, 2]/abs_b_star_para
 
             filling_v[:] = weight * tmp_v * mu / abs_b_star_para * scale_vec
 
             # call the appropriate matvec filler
             mvf.vec_fill_v0(pn, span1, span2, span3,
                             bn1, bn2, bn3,
                             starts0,
                             vec1, vec2, vec3,
                             filling_v[0], filling_v[1], filling_v[2])
-        
+
         elif basis_u == 1:
-            
+
             linalg.matrix_matrix(g_inv, b_prod, tmp1)
             linalg.matrix_matrix(tmp1, g_inv, tmp2)
             linalg.matrix_matrix(tmp2, norm_b2_prod, tmp1)
             linalg.matrix_matrix(tmp1, g_inv, tmp2)
             linalg.matrix_vector(tmp2, grad_PB, tmp_v)
 
             # saving S(H_n)
-            markers[ip, 18:21] = tmp2[0,:]/abs_b_star_para
-            markers[ip, 21:23] = tmp2[1,1:3]/abs_b_star_para
-            markers[ip, 23]    = tmp2[2,2]/abs_b_star_para
+            markers[ip, 18:21] = tmp2[0, :]/abs_b_star_para
+            markers[ip, 21:23] = tmp2[1, 1:3]/abs_b_star_para
+            markers[ip, 23] = tmp2[2, 2]/abs_b_star_para
 
-            filling_v[:] =    weight * tmp_v * mu / abs_b_star_para * scale_vec
+            filling_v[:] = weight * tmp_v * mu / abs_b_star_para * scale_vec
 
             # call the appropriate matvec filler
             mvf.vec_fill_v1(pn, span1, span2, span3,
                             bn1, bn2, bn3,
                             bd1, bd2, bd3,
                             starts1,
                             vec1, vec2, vec3,
                             filling_v[0], filling_v[1], filling_v[2])
-            
+
         elif basis_u == 2:
-            
+
             linalg.matrix_matrix(b_prod, g_inv, tmp1)
             linalg.matrix_matrix(tmp1, norm_b2_prod, tmp2)
             linalg.matrix_matrix(tmp2, g_inv, tmp1)
             linalg.matrix_vector(tmp1, grad_PB, tmp_v)
 
             # saving S(H_n)
-            markers[ip, 18:21] = tmp1[0,:]/det_df/abs_b_star_para
-            markers[ip, 21:23] = tmp1[1,1:3]/det_df/abs_b_star_para
-            markers[ip, 23]    = tmp1[2,2]/det_df/abs_b_star_para
+            markers[ip, 18:21] = tmp1[0, :]/det_df/abs_b_star_para
+            markers[ip, 21:23] = tmp1[1, 1:3]/det_df/abs_b_star_para
+            markers[ip, 23] = tmp1[2, 2]/det_df/abs_b_star_para
 
-            filling_v[:] =    weight * tmp_v * mu / abs_b_star_para / det_df * scale_vec
+            filling_v[:] = weight * tmp_v * mu / \
+                abs_b_star_para / det_df * scale_vec
 
             # call the appropriate matvec filler
             mvf.vec_fill_v2(pn, span1, span2, span3,
-                            bn1, bn2, bn3, 
+                            bn1, bn2, bn3,
                             bd1, bd2, bd3,
                             starts2,
                             vec1, vec2, vec3,
                             filling_v[0], filling_v[1], filling_v[2])
-            
+
     vec1 /= n_markers_tot
     vec2 /= n_markers_tot
     vec3 /= n_markers_tot
 
 
 @stack_array('bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3')
 def cc_lin_mhd_5d_mu(markers: 'float[:,:]', n_markers_tot: 'int',
@@ -2675,15 +1379,14 @@
                      kind_map: 'int', params_map: 'float[:]',
                      p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
                      ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
                      cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
                      mat: 'float[:,:,:,:,:,:]',
                      vec: 'float[:,:,:]',
                      coupling_const: 'float'):
-    
     r"""Accumulates into V0 with the filling functions
 
     .. math::
 
         A_p= w_p * \mu_p \,.
 
     Parameters
@@ -2696,17 +1399,17 @@
 
     bd1 = empty(pn[0], dtype=float)
     bd2 = empty(pn[1], dtype=float)
     bd3 = empty(pn[2], dtype=float)
 
     # get number of markers
     n_markers_loc = shape(markers)[0]
-    
+
     for ip in range(n_markers_loc):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         # marker positions
         eta1 = markers[ip, 0]
         eta2 = markers[ip, 1]
@@ -2721,18 +1424,19 @@
         span2 = bsp.find_span(tn2, pn[1], eta2)
         span3 = bsp.find_span(tn3, pn[2], eta3)
 
         bsp.b_d_splines_slim(tn1, pn[0], eta1, span1, bn1, bd1)
         bsp.b_d_splines_slim(tn2, pn[1], eta2, span2, bn2, bd2)
         bsp.b_d_splines_slim(tn3, pn[2], eta3, span3, bn3, bd3)
 
-        filling= weight * mu * coupling_const
+        filling = weight * mu * coupling_const
 
         # call the appropriate matvec filler
-        mvf.scalar_fill_v0(pn, span1, span2, span3, bn1, bn2, bn3, starts0, vec, filling)
+        mvf.scalar_fill_v0(pn, span1, span2, span3, bn1,
+                           bn2, bn3, starts0, vec, filling)
 
     vec /= n_markers_tot
 
 
 @stack_array('df', 'df_t', 'df_inv', 'g_inv', 'filling_m', 'filling_v', 'tmp1', 'tmp2', 'tmp_t', 'tmp_m', 'tmp_v', 'b', 'b_prod', 'norm_b2_prod', 'b_star', 'curl_norm_b', 'norm_b1', 'norm_b2', 'grad_PB', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3')
 def cc_lin_mhd_5d_M(markers: 'float[:,:]', n_markers_tot: 'int',
                     pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
@@ -2755,16 +1459,15 @@
                     vec3: 'float[:,:,:]',
                     b1: 'float[:,:,:]',   # model specific argument
                     b2: 'float[:,:,:]',   # model specific argument
                     b3: 'float[:,:,:]',   # model specific argument
                     curl_norm_b1: 'float[:,:,:]',  # model specific argument
                     curl_norm_b2: 'float[:,:,:]',  # model specific argument
                     curl_norm_b3: 'float[:,:,:]',  # model specific argument
-                    basis_u : 'int', scale_vec : 'float'): # model specific argument
-    
+                    basis_u: 'int', scale_vec: 'float'):  # model specific argument
     r"""TODO
     """
 
     # allocate for magnetic field evaluation
     b = empty(3, dtype=float)
     b_prod = zeros((3, 3), dtype=float)
     curl_norm_b = empty(3, dtype=float)
@@ -2772,32 +1475,32 @@
     bn1 = empty(pn[0] + 1, dtype=float)
     bn2 = empty(pn[1] + 1, dtype=float)
     bn3 = empty(pn[2] + 1, dtype=float)
 
     bd1 = empty(pn[0], dtype=float)
     bd2 = empty(pn[1], dtype=float)
     bd3 = empty(pn[2], dtype=float)
-    
+
     # allocate for metric coeffs
-    df       = empty((3, 3), dtype=float)
-    df_inv   = empty((3, 3), dtype=float)
+    df = empty((3, 3), dtype=float)
+    df_inv = empty((3, 3), dtype=float)
     df_inv_t = empty((3, 3), dtype=float)
-    g_inv    = empty((3, 3), dtype=float)
+    g_inv = empty((3, 3), dtype=float)
 
     # allocate for filling
     filling_v = empty(3, dtype=float)
 
     tmp_v1 = empty(3, dtype=float)
     tmp_v2 = empty(3, dtype=float)
 
     # get number of markers
     n_markers_loc = shape(markers)[0]
-    
+
     for ip in range(n_markers_loc):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         # marker positions
         eta1 = markers[ip, 0]
         eta2 = markers[ip, 1]
@@ -2819,47 +1522,53 @@
         # evaluate Jacobian, result in df
         map_eval.df(eta1, eta2, eta3,
                     kind_map, params_map,
                     t1_map, t2_map, t3_map, p_map,
                     ind1_map, ind2_map, ind3_map,
                     cx, cy, cz,
                     df)
-        
+
         det_df = linalg.det(df)
 
         # needed metric coefficients
         linalg.matrix_inv_with_det(df, det_df, df_inv)
         linalg.transpose(df_inv, df_inv_t)
         linalg.matrix_matrix(df_inv, df_inv_t, g_inv)
 
         # b; 2form
-        b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
+        b[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
+        b[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
+        b[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
 
         # curl_norm_b; 2form
-        curl_norm_b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
+        curl_norm_b[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
+        curl_norm_b[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
+        curl_norm_b[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
 
         linalg.cross(curl_norm_b, b, tmp_v1)
         tmp_v1 /= det_df
 
         if basis_u == 0:
-            
+
             filling_v[:] = weight * mu * tmp_v1 * scale_vec
 
             mvf.vec_fill_v0(pn, span1, span2, span3,
                             bn1, bn2, bn3,
                             starts0,
                             vec1, vec2, vec3,
                             filling_v[0], filling_v[1], filling_v[2])
 
         elif basis_u == 1:
-            
+
             linalg.matrix_vector(g_inv, tmp_v1, tmp_v2)
 
             filling_v[:] = weight * mu * tmp_v2 * scale_vec
 
             mvf.vec_fill_v1(pn, span1, span2, span3,
                             bn1, bn2, bn3, bd1, bd2, bd3,
                             starts1,
@@ -2876,49 +1585,49 @@
                             vec1, vec2, vec3,
                             filling_v[0], filling_v[1], filling_v[2])
 
     vec1 /= n_markers_tot
     vec2 /= n_markers_tot
     vec3 /= n_markers_tot
 
+
 @stack_array('df', 'df_t', 'df_inv', 'g_inv', 'filling_m', 'filling_v', 'tmp1', 'tmp2', 'tmp_t', 'tmp_m', 'tmp_v', 'b', 'b_prod', 'norm_b2_prod', 'b_star', 'curl_norm_b', 'norm_b1', 'norm_b2', 'grad_PB', 'grad_PB_mat', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3')
 def cc_lin_mhd_5d_J2(markers: 'float[:,:]', n_markers_tot: 'int',
-                    pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                    starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                    kind_map: 'int', params_map: 'float[:]',
-                    p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                    ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                    cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                    mat11: 'float[:,:,:,:,:,:]',
-                    mat12: 'float[:,:,:,:,:,:]',
-                    mat13: 'float[:,:,:,:,:,:]',
-                    mat22: 'float[:,:,:,:,:,:]',
-                    mat23: 'float[:,:,:,:,:,:]',
-                    mat33: 'float[:,:,:,:,:,:]',
-                    vec1: 'float[:,:,:]',
-                    vec2: 'float[:,:,:]',
-                    vec3: 'float[:,:,:]',
-                    kappa: float,    # model specific argument
-                    b1: 'float[:,:,:]',   # model specific argument
-                    b2: 'float[:,:,:]',   # model specific argument
-                    b3: 'float[:,:,:]',   # model specific argument
-                    norm_b11: 'float[:,:,:]',       # model specific argument    
-                    norm_b12: 'float[:,:,:]',       # model specific argument
-                    norm_b13: 'float[:,:,:]',       # model specific argument
-                    norm_b21: 'float[:,:,:]',       # model specific argument    
-                    norm_b22: 'float[:,:,:]',       # model specific argument
-                    norm_b23: 'float[:,:,:]',       # model specific argument
-                    curl_norm_b1: 'float[:,:,:]',  # model specific argument
-                    curl_norm_b2: 'float[:,:,:]',  # model specific argument
-                    curl_norm_b3: 'float[:,:,:]',  # model specific argument
-                    grad_PB1: 'float[:,:,:]',  # model specific argument
-                    grad_PB2: 'float[:,:,:]',  # model specific argument
-                    grad_PB3: 'float[:,:,:]',  # model specific argument
-                    basis_u : 'int', scale_mat : 'float', scale_vec : 'float'): # model specific argument
-    
+                     pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
+                     starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
+                     kind_map: 'int', params_map: 'float[:]',
+                     p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
+                     ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
+                     cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
+                     mat11: 'float[:,:,:,:,:,:]',
+                     mat12: 'float[:,:,:,:,:,:]',
+                     mat13: 'float[:,:,:,:,:,:]',
+                     mat22: 'float[:,:,:,:,:,:]',
+                     mat23: 'float[:,:,:,:,:,:]',
+                     mat33: 'float[:,:,:,:,:,:]',
+                     vec1: 'float[:,:,:]',
+                     vec2: 'float[:,:,:]',
+                     vec3: 'float[:,:,:]',
+                     kappa: float,    # model specific argument
+                     b1: 'float[:,:,:]',   # model specific argument
+                     b2: 'float[:,:,:]',   # model specific argument
+                     b3: 'float[:,:,:]',   # model specific argument
+                     norm_b11: 'float[:,:,:]',       # model specific argument
+                     norm_b12: 'float[:,:,:]',       # model specific argument
+                     norm_b13: 'float[:,:,:]',       # model specific argument
+                     norm_b21: 'float[:,:,:]',       # model specific argument
+                     norm_b22: 'float[:,:,:]',       # model specific argument
+                     norm_b23: 'float[:,:,:]',       # model specific argument
+                     curl_norm_b1: 'float[:,:,:]',  # model specific argument
+                     curl_norm_b2: 'float[:,:,:]',  # model specific argument
+                     curl_norm_b3: 'float[:,:,:]',  # model specific argument
+                     grad_PB1: 'float[:,:,:]',  # model specific argument
+                     grad_PB2: 'float[:,:,:]',  # model specific argument
+                     grad_PB3: 'float[:,:,:]',  # model specific argument
+                     basis_u: 'int', scale_mat: 'float', scale_vec: 'float'):  # model specific argument
     r"""Accumulates into V1 with the filling functions
 
     .. math::
 
         A_p^{\mu, \nu} &= w_p * [G^{-1}(\eta_p) * B2_{\times}(\eta_p) * B2_{\times}(\eta_p)^\top * G^{-1}(\eta_p) * v^2_{\parallel,p} * \left( 1/B^*_\parallel \right)^2 * |1/\sqrt{g} \hat \nabla \times \hat b^1_0|_p^2]_{\mu, \nu}
 
         B_p^\mu &= w_p *[ G^{-1}(\eta_p) * B2_{\times}(\eta_p)* v^2_{\parallel,p} * \left( 1/B^*_\parallel \right)]_\mu
@@ -2961,37 +1670,37 @@
     bn1 = empty(pn[0] + 1, dtype=float)
     bn2 = empty(pn[1] + 1, dtype=float)
     bn3 = empty(pn[2] + 1, dtype=float)
 
     bd1 = empty(pn[0], dtype=float)
     bd2 = empty(pn[1], dtype=float)
     bd3 = empty(pn[2], dtype=float)
-    
+
     # allocate for metric coeffs
-    df       = empty((3, 3), dtype=float)
-    df_inv   = empty((3, 3), dtype=float)
+    df = empty((3, 3), dtype=float)
+    df_inv = empty((3, 3), dtype=float)
     df_inv_t = empty((3, 3), dtype=float)
-    g_inv    = empty((3, 3), dtype=float)
+    g_inv = empty((3, 3), dtype=float)
 
     # allocate for filling
     filling_m = empty((3, 3), dtype=float)
     filling_v = empty(3, dtype=float)
 
-    tmp1   = empty((3, 3), dtype=float)
-    tmp2   = empty((3, 3), dtype=float)
-    tmp_t  = empty((3, 3), dtype=float)
-    tmp_m  = empty((3, 3), dtype=float)
+    tmp1 = empty((3, 3), dtype=float)
+    tmp2 = empty((3, 3), dtype=float)
+    tmp_t = empty((3, 3), dtype=float)
+    tmp_m = empty((3, 3), dtype=float)
 
     tmp_v = empty(3, dtype=float)
 
     # get number of markers
     n_markers_loc = shape(markers)[0]
-    
+
     for ip in range(n_markers_loc):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         # marker positions
         eta1 = markers[ip, 0]
         eta2 = markers[ip, 1]
@@ -3014,51 +1723,66 @@
         # evaluate Jacobian, result in df
         map_eval.df(eta1, eta2, eta3,
                     kind_map, params_map,
                     t1_map, t2_map, t3_map, p_map,
                     ind1_map, ind2_map, ind3_map,
                     cx, cy, cz,
                     df)
-        
+
         det_df = linalg.det(df)
 
         # needed metric coefficients
         linalg.matrix_inv_with_det(df, det_df, df_inv)
         linalg.transpose(df_inv, df_inv_t)
         linalg.matrix_matrix(df_inv, df_inv_t, g_inv)
 
         # b; 2form
-        b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
+        b[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
+        b[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
+        b[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
 
         # norm_b1; 1form
-        norm_b1[0] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
+        norm_b1[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
+        norm_b1[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
+        norm_b1[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
 
         # norm_b2; 2form
-        norm_b2[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, norm_b21, starts2[0])
-        norm_b2[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, norm_b22, starts2[1])
-        norm_b2[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, norm_b23, starts2[2])
+        norm_b2[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, norm_b21, starts2[0])
+        norm_b2[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, norm_b22, starts2[1])
+        norm_b2[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, norm_b23, starts2[2])
 
         # curl_norm_b; 2form
-        curl_norm_b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
+        curl_norm_b[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
+        curl_norm_b[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
+        curl_norm_b[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
 
         # grad_PB; 1form
-        grad_PB[0] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_PB1, starts1[0])
-        grad_PB[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_PB2, starts1[1])
-        grad_PB[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_PB3, starts1[2])
-
-        grad_PB_mat[0,0] = grad_PB[0]
-        grad_PB_mat[1,1] = grad_PB[1]
-        grad_PB_mat[2,2] = grad_PB[2]
-        
+        grad_PB[0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_PB1, starts1[0])
+        grad_PB[1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_PB2, starts1[1])
+        grad_PB[2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_PB3, starts1[2])
+
+        grad_PB_mat[0, 0] = grad_PB[0]
+        grad_PB_mat[1, 1] = grad_PB[1]
+        grad_PB_mat[2, 2] = grad_PB[2]
+
         # b_star; 2form transformed into H1vec
         b_star[:] = (b + curl_norm_b*v/kappa)/det_df
 
         # calculate abs_b_star_para
         abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
 
         # operator bx() as matrix
@@ -3073,106 +1797,113 @@
         norm_b2_prod[0, 2] = +norm_b2[1]
         norm_b2_prod[1, 0] = +norm_b2[2]
         norm_b2_prod[1, 2] = -norm_b2[0]
         norm_b2_prod[2, 0] = -norm_b2[1]
         norm_b2_prod[2, 1] = +norm_b2[0]
 
         if basis_u == 0:
-            
+
             linalg.matrix_matrix(b_prod, g_inv, tmp1)
             linalg.matrix_matrix(tmp1, norm_b2_prod, tmp2)
             linalg.matrix_matrix(tmp2, g_inv, tmp1)
 
             linalg.transpose(tmp1, tmp_t)
 
             linalg.matrix_vector(tmp1, grad_PB, tmp_v)
 
             linalg.matrix_matrix(tmp1, grad_PB_mat, tmp2)
             linalg.matrix_matrix(tmp2, tmp_t, tmp_m)
 
-            filling_m[:, :] = weight * tmp_m * mu / abs_b_star_para**2 * scale_mat
-            filling_v[:] =    weight * tmp_v * mu / abs_b_star_para    * scale_vec
+            filling_m[:, :] = weight * tmp_m * \
+                mu / abs_b_star_para**2 * scale_mat
+            filling_v[:] = weight * tmp_v * mu / abs_b_star_para * scale_vec
 
             # call the appropriate matvec filler
             mvf.m_v_fill_v0vec_symm(pn, span1, span2, span3,
                                     bn1, bn2, bn3,
                                     starts0,
-                                    mat11, mat12, mat13, 
-                                    mat22, mat23, 
-                                    mat33, 
-                                    filling_m[0, 0], filling_m[0, 1], filling_m[0, 2], 
-                                    filling_m[1, 1], filling_m[1, 2], 
+                                    mat11, mat12, mat13,
+                                    mat22, mat23,
+                                    mat33,
+                                    filling_m[0, 0], filling_m[0,
+                                                               1], filling_m[0, 2],
+                                    filling_m[1, 1], filling_m[1, 2],
                                     filling_m[2, 2],
                                     vec1, vec2, vec3,
                                     filling_v[0], filling_v[1], filling_v[2])
-        
+
         elif basis_u == 1:
-            
+
             linalg.matrix_matrix(g_inv, b_prod, tmp1)
             linalg.matrix_matrix(tmp1, g_inv, tmp2)
             linalg.matrix_matrix(tmp2, norm_b2_prod, tmp1)
             linalg.matrix_matrix(tmp1, g_inv, tmp2)
 
             linalg.transpose(tmp2, tmp_t)
 
             linalg.matrix_vector(tmp2, grad_PB, tmp_v)
 
             linalg.matrix_matrix(tmp2, grad_PB_mat, tmp1)
             linalg.matrix_matrix(tmp1, tmp_t, tmp_m)
 
-            filling_m[:, :] = weight * tmp_m * mu / abs_b_star_para**2 * scale_mat
-            filling_v[:] =    weight * tmp_v * mu / abs_b_star_para    * scale_vec
+            filling_m[:, :] = weight * tmp_m * \
+                mu / abs_b_star_para**2 * scale_mat
+            filling_v[:] = weight * tmp_v * mu / abs_b_star_para * scale_vec
 
             # call the appropriate matvec filler
             mvf.m_v_fill_v1_symm(pn, span1, span2, span3,
                                  bn1, bn2, bn3,
                                  bd1, bd2, bd3,
                                  starts1,
-                                 mat11, mat12, mat13, 
-                                 mat22, mat23, 
-                                 mat33, 
-                                 filling_m[0, 0], filling_m[0, 1], filling_m[0, 2], 
-                                 filling_m[1, 1], filling_m[1, 2], 
+                                 mat11, mat12, mat13,
+                                 mat22, mat23,
+                                 mat33,
+                                 filling_m[0, 0], filling_m[0,
+                                                            1], filling_m[0, 2],
+                                 filling_m[1, 1], filling_m[1, 2],
                                  filling_m[2, 2],
                                  vec1, vec2, vec3,
                                  filling_v[0], filling_v[1], filling_v[2])
-            
+
         elif basis_u == 2:
-            
+
             linalg.matrix_matrix(b_prod, g_inv, tmp1)
             linalg.matrix_matrix(tmp1, norm_b2_prod, tmp2)
             linalg.matrix_matrix(tmp2, g_inv, tmp1)
 
             linalg.transpose(tmp1, tmp_t)
- 
+
             linalg.matrix_vector(tmp1, grad_PB, tmp_v)
 
             linalg.matrix_matrix(tmp1, grad_PB_mat, tmp2)
             linalg.matrix_matrix(tmp2, tmp_t, tmp_m)
 
-            filling_m[:, :] = weight * tmp_m * mu / abs_b_star_para**2 / det_df**2 * scale_mat
-            filling_v[:] =    weight * tmp_v * mu / abs_b_star_para    / det_df    * scale_vec
+            filling_m[:, :] = weight * tmp_m * mu / \
+                abs_b_star_para**2 / det_df**2 * scale_mat
+            filling_v[:] = weight * tmp_v * mu / \
+                abs_b_star_para / det_df * scale_vec
 
             # call the appropriate matvec filler
             mvf.m_v_fill_v2_symm(pn, span1, span2, span3,
                                  bn1, bn2, bn3,
                                  bd1, bd2, bd3,
                                  starts2,
-                                 mat11, mat12, mat13, 
-                                 mat22, mat23, 
-                                 mat33, 
-                                 filling_m[0, 0], filling_m[0, 1], filling_m[0, 2], 
-                                 filling_m[1, 1], filling_m[1, 2], 
+                                 mat11, mat12, mat13,
+                                 mat22, mat23,
+                                 mat33,
+                                 filling_m[0, 0], filling_m[0,
+                                                            1], filling_m[0, 2],
+                                 filling_m[1, 1], filling_m[1, 2],
                                  filling_m[2, 2],
                                  vec1, vec2, vec3,
                                  filling_v[0], filling_v[1], filling_v[2])
-    
+
     mat11 /= n_markers_tot
     mat12 /= n_markers_tot
     mat13 /= n_markers_tot
     mat22 /= n_markers_tot
     mat23 /= n_markers_tot
     mat33 /= n_markers_tot
-    
+
     vec1 /= n_markers_tot
     vec2 /= n_markers_tot
-    vec3 /= n_markers_tot
+    vec3 /= n_markers_tot
```

### Comparing `struphy-2.0.1/src/struphy/pic/filler_kernels.py` & `struphy-2.0.2/src/struphy/pic/filler_kernels.py`

 * *Files 0% similar despite different names*

```diff
@@ -466,21 +466,30 @@
             i2 = cell_left[1] + il2 - starts0[1] + pn[1]
             for il3 in range(cell_number[2]):
                 i3 = cell_left[2] + il3 - starts0[2] + pn[2]
 
                 for jl1 in range(quad[0]):
                     # quad_pts_x contains the quadrature points in x direction.
                     temp1[0] = (cell_left[0] + il1) / Nel[0] + quad_pts_x[jl1]
-                    temp4[0] = abs(temp1[0] - eta1) - compact[0] / 2.0  # if > 0, result is 0
+                    temp4[0] = abs(temp1[0] - eta1) - \
+                        compact[0] / 2.0  # if > 0, result is 0
                     for jl2 in range(quad[1]):
-                        temp1[1] = (cell_left[1] + il2) / Nel[1] + quad_pts_y[jl2]
-                        temp4[1] = abs(temp1[1] - eta2) - compact[1] / 2.0  # if > 0, result is 0
+                        temp1[1] = (cell_left[1] + il2) / \
+                            Nel[1] + quad_pts_y[jl2]
+                        temp4[1] = abs(temp1[1] - eta2) - \
+                            compact[1] / 2.0  # if > 0, result is 0
                         for jl3 in range(quad[2]):
-                            temp1[2] = (cell_left[2] + il3) / Nel[2] + quad_pts_z[jl3]
-                            temp4[2] = abs(temp1[2] - eta3) - compact[2]/2.0  # if > 0, result is 0
+                            temp1[2] = (cell_left[2] + il3) / \
+                                Nel[2] + quad_pts_z[jl3]
+                            temp4[2] = abs(temp1[2] - eta3) - \
+                                compact[2]/2.0  # if > 0, result is 0
 
                             if temp4[0] < 0.0 and temp4[1] < 0.0 and temp4[2] < 0.0:
-                                value_x = bsp.convolution(p_shape[0], grids_shapex, temp1[0])
-                                value_y = bsp.piecewise(p_shape[1], p_size[1], temp1[1] - eta2)
-                                value_z = bsp.piecewise(p_shape[2], p_size[2], temp1[2] - eta3)
+                                value_x = bsp.convolution(
+                                    p_shape[0], grids_shapex, temp1[0])
+                                value_y = bsp.piecewise(
+                                    p_shape[1], p_size[1], temp1[1] - eta2)
+                                value_z = bsp.piecewise(
+                                    p_shape[2], p_size[2], temp1[2] - eta3)
 
-                                mat[i1, i2, i3, jl1, jl2, jl3] += weight * value_x * value_y * value_z
+                                mat[i1, i2, i3, jl1, jl2, jl3] += weight * \
+                                    value_x * value_y * value_z
```

### Comparing `struphy-2.0.1/src/struphy/pic/mat_vec_filler.py` & `struphy-2.0.2/src/struphy/pic/mat_vec_filler.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/pic/particles.py` & `struphy-2.0.2/src/struphy/pic/base.py`

 * *Files 11% similar despite different names*

```diff
@@ -2,25 +2,30 @@
 
 import numpy as np
 import h5py
 import scipy.special as sp
 
 from struphy.pic import sampling, sobol_seq
 from struphy.pic.pusher_utilities import reflect
+from struphy.pic.utilities_kernels import eval_magnetic_energy
 from struphy.kinetic_background import maxwellians
 from struphy.fields_background.mhd_equil.equils import set_defaults
 
 
 class Particles(metaclass=ABCMeta):
     """
     Base class for a particle based kinetic species.
 
-    Loading and compute initial particles and save the values at the corresponding column of markers array.
-    | 0 | 1 | 2 | 3 | ... | 3+(vdim-1) | 3+vdim | 4+vdim | 5+vdim |
-    |    eta    |      velocities      | weight |   s0   |   w0   |
+    Loading and compute initial particles and save the values at the corresponding column of markers array:
+    
+    ===== ============== ======================= ======= ====== ====== ==========
+    index  | 0 | 1 | 2 | | 3 | ... | 3+(vdim-1)|  3+vdim 4+vdim 5+vdim >=6+vdim
+    ===== ============== ======================= ======= ====== ====== ==========
+    value position (eta)    velocities           weight   s0     w0    additional
+    ===== ============== ======================= ======= ====== ====== ==========
 
     Parameters
     ----------
     name : str
         Name of particle species.
 
     **params : dict
@@ -160,15 +165,21 @@
     def n_mks_load(self):
         """ Array of number of markers on each process at loading stage
         """
         return self._n_mks_load
 
     @property
     def markers(self):
-        """ Array holding the marker information, including holes. The i-th row holds the i-th marker info.
+        """ Numpy array holding the marker information, including holes. The i-th row holds the i-th marker info.
+        
+        ===== ============== ======================= ======= ====== ====== ==========
+        index  | 0 | 1 | 2 | | 3 | ... | 3+(vdim-1)|  3+vdim 4+vdim 5+vdim >=6+vdim
+        ===== ============== ======================= ======= ====== ====== ==========
+        value position (eta)    velocities           weight   s0     w0    additional
+        ===== ============== ======================= ======= ====== ====== ==========
         """
         return self._markers
 
     @property
     def holes(self):
         """ Array of booleans stating if an entry in the markers array is a hole or not. 
         """
@@ -206,14 +217,20 @@
 
     @property
     def n_lost_markers(self):
         """ Number of removed particles.
         """
         return self._n_lost_markers
 
+    @property
+    def bt_energy(self):
+        """ Sum of energy differences caused by boundary transfer.
+        """
+        return self._bt_energy
+
     def create_marker_array(self):
         """ Create marker array. (self.markers)
         """
 
         # number of cells on current process
         n_cells_loc = np.prod(
             self._domain_decomp[self._mpi_rank, 2::3], dtype=int)
@@ -255,14 +272,17 @@
                              (1 + 1/np.sqrt(n_mks_load_loc) + self.params['eps']))
         self._markers = np.zeros((markers_size, self.n_cols), dtype=float)
 
         # create array container (3 x positions, vdim x velocities, weight, s0, w0, ID) for removed markers
         self._n_lost_markers = 0
         self._lost_markers = np.zeros((int(markers_size*0.5), 10), dtype=float)
 
+        # create a scalar container for saving sum of energy differences caused by boundary transfer.
+        self._bt_energy = 0.
+
     def draw_markers(self):
         r""" 
         Drawing markers according to the volume density :math:`s^n_{\textnormal{in}}`.
         In Struphy, the initial marker distribution :math:`s^n_{\textnormal{in}}` is always of the form
 
         .. math::
 
@@ -293,15 +313,15 @@
         """
 
         # number of markers on the local process at loading stage
         n_mks_load_loc = self.n_mks_load[self._mpi_rank]
 
         # cumulative sum of number of markers on each process at loading stage.
         n_mks_load_cum_sum = np.cumsum(self.n_mks_load)
-        
+
         if self._mpi_rank == 0:
             print('\nMARKERS:')
 
         # load markers from external .hdf5 file
         if self._params['loading']['type'] == 'external':
 
             if self._mpi_rank == 0:
@@ -320,15 +340,15 @@
                 recvbuf = np.zeros(
                     (n_mks_load_loc, self._markers.shape[1]), dtype=float)
                 self._mpi_comm.Recv(recvbuf, source=0, tag=123)
                 self._markers[:n_mks_load_loc, :] = recvbuf
 
         # load fresh markers
         else:
-            
+
             if self._mpi_rank == 0:
                 for key, val in self._params['loading'].items():
                     print((key + ' :').ljust(25), val)
 
             # 1. standard random number generator (pseudo-random)
             if self._params['loading']['type'] == 'pseudo_random':
 
@@ -578,15 +598,15 @@
 
         # compute weights of histogram:
         _weights = self.markers_wo_holes[:, _n]
 
         # in case of approximation of f^0
         if domain is not None:
             _weights /= domain.jacobian_det(self.markers)
-            
+
         if velocity_det is not None:
             _weights /= velocity_det(self.markers)
 
         f_slice = np.histogramdd(self.markers_wo_holes[:, slicing],
                                  bins=bin_edges,
                                  weights=_weights)[0]
 
@@ -603,31 +623,33 @@
             List of length 6 giving the directions in phase space in which to bin.
 
         bin_edges : list[array]
             List of bin edges (resolution) having the length of True entries in components.
 
         domain : struphy.geometry.domains
             Mapping info for evaluating metric coefficients.
-            
+
         velocity_det : callable
             The Jacobian deteminant of a velocity space transformation. 
             Must perform "marker evaluation" if a 2D numpy array is passed, just as ``domain.jacobian_det()``.
         """
 
         import matplotlib.pyplot as plt
 
         n_dim = np.count_nonzero(components)
 
         assert n_dim == 1 or n_dim == 2, f'Distribution function can only be shown in 1D or 2D slices, not {n_dim}.'
 
-        f_slice = self.binning(components, bin_edges, domain=domain, velocity_det=velocity_det)
+        f_slice = self.binning(components, bin_edges,
+                               domain=domain, velocity_det=velocity_det)
 
         bin_centers = [bi[:-1] + (bi[1] - bi[0])/2 for bi in bin_edges]
 
-        labels = {0 : '$\eta_1$', 1 : '$\eta_2$', 2 : '$\eta_3$', 3 : '$v_1$', 4 : '$v_2$', 5 : '$v_3$'}
+        labels = {0: '$\eta_1$', 1: '$\eta_2$',
+                  2: '$\eta_3$', 3: '$v_1$', 4: '$v_2$', 5: '$v_3$'}
         indices = np.nonzero(components)[0]
 
         if n_dim == 1:
             plt.plot(bin_centers[0], f_slice)
             plt.xlabel(labels[indices[0]])
         else:
             plt.contourf(bin_centers[0], bin_centers[1], f_slice, levels=20)
@@ -692,300 +714,75 @@
                 reflect(self.markers, *self.domain.args_map, outside_inds, axis)
 
             else:
                 raise NotImplementedError('Given bc_type is not implemented!')
 
         self.comm.Barrier()
 
-
-class Particles6D(Particles):
-    """
-    A class for initializing particles in models that use the full 6D phase space.
-
-    | 0 | 1 | 2 | 3 | 4 | 5 |   6  | 7  | 8  |
-    |    eta    |     v     |weight| s0 | w0 |
-
-    Parameters
-    ----------
-    name : str
-        Name of the particle species.
-
-    **params : dict
-        Parameters for markers.
-    """
-
-    def __init__(self, name, **params):
-
-        # base class params
-        base_params = {}
-
-        list_base_params = ['type', 'ppc', 'Np', 'eps',
-                            'bc_type', 'loading', 'comm', 'domain', 'domain_array']
-
-        for key, val in params.items():
-            if key in list_base_params:
-                base_params[key] = val
-
-        super().__init__(name, **base_params)
-
-    @property
-    def n_cols(self):
-        """Number of the columns at each markers.
-        """
-        return 16
-
-    @property
-    def vdim(self):
-        """Dimension of the velocity space.
-        """
-        return 3
-
-    def svol(self, eta1, eta2, eta3, *v):
-        """ 
-        Sampling density function as volume form.
-
-        Parameters
-        ----------
-        eta1, eta2, eta3 : array_like
-            Logical evaluation points.
-
-        *v : array_like
-            Velocity evaluation points.
-
-        Returns
-        -------
-        out : array-like
-            The volume-form sampling density.
-        -------
-        """
-        # load sampling density svol = s6 = s3 (normalized to 1 in logical space!)
-        Maxwellian6DUniform = getattr(maxwellians, 'Maxwellian6DUniform')
-
-        s3 = Maxwellian6DUniform(n=1.,
-                                 u1=self._params['loading']['moments'][0],
-                                 u2=self._params['loading']['moments'][1],
-                                 u3=self._params['loading']['moments'][2],
-                                 vth1=self._params['loading']['moments'][3],
-                                 vth2=self._params['loading']['moments'][4],
-                                 vth3=self._params['loading']['moments'][5])
-
-        return s3(eta1, eta2, eta3, *v)
-
-    def s0(self, eta1, eta2, eta3, *v, remove_holes=True):
-        """ 
-        Sampling density function as 0 form.
-
-        Parameters
-        ----------
-        eta1, eta2, eta3 : array_like
-            Logical evaluation points.
-
-        *v : array_like
-            Velocity evaluation points.
-
-        remove_holes : bool
-            If True, holes are removed from the returned array. If False, holes are evaluated to -1.
-
-        Returns
-        -------
-        out : array-like
-            The 0-form sampling density.
-        -------
-        """
-        return self.domain.transform(self.svol(eta1, eta2, eta3, *v), self.markers, kind='3_to_0', remove_outside=remove_holes)
-
-
-class Particles5D(Particles):
-    """
-    A class for initializing particles in guiding-center, drift-kinetic or gyro-kinetic models that use the 5D phase space.
-
-    | 0 | 1 | 2 |     3      |        4        |  5   | 6  | 7  |
-    |    eta    | v_parallel | magnetic moment |weight| s0 | w0 |         
-
-    Parameters
-    ----------
-    name : str
-        Name of the particle species.
-
-    **params : dict
-        Parameters for markers.
-    """
-
-    def __init__(self, name, **params):
-
-        # base class params
-        base_params = {}
-
-        list_base_params = ['type', 'ppc', 'Np', 'eps',
-                            'bc_type', 'loading', 'comm', 'domain', 'domain_array']
-
-        for key, val in params.items():
-            if key in list_base_params:
-                base_params[key] = val
-
-        super().__init__(name, **base_params)
-
-        # child class params
-        child_params = {}
-
-        list_child_params = ['A', 'Z', 'mhd_equil', 'units_basic']
-
-        for key, val in params.items():
-            if key in list_child_params:
-                child_params[key] = val
-
-        params_default = {'A': 1,
-                          'Z': 1,
-                          'mhd_equil': None,
-                          'units_basic': None
-                          }
-
-        child_params = set_defaults(child_params, params_default)
-
-        self._mhd_equil = params['mhd_equil']
-
-        # compute kappa
-        ee = 1.602176634e-19  # elementary charge (C)
-        mH = 1.67262192369e-27  # proton mass (kg)
-
-        Ah = child_params['A']
-        Zh = child_params['Z']
-
-        omega_ch = (Zh*ee*child_params['units_basic']['B'])/(Ah*mH)
-        self._kappa = omega_ch*child_params['units_basic']['t']
-
-    @property
-    def n_cols(self):
-        """Number of the columns at each markers.
+    def boundary_transfer(self, derham, PB):
         """
-        return 29
+        Still draft. ONLY valid for the poloidal geometry (eta1: clamped r-direction, eta2: periodic theta-direction). 
 
-    @property
-    def vdim(self):
-        """Dimension of the velocity space.
-        """
-        return 2
+        When particles reach to rmin, transfer them to the opposite side of the rmin circle.
 
-    def svol(self, eta1, eta2, eta3, *v):
-        """ 
-        Sampling density function as volume-form.
+        ex: when rmin is 0.1, transfer the particle from (0.09, 0.3, 0.4) to (0.1, 0.8, 0.4).
 
         Parameters
         ----------
-        eta1, eta2, eta3 : array_like
-            Logical evaluation points.
-
-        *v : array_like
-            Velocity evaluation points.
-
-        Returns
-        -------
-        out : array-like
-            The volume-form sampling density.
-        -------
-        """
-        # load sampling density svol = s5 (normalized to 1 in logical space!)
-        Maxwellian5DUniform = getattr(maxwellians, 'Maxwellian5DUniform')
-
-        s5 = Maxwellian5DUniform(n=1.,
-                                 u_parallel=self.params['loading']['moments'][0],
-                                 u_perp=self.params['loading']['moments'][1],
-                                 vth_parallel=self.params['loading']['moments'][2],
-                                 vth_perp=self.params['loading']['moments'][3])
-
-        return s5(eta1, eta2, eta3, *v)
-
-    def s3(self, eta1, eta2, eta3, *v):
         """
-        Sampling density function as 3-form.
-
-        Parameters
-        ----------
-        eta1, eta2, eta3 : array_like
-            Logical evaluation points.
-
-        *v : array_like
-            Velocity evaluation points.
-
-        Returns
-        -------
-        out : array-like
-            The 3-form sampling density.
-        -------
-        """
-        # call equilibrium arrays
-        etas = (np.vstack((eta1, eta2, eta3)).T).copy()
-        bv = self._mhd_equil.bv(etas)
-        curlb = self._mhd_equil.jv(etas)/self._mhd_equil.absB0(etas)
-        unit_b1 = self._mhd_equil.unit_b1(etas)
-
-        # contra-variant components of B* = B + 1/kappa*v_parallel*curlb0
-        bstar = bv + 1/self._kappa*v[0]*curlb
-
-        # B*_parallel = b0 . B*
-        jacobian_det = np.einsum('ij,ij->j', unit_b1, bstar)/v[1]
-
-        return self.svol(eta1, eta2, eta3, *v)/np.abs(jacobian_det)
-
-    def s0(self, eta1, eta2, eta3, *v, remove_holes=True):
-        """ 
-        Sampling density function as 0-form.
-
-        Parameters
-        ----------
-        eta1, eta2, eta3 : array_like
-            Logical evaluation points.
+        T1, T2, T3 = derham.Vh_fem['0'].knots
 
-        v_parallel, v_perp : array_like
-            Velocity evaluation points.
+        self.comm.Barrier()
 
-        remove_holes : bool
-            If True, holes are removed from the returned array. If False, holes are evaluated to -1.
+        # sorting out particles inside of the rmin circle
+        smaller_than_rmin = self.markers[:, 0] < self._rmin
+        # exclude holes
+        smaller_than_rmin[self.holes] = False
 
-        Returns
-        -------
-        out : array-like
-            The 0-form sampling density.
-        -------
-        """
-        return self.domain.transform(self.s3(eta1, eta2, eta3, *v), self.markers, kind='3_to_0', remove_outside=remove_holes)
+        # indices or particles that are inside of the rmin circle
+        transfer_inds = np.nonzero(smaller_than_rmin)[0]
 
-    def save_magnetic_moment(self, derham):
-        r"""
-        Calculate magnetic moment of each particles :math:`\mu = \frac{m v_\perp^2}{2B}` and asign it into markers[:,4].
-        """
-        from struphy.pic.utilities_kernels import eval_magnetic_moment_5d
+        # add the old energy of the particles
+        self._bt_energy += np.sum(self.markers[transfer_inds, 5].dot(
+            self.markers[transfer_inds, 8])/self.n_mks)
 
-        T1, T2, T3 = derham.Vh_fem['0'].knots
+        # transfer
+        self.markers[transfer_inds, 1] += 0.5
+        self.markers[transfer_inds, 1] = self.markers[transfer_inds, 1] % 1.
+        self.markers[transfer_inds, 0] = self._rmin
+        self.markers[transfer_inds, 3] = self.markers[transfer_inds, 12]
 
-        absB = derham.P['0'](self._mhd_equil.absB0)
+        # marking before sorting
+        self.markers[transfer_inds, 22] = -1.
 
-        E0T = derham.E['0'].transpose()
+        self.mpi_sort_markers()
 
-        absB = E0T.dot(absB)
+        # sorting from the makring
+        smaller_than_rmin = self.markers[:, 22] == -1
 
-        eval_magnetic_moment_5d(self._markers,
-                                np.array(derham.p), T1, T2, T3,
-                                np.array(derham.Vh['0'].starts),
-                                absB._data)
+        # exclude holes
+        smaller_than_rmin[self.holes] = False
 
-    def save_magnetic_energy(self, derham, PB):
-        r"""
-        Calculate magnetic field energy at each particles' position and asign it into markers[:,8].
-        """
-        from struphy.pic.utilities_kernels import eval_magnetic_energy
-
-        T1, T2, T3 = derham.Vh_fem['0'].knots
+        # indices or particles which are just transfered
+        transfer_inds = np.nonzero(smaller_than_rmin)[0]
 
+        # subtract new energy
         eval_magnetic_energy(self._markers,
                              np.array(derham.p), T1, T2, T3,
                              np.array(derham.Vh['0'].starts),
                              PB._data)
 
+        self._bt_energy -= np.sum(self.markers[transfer_inds, 5].dot(
+            self.markers[transfer_inds, 8])/self.n_mks)
 
+        self.markers[transfer_inds, 23] = -1.
+
+        self.comm.Barrier()
+        
+        
 def sendrecv_determine_mtbs(markers, holes, domain_decomp, mpi_rank):
     """
     Determine which markers have to be sent from current process and put them in a new array. 
     Corresponding rows in markers array become holes and are therefore set to -1.
     This can be done purely with numpy functions (fast, vectorized).
 
     Parameters
@@ -1155,8 +952,8 @@
                 # check if data has been received
                 if req.Test():
 
                     markers[hole_inds_after_send[first_hole[i] +
                                                  np.arange(recv_info[i])]] = recvbufs[i]
 
                     test_reqs.pop()
-                    reqs[i] = None
+                    reqs[i] = None
```

### Comparing `struphy-2.0.1/src/struphy/pic/particles_to_grid.py` & `struphy-2.0.2/src/struphy/pic/particles_to_grid.py`

 * *Files 6% similar despite different names*

```diff
@@ -2,14 +2,15 @@
 
 from psydac.linalg.stencil import StencilVector, StencilMatrix
 from psydac.linalg.block import BlockVector
 
 from struphy.psydac_api.mass import WeightedMassOperator
 
 import struphy.pic.accum_kernels as accums
+import struphy.pic.accum_kernels as accums_gc
 
 
 class Accumulator:
     r"""
     Struphy accumulation matrices and vectors of the form
 
     .. math::
@@ -31,30 +32,30 @@
 
     domain : struphy.geometry.domains
         Mapping info for evaluating metric coefficients.
 
     space_id : str
         Space identifier for the matrix/vector (H1, Hcurl, Hdiv, L2 or H1vec) to be accumulated into.
 
-    accumulator_name : str
+    kernel_name : str
         Name of accumulator function to be loaded from struphy/pic/accum_kernels.py.
 
     add_vector : bool
         True if, additionally to a matrix, a vector in the same space is to be accumulated. Default=False.
 
     symmetry : str
         In case of space_id=Hcurl/Hdiv, the symmetry property of the block matrix: diag, asym, symm, pressure or None (=full matrix, default)
 
     Note
     ----
         Struphy accumulation kernels called by ``Accumulator`` objects should be added to ``struphy/pic/accum_kernels.py``. 
         Please follow the docstring in `struphy.pic.accum_kernels._docstring`.
     """
 
-    def __init__(self, derham, domain, space_id, accumulator_name, add_vector=False, symmetry=None):
+    def __init__(self, derham, domain, space_id, kernel_name, add_vector=False, symmetry=None):
 
         self._derham = derham
         self._domain = domain
 
         self._space_id = space_id
         self._symmetry = symmetry
 
@@ -127,16 +128,24 @@
                           derham.Vh_fem['0'].knots[2],
                           np.array(derham.Vh['0'].starts),
                           np.array(derham.Vh['1'].starts),
                           np.array(derham.Vh['2'].starts),
                           np.array(derham.Vh['3'].starts))
 
         # load the appropriate accumulation kernel (pyccelized, fast)
-        self._accumulator_name = accumulator_name
-        self._accumulator_kernel = getattr(accums, accumulator_name)
+        self._kernel_name = kernel_name
+        self._kernel = None
+
+        objs = [accums, accums_gc]
+        for obj in objs:
+            try:
+                self._kernel = getattr(obj, self.kernel_name)
+            except AttributeError:
+                pass
+        assert self.kernel is not None
 
     @property
     def derham(self):
         """ Discrete Derham complex on the logical unit cube.
         """
         return self._derham
 
@@ -175,24 +184,24 @@
         for vec in self._vectors:
             out += [self._derham.B[space_key].dot(
                 self._derham.E[space_key].dot(vec))]
 
         return out
 
     @property
-    def accumulator_name(self):
+    def kernel_name(self):
         """ String that identifies which function to load from the module struphy.pic.accum_kernels.
         """
-        return self._accumulator_name
+        return self._kernel_name
 
     @property
-    def accumulator_kernel(self):
+    def kernel(self):
         """ The kernel loaded from the module struphy.pic.accum_kernels.
         """
-        return self._accumulator_kernel
+        return self._kernel
 
     def accumulate(self, particles, *args_add, **args_control):
         """
         Performs the accumulation into the matrix/vector by calling the chosen accumulation kernel and additional analytical contributions (control variate, optional).
 
         Parameters
         ----------
@@ -214,17 +223,17 @@
         mat_finished = False
 
         # reset data
         for dat in self._args_data:
             dat[:] = 0.
 
         # accumulate into matrix (and vector) with markers
-        self._accumulator_kernel(particles.markers, particles.n_mks,
-                                 *self._args_fem, *self._domain.args_map,
-                                 *self._args_data, *args_add)
+        self.kernel(particles.markers, particles.n_mks,
+                    *self._args_fem, *self._domain.args_map,
+                    *self._args_data, *args_add)
         # add analytical contribution (control variate) to matrix
         if 'control_mat' in args_control:
             self._operators[0].assemble(weights=args_control['control_mat'])
 
         # add analytical contribution (control variate) to vector
         if 'control_vec' in args_control and len(self._vectors) > 0:
             WeightedMassOperator.assemble_vec(self._derham.Vh_fem[self._derham.spaces_dict[self._space_id]],
@@ -299,24 +308,24 @@
 
     domain : struphy.geometry.domains
         Mapping info for evaluating metric coefficients.
 
     space_id : str
         Space identifier for the matrix/vector (H1, Hcurl, Hdiv, L2 or H1vec) to be accumulated into.
 
-    accumulator_name : str
+    kernel_name : str
         Name of accumulator function to be loaded from struphy/pic/accum_kernels.py.
 
     Note
     ----
     Struphy accumulation kernels called by ``Accumulator`` objects should be added to ``struphy/pic/accum_kernels.py``. 
     Please follow the docstring in `struphy.pic.accum_kernels._docstring`.
     """
 
-    def __init__(self, derham, domain, space_id, accumulator_name):
+    def __init__(self, derham, domain, space_id, kernel_name):
 
         self._derham = derham
         self._domain = domain
 
         self._space_id = space_id
 
         space_key = derham.spaces_dict[space_id]
@@ -324,15 +333,16 @@
         # initialize vectors
         self._vectors = []
 
         # collect all _data attributes needed in accumulation kernel
         self._args_data = ()
 
         if space_id in ("H1", "L2"):
-            self._vectors += [StencilVector(derham.Vh_fem[space_key].vector_space)]
+            self._vectors += [StencilVector(
+                derham.Vh_fem[space_key].vector_space)]
 
         elif space_id in ("Hcurl", "Hdiv", "H1vec"):
             self._vectors += [BlockVector(derham.Vh_fem[space_key].vector_space)]
 
         for vec in self._vectors:
             if isinstance(vec, StencilVector):
                 self._args_data += (vec._data,)
@@ -347,16 +357,24 @@
                           derham.Vh_fem['0'].knots[2],
                           np.array(derham.Vh['0'].starts),
                           np.array(derham.Vh['1'].starts),
                           np.array(derham.Vh['2'].starts),
                           np.array(derham.Vh['3'].starts))
 
         # load the appropriate accumulation kernel (pyccelized, fast)
-        self._accumulator_name = accumulator_name
-        self._accumulator_kernel = getattr(accums, accumulator_name)
+        self._kernel_name = kernel_name
+        self._kernel = None
+
+        objs = [accums, accums_gc]
+        for obj in objs:
+            try:
+                self._kernel = getattr(obj, self.kernel_name)
+            except AttributeError:
+                pass
+        assert self.kernel is not None
 
     @property
     def derham(self):
         """ Discrete Derham complex on the logical unit cube.
         """
         return self._derham
 
@@ -372,34 +390,34 @@
         """
         return self._space_id
 
     @property
     def vectors(self):
         """ List of Stencil-/Block-/PolarVectors of the accumulator.
         """
-        space_key = self._derham.spaces_dict[self._space_id]
+        space_key = self.derham.spaces_dict[self._space_id]
 
         out = []
         for vec in self._vectors:
             out += [self._derham.B[space_key].dot(
                 self._derham.E[space_key].dot(vec))]
 
         return out
 
     @property
-    def accumulator_name(self):
+    def kernel_name(self):
         """ String that identifies which function to load from the module struphy.pic.accum_kernels.
         """
-        return self._accumulator_name
+        return self._kernel_name
 
     @property
-    def accumulator_kernel(self):
+    def kernel(self):
         """ The kernel loaded from the module struphy.pic.accum_kernels.
         """
-        return self._accumulator_kernel
+        return self._kernel
 
     def accumulate(self, particles, *args_add, **args_control):
         """
         Performs the accumulation into the vector by calling the chosen accumulation kernel and additional analytical contributions (control variate, optional).
 
         Parameters
         ----------
@@ -420,17 +438,17 @@
         vec_finished = False
 
         # reset data
         for dat in self._args_data:
             dat[:] = 0.
 
         # accumulate into matrix (and vector) with markers
-        self._accumulator_kernel(particles.markers, particles.n_mks,
-                                 *self._args_fem, *self._domain.args_map,
-                                 *self._args_data, *args_add)
+        self.kernel(particles.markers, particles.n_mks,
+                    *self._args_fem, *self._domain.args_map,
+                    *self._args_data, *args_add)
 
         # add analytical contribution (control variate) to matrix
         if 'control_mat' in args_control:
             self._operators[0].assemble(weights=args_control['control_mat'])
 
         # add analytical contribution (control variate) to vector
         if 'control_vec' in args_control and len(self._vectors) > 0:
```

### Comparing `struphy-2.0.1/src/struphy/pic/pusher.py` & `struphy-2.0.2/src/struphy/pic/pusher.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,19 +1,20 @@
 import struphy.pic.pusher_kernels as pushers
+import struphy.pic.pusher_kernels_gc as pushers_gc
 import struphy.pic.utilities_kernels as utilities
 
 import numpy as np
 
 
 class Pusher:
     """
     Wrapper class for particle pushing. 
-    
+
     It retrieves the correct pusher kernel and prepares the FEM arguments passed to the pusher kernel.
-    
+
     Parameters
     ----------
         derham : struphy.psydac_api.psydac_derham.Derham
             Discrete de Rham sequence on the logical unit cube.
 
         domain : struphy.geometry.domains
             All things mapping.
@@ -37,15 +38,23 @@
                           np.array(derham.Vh['0'].starts),
                           np.array(derham.Vh['1'].starts),
                           np.array(derham.Vh['2'].starts),
                           np.array(derham.Vh['3'].starts))
 
         # select pusher kernel
         self._kernel_name = kernel_name
-        self._kernel = getattr(pushers, self._kernel_name)
+        self._kernel = None
+
+        objs = [pushers, pushers_gc]
+        for obj in objs:
+            try:
+                self._kernel = getattr(obj, self.kernel_name)
+            except AttributeError:
+                pass
+        assert self.kernel is not None
 
     def __call__(self, particles, dt, *args_opt, mpi_sort=None, verbose=False):
         """
         Applies the chosen pusher kernel by a time step dt, applies kinetic boundary conditions and performs MPI sorting.
 
         Parameters
         ----------
@@ -68,30 +77,31 @@
                 Whether to print some info or not.
         """
         # save initial etas in columns 9-11
         particles.markers[~particles.holes,
                           9:12] = particles.markers[~particles.holes, 0:3]
 
         if particles.kinds == 'Particles5D':
-            particles.markers[~particles.holes, 12] = particles.markers[~particles.holes, 3]
+            particles.markers[~particles.holes,
+                              12] = particles.markers[~particles.holes, 3]
 
         for stage in range(self._n_stages):
-            self._kernel(particles.markers, dt, stage, *
-                         self.args_fem, *self.domain.args_map, *args_opt)
+            self.kernel(particles.markers, dt, stage, *
+                        self.args_fem, *self.domain.args_map, *args_opt)
 
             # applying kinetic boundary condition
             particles.apply_kinetic_bc()
-            
+
             # sort markers according to domain decomposition
             if mpi_sort == 'each':
                 particles.mpi_sort_markers()
 
             # print stage info
             if self._derham.comm.Get_rank() == 0 and verbose:
-                print(self._kernel_name, 'done. (stage :', stage + 1, ')')
+                print(self.kernel_name, 'done. (stage :', stage + 1, ')')
 
         # sort markers according to domain decomposition
         if mpi_sort == 'last':
             particles.mpi_sort_markers(do_test=True)
 
         # clear buffer columns 9-14 for multi-stage pushers
         particles.markers[~particles.holes, 9:15] = 0.
@@ -125,19 +135,25 @@
 
     @property
     def kernel_name(self):
         """ The name of the pyccelized pusher kernel.
         """
         return self._kernel_name
 
+    @property
+    def kernel(self):
+        """ The pyccelized pusher kernel.
+        """
+        return self._kernel
+
 
 class ButcherTableau:
     """
     Butcher tableau for explicit s-stage Runge-Kutta methods. 
-    
+
     A Butcher tableau has the form
 
       c_0   | 
       c_1   | a_10
       c_2   |   0  a_21
       c_3   |   0    0  a_32
        .    |   .    .    .
@@ -198,15 +214,15 @@
         """
         return self._n_stages
 
 
 class Pusher_iteration_Gonzalez:
     """
     Wrapper class for particle pushing with discrete_gradient scheme (Gonzalez, mid-point).
-    
+
     It retrieves the correct pusher kernel(s) and prepares the FEM arguments passed to the pusher kernel.
 
     Parameters
     ----------
         derham : struphy.psydac_api.psydac_derham.Derham
             Discrete de Rham sequence on the logical unit cube.
 
@@ -233,18 +249,28 @@
                           np.array(derham.Vh['0'].starts),
                           np.array(derham.Vh['1'].starts),
                           np.array(derham.Vh['2'].starts),
                           np.array(derham.Vh['3'].starts))
 
         # select kernels
         self._kernel_name = kernel_name
-        self._kernel = getattr(pushers, self._kernel_name)
-        self._kernel_prepare = getattr(utilities, self._kernel_name + '_prepare')
-        self._kernel_eval_gradI = getattr(utilities, self._kernel_name + '_eval_gradI')
+        self._kernel = None
 
+        objs = [pushers, pushers_gc]
+        for obj in objs:
+            try:
+                self._kernel = getattr(obj, self.kernel_name)
+            except AttributeError:
+                pass
+        assert self.kernel is not None
+
+        self._kernel_prepare = getattr(
+            utilities, self.kernel_name + '_prepare')
+        self._kernel_eval_gradI = getattr(
+            utilities, self.kernel_name + '_eval_gradI')
 
     def __call__(self, particles, dt, *args_opt, mpi_sort=None, verbose=False):
         """
         Applies the chosen pusher kernel by a time step dt, applies kinetic boundary conditions and performs MPI sorting.
 
         Parameters
         ----------
@@ -257,42 +283,48 @@
             args_opt : tuple
                 Optional arguments needed for the pushing (typically spline coefficients for field evaluation).
 
             verbose : bool
                 Whether to print some info or not.
         """
         # save initial etas and v_parallel in columns 9:13
-        particles.markers[~particles.holes, 9:13] = particles.markers[~particles.holes, 0:4]
+        particles.markers[~particles.holes,
+                          9:13] = particles.markers[~particles.holes, 0:4]
 
         # prepare the iteration:
-        self._kernel_prepare(particles.markers, dt, *self.args_fem, *self.domain.args_map, *args_opt)
+        self.kernel_prepare(particles.markers, dt, *
+                            self.args_fem, *self.domain.args_map, *args_opt)
         particles.mpi_sort_markers()
 
-        # eval gradI 
-        self._kernel_eval_gradI(particles.markers, dt, *self.args_fem, *self.domain.args_map, *args_opt)
+        # eval gradI
+        self.kernel_eval_gradI(particles.markers, dt, *
+                               self.args_fem, *self.domain.args_map, *args_opt)
         particles.mpi_sort_markers()
 
         # start iteration
         for stage in range(self._maxiter):
 
-            self._kernel(particles.markers, dt, stage, self._tol, *self.args_fem, *self.domain.args_map, *args_opt)
+            self.kernel(particles.markers, dt, stage, self._tol,
+                        *self.args_fem, *self.domain.args_map, *args_opt)
             particles.mpi_sort_markers()
 
-            self._kernel_eval_gradI(particles.markers, dt, *self.args_fem, *self.domain.args_map, *args_opt)
+            self.kernel_eval_gradI(
+                particles.markers, dt, *self.args_fem, *self.domain.args_map, *args_opt)
             particles.mpi_sort_markers()
 
             if stage == self._maxiter-1 and verbose:
-                not_converged = np.logical_not(particles.markers[:,23]==-1.)
-                print('Number of not converged particles:', np.count_nonzero(not_converged))
-                # print('Non converged partices:')
-                # print(particles.markers[not_converged, 0:13])
-                # print('NUmber of iterations', np.average(particles.markers[~particles.holes,20])+1)
+                not_converged = np.logical_not(particles.markers[:, 23] == -1.)
+                print('Number of not converged particles:',
+                      np.count_nonzero(not_converged))
+                # print('Non converged partices:', particles.markers[not_converged, 0:13])
+                print('NUmber of iterations', np.average(
+                    particles.markers[~particles.holes, 20])+1)
 
         # clear buffer columns 9-23 for multi-stage pushers
-        particles.markers[~particles.holes, 9:28] = 0.
+        particles.markers[~particles.holes, 9:25] = 0.
 
     @property
     def derham(self):
         """ Discrete derham sequence.
         """
         return self._derham
 
@@ -315,20 +347,38 @@
         return self._args_fem
 
     @property
     def kernel_name(self):
         """ The name of the pyccelized pusher kernel.
         """
         return self._kernel_name
-    
+
+    @property
+    def kernel(self):
+        """ The pyccelized pusher kernel.
+        """
+        return self._kernel
+
+    @property
+    def kernel_prepare(self):
+        """ A preparation kernel.
+        """
+        return self._kernel_prepare
+
+    @property
+    def kernel_eval_gradI(self):
+        """ A preparation kernel.
+        """
+        return self._kernel_eval_gradI
+
 
 class Pusher_iteration_Itoh:
     """
     Wrapper class for particle pushing with discrete_gradient scheme (Itoh_Newton).
-    
+
     It retrieves the correct pusher kernel(s) and prepares the FEM arguments passed to the pusher kernel.
 
     Parameters
     ----------
         derham : struphy.psydac_api.psydac_derham.Derham
             Discrete de Rham sequence on the logical unit cube.
 
@@ -355,18 +405,30 @@
                           np.array(derham.Vh['0'].starts),
                           np.array(derham.Vh['1'].starts),
                           np.array(derham.Vh['2'].starts),
                           np.array(derham.Vh['3'].starts))
 
         # select kernels
         self._kernel_name = kernel_name
-        self._kernel = getattr(pushers, self._kernel_name)
-        self._kernel_prepare = getattr(utilities, self._kernel_name + '_prepare')
-        self._kernel_prepare1 = getattr(utilities, self._kernel_name + '_prepare1')
-        self._kernel_prepare2 = getattr(utilities, self._kernel_name + '_prepare2')
+        self._kernel = None
+
+        objs = [pushers, pushers_gc]
+        for obj in objs:
+            try:
+                self._kernel = getattr(obj, self.kernel_name)
+            except AttributeError:
+                pass
+        assert self.kernel is not None
+
+        self._kernel_prepare = getattr(
+            utilities, self.kernel_name + '_prepare')
+        self._kernel_prepare1 = getattr(
+            utilities, self.kernel_name + '_prepare1')
+        self._kernel_prepare2 = getattr(
+            utilities, self.kernel_name + '_prepare2')
 
     def __call__(self, particles, dt, *args_opt, mpi_sort=None, verbose=False):
         """
         Applies the chosen pusher kernel by a time step dt, applies kinetic boundary conditions and performs MPI sorting.
 
         Parameters
         ----------
@@ -379,39 +441,45 @@
             args_opt : tuple
                 Optional arguments needed for the pushing (typically spline coefficients for field evaluation).
 
             verbose : bool
                 Whether to print some info or not.
         """
         # save initial etas and v_parallel in columns 9:13
-        particles.markers[~particles.holes, 9:13] = particles.markers[~particles.holes, 0:4]
+        particles.markers[~particles.holes,
+                          9:13] = particles.markers[~particles.holes, 0:4]
 
         # prepare the iteration:
-        self._kernel_prepare(particles.markers, dt, *self.args_fem, *self.domain.args_map, *args_opt)
+        self.kernel_prepare(particles.markers, dt, *
+                            self.args_fem, *self.domain.args_map, *args_opt)
         particles.mpi_sort_markers()
 
         # start iteration
         for stage in range(self._maxiter):
 
-            self._kernel_prepare1(particles.markers, dt, *self.args_fem, *self.domain.args_map, *args_opt)
+            self.kernel_prepare1(particles.markers, dt, *
+                                 self.args_fem, *self.domain.args_map, *args_opt)
             particles.mpi_sort_markers()
 
-            self._kernel_prepare2(particles.markers, dt, *self.args_fem, *self.domain.args_map, *args_opt)
+            self.kernel_prepare2(particles.markers, dt, *
+                                 self.args_fem, *self.domain.args_map, *args_opt)
             particles.mpi_sort_markers()
 
-            self._kernel(particles.markers, dt, stage, self._maxiter, self._tol, *self.args_fem, *self.domain.args_map, *args_opt)
+            self.kernel(particles.markers, dt, stage, self._maxiter,
+                        self._tol, *self.args_fem, *self.domain.args_map, *args_opt)
             particles.mpi_sort_markers()
 
             if stage == self._maxiter-1 and verbose:
-                not_converged = np.logical_not(particles.markers[:,13]==-1.)
-                print('Number of not converged particles:', np.count_nonzero(not_converged))
-                # print('Non converged partices:')
-                # print(particles.markers[not_converged, 0:13])
-                # print('Number of iterations', np.average(particles.markers[~particles.holes,14])+1)
-                
+                not_converged = np.logical_not(particles.markers[:, 13] == -1.)
+                print('Number of not converged particles:',
+                      np.count_nonzero(not_converged))
+                # print('Non converged partices:', particles.markers[not_converged, 0:13])
+                print('NUmber of iterations', np.average(
+                    particles.markers[~particles.holes, 14])+1)
+
         # clear buffer columns 9-23 for multi-stage pushers
         particles.markers[~particles.holes, 9:25] = 0.
 
     @property
     def derham(self):
         """ Discrete derham sequence.
         """
@@ -436,7 +504,31 @@
         return self._args_fem
 
     @property
     def kernel_name(self):
         """ The name of the pyccelized pusher kernel.
         """
         return self._kernel_name
+
+    @property
+    def kernel(self):
+        """ The pyccelized pusher kernel.
+        """
+        return self._kernel
+
+    @property
+    def kernel_prepare(self):
+        """ A preparation kernel.
+        """
+        return self._kernel_prepare
+
+    @property
+    def kernel_prepare1(self):
+        """ A preparation kernel.
+        """
+        return self._kernel_prepare1
+
+    @property
+    def kernel_prepare2(self):
+        """ A preparation kernel.
+        """
+        return self._kernel_prepare2
```

### Comparing `struphy-2.0.1/src/struphy/pic/pusher_kernels.py` & `struphy-2.0.2/src/struphy/pic/pusher_kernels.py`

 * *Files 26% similar despite different names*

```diff
@@ -461,18 +461,21 @@
         a_form[0] = eval_3d.eval_spline_mpi_kernel(
             pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, a1_1, starts1[0])
         a_form[1] = eval_3d.eval_spline_mpi_kernel(
             pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, a1_2, starts1[1])
         a_form[2] = eval_3d.eval_spline_mpi_kernel(
             pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, a1_3, starts1[2])
 
-        rot_temp[0] = dfinv_t[0,0] * a_form[0] + dfinv_t[0,1] * a_form[1] + dfinv_t[0,2] * a_form[2]
-        rot_temp[1] = dfinv_t[1,0] * a_form[0] + dfinv_t[1,1] * a_form[1] + dfinv_t[1,2] * a_form[2]
-        rot_temp[2] = dfinv_t[2,0] * a_form[0] + dfinv_t[2,1] * a_form[1] + dfinv_t[2,2] * a_form[2]
-        
+        rot_temp[0] = dfinv_t[0, 0] * a_form[0] + \
+            dfinv_t[0, 1] * a_form[1] + dfinv_t[0, 2] * a_form[2]
+        rot_temp[1] = dfinv_t[1, 0] * a_form[0] + \
+            dfinv_t[1, 1] * a_form[1] + dfinv_t[1, 2] * a_form[2]
+        rot_temp[2] = dfinv_t[2, 0] * a_form[0] + \
+            dfinv_t[2, 1] * a_form[1] + dfinv_t[2, 2] * a_form[2]
+
         v[0] = v[0] - rot_temp[0]
         v[1] = v[1] - rot_temp[1]
         v[2] = v[2] - rot_temp[2]
 
         # magnetic field: Cartesian components
         linalg.matrix_vector(df, b_form, b_cart)
         b_cart[:] = b_cart/det_df
@@ -500,96 +503,95 @@
             cos(b_abs*dt)*vperp - sin(b_abs*dt)*b_normxvperp + rot_temp
 
     #$ omp end parallel
 
 
 @stack_array('df', 'dfinv', 'dfinv_t', 'eta1', 'eta2', 'eta3')
 def push_hybrid_xp_lnn(markers: 'float[:,:]', dt: float, stage: int,
-                      pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                      starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                      kind_map: int, params_map: 'float[:]',
-                      p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                      ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                      cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                      p_shape: 'int[:]', p_size: 'float[:]', Nel: 'int[:]', 
-                      pts1: 'float[:]', pts2: 'float[:]', pts3: 'float[:]',
-                      wts1: 'float[:]', wts2: 'float[:]', wts3: 'float[:]',
-                      weight: 'float[:,:,:,:,:,:]', thermal: 'float', n_quad: 'int[:]'):
+                       pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
+                       starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
+                       kind_map: int, params_map: 'float[:]',
+                       p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
+                       ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
+                       cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
+                       p_shape: 'int[:]', p_size: 'float[:]', Nel: 'int[:]',
+                       pts1: 'float[:]', pts2: 'float[:]', pts3: 'float[:]',
+                       wts1: 'float[:]', wts2: 'float[:]', wts3: 'float[:]',
+                       weight: 'float[:,:,:,:,:,:]', thermal: 'float', n_quad: 'int[:]'):
     r'''Solves exactly the rotation
 
     .. math::
 
         \frac{\textnormal d \mathbf v_p(t)}{\textnormal d t} =  \mathbf v_p(t) \times \frac{DF\, \hat{\mathbf B}^2}{\sqrt g}
 
     for each marker :math:`p` in markers array, with fixed rotation vector.
     '''
 
     # allocate metric coeffs
     df = empty((3, 3), dtype=float)
     dfinv = empty((3, 3), dtype=float)
     dfinv_t = empty((3, 3), dtype=float)
 
-    compact      = zeros(3, dtype=float)
-    compact[0]   = (p_shape[0]+1.0)*p_size[0]
-    compact[1]   = (p_shape[1]+1.0)*p_size[1]
-    compact[2]   = (p_shape[2]+1.0)*p_size[2]
-
-    cell_left    = empty(3, dtype=int)
-    point_left   = zeros(3, dtype=float)
-    point_right  = zeros(3, dtype=float)
-    cell_number  = empty(3, dtype=int)
+    compact = zeros(3, dtype=float)
+    compact[0] = (p_shape[0]+1.0)*p_size[0]
+    compact[1] = (p_shape[1]+1.0)*p_size[1]
+    compact[2] = (p_shape[2]+1.0)*p_size[2]
+
+    cell_left = empty(3, dtype=int)
+    point_left = zeros(3, dtype=float)
+    point_right = zeros(3, dtype=float)
+    cell_number = empty(3, dtype=int)
 
     grids_shapex = zeros(p_shape[0] + 2, dtype=float)
     grids_shapey = zeros(p_shape[1] + 2, dtype=float)
     grids_shapez = zeros(p_shape[2] + 2, dtype=float)
 
     temp1 = empty(3, dtype=float)
     temp4 = empty(3, dtype=float)
     temp6 = empty(3, dtype=float)
     temp8 = empty(3, dtype=float)
-    ww    = empty(1, dtype=float)
+    ww = empty(1, dtype=float)
 
     value = empty(3, dtype=float)
     valuexyz = empty(3, dtype=float)
     dvaluexyz = empty(3, dtype=float)
 
-
     # get number of markers
     n_markers = shape(markers)[0]
 
     #$ omp parallel private (ip, eta1, eta2, eta3, df, dfinv, dfinv_t, det_df, point_left, point_right, cell_left, cell_number, i, grids_shapex, grids_shapey, grids_shapez, x_ii, y_ii, z_ii, il1, il2, il3, q1, q2, q3, temp1, temp4, temp6, valuexyz, dvaluexyz, temp8, ww)
     #$ omp for
     for ip in range(n_markers):
 
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
-        eta1   = markers[ip, 0]
-        eta2   = markers[ip, 1]
-        eta3   = markers[ip, 2]
+        eta1 = markers[ip, 0]
+        eta2 = markers[ip, 1]
+        eta3 = markers[ip, 2]
 
         # evaluate Jacobian, result in df
         map_eval.df(eta1, eta2, eta3,
                     kind_map, params_map,
                     t1_map, t2_map, t3_map, p_map,
                     ind1_map, ind2_map, ind3_map,
                     cx, cy, cz,
                     df)
 
         linalg.matrix_inv(df, dfinv)
         linalg.transpose(dfinv, dfinv_t)
         # metric coeffs
         det_df = linalg.det(df)
 
-        point_left[0]  = eta1 - 0.5*compact[0]
+        point_left[0] = eta1 - 0.5*compact[0]
         point_right[0] = eta1 + 0.5*compact[0]
-        point_left[1]  = eta2 - 0.5*compact[1]
+        point_left[1] = eta2 - 0.5*compact[1]
         point_right[1] = eta2 + 0.5*compact[1]
-        point_left[2]  = eta3 - 0.5*compact[2]
+        point_left[2] = eta3 - 0.5*compact[2]
         point_right[2] = eta3 + 0.5*compact[2]
 
         cell_left[0] = int(floor(point_left[0]*Nel[0]))
         cell_left[1] = int(floor(point_left[1]*Nel[1]))
         cell_left[2] = int(floor(point_left[2]*Nel[2]))
 
         cell_number[0] = int(floor(point_right[0]*Nel[0])) - cell_left[0] + 1.0
@@ -604,60 +606,85 @@
             grids_shapey[i] = point_left[1] + i * p_size[1]
         grids_shapey[p_shape[1] + 1] = point_right[1]
 
         for i in range(p_shape[2] + 1):
             grids_shapez[i] = point_left[2] + i * p_size[2]
         grids_shapez[p_shape[2] + 1] = point_right[2]
 
-        # if periodic 
+        # if periodic
         x_ii = pn[0] + cell_left[0] - starts0[0]
         y_ii = pn[1] + cell_left[1] - starts0[1]
         z_ii = pn[2] + cell_left[2] - starts0[2]
 
-        #======================================
+        # ======================================
         for il1 in range(cell_number[0]):
             for il2 in range(cell_number[1]):
                 for il3 in range(cell_number[2]):
                     for q1 in range(n_quad[0]):
                         for q2 in range(n_quad[1]):
                             for q3 in range(n_quad[2]):
-                                temp1[0] = (cell_left[0] + il1)/Nel[0] + pts1[q1] # quadrature points in the cell x direction
-                                temp4[0] = abs(temp1[0] - eta1) - compact[0]/2 # if > 0, result is 0
-
-                                temp1[1] = (cell_left[1] + il2)/Nel[1] + pts2[q2] 
-                                temp4[1] = abs(temp1[1] - eta2) - compact[1]/2 # if > 0, result is 0
-
-                                temp1[2] = (cell_left[2] + il3)/Nel[2] + pts3[q3] 
-                                temp4[2] = abs(temp1[2] - eta3) - compact[2]/2 # if > 0, result is 0
+                                # quadrature points in the cell x direction
+                                temp1[0] = (cell_left[0] + il1) / \
+                                    Nel[0] + pts1[q1]
+                                # if > 0, result is 0
+                                temp4[0] = abs(temp1[0] - eta1) - compact[0]/2
+
+                                temp1[1] = (cell_left[1] + il2) / \
+                                    Nel[1] + pts2[q2]
+                                # if > 0, result is 0
+                                temp4[1] = abs(temp1[1] - eta2) - compact[1]/2
+
+                                temp1[2] = (cell_left[2] + il3) / \
+                                    Nel[2] + pts3[q3]
+                                # if > 0, result is 0
+                                temp4[2] = abs(temp1[2] - eta3) - compact[2]/2
 
                                 if temp4[0] < 0 and temp4[1] < 0 and temp4[2] < 0:
 
-                                    valuexyz[0] = bspparticle.convolution(p_shape[0], grids_shapex, temp1[0])
-                                    dvaluexyz[0] = bspparticle.convolution_der(p_shape[0], grids_shapex, temp1[0])
-                                    
-                                    valuexyz[1] = bspparticle.piecewise(p_shape[1], p_size[1], temp1[1] - eta2)
-                                    dvaluexyz[1] = bspparticle.piecewise(p_shape[2], p_size[2], temp1[2] - eta3)
-                                    
-                                    valuexyz[2] = bspparticle.piecewise_der(p_shape[1], p_size[1], temp1[1] - eta2)
-                                    dvaluexyz[2] = bspparticle.piecewise_der(p_shape[2], p_size[2], temp1[2] - eta3)
-
-                                    temp8[0] = dvaluexyz[0] * valuexyz[1] * valuexyz[2]
-                                    temp8[1] = valuexyz[0] * dvaluexyz[1] * valuexyz[2]
-                                    temp8[2] = valuexyz[0] * valuexyz[1] * dvaluexyz[2]
-
-                                    ww[0] = weight[x_ii + il1, y_ii + il2, z_ii + il3, q1, q2, q3] * wts1[q1] * wts2[q2] * wts3[q3]
-
-                                    temp6[0] = dfinv_t[0,0]*temp8[0] + dfinv_t[0,1]*temp8[1] + dfinv_t[0,2]*temp8[2] 
-                                    temp6[1] = dfinv_t[1,0]*temp8[0] + dfinv_t[1,1]*temp8[1] + dfinv_t[1,2]*temp8[2] 
-                                    temp6[2] = dfinv_t[2,0]*temp8[0] + dfinv_t[2,1]*temp8[1] + dfinv_t[2,2]*temp8[2] 
+                                    valuexyz[0] = bspparticle.convolution(
+                                        p_shape[0], grids_shapex, temp1[0])
+                                    dvaluexyz[0] = bspparticle.convolution_der(
+                                        p_shape[0], grids_shapex, temp1[0])
+
+                                    valuexyz[1] = bspparticle.piecewise(
+                                        p_shape[1], p_size[1], temp1[1] - eta2)
+                                    dvaluexyz[1] = bspparticle.piecewise(
+                                        p_shape[2], p_size[2], temp1[2] - eta3)
+
+                                    valuexyz[2] = bspparticle.piecewise_der(
+                                        p_shape[1], p_size[1], temp1[1] - eta2)
+                                    dvaluexyz[2] = bspparticle.piecewise_der(
+                                        p_shape[2], p_size[2], temp1[2] - eta3)
+
+                                    temp8[0] = dvaluexyz[0] * \
+                                        valuexyz[1] * valuexyz[2]
+                                    temp8[1] = valuexyz[0] * \
+                                        dvaluexyz[1] * valuexyz[2]
+                                    temp8[2] = valuexyz[0] * \
+                                        valuexyz[1] * dvaluexyz[2]
+
+                                    ww[0] = weight[x_ii + il1, y_ii + il2, z_ii + il3,
+                                                   q1, q2, q3] * wts1[q1] * wts2[q2] * wts3[q3]
+
+                                    temp6[0] = dfinv_t[0, 0]*temp8[0] + \
+                                        dfinv_t[0, 1]*temp8[1] + \
+                                        dfinv_t[0, 2]*temp8[2]
+                                    temp6[1] = dfinv_t[1, 0]*temp8[0] + \
+                                        dfinv_t[1, 1]*temp8[1] + \
+                                        dfinv_t[1, 2]*temp8[2]
+                                    temp6[2] = dfinv_t[2, 0]*temp8[0] + \
+                                        dfinv_t[2, 1]*temp8[1] + \
+                                        dfinv_t[2, 2]*temp8[2]
                                     # check weight_123 index
-                                    markers[ip, 3] += dt * ww[0] * thermal * temp6[0]
-                                    markers[ip, 4] += dt * ww[0] * thermal * temp6[1]
-                                    markers[ip, 5] += dt * ww[0] * thermal * temp6[2]
-
+                                    markers[ip, 3] += dt * \
+                                        ww[0] * thermal * temp6[0]
+                                    markers[ip, 4] += dt * \
+                                        ww[0] * thermal * temp6[1]
+                                    markers[ip, 5] += dt * \
+                                        ww[0] * thermal * temp6[2]
 
     #$ omp end parallel
 
 
 @stack_array('df', 'dfinv', 'dfinv_t', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3')
 def push_hybrid_xp_ap(markers: 'float[:,:]', dt: float, stage: int,
                       pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
@@ -694,48 +721,48 @@
     rhs = empty(3, dtype=float)
 
     # particle position and velocity
     e = empty(3, dtype=float)
     v = empty(3, dtype=float)
 
     # p + 1 non-vanishing basis functions up tp degree p
-    b1  = zeros((pn[0] + 1, pn[0] + 1), dtype=float)
-    b2  = zeros((pn[1] + 1, pn[1] + 1), dtype=float)
-    b3  = zeros((pn[2] + 1, pn[2] + 1), dtype=float)
-    
-    l1  = zeros( pn[0]              , dtype=float)
-    l2  = zeros( pn[1]              , dtype=float)
-    l3  = zeros( pn[2]              , dtype=float)
-    
-    r1  = zeros( pn[0]              , dtype=float)
-    r2  = zeros( pn[1]              , dtype=float)
-    r3  = zeros( pn[2]              , dtype=float)
-    
+    b1 = zeros((pn[0] + 1, pn[0] + 1), dtype=float)
+    b2 = zeros((pn[1] + 1, pn[1] + 1), dtype=float)
+    b3 = zeros((pn[2] + 1, pn[2] + 1), dtype=float)
+
+    l1 = zeros(pn[0], dtype=float)
+    l2 = zeros(pn[1], dtype=float)
+    l3 = zeros(pn[2], dtype=float)
+
+    r1 = zeros(pn[0], dtype=float)
+    r2 = zeros(pn[1], dtype=float)
+    r3 = zeros(pn[2], dtype=float)
+
     # scaling arrays for M-splines
-    d1  = zeros( pn[0]              , dtype=float)
-    d2  = zeros( pn[1]              , dtype=float)
-    d3  = zeros( pn[2]              , dtype=float)
-    
+    d1 = zeros(pn[0], dtype=float)
+    d2 = zeros(pn[1], dtype=float)
+    d3 = zeros(pn[2], dtype=float)
+
     # non-vanishing N-splines
-    bn1 = zeros( pn[0] + 1          , dtype=float)
-    bn2 = zeros( pn[1] + 1          , dtype=float)
-    bn3 = zeros( pn[2] + 1          , dtype=float)
-    
+    bn1 = zeros(pn[0] + 1, dtype=float)
+    bn2 = zeros(pn[1] + 1, dtype=float)
+    bn3 = zeros(pn[2] + 1, dtype=float)
+
     # non-vanishing D-splines
-    bd1 = zeros( pn[0]          , dtype=float)
-    bd2 = zeros( pn[1]          , dtype=float)
-    bd3 = zeros( pn[2]          , dtype=float)
+    bd1 = zeros(pn[0], dtype=float)
+    bd2 = zeros(pn[1], dtype=float)
+    bd3 = zeros(pn[2], dtype=float)
 
-    pd1 = pn[0] - 1 
+    pd1 = pn[0] - 1
     pd2 = pn[1] - 1
     pd3 = pn[2] - 1
 
-    bdd1 = zeros( pd1          , dtype=float)
-    bdd2 = zeros( pd2          , dtype=float)
-    bdd3 = zeros( pd3          , dtype=float)
+    bdd1 = zeros(pd1, dtype=float)
+    bdd2 = zeros(pd2, dtype=float)
+    bdd3 = zeros(pd3, dtype=float)
 
     # get number of markers
     n_markers = shape(markers)[0]
 
     #$ omp parallel private (ip, e, v, df, dfinv, dfinv_t, span1, span2, span3, bn1, bn2, bn3, bd1, bd2, bd3, bdd1, bdd2, bdd3, l1, l2, l3, r1, r2, r3, b1, b2, b3, d1, d2, d3, a_form, a_xx, a_xxtrans, matrixp, matrixpp, matrixppp, lhs, rhs, lhsinv)
     #$ omp for
     for ip in range(n_markers):
@@ -767,15 +794,15 @@
         bsp.basis_funs_all(tn2, pn[1], e[1], span2, l2, r2, b2, d2)
         bsp.basis_funs_all(tn3, pn[2], e[2], span3, l3, r3, b3, d3)
 
         # N-splines and D-splines
         bn1[:] = b1[pn[0], :]
         bn2[:] = b2[pn[1], :]
         bn3[:] = b3[pn[2], :]
-        
+
         for il1 in range(pn[0]):
             bd1[il1] = b1[pd1, il1] * d1[il1]
 
         for il2 in range(pn[1]):
             bd2[il2] = b2[pd2, il2] * d2[il2]
 
         for il3 in range(pn[2]):
@@ -784,83 +811,88 @@
         for il1 in range(pd1):
             bdd1[il1] = b1[pd1 - 1, il1] * d1[il1] * d1[il1]
 
         for il2 in range(pd2):
             bdd2[il2] = b2[pd2 - 1, il2] * d2[il2] * d2[il2]
 
         for il3 in range(pd3):
-            bdd3[il3] = b3[pd3 - 1, il3] * d3[il3] * d3[il3]        
-
+            bdd3[il3] = b3[pd3 - 1, il3] * d3[il3] * d3[il3]
 
         # vector potential: 1-form components
         a_form[0] = eval_3d.eval_spline_mpi_kernel(
             pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, a1_1, starts1[0])
         a_form[1] = eval_3d.eval_spline_mpi_kernel(
             pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, a1_2, starts1[1])
         a_form[2] = eval_3d.eval_spline_mpi_kernel(
             pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, a1_3, starts1[2])
 
-        a_xx[0,0] = eval_3d.eval_spline_derivative_mpi_kernel(
+        a_xx[0, 0] = eval_3d.eval_spline_derivative_mpi_kernel(
             pn[0] - 2, pn[1], pn[2], bdd1, bn2, bn3, span1, span2, span3, a1_1, starts1[0], int(1))
-        a_xx[0,1] = eval_3d.eval_spline_derivative_mpi_kernel(
+        a_xx[0, 1] = eval_3d.eval_spline_derivative_mpi_kernel(
             pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, a1_1, starts1[1], int(2))
-        a_xx[0,2] = eval_3d.eval_spline_derivative_mpi_kernel(
+        a_xx[0, 2] = eval_3d.eval_spline_derivative_mpi_kernel(
             pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, a1_1, starts1[2], int(3))
 
-        a_xx[1,0] = eval_3d.eval_spline_derivative_mpi_kernel(
+        a_xx[1, 0] = eval_3d.eval_spline_derivative_mpi_kernel(
             pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, a1_2, starts1[0], int(1))
-        a_xx[1,1] = eval_3d.eval_spline_derivative_mpi_kernel(
+        a_xx[1, 1] = eval_3d.eval_spline_derivative_mpi_kernel(
             pn[0], pn[1] - 2, pn[2], bn1, bdd2, bn3, span1, span2, span3, a1_2, starts1[1], int(2))
-        a_xx[1,2] = eval_3d.eval_spline_derivative_mpi_kernel(
+        a_xx[1, 2] = eval_3d.eval_spline_derivative_mpi_kernel(
             pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, a1_2, starts1[2], int(3))
 
-        a_xx[2,0] = eval_3d.eval_spline_derivative_mpi_kernel(
+        a_xx[2, 0] = eval_3d.eval_spline_derivative_mpi_kernel(
             pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, a1_3, starts1[0], int(1))
-        a_xx[2,1] = eval_3d.eval_spline_derivative_mpi_kernel(
+        a_xx[2, 1] = eval_3d.eval_spline_derivative_mpi_kernel(
             pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, a1_3, starts1[1], int(2))
-        a_xx[2,2] = eval_3d.eval_spline_derivative_mpi_kernel(
+        a_xx[2, 2] = eval_3d.eval_spline_derivative_mpi_kernel(
             pn[0], pn[1], pn[2] - 2, bn1, bn2, bdd3, span1, span2, span3, a1_3, starts1[2], int(3))
 
         linalg.transpose(a_xx, a_xxtrans)
         linalg.matrix_matrix(a_xxtrans, dfinv, matrixp)
-        linalg.matrix_matrix(dfinv_t, matrixp, matrixpp) # left matrix
-        linalg.matrix_matrix(matrixpp, dfinv_t, matrixppp) # right matrix 
+        linalg.matrix_matrix(dfinv_t, matrixp, matrixpp)  # left matrix
+        linalg.matrix_matrix(matrixpp, dfinv_t, matrixppp)  # right matrix
 
-        lhs[0,0] = 1.0 - dt*matrixpp[0,0]
-        lhs[0,1] =     - dt*matrixpp[0,1]
-        lhs[0,2] =     - dt*matrixpp[0,2]
-
-        lhs[1,0] =     - dt*matrixpp[0,0]
-        lhs[1,1] = 1.0 - dt*matrixpp[1,1]
-        lhs[1,2] =     - dt*matrixpp[1,2]
-
-        lhs[2,0] =     - dt*matrixpp[2,0]
-        lhs[2,1] =     - dt*matrixpp[2,1]
-        lhs[2,2] = 1.0 - dt*matrixpp[2,2]
+        lhs[0, 0] = 1.0 - dt*matrixpp[0, 0]
+        lhs[0, 1] = - dt*matrixpp[0, 1]
+        lhs[0, 2] = - dt*matrixpp[0, 2]
+
+        lhs[1, 0] = - dt*matrixpp[0, 0]
+        lhs[1, 1] = 1.0 - dt*matrixpp[1, 1]
+        lhs[1, 2] = - dt*matrixpp[1, 2]
+
+        lhs[2, 0] = - dt*matrixpp[2, 0]
+        lhs[2, 1] = - dt*matrixpp[2, 1]
+        lhs[2, 2] = 1.0 - dt*matrixpp[2, 2]
 
         linalg.matrix_vector(matrixppp, a_form, rhs)
         rhs[0] = v[0] - dt*rhs[0]
         rhs[1] = v[1] - dt*rhs[1]
         rhs[2] = v[2] - dt*rhs[2]
 
         linalg.matrix_inv(lhs, lhsinv)
-        # update velocity 
-        markers[ip, 3] = lhsinv[0,0]*rhs[0] + lhsinv[0,1]*rhs[1] + lhsinv[0,2]*rhs[2]
-        markers[ip, 4] = lhsinv[1,0]*rhs[0] + lhsinv[1,1]*rhs[1] + lhsinv[1,2]*rhs[2]
-        markers[ip, 5] = lhsinv[2,0]*rhs[0] + lhsinv[2,1]*rhs[1] + lhsinv[2,2]*rhs[2]
+        # update velocity
+        markers[ip, 3] = lhsinv[0, 0]*rhs[0] + \
+            lhsinv[0, 1]*rhs[1] + lhsinv[0, 2]*rhs[2]
+        markers[ip, 4] = lhsinv[1, 0]*rhs[0] + \
+            lhsinv[1, 1]*rhs[1] + lhsinv[1, 2]*rhs[2]
+        markers[ip, 5] = lhsinv[2, 0]*rhs[0] + \
+            lhsinv[2, 1]*rhs[1] + lhsinv[2, 2]*rhs[2]
 
         # update position
         linalg.matrix_vector(dfinv_t, a_form, rhs)
         rhs[0] = markers[ip, 3] - rhs[0]
         rhs[1] = markers[ip, 4] - rhs[1]
         rhs[2] = markers[ip, 5] - rhs[2]
 
-        markers[ip, 0] = e[0] + dt * (dfinv[0,0]*rhs[0] + dfinv[0,1]*rhs[1] + dfinv[0,2]*rhs[2])
-        markers[ip, 1] = e[1] + dt * (dfinv[1,0]*rhs[0] + dfinv[1,1]*rhs[1] + dfinv[1,2]*rhs[2])
-        markers[ip, 2] = e[2] + dt * (dfinv[2,0]*rhs[0] + dfinv[2,1]*rhs[1] + dfinv[2,2]*rhs[2])
+        markers[ip, 0] = e[0] + dt * \
+            (dfinv[0, 0]*rhs[0] + dfinv[0, 1]*rhs[1] + dfinv[0, 2]*rhs[2])
+        markers[ip, 1] = e[1] + dt * \
+            (dfinv[1, 0]*rhs[0] + dfinv[1, 1]*rhs[1] + dfinv[1, 2]*rhs[2])
+        markers[ip, 2] = e[2] + dt * \
+            (dfinv[2, 0]*rhs[0] + dfinv[2, 1]*rhs[1] + dfinv[2, 2]*rhs[2])
 
     #$ omp end parallel
 
 
 @stack_array('df', 'b_form', 'u_form', 'b_cart', 'u_cart', 'e_cart', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3')
 def push_bxu_Hdiv(markers: 'float[:,:]', dt: float, stage: int,
                   pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
@@ -1396,15 +1428,15 @@
     df = empty((3, 3), dtype=float)
     dfinv = empty((3, 3), dtype=float)
     dfinv_t = empty((3, 3), dtype=float)
 
     # allocate for field evaluations
     e = empty(3, dtype=float)
     e_cart = empty(3, dtype=float)
-    GXu = empty((3,3), dtype=float)
+    GXu = empty((3, 3), dtype=float)
 
     # particle velocity
     v = empty(3, dtype=float)
 
     # allocate spline values
     bn1 = empty(pn[0] + 1, dtype=float)
     bn2 = empty(pn[1] + 1, dtype=float)
@@ -1444,27 +1476,36 @@
         span3 = bsp.find_span(tn3, pn[2], eta3)
 
         bsp.b_d_splines_slim(tn1, pn[0], eta1, span1, bn1, bd1)
         bsp.b_d_splines_slim(tn2, pn[1], eta2, span2, bn2, bd2)
         bsp.b_d_splines_slim(tn3, pn[2], eta3, span3, bn3, bd3)
 
         # Evaluate grad(X(u, v)) at the particle positions
-        GXu[0,0] =eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, GXu_11, starts1[0])
-        GXu[1,0] =eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, GXu_21, starts1[0])
-        GXu[2,0] =eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, GXu_31, starts1[0])
-        GXu[0,1] =eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, GXu_12, starts1[1])
-        GXu[1,1] =eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, GXu_22, starts1[1])
-        GXu[2,1] =eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, GXu_32, starts1[1])
-        GXu[0,2] =eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, GXu_13, starts1[2])
-        GXu[1,2] =eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, GXu_23, starts1[2])
-        GXu[2,2] =eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, GXu_33, starts1[2])
-
-        e[0] = GXu[0,0] * v[0] + GXu[1,0] * v[1] + GXu[2,0] * v[2]
-        e[1] = GXu[0,1] * v[0] + GXu[1,1] * v[1] + GXu[2,1] * v[2]
-        e[2] = GXu[0,2] * v[0] + GXu[1,2] * v[1] + GXu[2,2] * v[2]
+        GXu[0, 0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, GXu_11, starts1[0])
+        GXu[1, 0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, GXu_21, starts1[0])
+        GXu[2, 0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, GXu_31, starts1[0])
+        GXu[0, 1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, GXu_12, starts1[1])
+        GXu[1, 1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, GXu_22, starts1[1])
+        GXu[2, 1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, GXu_32, starts1[1])
+        GXu[0, 2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, GXu_13, starts1[2])
+        GXu[1, 2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, GXu_23, starts1[2])
+        GXu[2, 2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, GXu_33, starts1[2])
+
+        e[0] = GXu[0, 0] * v[0] + GXu[1, 0] * v[1] + GXu[2, 0] * v[2]
+        e[1] = GXu[0, 1] * v[0] + GXu[1, 1] * v[1] + GXu[2, 1] * v[2]
+        e[2] = GXu[0, 2] * v[0] + GXu[1, 2] * v[1] + GXu[2, 2] * v[2]
 
         linalg.matrix_vector(dfinv_t, e, e_cart)
 
         # update velocities
         markers[ip, 3:6] -= dt*e_cart/2.
 
 
@@ -1499,16 +1540,16 @@
     df = empty((3, 3), dtype=float)
     dfinv = empty((3, 3), dtype=float)
     dfinv_t = empty((3, 3), dtype=float)
 
     # allocate for field evaluations
     e = empty(3, dtype=float)
     e_cart = empty(3, dtype=float)
-    GXu = empty((3,3), dtype=float)
-    GXu_t = empty((3,3), dtype=float)
+    GXu = empty((3, 3), dtype=float)
+    GXu_t = empty((3, 3), dtype=float)
 
     # particle velocity
     v = empty(3, dtype=float)
 
     # allocate spline values
     bn1 = empty(pn[0] + 1, dtype=float)
     bn2 = empty(pn[1] + 1, dtype=float)
@@ -1548,24 +1589,30 @@
         span3 = bsp.find_span(tn3, pn[2], eta3)
 
         bsp.b_d_splines_slim(tn1, pn[0], eta1, span1, bn1, bd1)
         bsp.b_d_splines_slim(tn2, pn[1], eta2, span2, bn2, bd2)
         bsp.b_d_splines_slim(tn3, pn[2], eta3, span3, bn3, bd3)
 
         # Evaluate grad(X(u, v)) at the particle positions
-        GXu[0,0] =eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, GXu_11, starts1[0])
-        GXu[1,0] =eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, GXu_21, starts1[0])
-        GXu[0,1] =eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, GXu_12, starts1[1])
-        GXu[1,1] =eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, GXu_22, starts1[1])
-        GXu[0,2] =eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, GXu_13, starts1[2])
-        GXu[1,2] =eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, GXu_23, starts1[2])
-
-        e[0] = GXu[0,0] * v[0] + GXu[1,0] * v[1]
-        e[1] = GXu[0,1] * v[0] + GXu[1,1] * v[1]
-        e[2] = GXu[0,2] * v[0] + GXu[1,2] * v[1]
+        GXu[0, 0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, GXu_11, starts1[0])
+        GXu[1, 0] = eval_3d.eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, GXu_21, starts1[0])
+        GXu[0, 1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, GXu_12, starts1[1])
+        GXu[1, 1] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, GXu_22, starts1[1])
+        GXu[0, 2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, GXu_13, starts1[2])
+        GXu[1, 2] = eval_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, GXu_23, starts1[2])
+
+        e[0] = GXu[0, 0] * v[0] + GXu[1, 0] * v[1]
+        e[1] = GXu[0, 1] * v[0] + GXu[1, 1] * v[1]
+        e[2] = GXu[0, 2] * v[0] + GXu[1, 2] * v[1]
 
         linalg.matrix_vector(dfinv_t, e, e_cart)
 
         # update velocities
         markers[ip, 3:6] -= dt*e_cart/2.
 
 
@@ -2777,2227 +2824,7 @@
                                           eps, maxiter)
                 run = run + temp
 
         # write the results in the particles array
         markers[ip, :] = particle[:]
 
     #$ omp end parallel
-
-
-def push_gc1_explicit_stage(markers: 'float[:,:]', dt: float, stage: int,
-                            pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                            starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                            kind_map: int, params_map: 'float[:]',
-                            p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                            ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                            cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                            kappa: float,
-                            b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
-                            norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
-                            norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
-                            curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
-                            grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]',
-                            a: 'float[:]', b: 'float[:]', c: 'float[:]'):
-    r'''Single stage of a s-stage Runge-Kutta solve of 
-
-    .. math::
-
-        \dot{\mathbf X} &= \frac{\mu}{\kappa B^*_\parallel}  G^{-1}(\eta_p(t)) \hat{\mathbb{b}}^2_0 \times G^{-1}(\eta_p(t)) \hat \nabla |\mathcal{P}^B \hat{\mathbb{B}}^2| \,,
-
-        \dot v_\parallel &= 0 \,.
-
-    for each marker :math:`p` in markers array.
-    '''
-
-    # allocate metric coeffs
-    df = empty((3, 3), dtype=float)
-    df_t = empty((3, 3), dtype=float)
-    g = empty((3, 3), dtype=float)
-    g_inv = empty((3, 3), dtype=float)
-
-    # allocate spline values
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-
-    # containers for fields
-    grad_abs_b = empty(3, dtype=float)
-    temp1 = empty(3, dtype=float)
-    norm_b2 = empty(3, dtype=float)
-    temp2 = empty(3, dtype=float)
-    b_star = empty(3, dtype=float)
-    norm_b1 = empty(3, dtype=float)
-    bb = empty(3, dtype=float)
-    curl_norm_b = empty(3, dtype=float)
-
-    # marker position e
-    e = empty(3, dtype=float)
-
-    # intermediate k-vector
-    k = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    # get number of stages
-    n_stages = shape(b)[0]
-
-    if stage == n_stages - 1:
-        last = 1.
-    else:
-        last = 0.
-
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        e[:] = markers[ip, 0:3]
-        v = markers[ip, 3]
-        mu = markers[ip, 4]
-
-        # evaluate Jacobian, result in df
-        map_eval.df(e[0], e[1], e[2],
-                    kind_map, params_map,
-                    t1_map, t2_map, t3_map, p_map,
-                    ind1_map, ind2_map, ind3_map,
-                    cx, cy, cz,
-                    df)
-
-        # evaluate inverse of G
-        linalg.transpose(df, df_t)
-        linalg.matrix_matrix(df_t, df, g)
-        linalg.matrix_inv(g, g_inv)
-
-        # metric coeffs
-        det_df = linalg.det(df)
-
-        # spline evaluation
-        span1 = bsp.find_span(tn1, pn[0], e[0])
-        span2 = bsp.find_span(tn2, pn[1], e[1])
-        span3 = bsp.find_span(tn3, pn[2], e[2])
-
-        bsp.b_d_splines_slim(tn1, pn[0], e[0], span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], e[1], span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], e[2], span3, bn3, bd3)
-
-        # eval all the needed field
-        # grad_abs_b; 1form
-        grad_abs_b[0] = eval_3d.eval_spline_mpi_kernel(
-            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
-        grad_abs_b[1] = eval_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
-        grad_abs_b[2] = eval_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
-
-        # norm_b1; 1form
-        norm_b1[0] = eval_3d.eval_spline_mpi_kernel(
-            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
-
-        # norm_b2; 2form
-        norm_b2[0] = eval_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, norm_b21, starts2[0])
-        norm_b2[1] = eval_3d.eval_spline_mpi_kernel(
-            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, norm_b22, starts2[1])
-        norm_b2[2] = eval_3d.eval_spline_mpi_kernel(
-            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, norm_b23, starts2[2])
-
-        # b; 2form
-        bb[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        bb[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        bb[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
-        
-        # curl_norm_b; 2form
-        curl_norm_b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
-
-        # transform to H1vec
-        b_star[:] = bb + 1/kappa*v*curl_norm_b
-        b_star[:] = b_star/det_df
-
-        # calculate abs_b_star_para
-        abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
-
-        # calculate norm_b X grad_abs_b
-        linalg.matrix_vector(g_inv, grad_abs_b, temp1)
-
-        linalg.cross(norm_b2, temp1, temp2)
-
-        linalg.matrix_vector(g_inv, temp2, temp1)
-
-        # calculate k
-        k[:] = 1/kappa*mu/abs_b_star_para*temp1
-
-        # accumulation for last stage
-        markers[ip, 13:16] += dt*b[stage]*k
-
-        # update positions for intermediate stages or last stage
-        markers[ip, 0:3] = markers[ip, 9:12] + \
-            dt*a[stage]*k + last*markers[ip, 13:16]
-
-
-def push_gc2_explicit_stage(markers: 'float[:,:]', dt: float, stage: int,
-                            pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                            starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                            kind_map: int, params_map: 'float[:]',
-                            p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                            ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                            cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                            kappa: float,
-                            b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
-                            norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
-                            norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
-                            curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
-                            grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]',
-                            a: 'float[:]', b: 'float[:]', c: 'float[:]'):
-    r'''Single stage of a s-stage Runge-Kutta solve of 
-
-    .. math::
-
-        &\dot{\mathbf H}_p &= \frac{1}{|B^*_{p,\parallel}|} \left( \frac{1}{\sqrt{g}} \hat{\mathbf B}^{*2}_p \right) v_{p, \parallel} \,,
-
-        &\dot v_{p, \parallel} &= -\frac{\mu}{|B^*_{p,\parallel}|}  \left( \frac{1}{\sqrt{g}} \hat{\mathbf B}^{*2}_p \right) \cdot \hat \nabla |\hat B^0_0|_p \,.
-
-    for each marker :math:`p` in markers array.
-    '''
-
-    # allocate metric coeffs
-    df = empty((3, 3), dtype=float)
-
-    # allocate spline values
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-
-    # containers for fields
-    grad_abs_b = empty(3, dtype=float)
-    b_star = empty(3, dtype=float)
-    norm_b1 = empty(3, dtype=float)
-    bb = empty(3, dtype=float)
-    curl_norm_b = empty(3, dtype=float)
-
-    # marker position e
-    e = empty(3, dtype=float)
-
-    # intermediate k-vector
-    k = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    # get number of stages
-    n_stages = shape(b)[0]
-
-    if stage == n_stages - 1:
-        last = 1.
-    else:
-        last = 0.
-
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        e[:] = markers[ip, 0:3]
-        v = markers[ip, 3]
-        mu = markers[ip, 4]
-
-        # evaluate Jacobian, result in df
-        map_eval.df(e[0], e[1], e[2],
-                    kind_map, params_map,
-                    t1_map, t2_map, t3_map, p_map,
-                    ind1_map, ind2_map, ind3_map,
-                    cx, cy, cz,
-                    df)
-
-        # metric coeffs
-        det_df = linalg.det(df)
-
-        # spline evaluation
-        span1 = bsp.find_span(tn1, pn[0], e[0])
-        span2 = bsp.find_span(tn2, pn[1], e[1])
-        span3 = bsp.find_span(tn3, pn[2], e[2])
-
-        bsp.b_d_splines_slim(tn1, pn[0], e[0], span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], e[1], span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], e[2], span3, bn3, bd3)
-
-        # eval all the needed field
-        # grad_abs_b; 1form
-        grad_abs_b[0] = eval_3d.eval_spline_mpi_kernel(
-            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
-        grad_abs_b[1] = eval_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
-        grad_abs_b[2] = eval_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
-
-        # norm_b1; 1form
-        norm_b1[0] = eval_3d.eval_spline_mpi_kernel(
-            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
-
-        # b; 2form
-        bb[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        bb[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        bb[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
-        
-        # curl_norm_b; 2form
-        curl_norm_b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
-
-        # transform to H1vec
-        b_star[:] = bb + 1/kappa*v*curl_norm_b
-        b_star[:] = b_star/det_df
-
-        # calculate abs_b_star_para
-        abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
-
-        # calculate k for X
-        k[:] = b_star/abs_b_star_para*v
-
-        # calculate k_v for v
-        temp = linalg.scalar_dot(b_star, grad_abs_b)
-        k_v = -1*mu/abs_b_star_para*temp
-
-        # accumulation for last stage
-        markers[ip, 13:16] += dt*b[stage]*k
-        markers[ip, 16] += dt*b[stage]*k_v
-
-        # update positions for intermediate stages or last stage
-        markers[ip, 0:3] = markers[ip, 9:12] + \
-            dt*a[stage]*k + last*markers[ip, 13:16]
-        markers[ip, 3] = markers[ip, 12] + dt * \
-            a[stage]*k_v + last*markers[ip, 16]
-
-
-def push_gc_explicit_stage(markers: 'float[:,:]', dt: float, stage: int,
-                           pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                           starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                           kind_map: int, params_map: 'float[:]',
-                           p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                           ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                           cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                           kappa: float,
-                           b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
-                           norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
-                           norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
-                           curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
-                           grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]',
-                           a: 'float[:]', b: 'float[:]', c: 'float[:]'):
-    r'''Single stage of a s-stage Runge-Kutta solve of 
-
-    .. math::
-
-        &\dot{\mathbf H}_p = \frac{\epsilon \mu_p}{|B^*_{p,\parallel}|}  G_p^{-1} \mathbb{b}_{p,0, \otimes}G_p^{-1} \hat \nabla |\hat B^0_{p,0}| + \frac{1}{|B^*_{p,\parallel}|} \left( \frac{1}{\sqrt{g}} \hat{\mathbf B}^{*2}_p \right) v_{p, \parallel}\,,
-
-        &\dot v_{p, \parallel} &= -\frac{\mu}{|B^*_{p,\parallel}|}  \left( \frac{1}{\sqrt{g}} \hat{\mathbf B}^{*2}_p \right) \cdot \hat \nabla |\hat B^0_0|_p \,.
-
-    for each marker :math:`p` in markers array, where :math:`\mathbf v` is constant.
-    '''
-
-    # allocate metric coeffs
-    df = empty((3, 3), dtype=float)
-    df_t = empty((3, 3), dtype=float)
-    g = empty((3, 3), dtype=float)
-    g_inv = empty((3, 3), dtype=float)
-
-    # allocate spline values
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-
-    # containers for fields
-    grad_abs_b = empty(3, dtype=float)
-    temp1 = empty(3, dtype=float)
-    norm_b2 = empty(3, dtype=float)
-    temp2 = empty(3, dtype=float)
-    b_star = empty(3, dtype=float)
-    norm_b1 = empty(3, dtype=float)
-    temp3 = empty(3, dtype=float)
-    bb = empty(3, dtype=float)
-    curl_norm_b = empty(3, dtype=float)
-
-    # marker position e
-    e = empty(3, dtype=float)
-
-    # intermediate k-vector
-    k = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    # get number of stages
-    n_stages = shape(b)[0]
-
-    if stage == n_stages - 1:
-        last = 1.
-    else:
-        last = 0.
-
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        e[:] = markers[ip, 0:3]
-        v = markers[ip, 3]
-        mu = markers[ip, 4]
-
-        # evaluate Jacobian, result in df
-        map_eval.df(e[0], e[1], e[2],
-                    kind_map, params_map,
-                    t1_map, t2_map, t3_map, p_map,
-                    ind1_map, ind2_map, ind3_map,
-                    cx, cy, cz,
-                    df)
-
-        # evaluate inverse of G
-        linalg.transpose(df, df_t)
-        linalg.matrix_matrix(df_t, df, g)
-        linalg.matrix_inv(g, g_inv)
-
-        # metric coeffs
-        det_df = linalg.det(df)
-
-        # spline evaluation
-        span1 = bsp.find_span(tn1, pn[0], e[0])
-        span2 = bsp.find_span(tn2, pn[1], e[1])
-        span3 = bsp.find_span(tn3, pn[2], e[2])
-
-        bsp.b_d_splines_slim(tn1, pn[0], e[0], span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], e[1], span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], e[2], span3, bn3, bd3)
-
-        # eval all the needed field
-        # grad_abs_b; 1form
-        grad_abs_b[0] = eval_3d.eval_spline_mpi_kernel(
-            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
-        grad_abs_b[1] = eval_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
-        grad_abs_b[2] = eval_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
-
-        # norm_b1; 1form
-        norm_b1[0] = eval_3d.eval_spline_mpi_kernel(
-            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
-
-        # norm_b2; 2form
-        norm_b2[0] = eval_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, norm_b21, starts2[0])
-        norm_b2[1] = eval_3d.eval_spline_mpi_kernel(
-            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, norm_b22, starts2[1])
-        norm_b2[2] = eval_3d.eval_spline_mpi_kernel(
-            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, norm_b23, starts2[2])
-
-        # b; 2form
-        bb[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        bb[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        bb[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
-        
-        # curl_norm_b; 2form
-        curl_norm_b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
-
-        # transform to H1vec
-        b_star[:] = bb + 1/kappa*v*curl_norm_b
-        b_star[:] = b_star/det_df
-
-        # calculate abs_b_star_para
-        abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
-
-        # calculate norm_b X grad_abs_b
-        linalg.matrix_vector(g_inv, grad_abs_b, temp1)
-
-        linalg.cross(norm_b2, temp1, temp2)
-
-        linalg.matrix_vector(g_inv, temp2, temp3)
-
-        # calculate k
-        k[:] = (1/kappa*mu*temp3 + b_star*v)/abs_b_star_para
-
-        # calculate k_v for v
-        temp = linalg.scalar_dot(b_star, grad_abs_b)
-
-        k_v = -1*mu/abs_b_star_para*temp
-
-        # accumulation for last stage
-        markers[ip, 13:16] += dt*b[stage]*k
-        markers[ip, 16] += dt*b[stage]*k_v
-
-        # update positions for intermediate stages or last stage
-        markers[ip, 0:3] = markers[ip, 9:12] + \
-            dt*a[stage]*k + last*markers[ip, 13:16]
-        markers[ip, 3] = markers[ip, 12] + dt * \
-            a[stage]*k_v + last*markers[ip, 16]
-
-
-def push_gc1_discrete_gradients(markers: 'float[:,:]', dt: float, stage: int, tol: float,
-                                domain_array: 'float[:]',
-                                pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                                starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                                kind_map: int, params_map: 'float[:]',
-                                p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                                ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                                cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                kappa: float,
-                                abs_b: 'float[:,:,:]',
-                                b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
-                                norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
-                                norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
-                                curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
-                                grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]'):
-    r'''Single stage of the fixed-point iteration for the discrete gradient method
-
-    .. math::
-
-        {\mathbf H}^k_{n+1} = {\mathbf H}_n + dt*S1({\mathbf H}_n)*\bar{\nabla} I_1 ({\mathbf H}_n, {\mathbf H}^{k-1}_{n+1})
-
-    where
-
-    ..math::
-
-        \bar{\nabla} I_1 ({\mathbf H}_n, {\mathbf H}_{n+1}) = \mu \nabla |\hat B^0_0({\mathbf H}_{n+1/2})| + ({\mathbf H}_{n+1} + {\mathbf H}_{n}) \frac{\mu |\hat B^0_0({\mathbf H}_{n+1})| - \mu |\hat B^0_0({\mathbf H}_n)| - ({\mathbf H}_{n+1} - {\mathbf H}_n)\cdot \mu \nabla |\hat B^0_0({\mathbf H}_{n+1/2})|}{||{\mathbf H}_{n+1} - {\mathbf H}_n||^2}
-
-    for each marker :math:`p` in markers array, where :math:`\mathbf v` is constant.
-    '''
-    # allocate spline values
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-
-    # containers for fields
-    temp = empty(3, dtype=float)
-    S = empty((3, 3), dtype=float)
-    grad_I = empty(3, dtype=float)
-
-    # marker position e
-    e = empty(3, dtype=float)
-    e_diff = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        if markers[ip, 23] == -1.:
-            continue
-
-        e[:] = markers[ip, 0:3]
-        e_diff[:] = e[:] - markers[ip, 9:12]
-        mu = markers[ip, 4]
-
-        #TODO: replace with better idea
-        for axis in range(3):
-            if e_diff[axis] > 0.5:
-                e_diff[axis] -= 1.
-            elif e_diff[axis] < -0.5:
-                e_diff[axis] += 1.
-
-        # spline evaluation
-        span1 = bsp.find_span(tn1, pn[0], e[0])
-        span2 = bsp.find_span(tn2, pn[1], e[1])
-        span3 = bsp.find_span(tn3, pn[2], e[2])
-
-        bsp.b_d_splines_slim(tn1, pn[0], e[0], span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], e[1], span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], e[2], span3, bn3, bd3)
-
-        # eval all the needed field
-        # abs_b; 0form
-        abs_b0 = eval_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
-
-        # assemble S
-        S[:, :] = ((markers[ip, 13],  markers[ip, 14], markers[ip, 15]),
-                   (-markers[ip, 14],  markers[ip, 16], markers[ip, 17]),
-                   (-markers[ip, 15], -markers[ip, 17], markers[ip, 18]))
-
-        # calculate grad_I
-        temp_scalar = linalg.scalar_dot(e_diff[:], markers[ip, 20:23])
-        temp_scalar2 = e_diff[0]**2 + e_diff[1]**2 + e_diff[2]**2
-
-        grad_I[:] = markers[ip, 20:23] + e_diff[:] * \
-            (abs_b0*mu - markers[ip, 19] - temp_scalar)/temp_scalar2
-
-        linalg.matrix_vector(S, grad_I, temp)
-
-        markers[ip, 0:3] = markers[ip, 9:12] + dt*temp[:]
-
-        markers[ip, 20:23] = markers[ip, 0:3]
-
-        diff = sqrt((e[0] - markers[ip, 0])**2 +
-                    (e[1] - markers[ip, 1])**2 + (e[2] - markers[ip, 2])**2)
-
-        if diff < tol:
-            markers[ip, 23] = -1.
-            markers[ip, 20] = stage
-            
-            continue
-
-        markers[ip, 0:4] = (markers[ip, 0:4] + markers[ip, 9:13])/2.
-
-
-def push_gc2_discrete_gradients(markers: 'float[:,:]', dt: float, stage: int, tol: float,
-                                domain_array: 'float[:]',
-                                pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                                starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                                kind_map: int, params_map: 'float[:]',
-                                p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                                ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                                cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                kappa: float,
-                                abs_b: 'float[:,:,:]',
-                                b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
-                                norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
-                                norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
-                                curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
-                                grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]'):
-    r'''Single stage of the fixed-point iteration for the discrete gradient method
-
-    .. math::
-
-        {\mathbf z}^k_{n+1} = {\mathbf z}_n + dt*S2({\mathbf z}_n)*\bar{\nabla} I_2 ({\mathbf z}_n, {\mathbf z}^{k-1}_{n+1})
-
-    for each marker :math:`p` in markers array, where :math:`\mathbf v` is constant.
-    '''
-    # allocate spline values
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-
-    # containers for fields
-    grad_I = empty(3, dtype=float)
-
-    # marker position e
-    e = empty(3, dtype=float)
-    e_diff = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        if markers[ip, 23] == -1.:
-            continue
-
-        e[:] = markers[ip, 0:3]
-        e_diff[:] = e[:] - markers[ip, 9:12]
-
-        #TODO: replace with better idea
-        for axis in range(3):
-            if e_diff[axis] > 0.5:
-                e_diff[axis] -= 1.
-            elif e_diff[axis] < -0.5:
-                e_diff[axis] += 1.
-
-        v = markers[ip, 3]
-        v_old = markers[ip, 12]
-        v_mid = (markers[ip, 3] + markers[ip, 12])/2.
-        mu = markers[ip, 4]
-
-        # spline evaluation
-        span1 = bsp.find_span(tn1, pn[0], e[0])
-        span2 = bsp.find_span(tn2, pn[1], e[1])
-        span3 = bsp.find_span(tn3, pn[2], e[2])
-
-        bsp.b_d_splines_slim(tn1, pn[0], e[0], span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], e[1], span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], e[2], span3, bn3, bd3)
-
-        # eval all the needed field
-        # abs_b; 0form
-        abs_b0 = eval_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
-
-        # calculate grad_I
-        temp_scalar = linalg.scalar_dot(e_diff[:], markers[ip, 20:23])
-        temp_scalar2 = e_diff[0]**2 + e_diff[1]**2 + e_diff[2]**2 + (v - v_old)**2
-
-        grad_I[:] = markers[ip, 20:23] + e_diff * (abs_b0*mu - markers[ip, 19] - temp_scalar)/temp_scalar2
-        grad_Iv = v_mid + (v - v_old)*(abs_b0*mu - markers[ip, 19] - temp_scalar)/temp_scalar2
-
-        temp_scalar3 = linalg.scalar_dot(markers[ip, 13:16], grad_I)
-
-        markers[ip, 0:3] = markers[ip, 9:12] + dt*markers[ip, 13:16]*grad_Iv
-        markers[ip, 3] = markers[ip, 12] - dt*temp_scalar3
-
-        markers[ip, 20:24] = markers[ip, 0:4]
-
-        diff = sqrt((e[0] - markers[ip, 0])**2 + (e[1] - markers[ip, 1])**2 + (e[2] - markers[ip, 2])**2 + (v - markers[ip, 3])**2)
-
-        if diff < tol:
-            markers[ip, 23] = -1.
-            markers[ip, 20] = stage
-            continue
-
-        markers[ip, 0:4] = (markers[ip, 0:4] + markers[ip, 9:13])/2.
-
-
-def push_gc1_discrete_gradients_faster(markers: 'float[:,:]', dt: float, stage: int, tol: float,
-                                       domain_array: 'float[:]',
-                                       pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                                       starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                                       kind_map: int, params_map: 'float[:]',
-                                       p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                                       ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                                       cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                       kappa: float,
-                                       abs_b: 'float[:,:,:]',
-                                       b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
-                                       norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
-                                       norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
-                                       curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
-                                       grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]'):
-    r'''Single stage of the fixed-point iteration for the discrete gradient method
-
-    .. math::
-
-        {\mathbf H}^k_{n+1} = {\mathbf H}_n + dt*S1({\mathbf H}_n)*\bar{\nabla} I_1 ({\mathbf H}_n, {\mathbf H}^{k-1}_{n+1})
-
-    where
-
-    ..math::
-
-        \bar{\nabla} I_1 ({\mathbf H}_n, {\mathbf H}_{n+1}) = \mu \nabla |\hat B^0_0({\mathbf H}_{n+1/2})| + ({\mathbf H}_{n+1} + {\mathbf H}_{n}) \frac{\mu |\hat B^0_0({\mathbf H}_{n+1})| - \mu |\hat B^0_0({\mathbf H}_n)| - ({\mathbf H}_{n+1} - {\mathbf H}_n)\cdot \mu \nabla |\hat B^0_0({\mathbf H}_{n+1/2})|}{||{\mathbf H}_{n+1} - {\mathbf H}_n||^2}
-
-    for each marker :math:`p` in markers array, where :math:`\mathbf v` is constant.
-    '''
-    # allocate spline values
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-
-    # containers for fields
-    temp = empty(3, dtype=float)
-    S = empty((3, 3), dtype=float)
-    grad_I = empty(3, dtype=float)
-
-    # marker position e
-    e = empty(3, dtype=float)
-    e_diff = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        if markers[ip, 23] == -1.:
-            continue
-
-        e[:] = markers[ip, 0:3]
-        e_diff[:] = e[:] - markers[ip, 9:12]
-        mu = markers[ip, 4]
-
-        #TODO: replace with better idea
-        for axis in range(3):
-            if e_diff[axis] > 0.5:
-                e_diff[axis] -= 1.
-            elif e_diff[axis] < -0.5:
-                e_diff[axis] += 1.
-
-        # spline evaluation
-        span1 = bsp.find_span(tn1, pn[0], e[0])
-        span2 = bsp.find_span(tn2, pn[1], e[1])
-        span3 = bsp.find_span(tn3, pn[2], e[2])
-
-        bsp.b_d_splines_slim(tn1, pn[0], e[0], span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], e[1], span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], e[2], span3, bn3, bd3)
-
-        # eval all the needed field
-        # abs_b; 0form
-        abs_b0 = eval_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
-
-        # assemble S
-        S[:, :] = ((markers[ip, 13],  markers[ip, 14], markers[ip, 15]),
-                   (-markers[ip, 14],  markers[ip, 16], markers[ip, 17]),
-                   (-markers[ip, 15], -markers[ip, 17], markers[ip, 18]))
-
-        # calculate grad_I
-        temp_scalar = linalg.scalar_dot(e_diff[:], markers[ip, 20:23])
-        temp_scalar2 = e_diff[0]**2 + e_diff[1]**2 + e_diff[2]**2
-
-        grad_I[:] = markers[ip, 20:23] + e_diff[:] * (abs_b0*mu - markers[ip, 19] - temp_scalar)/temp_scalar2
-
-        linalg.matrix_vector(S, grad_I, temp)
-
-        markers[ip, 0:3] = markers[ip, 9:12] + dt*temp[:]
-
-        markers[ip, 20:23] = markers[ip, 0:3]
-
-        diff = sqrt((e[0] - markers[ip, 0])**2 +
-                    (e[1] - markers[ip, 1])**2 + (e[2] - markers[ip, 2])**2)
-
-        if diff < tol:
-            markers[ip, 23] = -1.
-            markers[ip, 20] = stage
-
-            continue
-
-        markers[ip, 0:3] = (markers[ip, 0:3] + markers[ip, 9:12])/2.
-
-
-def push_gc2_discrete_gradients_faster(markers: 'float[:,:]', dt: float, stage: int, tol: float,
-                                       domain_array: 'float[:]',
-                                       pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                                       starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                                       kind_map: int, params_map: 'float[:]',
-                                       p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                                       ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                                       cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                       kappa: float,
-                                       abs_b: 'float[:,:,:]',
-                                       b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
-                                       norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
-                                       norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
-                                       curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
-                                       grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]'):
-    r'''Single stage of the fixed-point iteration for the discrete gradient method
-
-    .. math::
-
-        {\mathbf z}^k_{n+1} = {\mathbf z}_n + dt*S2({\mathbf z}_n)*\bar{\nabla} I_2 ({\mathbf z}_n, {\mathbf z}^{k-1}_{n+1})
-
-    for each marker :math:`p` in markers array, where :math:`\mathbf v` is constant.
-    '''
-
-    # allocate spline values
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-
-    # containers for fields
-    grad_I = empty(3, dtype=float)
-
-    # marker position e
-    e = empty(3, dtype=float)
-    e_diff = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        if markers[ip, 23] == -1.:
-            continue
-
-        e[:] = markers[ip, 0:3]
-        e_diff[:] = e[:] - markers[ip, 9:12]
-
-        #TODO: replace with better idea
-        for axis in range(3):
-            if e_diff[axis] > 0.5:
-                e_diff[axis] -= 1.
-            elif e_diff[axis] < -0.5:
-                e_diff[axis] += 1.
-
-        v = markers[ip, 3]
-        v_old = markers[ip, 12]
-        v_mid = (markers[ip, 3] + markers[ip, 12])/2.
-        mu = markers[ip, 4]
-
-        # spline evaluation
-        span1 = bsp.find_span(tn1, pn[0], e[0])
-        span2 = bsp.find_span(tn2, pn[1], e[1])
-        span3 = bsp.find_span(tn3, pn[2], e[2])
-
-        bsp.b_d_splines_slim(tn1, pn[0], e[0], span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], e[1], span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], e[2], span3, bn3, bd3)
-
-        # eval all the needed field
-        # abs_b; 0form
-        abs_b0 = eval_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
-
-        # calculate grad_I
-        temp_scalar = linalg.scalar_dot(e_diff[:], markers[ip, 20:23])
-        temp_scalar2 = e_diff[0]**2 + e_diff[1]**2 + e_diff[2]**2 + (v - v_old)**2
-
-        grad_I[:] = markers[ip, 20:23] + e_diff * (abs_b0*mu - markers[ip, 19] - temp_scalar)/temp_scalar2
-        grad_Iv = v_mid + (v - v_old)*(abs_b0*mu - markers[ip, 19] - temp_scalar)/temp_scalar2
-
-        temp_scalar3 = linalg.scalar_dot(markers[ip, 13:16], grad_I)
-
-        markers[ip, 0:3] = markers[ip, 9:12] + dt*markers[ip, 13:16]*grad_Iv
-        markers[ip, 3] = markers[ip, 12] - dt*temp_scalar3
-
-        markers[ip, 20:23] = markers[ip, 0:3]
-
-        diff = sqrt((e[0] - markers[ip, 0])**2 + (e[1] - markers[ip, 1])**2 + (e[2] - markers[ip, 2])**2 + (v - markers[ip, 3])**2)
-
-        if diff < tol:
-            markers[ip, 23] = -1.
-            markers[ip, 20] = stage
-            continue
-
-        markers[ip, 0:3] = (markers[ip, 0:3] + markers[ip, 9:12])/2.
-
-
-def push_gc1_discrete_gradients_Itoh_Newton(markers: 'float[:,:]', dt: float, stage: int, max_iter: int, tol: float,
-                                            domain_array: 'float[:]',
-                                            pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                                            starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                                            kind_map: int, params_map: 'float[:]',
-                                            p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                                            ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                                            cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                            kappa: float,
-                                            abs_b: 'float[:,:,:]',
-                                            b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
-                                            norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
-                                            norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
-                                            curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
-                                            grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]'):
-    r'''
-    '''
-    # allocate spline values
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-
-    # containers for fields
-    identity = zeros((3, 3), dtype=float)
-    temp = empty(3, dtype=float)
-    F = empty(3, dtype=float)
-    S = empty((3, 3), dtype=float)
-    grad_abs_b = empty(3, dtype=float)
-    grad_I = empty(3, dtype=float)
-    Jacobian_grad_I = empty((3, 3), dtype=float)
-    Jacobian = empty((3, 3), dtype=float)
-    Jacobian_inv = empty((3, 3), dtype=float)
-
-    # marker position e
-    e = empty(3, dtype=float)
-    e_old = empty(3, dtype=float)
-    e_diff = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        if markers[ip, 13] == -1.:
-            continue
-
-        e[:] = markers[ip, 0:3]
-        e_old[:] = markers[ip, 9:12]
-        mu = markers[ip, 4]
-
-        e_diff[:] = e[:] - e_old[:]
-
-        for axis in range(3):
-            if e_diff[axis] > 0.5:
-                e_diff[axis] -= 1.
-            elif e_diff[axis] < -0.5:
-                e_diff[axis] += 1.
-
-        # assemble S
-        S[:, :] = ((              0.,  markers[ip, 13], markers[ip, 14]),
-                   (-markers[ip, 13],               0., markers[ip, 15]),
-                   (-markers[ip, 14], -markers[ip, 15],              0.))
-
-        # identity matrix
-        identity[0, 0] = 1.
-        identity[1, 1] = 1.
-        identity[2, 2] = 1.
-
-        # spline evaluation
-        span1 = bsp.find_span(tn1, pn[0], e[0])
-        span2 = bsp.find_span(tn2, pn[1], e[1])
-        span3 = bsp.find_span(tn3, pn[2], e[2])
-
-        bsp.b_d_splines_slim(tn1, pn[0], e[0], span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], e[1], span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], e[2], span3, bn3, bd3)
-
-        # eval all the needed field
-        # abs_b; 0form
-        abs_b0 = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
-
-        # grad_abs_b; 1form
-        grad_abs_b[0] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
-        grad_abs_b[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
-        grad_abs_b[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
-
-        # assemble gradI
-        grad_I[0] = mu*(markers[ip,20] - markers[ip,19])/(e_diff[0])
-        grad_I[1] = mu*(markers[ip,22] - markers[ip,20])/(e_diff[1])
-        grad_I[2] = mu*(abs_b0         - markers[ip,22])/(e_diff[2])
-
-        # calculate F = eta - eta_old + dt*S*grad_I
-        linalg.matrix_vector(S,grad_I,F)
-        F *= -dt
-        F += e_diff[:]
-
-        # assemble Jacobian_grad_I
-        Jacobian_grad_I[0,0] = mu*(markers[ip, 21]*(e_diff[0]) - markers[ip, 20] + markers[ip, 19])/(e_diff[0])**2
-        Jacobian_grad_I[1,0] = mu*(markers[ip, 23]                   - markers[ip, 21])/(e_diff[1])
-        Jacobian_grad_I[2,0] = mu*(grad_abs_b[0]                     - markers[ip, 23])/(e_diff[2])
-        Jacobian_grad_I[0,1] = 0.
-        Jacobian_grad_I[1,1] = mu*(markers[ip, 24]*(e_diff[1]) - markers[ip, 22] + markers[ip, 20])/(e_diff[1])**2
-        Jacobian_grad_I[2,1] = mu*(grad_abs_b[1]                     - markers[ip, 24])/(e_diff[2])
-        Jacobian_grad_I[0,2] = 0.
-        Jacobian_grad_I[1,2] = 0.
-        Jacobian_grad_I[2,2] = mu*(grad_abs_b[2]*(e_diff[2]) - abs_b0 + markers[ip, 22])/(e_diff[2])**2
-
-        # assemble Jacobian and its inverse
-        linalg.matrix_matrix(S,Jacobian_grad_I,Jacobian)
-        Jacobian *= dt
-        Jacobian += identity
-
-        linalg.matrix_inv(Jacobian, Jacobian_inv)
-
-        # calculate eta_new
-        linalg.matrix_vector(Jacobian_inv,F,temp)
-        markers[ip,16:19] = e[:] - temp
-
-        diff = sqrt((temp[0])**2 + (temp[1])**2 + (temp[2])**2)
-
-        if diff < tol:
-            markers[ip, 13] = -1.
-            markers[ip, 14] = stage
-            markers[ip, 0:3] = markers[ip, 16:19]
-
-            continue
-
-        if stage ==  max_iter-1:
-            markers[ip, 0:3] = markers[ip, 16:19]
-
-            continue
-
-        markers[ip, 0] = markers[ip,16]
-        markers[ip, 1] = e_old[1]
-        markers[ip, 2] = e_old[2]
-
-
-def push_gc2_discrete_gradients_Itoh_Newton(markers: 'float[:,:]', dt: float, stage: int, max_iter: int, tol: float,
-                                            domain_array: 'float[:]',
-                                            pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                                            starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                                            kind_map: int, params_map: 'float[:]',
-                                            p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                                            ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                                            cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                            kappa: float,
-                                            abs_b: 'float[:,:,:]',
-                                            b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
-                                            norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
-                                            norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
-                                            curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
-                                            grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]'):
-    r'''
-    '''
-    # allocate spline values
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-
-    # containers for fields
-    identity = zeros((4, 4), dtype=float)
-    temp = empty(4, dtype=float)
-    F = empty(4, dtype=float)
-    S = zeros((4, 4), dtype=float)
-    grad_abs_b = empty(3, dtype=float)
-    grad_I = empty(4, dtype=float)
-    Jacobian_grad_I = empty((4, 4), dtype=float)
-    Jacobian = empty((4, 4), dtype=float)
-    Jacobian_inv = empty((4, 4), dtype=float)
-    Jacobian_temp34 = empty((3,4), dtype=float)
-    Jacobian_temp33 = empty((3,3), dtype=float)
-
-    # marker position e
-    e = empty(3, dtype=float)
-    e_old = empty(3, dtype=float)
-    e_diff = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        if markers[ip, 13] == -1.:
-            continue
-
-        e[:] = markers[ip, 0:3]
-        e_old[:] = markers[ip, 9:12]
-        v = markers[ip, 3]
-        v_old = markers[ip, 12]
-        v_mid = (v + v_old)/2.
-        mu = markers[ip, 4]
-
-        e_diff[:] = e[:] - e_old[:]
-
-        for axis in range(3):
-            if e_diff[axis] > 0.5:
-                e_diff[axis] -= 1.
-            elif e_diff[axis] < -0.5:
-                e_diff[axis] += 1.
-
-        # assemble S
-        S[0:3, 3] = markers[ip, 13:16]
-        S[3, 0:3] = -markers[ip, 13:16]
-
-        # identity matrix
-        identity[0, 0] = 1.
-        identity[1, 1] = 1.
-        identity[2, 2] = 1.
-        identity[3, 3] = 1.
-
-        # spline evaluation
-        span1 = bsp.find_span(tn1, pn[0], e[0])
-        span2 = bsp.find_span(tn2, pn[1], e[1])
-        span3 = bsp.find_span(tn3, pn[2], e[2])
-
-        bsp.b_d_splines_slim(tn1, pn[0], e[0], span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], e[1], span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], e[2], span3, bn3, bd3)
-
-        # eval all the needed field
-        # abs_b; 0form
-        abs_b0 = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
-
-        # grad_abs_b; 1form
-        grad_abs_b[0] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
-        grad_abs_b[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
-        grad_abs_b[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
-
-        # assemble gradI
-        grad_I[0] = mu*(markers[ip,20] - markers[ip,19])/(e_diff[0])
-        grad_I[1] = mu*(markers[ip,22] - markers[ip,20])/(e_diff[1])
-        grad_I[2] = mu*(abs_b0         - markers[ip,22])/(e_diff[2])
-        grad_I[3] = v_mid
-
-        # calculate F = eta - eta_old + dt*S*grad_I
-        linalg.matrix_vector4(S,grad_I,F)
-        F *= -dt
-        F[0:3] += e_diff[:]
-        F[3] += v - v_old
-
-        # assemble Jacobian_grad_I
-        Jacobian_grad_I[0,0] = mu*(markers[ip, 21]*(e_diff[0]) - markers[ip, 20] + markers[ip, 19])/(e_diff[0])**2
-        Jacobian_grad_I[1,0] = mu*(markers[ip, 20]                   - markers[ip, 21])/(e_diff[1])
-        Jacobian_grad_I[2,0] = mu*(grad_abs_b[0]                     - markers[ip, 20])/(e_diff[2])
-        Jacobian_grad_I[3,0] = 0.
-
-        Jacobian_grad_I[0,1] = 0.
-        Jacobian_grad_I[1,1] = mu*(markers[ip, 21]*(e_diff[1]) - markers[ip, 22] + markers[ip, 20])/(e_diff[1])**2
-        Jacobian_grad_I[2,1] = mu*(grad_abs_b[1]                     - markers[ip, 21])/(e_diff[2])
-        Jacobian_grad_I[3,1] = 0.
-
-        Jacobian_grad_I[0,2] = 0.
-        Jacobian_grad_I[1,2] = 0.
-        Jacobian_grad_I[2,2] = mu*(grad_abs_b[2]*(e_diff[2]) - abs_b0 + markers[ip, 22])/(e_diff[2])**2
-        Jacobian_grad_I[3,2] = 0.
-
-        Jacobian_grad_I[0,3] = 0.
-        Jacobian_grad_I[1,3] = 0.
-        Jacobian_grad_I[2,3] = 0.
-        Jacobian_grad_I[3,3] = 0.5
-
-        # assemble Jacobian and its inverse
-        linalg.matrix_matrix4(S,Jacobian_grad_I,Jacobian)
-        Jacobian *= -dt
-        Jacobian += identity
-
-        # Inverse of the Jacobian
-        det_J = linalg.det4(Jacobian)
-
-        Jacobian_inv[0, 0] =  linalg.det(Jacobian[1:     ,1:])/det_J
-        Jacobian_inv[0, 1] = -linalg.det(Jacobian[(0,2,3),1:])/det_J
-        Jacobian_inv[0, 2] =  linalg.det(Jacobian[(0,1,3),1:])/det_J
-        Jacobian_inv[0, 3] = -linalg.det(Jacobian[:3     ,1:])/det_J
-
-        Jacobian_inv[1, 0] = -linalg.det(Jacobian[1:,(0,2,3)])/det_J
-        Jacobian_temp34 = Jacobian[(0,2,3),:]
-        Jacobian_temp33 = Jacobian_temp34[:,(0,2,3)]
-        Jacobian_inv[1, 1] =  linalg.det(Jacobian_temp33)/det_J
-        Jacobian_temp34 = Jacobian[(0,1,3),:]
-        Jacobian_temp33 = Jacobian_temp34[:,(0,2,3)]
-        Jacobian_inv[1, 2] = -linalg.det(Jacobian_temp33)/det_J
-        Jacobian_inv[1, 3] =  linalg.det(Jacobian[:3,(0,2,3)])/det_J
-
-        Jacobian_inv[2, 0] =  linalg.det(Jacobian[1:,(0,1,3)])/det_J
-        Jacobian_temp34 = Jacobian[(0,2,3),:]
-        Jacobian_temp33 = Jacobian_temp34[:,(0,1,3)]
-        Jacobian_inv[2, 1] = -linalg.det(Jacobian_temp33)/det_J
-        Jacobian_temp34 = Jacobian[(0,1,3),:]
-        Jacobian_temp33 = Jacobian_temp34[:,(0,1,3)]
-        Jacobian_inv[2, 2] =  linalg.det(Jacobian_temp33)/det_J
-        Jacobian_inv[2, 3] = -linalg.det(Jacobian[:3,(0,1,3)])/det_J
-
-        Jacobian_inv[3, 0] = -linalg.det(Jacobian[1:     ,:3])/det_J
-        Jacobian_inv[3, 1] =  linalg.det(Jacobian[(0,2,3),:3])/det_J
-        Jacobian_inv[3, 2] = -linalg.det(Jacobian[(0,1,3),:3])/det_J
-        Jacobian_inv[3, 3] =  linalg.det(Jacobian[:3     ,:3])/det_J
-
-        # calculate eta_new
-        linalg.matrix_vector4(Jacobian_inv,F,temp)
-        markers[ip, 16:19] = e[:] - temp[0:3]
-        markers[ip, 3] = v - temp[3]
-
-        diff = sqrt((temp[0])**2 + (temp[1])**2 + (temp[2])**2)
-
-        if diff < tol:
-            markers[ip, 13] = -1.
-            markers[ip, 14] = stage
-            markers[ip, 0:3] = markers[ip, 16:19]
-
-            continue
-
-        if stage == max_iter-1:
-            markers[ip, 0:3] = markers[ip, 16:19]
-
-            continue
-
-        markers[ip, 0] = markers[ip,16]
-        markers[ip, 1] = e_old[1]
-        markers[ip, 2] = e_old[2]
-
-
-def push_gc_cc_J1_H1vec(markers: 'float[:,:]', dt: float, stage: int,
-                       pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                       starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                       kind_map: int, params_map: 'float[:]',
-                       p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                       ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                       cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                       kappa: float,
-                       b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
-                       norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
-                       curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
-                       u1: 'float[:,:,:]', u2: 'float[:,:,:]', u3: 'float[:,:,:]'):
-    r'''
-    TODO
-    '''
-
-    # allocate metric coeffs
-    df = empty((3, 3), dtype=float)
-
-    # allocate spline values
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-
-    # containers for fields
-    e = empty(3, dtype=float)
-    u = empty(3, dtype=float)
-    b = empty(3, dtype=float)
-    b_star = empty(3, dtype=float)
-    norm_b1 = empty(3, dtype=float)
-    curl_norm_b = empty(3, dtype=float)
-
-    # marker position eta
-    eta = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        eta[:] = markers[ip, 0:3]
-        v = markers[ip, 3]
-
-        # evaluate Jacobian, result in df
-        map_eval.df(eta[0], eta[1], eta[2],
-                    kind_map, params_map,
-                    t1_map, t2_map, t3_map, p_map,
-                    ind1_map, ind2_map, ind3_map,
-                    cx, cy, cz,
-                    df)
-
-        # metric coeffs
-        det_df = linalg.det(df)
-
-        # spline evaluation
-        span1 = bsp.find_span(tn1, pn[0], eta[0])
-        span2 = bsp.find_span(tn2, pn[1], eta[1])
-        span3 = bsp.find_span(tn3, pn[2], eta[2])
-
-        bsp.b_d_splines_slim(tn1, pn[0], eta[0], span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], eta[1], span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], eta[2], span3, bn3, bd3)
-
-        # eval all the needed field
-        # b; 2form
-        b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
-
-        # u; 0form
-        u[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, u1, starts0)
-        u[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, u2, starts0)
-        u[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, u3, starts0)
-
-        # norm_b1; 1form
-        norm_b1[0] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
-
-        # curl_norm_b; 2form
-        curl_norm_b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
-
-        # b_star; 2form in H1vec
-        b_star[:] = (b + curl_norm_b*v/kappa)/det_df
-
-        # calculate abs_b_star_para
-        abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
-
-        # electric field E(1) = B(2) X U(0)
-        linalg.cross(b, u, e)
-
-        # curl_norm_b dot electric field
-        temp = linalg.scalar_dot(e, curl_norm_b) / det_df
-
-        markers[ip, 3] += temp/abs_b_star_para*v*dt
-
-
-def push_gc_cc_J1_Hcurl(markers: 'float[:,:]', dt: float, stage: int,
-                       pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                       starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                       kind_map: int, params_map: 'float[:]',
-                       p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                       ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                       cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                       kappa: float,
-                       b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
-                       norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
-                       curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
-                       u1: 'float[:,:,:]', u2: 'float[:,:,:]', u3: 'float[:,:,:]'):
-    r'''
-    TODO
-    '''
-
-    # allocate metric coeffs
-    df = empty((3, 3), dtype=float)
-    df_t = empty((3, 3), dtype=float)
-    g = empty((3, 3), dtype=float)
-    g_inv = empty((3, 3), dtype=float)
-
-    # allocate spline values
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-
-    # containers for fields
-    e = empty(3, dtype=float)
-    u = empty(3, dtype=float)
-    u0 = empty(3, dtype=float)
-    b = empty(3, dtype=float)
-    b_star = empty(3, dtype=float)
-    norm_b1 = empty(3, dtype=float)
-    curl_norm_b = empty(3, dtype=float)
-
-    # marker position eta
-    eta = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        eta[:] = markers[ip, 0:3]
-        v = markers[ip, 3]
-
-        # evaluate Jacobian, result in df
-        map_eval.df(eta[0], eta[1], eta[2],
-                    kind_map, params_map,
-                    t1_map, t2_map, t3_map, p_map,
-                    ind1_map, ind2_map, ind3_map,
-                    cx, cy, cz,
-                    df)
-
-        # evaluate inverse of G
-        linalg.transpose(df, df_t)
-        linalg.matrix_matrix(df_t, df, g)
-        linalg.matrix_inv(g, g_inv)
-
-        # metric coeffs
-        det_df = linalg.det(df)
-
-        # spline evaluation
-        span1 = bsp.find_span(tn1, pn[0], eta[0])
-        span2 = bsp.find_span(tn2, pn[1], eta[1])
-        span3 = bsp.find_span(tn3, pn[2], eta[2])
-
-        bsp.b_d_splines_slim(tn1, pn[0], eta[0], span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], eta[1], span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], eta[2], span3, bn3, bd3)
-
-        # eval all the needed field
-        # b; 2form
-        b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
-
-        # u; 1form
-        u[0] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, u1, starts1[0])
-        u[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, u2, starts1[1])
-        u[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, u3, starts1[2])
-
-        # norm_b1; 1form
-        norm_b1[0] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
-
-        # curl_norm_b; 2form
-        curl_norm_b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
-
-        # b_star; 2form in H1vec
-        b_star[:] = (b + curl_norm_b*v/kappa)/det_df
-
-        # calculate abs_b_star_para
-        abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
-
-        # transform u into H1vec
-        linalg.matrix_vector(g_inv, u, u0)
-
-        # electric field E(1) = B(2) X U(0)
-        linalg.cross(b, u0, e)
-
-        # curl_norm_b dot electric field
-        temp = linalg.scalar_dot(e, curl_norm_b) / det_df
-
-        markers[ip, 3] += temp/abs_b_star_para*v*dt
-
-
-def push_gc_cc_J1_Hdiv(markers: 'float[:,:]', dt: float, stage: int,
-                       pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                       starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                       kind_map: int, params_map: 'float[:]',
-                       p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                       ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                       cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                       kappa: float,
-                       b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
-                       norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
-                       curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
-                       u1: 'float[:,:,:]', u2: 'float[:,:,:]', u3: 'float[:,:,:]'):
-    r'''
-    TODO
-    '''
-
-    # allocate metric coeffs
-    df = empty((3, 3), dtype=float)
-
-    # allocate spline values
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-
-    # containers for fields
-    e = empty(3, dtype=float)
-    u = empty(3, dtype=float)
-    b = empty(3, dtype=float)
-    b_star = empty(3, dtype=float)
-    norm_b1 = empty(3, dtype=float)
-    curl_norm_b = empty(3, dtype=float)
-
-    # marker position eta
-    eta = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        eta[:] = markers[ip, 0:3]
-        v = markers[ip, 3]
-
-        # evaluate Jacobian, result in df
-        map_eval.df(eta[0], eta[1], eta[2],
-                    kind_map, params_map,
-                    t1_map, t2_map, t3_map, p_map,
-                    ind1_map, ind2_map, ind3_map,
-                    cx, cy, cz,
-                    df)
-
-        # metric coeffs
-        det_df = linalg.det(df)
-
-        # spline evaluation
-        span1 = bsp.find_span(tn1, pn[0], eta[0])
-        span2 = bsp.find_span(tn2, pn[1], eta[1])
-        span3 = bsp.find_span(tn3, pn[2], eta[2])
-
-        bsp.b_d_splines_slim(tn1, pn[0], eta[0], span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], eta[1], span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], eta[2], span3, bn3, bd3)
-
-        # eval all the needed field
-        # b; 2form
-        b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
-
-        # u; 2form
-        u[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, u1, starts2[0])
-        u[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, u2, starts2[1])
-        u[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, u3, starts2[2])
-
-        # norm_b1; 1form
-        norm_b1[0] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
-
-        # curl_norm_b; 2form
-        curl_norm_b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
-
-        # b_star; 2form in H1vec
-        b_star[:] = (b + curl_norm_b*v/kappa)/det_df
-
-        # calculate abs_b_star_para
-        abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
-
-        # transform u into H1vec
-        u = u/det_df
-
-        # electric field E(1) = B(2) X U(0)
-        linalg.cross(b, u, e)
-
-        # curl_norm_b dot electric field
-        temp = linalg.scalar_dot(e, curl_norm_b) / det_df
-
-        markers[ip, 3] += temp/abs_b_star_para*v*dt
-
-
-def push_gc_cc_J2_dg_prepare_H1vec(markers: 'float[:,:]', dt: float, stage: int,
-                       pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                       starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                       kind_map: int, params_map: 'float[:]',
-                       p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                       ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                       cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                       kappa: float,
-                       b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
-                       norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
-                       norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
-                       curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
-                       u1: 'float[:,:,:]', u2: 'float[:,:,:]', u3: 'float[:,:,:]'):
-    r'''
-    TODO
-    '''
-
-    # allocate metric coeffs
-    df = empty((3, 3), dtype=float)
-    df_inv   = empty((3, 3), dtype=float)
-    df_inv_t = empty((3, 3), dtype=float)
-    g_inv    = empty((3, 3), dtype=float)
-
-    # allocate spline values
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-
-    # containers for fields
-    tmp1 = empty((3,3), dtype=float)
-    tmp2 = empty((3,3), dtype=float)
-    b_prod = zeros((3,3), dtype=float)
-    norm_b2_prod = zeros((3,3), dtype=float)
-    e = empty(3, dtype=float)
-    u = empty(3, dtype=float)
-    b = empty(3, dtype=float)
-    b_star = empty(3, dtype=float)
-    norm_b1 = empty(3, dtype=float)
-    norm_b2 = empty(3, dtype=float)
-    curl_norm_b = empty(3, dtype=float)
-
-    # marker position eta
-    eta = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        eta[:] = markers[ip, 0:3]
-        v = markers[ip, 3]
-
-        # evaluate Jacobian, result in df
-        map_eval.df(eta[0], eta[1], eta[2],
-                    kind_map, params_map,
-                    t1_map, t2_map, t3_map, p_map,
-                    ind1_map, ind2_map, ind3_map,
-                    cx, cy, cz,
-                    df)
-
-        # metric coeffs
-        det_df = linalg.det(df)
-        linalg.matrix_inv_with_det(df, det_df, df_inv)
-        linalg.transpose(df_inv, df_inv_t)
-        linalg.matrix_matrix(df_inv, df_inv_t, g_inv)
-
-        # spline evaluation
-        span1 = bsp.find_span(tn1, pn[0], eta[0])
-        span2 = bsp.find_span(tn2, pn[1], eta[1])
-        span3 = bsp.find_span(tn3, pn[2], eta[2])
-
-        bsp.b_d_splines_slim(tn1, pn[0], eta[0], span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], eta[1], span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], eta[2], span3, bn3, bd3)
-
-        # eval all the needed field
-        # b; 2form
-        b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
-
-        # u; 0form
-        u[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, u1, starts0)
-        u[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, u2, starts0)
-        u[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, u3, starts0)
-
-        # norm_b1; 1form
-        norm_b1[0] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
-
-        # norm_b; 2form
-        norm_b2[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, norm_b21, starts2[0])
-        norm_b2[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, norm_b22, starts2[1])
-        norm_b2[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, norm_b23, starts2[2])
-
-        # curl_norm_b; 2form
-        curl_norm_b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
-
-        # operator bx() as matrix
-        b_prod[0, 1] = -b[2]
-        b_prod[0, 2] = +b[1]
-        b_prod[1, 0] = +b[2]
-        b_prod[1, 2] = -b[0]
-        b_prod[2, 0] = -b[1]
-        b_prod[2, 1] = +b[0]
-
-        norm_b2_prod[0, 1] = -norm_b2[2]
-        norm_b2_prod[0, 2] = +norm_b2[1]
-        norm_b2_prod[1, 0] = +norm_b2[2]
-        norm_b2_prod[1, 2] = -norm_b2[0]
-        norm_b2_prod[2, 0] = -norm_b2[1]
-        norm_b2_prod[2, 1] = +norm_b2[0]
-
-        # b_star; 2form in H1vec
-        b_star[:] = (b + curl_norm_b*v/kappa)/det_df
-
-        # calculate abs_b_star_para
-        abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
-
-        linalg.matrix_matrix(g_inv, norm_b2_prod, tmp1)
-        linalg.matrix_matrix(tmp1, g_inv, tmp2)
-        linalg.matrix_matrix(tmp2, b_prod, tmp1)
-
-        linalg.matrix_vector(tmp1, u, e)
-
-        markers[ip, 0:3] = markers[ip, 9:12]- e/abs_b_star_para*dt
-
-
-def push_gc_cc_J2_dg_H1vec(markers: 'float[:,:]', dt: float, stage: int,
-                       pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                       starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                       kind_map: int, params_map: 'float[:]',
-                       p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                       ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                       cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                       kappa: float,
-                       b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
-                       norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
-                       norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
-                       curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
-                       u1: 'float[:,:,:]', u2: 'float[:,:,:]', u3: 'float[:,:,:]'):
-    r'''
-    TODO
-    '''
-
-    # allocate metric coeffs
-    df = empty((3, 3), dtype=float)
-    df_inv   = empty((3, 3), dtype=float)
-    df_inv_t = empty((3, 3), dtype=float)
-    g_inv    = empty((3, 3), dtype=float)
-
-    # allocate spline values
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-
-    # containers for fields
-    tmp1 = empty((3,3), dtype=float)
-    tmp2 = empty((3,3), dtype=float)
-    b_prod = zeros((3,3), dtype=float)
-    norm_b2_prod = zeros((3,3), dtype=float)
-    e = empty(3, dtype=float)
-    u = empty(3, dtype=float)
-    b = empty(3, dtype=float)
-    b_star = empty(3, dtype=float)
-    norm_b1 = empty(3, dtype=float)
-    norm_b2 = empty(3, dtype=float)
-    curl_norm_b = empty(3, dtype=float)
-
-    # marker position eta
-    eta = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        eta[:] = markers[ip, 0:3]
-        v = markers[ip, 3]
-
-        # evaluate Jacobian, result in df
-        map_eval.df(eta[0], eta[1], eta[2],
-                    kind_map, params_map,
-                    t1_map, t2_map, t3_map, p_map,
-                    ind1_map, ind2_map, ind3_map,
-                    cx, cy, cz,
-                    df)
-
-        # metric coeffs
-        det_df = linalg.det(df)
-        linalg.matrix_inv_with_det(df, det_df, df_inv)
-        linalg.transpose(df_inv, df_inv_t)
-        linalg.matrix_matrix(df_inv, df_inv_t, g_inv)
-
-        # spline evaluation
-        span1 = bsp.find_span(tn1, pn[0], eta[0])
-        span2 = bsp.find_span(tn2, pn[1], eta[1])
-        span3 = bsp.find_span(tn3, pn[2], eta[2])
-
-        bsp.b_d_splines_slim(tn1, pn[0], eta[0], span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], eta[1], span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], eta[2], span3, bn3, bd3)
-
-        # eval all the needed field
-        # b; 2form
-        b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
-
-        # u; 0form
-        u[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, u1, starts0)
-        u[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, u2, starts0)
-        u[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, u3, starts0)
-
-        # norm_b1; 1form
-        norm_b1[0] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
-
-        # norm_b; 2form
-        norm_b2[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, norm_b21, starts2[0])
-        norm_b2[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, norm_b22, starts2[1])
-        norm_b2[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, norm_b23, starts2[2])
-
-        # curl_norm_b; 2form
-        curl_norm_b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
-
-        # operator bx() as matrix
-        b_prod[0, 1] = -b[2]
-        b_prod[0, 2] = +b[1]
-        b_prod[1, 0] = +b[2]
-        b_prod[1, 2] = -b[0]
-        b_prod[2, 0] = -b[1]
-        b_prod[2, 1] = +b[0]
-
-        norm_b2_prod[0, 1] = -norm_b2[2]
-        norm_b2_prod[0, 2] = +norm_b2[1]
-        norm_b2_prod[1, 0] = +norm_b2[2]
-        norm_b2_prod[1, 2] = -norm_b2[0]
-        norm_b2_prod[2, 0] = -norm_b2[1]
-        norm_b2_prod[2, 1] = +norm_b2[0]
-
-        # b_star; 2form in H1vec
-        b_star[:] = (b + curl_norm_b*v/kappa)/det_df
-
-        # calculate abs_b_star_para
-        abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
-
-        linalg.matrix_matrix(g_inv, norm_b2_prod, tmp1)
-        linalg.matrix_matrix(tmp1, g_inv, tmp2)
-        linalg.matrix_matrix(tmp2, b_prod, tmp1)
-
-        linalg.matrix_vector(tmp1, u, e)
-
-        markers[ip, 0:3] = markers[ip, 9:12]- e/abs_b_star_para*dt
-
-
-def push_gc_cc_J2_dg_faster_H1vec(markers: 'float[:,:]', dt: float, stage: int,
-                       pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                       starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                       kind_map: int, params_map: 'float[:]',
-                       p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                       ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                       cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                       kappa: float,
-                       b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
-                       norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
-                       norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
-                       curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
-                       u1: 'float[:,:,:]', u2: 'float[:,:,:]', u3: 'float[:,:,:]'):
-    r'''
-    TODO
-    '''
-    # allocate spline values
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-
-    # containers for fields
-    tmp = empty((3,3), dtype=float)
-    e = empty(3, dtype=float)
-    u = empty(3, dtype=float)
-
-    # marker position eta
-    eta = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        eta[:] = markers[ip, 0:3]
-
-        # spline evaluation
-        span1 = bsp.find_span(tn1, pn[0], eta[0])
-        span2 = bsp.find_span(tn2, pn[1], eta[1])
-        span3 = bsp.find_span(tn3, pn[2], eta[2])
-
-        bsp.b_d_splines_slim(tn1, pn[0], eta[0], span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], eta[1], span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], eta[2], span3, bn3, bd3)
-
-        # eval all the needed field
-        # u; 0form
-        u[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, u1, starts0)
-        u[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, u2, starts0)
-        u[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, u3, starts0)
-
-        tmp[:,:] = ((markers[ip, 18], markers[ip, 19], markers[ip, 20]),
-                    (markers[ip, 19], markers[ip, 21], markers[ip, 22]),
-                    (markers[ip, 20], markers[ip, 22], markers[ip, 23])) 
-
-        linalg.matrix_vector(tmp, u, e)
-
-        markers[ip, 0:3] = markers[ip, 9:12] - e*dt
-
-
-def push_gc_cc_J2_dg_faster_Hcurl(markers: 'float[:,:]', dt: float, stage: int,
-                       pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                       starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                       kind_map: int, params_map: 'float[:]',
-                       p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                       ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                       cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                       kappa: float,
-                       b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
-                       norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
-                       norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
-                       curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
-                       u1: 'float[:,:,:]', u2: 'float[:,:,:]', u3: 'float[:,:,:]'):
-    r'''
-    TODO
-    '''
-    # allocate spline values
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-
-    # containers for fields
-    tmp = empty((3,3), dtype=float)
-    e = empty(3, dtype=float)
-    u = empty(3, dtype=float)
-
-    # marker position eta
-    eta = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        eta[:] = markers[ip, 0:3]
-
-        # spline evaluation
-        span1 = bsp.find_span(tn1, pn[0], eta[0])
-        span2 = bsp.find_span(tn2, pn[1], eta[1])
-        span3 = bsp.find_span(tn3, pn[2], eta[2])
-
-        bsp.b_d_splines_slim(tn1, pn[0], eta[0], span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], eta[1], span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], eta[2], span3, bn3, bd3)
-
-        # eval all the needed field
-        # u; 1form
-        u[0] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, u1, starts1[0])
-        u[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, u2, starts1[1])
-        u[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, u3, starts1[2])
-
-        tmp[:,:] = ((markers[ip, 18], markers[ip, 19], markers[ip, 20]),
-                    (markers[ip, 19], markers[ip, 21], markers[ip, 22]),
-                    (markers[ip, 20], markers[ip, 22], markers[ip, 23])) 
-
-        linalg.matrix_vector(tmp, u, e)
-
-        markers[ip, 0:3] = markers[ip, 9:12] - e*dt
-
-
-def push_gc_cc_J2_dg_faster_Hdiv(markers: 'float[:,:]', dt: float, stage: int,
-                       pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                       starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                       kind_map: int, params_map: 'float[:]',
-                       p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                       ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                       cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                       kappa: float,
-                       b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
-                       norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
-                       norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
-                       curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
-                       u1: 'float[:,:,:]', u2: 'float[:,:,:]', u3: 'float[:,:,:]'):
-    r'''
-    TODO
-    '''
-    # allocate spline values
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-
-    # containers for fields
-    tmp = empty((3,3), dtype=float)
-    e = empty(3, dtype=float)
-    u = empty(3, dtype=float)
-
-    # marker position eta
-    eta = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        eta[:] = markers[ip, 0:3]
-
-        # spline evaluation
-        span1 = bsp.find_span(tn1, pn[0], eta[0])
-        span2 = bsp.find_span(tn2, pn[1], eta[1])
-        span3 = bsp.find_span(tn3, pn[2], eta[2])
-
-        bsp.b_d_splines_slim(tn1, pn[0], eta[0], span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], eta[1], span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], eta[2], span3, bn3, bd3)
-
-        # eval all the needed field
-        # u; 2form
-        u[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, u1, starts2[0])
-        u[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, u2, starts2[1])
-        u[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, u3, starts2[2])
-
-        tmp[:,:] = ((markers[ip, 18], markers[ip, 19], markers[ip, 20]),
-                    (markers[ip, 19], markers[ip, 21], markers[ip, 22]),
-                    (markers[ip, 20], markers[ip, 22], markers[ip, 23])) 
-
-        linalg.matrix_vector(tmp, u, e)
-
-        markers[ip, 0:3] = markers[ip, 9:12] - e*dt
-
-
-def push_gc_cc_J2_stage_H1vec(markers: 'float[:,:]', dt: float, stage: int,
-                              pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                              starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
-                              kind_map: int, params_map: 'float[:]',
-                              p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                              ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                              cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                              kappa: float,
-                              b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
-                              norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
-                              norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
-                              curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
-                              u1: 'float[:,:,:]', u2: 'float[:,:,:]', u3: 'float[:,:,:]',
-                              a: 'float[:]', b: 'float[:]', c: 'float[:]'):
-    r'''
-    TODO
-    '''
-
-    # allocate metric coeffs
-    df = empty((3, 3), dtype=float)
-    df_inv   = empty((3, 3), dtype=float)
-    df_inv_t = empty((3, 3), dtype=float)
-    g_inv    = empty((3, 3), dtype=float)
-
-    # allocate spline values
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
-
-    bd1 = empty(pn[0], dtype=float)
-    bd2 = empty(pn[1], dtype=float)
-    bd3 = empty(pn[2], dtype=float)
-
-    # containers for fields
-    tmp1 = empty((3,3), dtype=float)
-    tmp2 = empty((3,3), dtype=float)
-    b_prod = zeros((3,3), dtype=float)
-    norm_b2_prod = empty((3,3), dtype=float)
-    e = empty(3, dtype=float)
-    u = empty(3, dtype=float)
-    bb = empty(3, dtype=float)
-    b_star = empty(3, dtype=float)
-    norm_b1 = empty(3, dtype=float)
-    norm_b2 = empty(3, dtype=float)
-    curl_norm_b = empty(3, dtype=float)
-
-    # marker position eta
-    eta = empty(3, dtype=float)
-
-    # get number of markers
-    n_markers = shape(markers)[0]
-
-    # get number of stages
-    n_stages = shape(b)[0]
-
-    if stage == n_stages - 1:
-        last = 1.
-    else:
-        last = 0.
-
-    for ip in range(n_markers):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        eta[:] = markers[ip, 0:3]
-        v = markers[ip, 3]
-
-        # evaluate Jacobian, result in df
-        map_eval.df(eta[0], eta[1], eta[2],
-                    kind_map, params_map,
-                    t1_map, t2_map, t3_map, p_map,
-                    ind1_map, ind2_map, ind3_map,
-                    cx, cy, cz,
-                    df)
-
-        # metric coeffs
-        det_df = linalg.det(df)
-        linalg.matrix_inv_with_det(df, det_df, df_inv)
-        linalg.transpose(df_inv, df_inv_t)
-        linalg.matrix_matrix(df_inv, df_inv_t, g_inv)
-
-        # spline evaluation
-        span1 = bsp.find_span(tn1, pn[0], eta[0])
-        span2 = bsp.find_span(tn2, pn[1], eta[1])
-        span3 = bsp.find_span(tn3, pn[2], eta[2])
-
-        bsp.b_d_splines_slim(tn1, pn[0], eta[0], span1, bn1, bd1)
-        bsp.b_d_splines_slim(tn2, pn[1], eta[1], span2, bn2, bd2)
-        bsp.b_d_splines_slim(tn3, pn[2], eta[2], span3, bn3, bd3)
-
-        # eval all the needed field
-        # b; 2form
-        bb[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        bb[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        bb[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
-
-        # u; 0form
-        u[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, u1, starts0)
-        u[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, u2, starts0)
-        u[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, u3, starts0)
-
-        # norm_b1; 1form
-        norm_b1[0] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
-
-        # norm_b; 2form
-        norm_b2[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, norm_b21, starts2[0])
-        norm_b2[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, norm_b22, starts2[1])
-        norm_b2[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, norm_b23, starts2[2])
-
-        # curl_norm_b; 2form
-        curl_norm_b[0] = eval_3d.eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_3d.eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
-
-        # operator bx() as matrix
-        b_prod[0, 1] = -bb[2]
-        b_prod[0, 2] = +bb[1]
-        b_prod[1, 0] = +bb[2]
-        b_prod[1, 2] = -bb[0]
-        b_prod[2, 0] = -bb[1]
-        b_prod[2, 1] = +bb[0]
-
-        norm_b2_prod[0, 1] = -norm_b2[2]
-        norm_b2_prod[0, 2] = +norm_b2[1]
-        norm_b2_prod[1, 0] = +norm_b2[2]
-        norm_b2_prod[1, 2] = -norm_b2[0]
-        norm_b2_prod[2, 0] = -norm_b2[1]
-        norm_b2_prod[2, 1] = +norm_b2[0]
-
-        # b_star; 2form in H1vec
-        b_star[:] = (bb + curl_norm_b*v/kappa)/det_df
-
-        # calculate abs_b_star_para
-        abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
-
-        linalg.matrix_matrix(g_inv, norm_b2_prod, tmp1)
-        linalg.matrix_matrix(tmp1, g_inv, tmp2)
-        linalg.matrix_matrix(tmp2, b_prod, tmp1)
-
-        linalg.matrix_vector(tmp1, u, e)
-
-        e /= abs_b_star_para
-
-        # markers[ip, :3] -= e/abs_b_star_para*dt
-
-        markers[ip, 13:16] -= dt*b[stage]*e
-        markers[ip, 0:3] = markers[ip, 9:12] + dt*a[stage]*e + last*markers[ip, 13:16]
```

### Comparing `struphy-2.0.1/src/struphy/pic/pusher_utilities.py` & `struphy-2.0.2/src/struphy/pic/pusher_utilities.py`

 * *Files 0% similar despite different names*

```diff
@@ -337,20 +337,20 @@
     v3_curr = v3
 
     # Use Euler method as a predictor for positions
     map_eval.df(eta1, eta2, eta3, kind_map, params_map, t1_map, t2_map,
                 t3_map, p_map, ind1_map, ind2_map, ind3_map, cx, cy, cz, df)
     linalg.matrix_inv(df, df_inv)
 
-    v1_curv = kappa * (df_inv[0, 0] * (v1_curr + v1) + df_inv[0, 1] * \
-        (v2_curr + v2) + df_inv[0, 2] * (v3_curr + v3))
-    v2_curv = kappa * (df_inv[1, 0] * (v1_curr + v1) + df_inv[1, 1] * \
-        (v2_curr + v2) + df_inv[1, 2] * (v3_curr + v3))
-    v3_curv = kappa * (df_inv[2, 0] * (v1_curr + v1) + df_inv[2, 1] * \
-        (v2_curr + v2) + df_inv[2, 2] * (v3_curr + v3))
+    v1_curv = kappa * (df_inv[0, 0] * (v1_curr + v1) + df_inv[0, 1] *
+                       (v2_curr + v2) + df_inv[0, 2] * (v3_curr + v3))
+    v2_curv = kappa * (df_inv[1, 0] * (v1_curr + v1) + df_inv[1, 1] *
+                       (v2_curr + v2) + df_inv[1, 2] * (v3_curr + v3))
+    v3_curv = kappa * (df_inv[2, 0] * (v1_curr + v1) + df_inv[2, 1] *
+                       (v2_curr + v2) + df_inv[2, 2] * (v3_curr + v3))
 
     eta1_next = (eta1 + dt * v1_curv / 2.) % 1
     eta2_next = (eta2 + dt * v2_curv / 2.) % 1
     eta3_next = (eta3 + dt * v3_curv / 2.) % 1
 
     # set some initial value for v_next
     v1_next = v1_curr
@@ -380,20 +380,20 @@
                     cx, cy, cz, df)
 
         # evaluate inverse Jacobian matrix
         linalg.matrix_inv(df, df_inv)
 
         # ======================================================================================
         # update the positions and place them back into the computational domain
-        v1_curv = kappa * (df_inv[0, 0] * (v1_curr + v1) + df_inv[0, 1] * \
-            (v2_curr + v2) + df_inv[0, 2] * (v3_curr + v3))
-        v2_curv = kappa * (df_inv[1, 0] * (v1_curr + v1) + df_inv[1, 1] * \
-            (v2_curr + v2) + df_inv[1, 2] * (v3_curr + v3))
-        v3_curv = kappa * (df_inv[2, 0] * (v1_curr + v1) + df_inv[2, 1] * \
-            (v2_curr + v2) + df_inv[2, 2] * (v3_curr + v3))
+        v1_curv = kappa * (df_inv[0, 0] * (v1_curr + v1) + df_inv[0, 1] *
+                           (v2_curr + v2) + df_inv[0, 2] * (v3_curr + v3))
+        v2_curv = kappa * (df_inv[1, 0] * (v1_curr + v1) + df_inv[1, 1] *
+                           (v2_curr + v2) + df_inv[1, 2] * (v3_curr + v3))
+        v3_curv = kappa * (df_inv[2, 0] * (v1_curr + v1) + df_inv[2, 1] *
+                           (v2_curr + v2) + df_inv[2, 2] * (v3_curr + v3))
 
         # x_{n+1} = x_n + dt/2 * DF^{-1}(x_{n+1}/2 + x_n/2) * (v_{n+1} + v_n)
         eta1_next = (eta1 + dt * v1_curv / 2.) % 1
         eta2_next = (eta2 + dt * v2_curv / 2.) % 1
         eta3_next = (eta3 + dt * v3_curv / 2.) % 1
 
         # ======================================================================================
```

### Comparing `struphy-2.0.1/src/struphy/pic/sampling.py` & `struphy-2.0.2/src/struphy/pic/sampling.py`

 * *Files 1% similar despite different names*

```diff
@@ -10,23 +10,23 @@
 from struphy.b_splines.bspline_evaluation_3d import evaluation_kernel_3d
 
 # import module for mapping evaluation
 from struphy.geometry.map_eval import df
 
 
 @stack_array('e', 'v')
-def set_particles_symmetric_3d_3v(numbers : 'float[:,:]', markers : 'float[:,:]'):
-    
+def set_particles_symmetric_3d_3v(numbers: 'float[:,:]', markers: 'float[:,:]'):
+
     from numpy import shape, zeros
 
     e = zeros(3, dtype=float)
     v = zeros(3, dtype=float)
 
     np = 64*shape(numbers)[0]
-    
+
     for i_part in range(np):
         ip = i_part % 64
 
         if ip == 0:
             e[:] = numbers[int(i_part/64), 0:3]
             v[:] = numbers[int(i_part/64), 3:6]
 
@@ -45,27 +45,27 @@
         elif ip % 2 == 0:
             e[1] = 1 - e[1]
 
         else:
             e[0] = 1 - e[0]
 
         markers[i_part, 0:3] = e
-        markers[i_part, 3:6] = v  
+        markers[i_part, 3:6] = v
+
+
+@stack_array('e', 'v')
+def set_particles_symmetric_2d_3v(numbers: 'float[:,:]', markers: 'float[:,:]'):
 
-       
-@stack_array('e', 'v')        
-def set_particles_symmetric_2d_3v(numbers : 'float[:,:]', markers : 'float[:,:]'):
-    
     from numpy import shape, zeros
 
     e = zeros(2, dtype=float)
     v = zeros(3, dtype=float)
 
     np = 32*shape(numbers)[0]
-    
+
     for i_part in range(np):
         ip = i_part % 32
 
         if ip == 0:
             e[:] = numbers[int(i_part/32), 0:2]
             v[:] = numbers[int(i_part/32), 2:5]
```

### Comparing `struphy-2.0.1/src/struphy/pic/sobol_seq.py` & `struphy-2.0.2/src/struphy/pic/sobol_seq.py`

 * *Files 0% similar despite different names*

```diff
@@ -225,44 +225,44 @@
         v[0:40, 0] = np.transpose([
             1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
             1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
             1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
             1, 1, 1, 1, 1, 1, 1, 1, 1, 1])
 
         v[2:40, 1] = np.transpose([
-                  1, 3, 1, 3, 1, 3, 3, 1,
+            1, 3, 1, 3, 1, 3, 3, 1,
             3, 1, 3, 1, 3, 1, 1, 3, 1, 3,
             1, 3, 1, 3, 3, 1, 3, 1, 3, 1,
             3, 1, 1, 3, 1, 3, 1, 3, 1, 3])
 
         v[3:40, 2] = np.transpose([
-                     7, 5, 1, 3, 3, 7, 5,
+            7, 5, 1, 3, 3, 7, 5,
             5, 7, 7, 1, 3, 3, 7, 5, 1, 1,
             5, 3, 3, 1, 7, 5, 1, 3, 3, 7,
             5, 1, 1, 5, 7, 7, 5, 1, 3, 3])
 
         v[5:40, 3] = np.transpose([
-                                1, 7,  9,  13, 11,
+            1, 7,  9,  13, 11,
             1, 3,  7,  9,  5,  13, 13, 11, 3,  15,
             5, 3,  15, 7,  9,  13, 9,  1,  11, 7,
             5, 15, 1,  15, 11, 5,  3,  1,  7,  9])
 
         v[7:40, 4] = np.transpose([
-                                        9,  3,  27,
+            9,  3,  27,
             15, 29, 21, 23, 19, 11, 25, 7,  13, 17,
             1,  25, 29, 3,  31, 11, 5,  23, 27, 19,
             21, 5,  1,  17, 13, 7,  15, 9,  31, 9])
 
         v[13:40, 5] = np.transpose([
-                        37, 33, 7,  5,  11, 39, 63,
+            37, 33, 7,  5,  11, 39, 63,
             27, 17, 15, 23, 29, 3,  21, 13, 31, 25,
             9,  49, 33, 19, 29, 11, 19, 27, 15, 25])
 
         v[19:40, 6] = np.transpose([
-                                                   13,
+            13,
             33, 115, 41, 79, 17, 29,  119, 75, 73, 105,
             7,  59,  65, 21, 3,  113, 61,  89, 45, 107])
 
         v[37:40, 7] = np.transpose([
             7, 23, 39])
 
         #  Set POLY.
@@ -276,15 +276,14 @@
 
         #  Find the number of bits in ATMOST.
         maxcol = i4_bit_hi1(atmost)
 
         #  Initialize row 1 of V.
         v[0, 0:maxcol] = 1
 
-
     #  Things to do only if the dimension changed.
     if dim_num != dim_num_save:
 
         #  Check parameters.
         if dim_num < 1 or dim_max < dim_num:
             print('I4_SOBOL - Fatal error!')
             print('  The spatial dimension DIM_NUM should satisfy:')
```

### Comparing `struphy-2.0.1/src/struphy/pic/utilities.py` & `struphy-2.0.2/src/struphy/pic/utilities.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 import numpy as np
 
 import struphy.pic.utilities_kernels as utils
 
+
 def eval_field_at_particles(fe_coeffs, derham, space_id, particles):
     """
     TODO
 
     Parameters
     ----------
         fe_coeffs : psydac.linalg.stencil.StencilVector or psydac.linalg.block.BlockVector
@@ -19,58 +20,58 @@
 
         particles : struphy.pic.particles.Particles6D or struphy.pic.particles.Particles5D
             Particles object.
     """
 
     if space_id == 'H1':
         res = utils.eval_0_form_at_particles(particles.markers,
-                                             np.array(derham.p), 
+                                             np.array(derham.p),
                                              derham.V0.knots[0], derham.V0.knots[1], derham.V0.knots[2],
-                                             np.array(derham.V0.vector_space.starts),
+                                             np.array(
+                                                 derham.V0.vector_space.starts),
                                              fe_coeffs._data)
 
     elif space_id == 'Hcurl':
         res = np.empty(3, dtype=float)
         utils.eval_1_form_at_particles(particles.markers,
-                                       np.array(derham.p), 
+                                       np.array(derham.p),
                                        derham.V1.knots[0], derham.V1.knots[1], derham.V1.knots[2],
                                        np.array(derham.V1.vector_space.starts),
                                        fe_coeffs.blocks[0]._data, fe_coeffs.blocks[1]._data, fe_coeffs.blocks[2]._data,
                                        res)
 
     elif space_id == 'Hdiv':
         res = np.empty(3, dtype=float)
         utils.eval_2_form_at_particles(particles.markers,
-                                       np.array(derham.p), 
+                                       np.array(derham.p),
                                        derham.V2.knots[0], derham.V2.knots[1], derham.V2.knots[2],
                                        np.array(derham.V2.vector_space.starts),
                                        fe_coeffs.blocks[0]._data, fe_coeffs.blocks[1]._data, fe_coeffs.blocks[2]._data,
                                        res)
 
     elif space_id == 'L2':
         res = utils.eval_0_form_at_particles(particles.markers,
-                                             np.array(derham.p), 
+                                             np.array(derham.p),
                                              derham.V3.knots[0], derham.V3.knots[1], derham.V3.knots[2],
-                                             np.array(derham.V3.vector_space.starts),
+                                             np.array(
+                                                 derham.V3.vector_space.starts),
                                              fe_coeffs)
     elif space_id == 'H1vec':
         res = np.empty(3, dtype=float)
         utils.eval_2_form_at_particles(particles.markers,
-                                       np.array(derham.p), 
+                                       np.array(derham.p),
                                        derham.V0.knots[0], derham.V0.knots[1], derham.V0.knots[2],
                                        np.array(derham.V0.vector_space.starts),
                                        fe_coeffs.blocks[0]._data, fe_coeffs.blocks[1]._data, fe_coeffs.blocks[2]._data,
                                        res)
 
     else:
         raise NotImplementedError(f'The space {space_id} is not implemented!')
-    
-    return res
-
 
+    return res
 
 
 def get_kinetic_energy_particles(fe_coeffs, derham, domain, particles):
     """
     This function is for getting kinetic energy of the case when canonical momentum is used, rather than velocity
 
     Parameters
@@ -83,49 +84,45 @@
 
         particles : struphy.pic.particles.Particles6D
             Particles object.
     """
 
     res = np.empty(1, dtype=float)
     utils.canonical_kinetic_particles(res, particles.markers,
-                                       np.array(derham.p), 
-                                       derham.Vh_fem['0'].knots[0], derham.Vh_fem['0'].knots[1], derham.Vh_fem['0'].knots[2],
-                                       np.array(derham.Vh['1'].starts),
-                                       *domain.args_map,
-                                       fe_coeffs.blocks[0]._data, fe_coeffs.blocks[1]._data, fe_coeffs.blocks[2]._data)
+                                      np.array(derham.p),
+                                      derham.Vh_fem['0'].knots[0], derham.Vh_fem['0'].knots[1], derham.Vh_fem['0'].knots[2],
+                                      np.array(derham.Vh['1'].starts),
+                                      *domain.args_map,
+                                      fe_coeffs.blocks[0]._data, fe_coeffs.blocks[1]._data, fe_coeffs.blocks[2]._data)
 
-    
     return res
 
 
-
 def get_electron_thermal_energy(density_0_form, derham, domain, nel1, nel2, nel3, nqs1, nqs2, nqs3):
     """
     This function is for getting kinetic energy of the case when canonical momentum is used, rather than velocity
 
     Parameters
     ----------
         density_0_form : psydac.linalg.stencil.StencilVector
             values of density at quadrature points, 3-form.
 
         derham : struphy.psydac_api.psydac_derham.Derham
             Discrete Derham complex.
     """
 
     res = np.empty(1, dtype=float)
-    utils.thermal_energy(res, density_0_form._operators[0].matrix._data, 
-                        derham.Vh_fem['0'].vector_space.pads[0], 
-                        derham.Vh_fem['0'].vector_space.pads[1], 
-                        derham.Vh_fem['0'].vector_space.pads[2], 
-                        nel1, nel2, nel3, 
-                        nqs1, nqs2, nqs3,
-                        derham.Vh_fem['0'].quad_grids[0].weights,
-                        derham.Vh_fem['0'].quad_grids[1].weights,
-                        derham.Vh_fem['0'].quad_grids[2].weights,
-                        derham.Vh_fem['0'].quad_grids[0].points, 
-                        derham.Vh_fem['0'].quad_grids[1].points, 
-                        derham.Vh_fem['0'].quad_grids[2].points, 
-                        *domain.args_map)
+    utils.thermal_energy(res, density_0_form._operators[0].matrix._data,
+                         derham.Vh_fem['0'].vector_space.pads[0],
+                         derham.Vh_fem['0'].vector_space.pads[1],
+                         derham.Vh_fem['0'].vector_space.pads[2],
+                         nel1, nel2, nel3,
+                         nqs1, nqs2, nqs3,
+                         derham.Vh_fem['0']._quad_grids[0].weights,
+                         derham.Vh_fem['0']._quad_grids[1].weights,
+                         derham.Vh_fem['0']._quad_grids[2].weights,
+                         derham.Vh_fem['0']._quad_grids[0].points,
+                         derham.Vh_fem['0']._quad_grids[1].points,
+                         derham.Vh_fem['0']._quad_grids[2].points,
+                         *domain.args_map)
 
-    
     return res
-
```

### Comparing `struphy-2.0.1/src/struphy/pic/utilities_kernels.py` & `struphy-2.0.2/src/struphy/pic/utilities_kernels.py`

 * *Files 4% similar despite different names*

```diff
@@ -60,15 +60,15 @@
 
         bsp.b_splines_slim(tn1, pn[0], eta1, span1, bn1)
         bsp.b_splines_slim(tn2, pn[1], eta2, span2, bn2)
         bsp.b_splines_slim(tn3, pn[2], eta3, span3, bn3)
 
         # sum up result
         res = res + eval_spline_mpi_kernel(pn[0], pn[1], pn[2],
-                                       bn1, bn2, bn3, span1, span2, span3, coeffs, starts)
+                                           bn1, bn2, bn3, span1, span2, span3, coeffs, starts)
 
     #$ omp end parallel
 
     return res
 
 
 @stack_array('bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3')
@@ -128,19 +128,19 @@
 
         bsp.b_d_splines_slim(tn1, pn[0], eta1, span1, bn1, bd1)
         bsp.b_d_splines_slim(tn2, pn[1], eta2, span2, bn2, bd2)
         bsp.b_d_splines_slim(tn3, pn[2], eta3, span3, bn3, bd3)
 
         # sum up result
         res[0] = res[0] + eval_spline_mpi_kernel(pn[0], pn[1], pn[2],
-                                             bd1, bn2, bn3, span1, span2, span3, coeffs1, starts[0])
+                                                 bd1, bn2, bn3, span1, span2, span3, coeffs1, starts[0])
         res[1] = res[1] + eval_spline_mpi_kernel(pn[0], pn[1], pn[2],
-                                             bn1, bd2, bn3, span1, span2, span3, coeffs2, starts[1])
+                                                 bn1, bd2, bn3, span1, span2, span3, coeffs2, starts[1])
         res[2] = res[2] + eval_spline_mpi_kernel(pn[0], pn[1], pn[2],
-                                             bn1, bn2, bd3, span1, span2, span3, coeffs3, starts[2])
+                                                 bn1, bn2, bd3, span1, span2, span3, coeffs3, starts[2])
 
     #$ omp end parallel
 
 
 @stack_array('bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3')
 def eval_2_form_at_particles(markers: 'float[:,:]',
                              pn: 'int[:]',
@@ -198,19 +198,19 @@
 
         bsp.b_d_splines_slim(tn1, pn[0], eta1, span1, bn1, bd1)
         bsp.b_d_splines_slim(tn2, pn[1], eta2, span2, bn2, bd2)
         bsp.b_d_splines_slim(tn3, pn[2], eta3, span3, bn3, bd3)
 
         # sum up result
         res[0] = res[0] + eval_spline_mpi_kernel(pn[0], pn[1], pn[2],
-                                             bn1, bd2, bd3, span1, span2, span3, coeffs1, starts[0])
+                                                 bn1, bd2, bd3, span1, span2, span3, coeffs1, starts[0])
         res[1] = res[1] + eval_spline_mpi_kernel(pn[0], pn[1], pn[2],
-                                             bd1, bn2, bd3, span1, span2, span3, coeffs2, starts[1])
+                                                 bd1, bn2, bd3, span1, span2, span3, coeffs2, starts[1])
         res[2] = res[2] + eval_spline_mpi_kernel(pn[0], pn[1], pn[2],
-                                             bd1, bd2, bn3, span1, span2, span3, coeffs3, starts[2])
+                                                 bd1, bd2, bn3, span1, span2, span3, coeffs3, starts[2])
 
     #$ omp end parallel
 
 
 @stack_array('bd1', 'bd2', 'bd3')
 def eval_3_form_at_particles(markers: 'float[:,:]',
                              pn: 'int[:]',
@@ -262,15 +262,15 @@
 
         bsp.d_splines_slim(tn1, pn[0], eta1, span1, bd1)
         bsp.d_splines_slim(tn2, pn[1], eta2, span2, bd2)
         bsp.d_splines_slim(tn3, pn[2], eta3, span3, bd3)
 
         # sum up result
         res = res + eval_spline_mpi_kernel(pn[0], pn[1], pn[2],
-                                       bd1, bd2, bd3, span1, span2, span3, coeffs, starts)
+                                           bd1, bd2, bd3, span1, span2, span3, coeffs, starts)
 
     #$ omp end parallel
 
     return res
 
 
 @stack_array('bn1', 'bn2', 'bn3')
@@ -326,31 +326,31 @@
 
         bsp.b_splines_slim(tn1, pn[0], eta1, span1, bn1)
         bsp.b_splines_slim(tn2, pn[1], eta2, span2, bn2)
         bsp.b_splines_slim(tn3, pn[2], eta3, span3, bn3)
 
         # sum up result
         res[0] = res[0] + eval_spline_mpi_kernel(pn[0], pn[1], pn[2],
-                                             bn1, bn2, bn3, span1, span2, span3, coeffs1, starts)
+                                                 bn1, bn2, bn3, span1, span2, span3, coeffs1, starts)
         res[1] = res[1] + eval_spline_mpi_kernel(pn[0], pn[1], pn[2],
-                                             bn1, bn2, bn3, span1, span2, span3, coeffs2, starts)
+                                                 bn1, bn2, bn3, span1, span2, span3, coeffs2, starts)
         res[2] = res[2] + eval_spline_mpi_kernel(pn[0], pn[1], pn[2],
-                                             bn1, bn2, bn3, span1, span2, span3, coeffs3, starts)
+                                                 bn1, bn2, bn3, span1, span2, span3, coeffs3, starts)
 
     #$ omp end parallel
 
 
 @stack_array('bn1', 'bn2', 'bn3', 'b_cart', 'norm_b_cart', 'v', 'temp', 'v_perp')
 def eval_magnetic_moment_6d(markers: 'float[:,:]',
-                         pn: 'int[:]',
-                         tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                         starts0: 'int[:]',
-                         b_cart_1: 'float[:,:,:]',        
-                         b_cart_2: 'float[:,:,:]',      
-                         b_cart_3: 'float[:,:,:]'):
+                            pn: 'int[:]',
+                            tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
+                            starts0: 'int[:]',
+                            b_cart_1: 'float[:,:,:]',
+                            b_cart_2: 'float[:,:,:]',
+                            b_cart_3: 'float[:,:,:]'):
     """
     Evaluate parallel velocity and magnetic moment of each particles and asign it into markers[ip,3] and markers[ip,4] respectively.
 
     Parameters
     ----------
         markers : array[float]
             .markers attribute of a struphy.pic.particles.Particles object
@@ -400,17 +400,20 @@
         span3 = bsp.find_span(tn3, pn[2], eta3)
 
         bsp.b_splines_slim(tn1, pn[0], eta1, span1, bn1)
         bsp.b_splines_slim(tn2, pn[1], eta2, span2, bn2)
         bsp.b_splines_slim(tn3, pn[2], eta3, span3, bn3)
 
         # b_cart
-        b_cart[0] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, b_cart_1, starts0)
-        b_cart[1] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, b_cart_2, starts0)
-        b_cart[2] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, b_cart_3, starts0)
+        b_cart[0] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, b_cart_1, starts0)
+        b_cart[1] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, b_cart_2, starts0)
+        b_cart[2] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, b_cart_3, starts0)
 
         # calculate absB
         absB = sqrt(b_cart[0]**2 + b_cart[1]**2 + b_cart[2]**2)
 
         if absB != 0.:
             norm_b_cart[:] = b_cart/absB
         else:
@@ -419,22 +422,23 @@
         # calculate parallel velocity
         v_parallel = linalg.scalar_dot(norm_b_cart, v)
 
         # extract perpendicular velocity
         linalg.cross(v, norm_b_cart, temp)
         linalg.cross(norm_b_cart, temp, v_perp)
 
-        v_perp_square = (v_perp[0]**2 + v_perp[1]**2 +v_perp[2]**2)
+        v_perp_square = (v_perp[0]**2 + v_perp[1]**2 + v_perp[2]**2)
 
         # parallel velocity
-        markers[ip,3] = v_parallel
+        markers[ip, 3] = v_parallel
         # magnetic moment
-        markers[ip,4] = 1/2 * v_perp_square / absB
+        markers[ip, 4] = 1/2 * v_perp_square / absB
         # empty leftovers
-        markers[ip,5] = 0.
+        markers[ip, 5] = 0.
+
 
 @stack_array('bn1', 'bn2', 'bn3')
 def eval_magnetic_moment_5d(markers: 'float[:,:]',
                             pn: 'int[:]',
                             tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                             starts0: 'int[:]',
                             absB: 'float[:,:,:]'):
@@ -473,29 +477,30 @@
         if markers[ip, 0] == -1.:
             continue
 
         eta1 = markers[ip, 0]
         eta2 = markers[ip, 1]
         eta3 = markers[ip, 2]
 
-        v_perp = markers[ip,4]
+        v_perp = markers[ip, 4]
 
         # spline evaluation
         span1 = bsp.find_span(tn1, pn[0], eta1)
         span2 = bsp.find_span(tn2, pn[1], eta2)
         span3 = bsp.find_span(tn3, pn[2], eta3)
 
         bsp.b_splines_slim(tn1, pn[0], eta1, span1, bn1)
         bsp.b_splines_slim(tn2, pn[1], eta2, span2, bn2)
         bsp.b_splines_slim(tn3, pn[2], eta3, span3, bn3)
-        
-        B0 = eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, absB, starts0)
+
+        B0 = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, absB, starts0)
 
         # magnetic moment
-        markers[ip,4] = 1/2 * v_perp**2 / abs(B0)
+        markers[ip, 4] = 1/2 * v_perp**2 / abs(B0)
 
 
 @stack_array('bn1', 'bn2', 'bn3')
 def eval_magnetic_energy(markers: 'float[:,:]',
                          pn: 'int[:]',
                          tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                          starts0: 'int[:]',
@@ -542,33 +547,33 @@
         span2 = bsp.find_span(tn2, pn[1], eta2)
         span3 = bsp.find_span(tn3, pn[2], eta3)
 
         bsp.b_splines_slim(tn1, pn[0], eta1, span1, bn1)
         bsp.b_splines_slim(tn2, pn[1], eta2, span2, bn2)
         bsp.b_splines_slim(tn3, pn[2], eta3, span3, bn3)
 
-        B0 = eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, PB, starts0)
+        B0 = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, PB, starts0)
 
-        if B0 < 0: 
-            print('eta', eta1, eta2, eta3)
+        if B0 < 0:
             print('minus', B0)
 
-        markers[ip, 8] = abs(B0)*markers[ip, 4]
+        markers[ip, 8] = B0*markers[ip, 4]
 
 
 @stack_array('df', 'dfinv', 'g', 'g_inv', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3', 'e')
 def push_gc1_discrete_gradients_prepare(markers: 'float[:,:]', dt: float,
                                         domain_array: 'float[:]',
                                         pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                                         starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
                                         kind_map: int, params_map: 'float[:]',
                                         p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
                                         ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
                                         cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                        kappa: float, 
+                                        kappa: float,
                                         abs_b: 'float[:,:,:]',
                                         b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
                                         norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
                                         norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
                                         curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
                                         grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]'):
     r"""
@@ -585,35 +590,35 @@
     bn2 = empty(pn[1] + 1, dtype=float)
     bn3 = empty(pn[2] + 1, dtype=float)
 
     bd1 = empty(pn[0], dtype=float)
     bd2 = empty(pn[1], dtype=float)
     bd3 = empty(pn[2], dtype=float)
 
-    # containers 
+    # containers
     b = empty(3, dtype=float)
     curl_norm_b = empty(3, dtype=float)
     S = empty((3, 3), dtype=float)
     temp = empty(3, dtype=float)
     bcross = empty((3, 3), dtype=float)
     temp1 = empty((3, 3), dtype=float)
     norm_b2 = empty(3, dtype=float)
     temp2 = empty((3, 3), dtype=float)
     b_star = empty(3, dtype=float)
     norm_b1 = empty(3, dtype=float)
     grad_abs_b = empty(3, dtype=float)
 
     # marker position e
     e = empty(3, dtype=float)
-    
+
     # get number of markers
     n_markers = shape(markers)[0]
 
     for ip in range(n_markers):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         e[:] = markers[ip, 0:3]
         v = markers[ip, 3]
         mu = markers[ip, 4]
@@ -641,85 +646,101 @@
 
         bsp.b_d_splines_slim(tn1, pn[0], e[0], span1, bn1, bd1)
         bsp.b_d_splines_slim(tn2, pn[1], e[1], span2, bn2, bd2)
         bsp.b_d_splines_slim(tn3, pn[2], e[2], span3, bn3, bd3)
 
         # eval all the needed field
         # abs_b; 0form
-        abs_b0 = eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
+        abs_b0 = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
 
         # norm_b1; 1form
-        norm_b1[0] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
+        norm_b1[0] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
+        norm_b1[1] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
+        norm_b1[2] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
 
         # norm_b2; 2form
-        norm_b2[0] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, norm_b21, starts2[0])
-        norm_b2[1] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, norm_b22, starts2[1])
-        norm_b2[2] = eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, norm_b23, starts2[2])
+        norm_b2[0] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, norm_b21, starts2[0])
+        norm_b2[1] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, norm_b22, starts2[1])
+        norm_b2[2] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, norm_b23, starts2[2])
 
         # b; 2form
-        b[0] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        b[1] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        b[2] = eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
+        b[0] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
+        b[1] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
+        b[2] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
 
         # curl_norm_b; 2form
-        curl_norm_b[0] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
+        curl_norm_b[0] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
+        curl_norm_b[1] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
+        curl_norm_b[2] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
 
         # grad_abs_b; 1form
-        grad_abs_b[0] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
-        grad_abs_b[1] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
-        grad_abs_b[2] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
+        grad_abs_b[0] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
+        grad_abs_b[1] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
+        grad_abs_b[2] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
 
         # transform to H1vec
         b_star[:] = b + 1/kappa*v*curl_norm_b
         b_star[:] = b_star/det_df
 
         # calculate abs_b_star_para
         abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
 
         # assemble b cross (.) as 3x3 matrix
-        bcross[:,:] = ( (     0.     ,  -norm_b2[2],   norm_b2[1]), 
-                        (  norm_b2[2],      0.     ,  -norm_b2[0]), 
-                        ( -norm_b2[1],   norm_b2[0],      0.     ) )
+        bcross[:, :] = ((0.,  -norm_b2[2],   norm_b2[1]),
+                        (norm_b2[2],      0.,  -norm_b2[0]),
+                        (-norm_b2[1],   norm_b2[0],      0.))
 
-        # calculate G-1 b cross G-1 
+        # calculate G-1 b cross G-1
         linalg.matrix_matrix(bcross, g_inv, temp1)
         linalg.matrix_matrix(g_inv, temp1, temp2)
 
         # calculate S
-        S[:,:] = (1/kappa*temp2)/abs_b_star_para
+        S[:, :] = (1/kappa*temp2)/abs_b_star_para
 
         # save at the markers
-        markers[ip, 13:16] = S[0,:]
-        markers[ip, 16:18] = S[1,1:3]
-        markers[ip, 18]    = S[2,2]
-        markers[ip, 19]    = abs_b0*mu
+        markers[ip, 13:15] = S[0, 1:3]
+        markers[ip, 15] = S[1, 2]
+        markers[ip, 19] = abs_b0*mu
 
         # calculate S1 * grad I1
         linalg.matrix_vector(S, grad_abs_b, temp)
 
         # save at the markers
         markers[ip, 0:3] = markers[ip, 0:3] + dt*temp[:]*mu
 
-        markers[ip, 20:24] = markers[ip, 0:4]
-        markers[ip, 0:4] = (markers[ip, 0:4] + markers[ip, 9:13])/2.
+        markers[ip, 16:19] = markers[ip, 0:3]
+        markers[ip, 0:3] = (markers[ip, 0:3] + markers[ip, 9:12])/2.
+
 
 @stack_array('df', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3', 'e')
 def push_gc2_discrete_gradients_prepare(markers: 'float[:,:]', dt: float,
                                         domain_array: 'float[:]',
                                         pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                                         starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
                                         kind_map: int, params_map: 'float[:]',
                                         p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
                                         ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
                                         cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                        kappa: float, 
+                                        kappa: float,
                                         abs_b: 'float[:,:,:]',
                                         b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
                                         norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
                                         norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
                                         curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
                                         grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]'):
     r"""TODO
@@ -733,29 +754,29 @@
     bn2 = empty(pn[1] + 1, dtype=float)
     bn3 = empty(pn[2] + 1, dtype=float)
 
     bd1 = empty(pn[0], dtype=float)
     bd2 = empty(pn[1], dtype=float)
     bd3 = empty(pn[2], dtype=float)
 
-    # containers 
+    # containers
     b = empty(3, dtype=float)
     curl_norm_b = empty(3, dtype=float)
     grad_abs_b = empty(3, dtype=float)
     b_star = empty(3, dtype=float)
     norm_b1 = empty(3, dtype=float)
 
     # marker position e
     e = empty(3, dtype=float)
-    
+
     # get number of markers
     n_markers = shape(markers)[0]
 
     for ip in range(n_markers):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         e[:] = markers[ip, 0:3]
         v = markers[ip, 3]
         mu = markers[ip, 4]
@@ -778,35 +799,48 @@
 
         bsp.b_d_splines_slim(tn1, pn[0], e[0], span1, bn1, bd1)
         bsp.b_d_splines_slim(tn2, pn[1], e[1], span2, bn2, bd2)
         bsp.b_d_splines_slim(tn3, pn[2], e[2], span3, bn3, bd3)
 
         # eval all the needed field
         # abs_b; 0form
-        abs_b0 = eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
+        abs_b0 = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
 
         # norm_b1; 1form
-        norm_b1[0] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
+        norm_b1[0] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
+        norm_b1[1] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
+        norm_b1[2] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
 
         # b; 2form
-        b[0] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        b[1] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        b[2] = eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
+        b[0] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
+        b[1] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
+        b[2] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
 
         # curl_norm_b; 2form
-        curl_norm_b[0] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
+        curl_norm_b[0] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
+        curl_norm_b[1] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
+        curl_norm_b[2] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
 
         # grad_abs_b; 1form
-        grad_abs_b[0] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
-        grad_abs_b[1] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
-        grad_abs_b[2] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
+        grad_abs_b[0] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
+        grad_abs_b[1] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
+        grad_abs_b[2] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
 
         # transform to H1vec
         b_star[:] = b + 1/kappa*v*curl_norm_b
         b_star[:] = b_star/det_df
 
         # calculate abs_b_star_para
         abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
@@ -816,29 +850,31 @@
         markers[ip, 19] = mu*abs_b0
 
         # calculate b_star . grad_abs_b
         b_star_dot_grad_abs_b = linalg.scalar_dot(b_star, grad_abs_b)*mu
 
         # save at the markers
         markers[ip, 0:3] = markers[ip, 9:12] + dt*b_star[:]/abs_b_star_para*v
-        markers[ip, 3] = markers[ip, 12] - dt*b_star_dot_grad_abs_b/abs_b_star_para
+        markers[ip, 3] = markers[ip, 12] - dt * \
+            b_star_dot_grad_abs_b/abs_b_star_para
 
         markers[ip, 20:24] = markers[ip, 0:4]
         markers[ip, 0:4] = (markers[ip, 0:4] + markers[ip, 9:13])/2.
 
+
 @stack_array('df', 'dfinv', 'g', 'g_inv', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3', 'e')
 def push_gc1_discrete_gradients_faster_prepare(markers: 'float[:,:]', dt: float,
                                                domain_array: 'float[:]',
                                                pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                                                starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
                                                kind_map: int, params_map: 'float[:]',
                                                p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
                                                ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
                                                cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                               kappa: float, 
+                                               kappa: float,
                                                abs_b: 'float[:,:,:]',
                                                b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
                                                norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
                                                norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
                                                curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
                                                grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]'):
     r"""
@@ -870,20 +906,20 @@
     temp2 = empty((3, 3), dtype=float)
     b_star = empty(3, dtype=float)
     norm_b1 = empty(3, dtype=float)
     grad_abs_b = empty(3, dtype=float)
 
     # marker position e
     e = empty(3, dtype=float)
-    
+
     # get number of markers
     n_markers = shape(markers)[0]
 
     for ip in range(n_markers):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         e[:] = markers[ip, 0:3]
         v = markers[ip, 3]
         mu = markers[ip, 4]
@@ -911,85 +947,102 @@
 
         bsp.b_d_splines_slim(tn1, pn[0], e[0], span1, bn1, bd1)
         bsp.b_d_splines_slim(tn2, pn[1], e[1], span2, bn2, bd2)
         bsp.b_d_splines_slim(tn3, pn[2], e[2], span3, bn3, bd3)
 
         # eval all the needed field
         # abs_b; 0form
-        abs_b0 = eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
+        abs_b0 = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
 
         # norm_b1; 1form
-        norm_b1[0] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
+        norm_b1[0] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
+        norm_b1[1] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
+        norm_b1[2] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
 
         # norm_b2; 2form
-        norm_b2[0] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, norm_b21, starts2[0])
-        norm_b2[1] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, norm_b22, starts2[1])
-        norm_b2[2] = eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, norm_b23, starts2[2])
+        norm_b2[0] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, norm_b21, starts2[0])
+        norm_b2[1] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, norm_b22, starts2[1])
+        norm_b2[2] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, norm_b23, starts2[2])
 
         # b; 2form
-        b[0] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        b[1] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        b[2] = eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
+        b[0] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
+        b[1] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
+        b[2] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
 
         # curl_norm_b; 2form
-        curl_norm_b[0] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
+        curl_norm_b[0] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
+        curl_norm_b[1] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
+        curl_norm_b[2] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
 
         # grad_abs_b; 1form
-        grad_abs_b[0] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
-        grad_abs_b[1] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
-        grad_abs_b[2] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
+        grad_abs_b[0] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
+        grad_abs_b[1] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
+        grad_abs_b[2] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
 
         # transform to H1vec
         b_star[:] = b + 1/kappa*v*curl_norm_b
         b_star[:] = b_star/det_df
 
         # calculate abs_b_star_para
         abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
 
         # assemble b cross (.) as 3x3 matrix
-        bcross[:,:] = ( (     0.     ,  -norm_b2[2],   norm_b2[1]), 
-                        (  norm_b2[2],      0.     ,  -norm_b2[0]), 
-                        ( -norm_b2[1],   norm_b2[0],      0.     ) )
+        bcross[:, :] = ((0.,  -norm_b2[2],   norm_b2[1]),
+                        (norm_b2[2],      0.,  -norm_b2[0]),
+                        (-norm_b2[1],   norm_b2[0],      0.))
 
-        # calculate G-1 b cross G-1 
+        # calculate G-1 b cross G-1
         linalg.matrix_matrix(bcross, g_inv, temp1)
         linalg.matrix_matrix(g_inv, temp1, temp2)
 
         # calculate S
-        S[:,:] = (1/kappa*temp2)/abs_b_star_para
+        S[:, :] = (1/kappa*temp2)/abs_b_star_para
 
         # save at the markers
-        markers[ip, 13:16] = S[0,:]
-        markers[ip, 16:18] = S[1,1:3]
-        markers[ip, 18]    = S[2,2]
-        markers[ip, 19]    = abs_b0*mu
+        markers[ip, 13:16] = S[0, :]
+        markers[ip, 16:18] = S[1, 1:3]
+        markers[ip, 18] = S[2, 2]
+        markers[ip, 19] = abs_b0*mu
 
         # calculate S1 * grad I1
         linalg.matrix_vector(S, grad_abs_b, temp)
 
         # save at the markers
         markers[ip, 0:3] = markers[ip, 0:3] + dt*temp[:]*mu
 
         markers[ip, 20:23] = markers[ip, 0:3]
         markers[ip, 0:3] = (markers[ip, 0:3] + markers[ip, 9:12])/2.
 
+
 @stack_array('df', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3', 'e')
 def push_gc2_discrete_gradients_faster_prepare(markers: 'float[:,:]', dt: float,
                                                domain_array: 'float[:]',
                                                pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                                                starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
                                                kind_map: int, params_map: 'float[:]',
                                                p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
                                                ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
                                                cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                               kappa: float, 
+                                               kappa: float,
                                                abs_b: 'float[:,:,:]',
                                                b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
                                                norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
                                                norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
                                                curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
                                                grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]'):
     r"""TODO
@@ -1013,20 +1066,20 @@
     curl_norm_b = empty(3, dtype=float)
     grad_abs_b = empty(3, dtype=float)
     b_star = empty(3, dtype=float)
     norm_b1 = empty(3, dtype=float)
 
     # marker position e
     e = empty(3, dtype=float)
-    
+
     # get number of markers
     n_markers = shape(markers)[0]
 
     for ip in range(n_markers):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         e[:] = markers[ip, 0:3]
         v = markers[ip, 3]
         mu = markers[ip, 4]
@@ -1049,35 +1102,48 @@
 
         bsp.b_d_splines_slim(tn1, pn[0], e[0], span1, bn1, bd1)
         bsp.b_d_splines_slim(tn2, pn[1], e[1], span2, bn2, bd2)
         bsp.b_d_splines_slim(tn3, pn[2], e[2], span3, bn3, bd3)
 
         # eval all the needed field
         # abs_b; 0form
-        abs_b0 = eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
+        abs_b0 = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
 
         # norm_b1; 1form
-        norm_b1[0] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
+        norm_b1[0] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
+        norm_b1[1] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
+        norm_b1[2] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
 
         # b; 2form
-        b[0] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        b[1] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        b[2] = eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
+        b[0] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
+        b[1] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
+        b[2] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
 
         # curl_norm_b; 2form
-        curl_norm_b[0] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
+        curl_norm_b[0] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
+        curl_norm_b[1] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
+        curl_norm_b[2] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
 
         # grad_abs_b; 1form
-        grad_abs_b[0] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
-        grad_abs_b[1] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
-        grad_abs_b[2] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
+        grad_abs_b[0] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
+        grad_abs_b[1] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
+        grad_abs_b[2] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
 
         # transform to H1vec
         b_star[:] = b + 1/kappa*v*curl_norm_b
         b_star[:] = b_star/det_df
 
         # calculate abs_b_star_para
         abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
@@ -1087,29 +1153,31 @@
         markers[ip, 19] = mu*abs_b0
 
         # calculate b_star . grad_abs_b
         b_star_dot_grad_abs_b = linalg.scalar_dot(b_star, grad_abs_b)*mu
 
         # save at the markers
         markers[ip, 0:3] = markers[ip, 9:12] + dt*b_star[:]/abs_b_star_para*v
-        markers[ip, 3] = markers[ip, 12] - dt*b_star_dot_grad_abs_b/abs_b_star_para
+        markers[ip, 3] = markers[ip, 12] - dt * \
+            b_star_dot_grad_abs_b/abs_b_star_para
 
         markers[ip, 20:24] = markers[ip, 0:4]
         markers[ip, 0:4] = (markers[ip, 0:4] + markers[ip, 9:13])/2.
 
+
 @stack_array('df', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3', 'e_mid')
 def push_gc1_discrete_gradients_faster_eval_gradI(markers: 'float[:,:]', dt: float,
                                                   domain_array: 'float[:]',
                                                   pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                                                   starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
                                                   kind_map: int, params_map: 'float[:]',
                                                   p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
                                                   ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
                                                   cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                                  kappa: float, 
+                                                  kappa: float,
                                                   abs_b: 'float[:,:,:]',
                                                   b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
                                                   norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
                                                   norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
                                                   curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
                                                   grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]'):
     r"""TODO
@@ -1120,25 +1188,25 @@
     bn2 = empty(pn[1] + 1, dtype=float)
     bn3 = empty(pn[2] + 1, dtype=float)
 
     bd1 = empty(pn[0], dtype=float)
     bd2 = empty(pn[1], dtype=float)
     bd3 = empty(pn[2], dtype=float)
 
-    # containers 
+    # containers
     grad_abs_b = empty(3, dtype=float)
 
     # marker position e
     e_mid = empty(3, dtype=float)
-    
+
     # get number of markers
     n_markers = shape(markers)[0]
 
     for ip in range(n_markers):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         if markers[ip, 23] == -1.:
             continue
 
@@ -1153,30 +1221,34 @@
 
         bsp.b_d_splines_slim(tn1, pn[0], e_mid[0], span1, bn1, bd1)
         bsp.b_d_splines_slim(tn2, pn[1], e_mid[1], span2, bn2, bd2)
         bsp.b_d_splines_slim(tn3, pn[2], e_mid[2], span3, bn3, bd3)
 
         # eval all the needed field
         # grad_abs_b; 1form
-        grad_abs_b[0] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
-        grad_abs_b[1] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
-        grad_abs_b[2] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
+        grad_abs_b[0] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
+        grad_abs_b[1] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
+        grad_abs_b[2] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
 
         markers[ip, 20:23] = mu*grad_abs_b[:]
 
+
 @stack_array('df', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3', 'e_mid')
 def push_gc2_discrete_gradients_faster_eval_gradI(markers: 'float[:,:]', dt: float,
                                                   domain_array: 'float[:]',
                                                   pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                                                   starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
                                                   kind_map: int, params_map: 'float[:]',
                                                   p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
                                                   ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
                                                   cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                                  kappa: float, 
+                                                  kappa: float,
                                                   abs_b: 'float[:,:,:]',
                                                   b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
                                                   norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
                                                   norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
                                                   curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
                                                   grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]'):
     r"""TODO
@@ -1187,25 +1259,25 @@
     bn2 = empty(pn[1] + 1, dtype=float)
     bn3 = empty(pn[2] + 1, dtype=float)
 
     bd1 = empty(pn[0], dtype=float)
     bd2 = empty(pn[1], dtype=float)
     bd3 = empty(pn[2], dtype=float)
 
-    # containers 
+    # containers
     grad_abs_b = empty(3, dtype=float)
 
     # marker position e
     e_mid = empty(3, dtype=float)
-    
+
     # get number of markers
     n_markers = shape(markers)[0]
 
     for ip in range(n_markers):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         if markers[ip, 23] == -1.:
             continue
 
@@ -1220,30 +1292,34 @@
 
         bsp.b_d_splines_slim(tn1, pn[0], e_mid[0], span1, bn1, bd1)
         bsp.b_d_splines_slim(tn2, pn[1], e_mid[1], span2, bn2, bd2)
         bsp.b_d_splines_slim(tn3, pn[2], e_mid[2], span3, bn3, bd3)
 
         # eval all the needed field
         # grad_abs_b; 1form
-        grad_abs_b[0] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
-        grad_abs_b[1] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
-        grad_abs_b[2] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
+        grad_abs_b[0] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
+        grad_abs_b[1] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
+        grad_abs_b[2] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
 
         markers[ip, 20:23] = mu*grad_abs_b[:]
 
+
 @stack_array('df', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3', 'e_mid')
 def push_gc1_discrete_gradients_eval_gradI(markers: 'float[:,:]', dt: float,
                                            domain_array: 'float[:]',
                                            pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                                            starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
                                            kind_map: int, params_map: 'float[:]',
                                            p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
                                            ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
                                            cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                           kappa: float, 
+                                           kappa: float,
                                            abs_b: 'float[:,:,:]',
                                            b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
                                            norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
                                            norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
                                            curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
                                            grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]'):
     r"""TODO
@@ -1260,44 +1336,44 @@
     bn2 = empty(pn[1] + 1, dtype=float)
     bn3 = empty(pn[2] + 1, dtype=float)
 
     bd1 = empty(pn[0], dtype=float)
     bd2 = empty(pn[1], dtype=float)
     bd3 = empty(pn[2], dtype=float)
 
-    # containers 
+    # containers
     S = empty((3, 3), dtype=float)
     bcross = empty((3, 3), dtype=float)
     temp1 = empty((3, 3), dtype=float)
     temp2 = empty((3, 3), dtype=float)
     grad_abs_b = empty(3, dtype=float)
     norm_b1 = empty(3, dtype=float)
     norm_b2 = empty(3, dtype=float)
     b = empty(3, dtype=float)
     curl_norm_b = empty(3, dtype=float)
     b_star = empty(3, dtype=float)
 
     # marker position e
     e_mid = empty(3, dtype=float)
-    
+
     # get number of markers
     n_markers = shape(markers)[0]
 
     for ip in range(n_markers):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         if markers[ip, 23] == -1.:
             continue
 
         e_mid[:] = markers[ip, 0:3]
         v_mid = markers[ip, 3]
-        markers[ip, 0:4] = markers[ip, 20:24]
+        markers[ip, 0:3] = markers[ip, 16:19]
         mu = markers[ip, 4]
 
         # evaluate Jacobian, result in df
         map_eval.df(e_mid[0], e_mid[1], e_mid[2],
                     kind_map, params_map,
                     t1_map, t2_map, t3_map, p_map,
                     ind1_map, ind2_map, ind3_map,
@@ -1319,74 +1395,89 @@
 
         bsp.b_d_splines_slim(tn1, pn[0], e_mid[0], span1, bn1, bd1)
         bsp.b_d_splines_slim(tn2, pn[1], e_mid[1], span2, bn2, bd2)
         bsp.b_d_splines_slim(tn3, pn[2], e_mid[2], span3, bn3, bd3)
 
         # eval all the needed field
         # norm_b1; 1form
-        norm_b1[0] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
+        norm_b1[0] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
+        norm_b1[1] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
+        norm_b1[2] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
 
         # norm_b2; 2form
-        norm_b2[0] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, norm_b21, starts2[0])
-        norm_b2[1] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, norm_b22, starts2[1])
-        norm_b2[2] = eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, norm_b23, starts2[2])
+        norm_b2[0] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, norm_b21, starts2[0])
+        norm_b2[1] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, norm_b22, starts2[1])
+        norm_b2[2] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, norm_b23, starts2[2])
 
         # b; 2form
-        b[0] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        b[1] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        b[2] = eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
+        b[0] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
+        b[1] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
+        b[2] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
 
         # curl_norm_b; 2form
-        curl_norm_b[0] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
+        curl_norm_b[0] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
+        curl_norm_b[1] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
+        curl_norm_b[2] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
 
         # grad_abs_b; 1form
-        grad_abs_b[0] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
-        grad_abs_b[1] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
-        grad_abs_b[2] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
+        grad_abs_b[0] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
+        grad_abs_b[1] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
+        grad_abs_b[2] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
 
         # transform to H1vec
         b_star[:] = b + 1/kappa*v_mid*curl_norm_b
         b_star[:] = b_star/det_df
 
         # calculate abs_b_star_para
         abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
 
         # assemble b cross (.) as 3x3 matrix
-        bcross[:,:] = ( (     0.     ,  -norm_b2[2],   norm_b2[1]), 
-                        (  norm_b2[2],      0.     ,  -norm_b2[0]), 
-                        ( -norm_b2[1],   norm_b2[0],      0.     ) )
+        bcross[:, :] = ((0.,  -norm_b2[2],   norm_b2[1]),
+                        (norm_b2[2],      0.,  -norm_b2[0]),
+                        (-norm_b2[1],   norm_b2[0],      0.))
 
-        # calculate G-1 b cross G-1 
+        # calculate G-1 b cross G-1
         linalg.matrix_matrix(bcross, g_inv, temp1)
         linalg.matrix_matrix(g_inv, temp1, temp2)
 
         # calculate S
-        S[:,:] = (1/kappa*temp2)/abs_b_star_para
+        S[:, :] = (1/kappa*temp2)/abs_b_star_para
 
         # save at the markers
-        markers[ip, 13:16] = S[0,:]
-        markers[ip, 16:18] = S[1,1:3]
-        markers[ip, 18]    = S[2,2]
+        markers[ip, 13:15] = S[0, 1:3]
+        markers[ip, 15] = S[1, 2]
+
+        markers[ip, 16:19] = mu*grad_abs_b[:]
 
-        markers[ip, 20:23] = mu*grad_abs_b[:]
 
 @stack_array('df', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3', 'e_mid')
 def push_gc2_discrete_gradients_eval_gradI(markers: 'float[:,:]', dt: float,
                                            domain_array: 'float[:]',
                                            pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                                            starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
                                            kind_map: int, params_map: 'float[:]',
                                            p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
                                            ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
                                            cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                           kappa: float, 
+                                           kappa: float,
                                            abs_b: 'float[:,:,:]',
                                            b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
                                            norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
                                            norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
                                            curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
                                            grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]'):
     r"""TODO
@@ -1400,29 +1491,29 @@
     bn2 = empty(pn[1] + 1, dtype=float)
     bn3 = empty(pn[2] + 1, dtype=float)
 
     bd1 = empty(pn[0], dtype=float)
     bd2 = empty(pn[1], dtype=float)
     bd3 = empty(pn[2], dtype=float)
 
-    # containers 
+    # containers
     grad_abs_b = empty(3, dtype=float)
     b_star = empty(3, dtype=float)
     norm_b1 = empty(3, dtype=float)
     b = empty(3, dtype=float)
     curl_norm_b = empty(3, dtype=float)
 
     # marker position e
     e_mid = empty(3, dtype=float)
-    
+
     # get number of markers
     n_markers = shape(markers)[0]
 
     for ip in range(n_markers):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         if markers[ip, 23] == -1.:
             continue
 
@@ -1449,54 +1540,67 @@
 
         bsp.b_d_splines_slim(tn1, pn[0], e_mid[0], span1, bn1, bd1)
         bsp.b_d_splines_slim(tn2, pn[1], e_mid[1], span2, bn2, bd2)
         bsp.b_d_splines_slim(tn3, pn[2], e_mid[2], span3, bn3, bd3)
 
         # eval all the needed field
         # norm_b1; 1form
-        norm_b1[0] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
+        norm_b1[0] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
+        norm_b1[1] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
+        norm_b1[2] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
 
         # b; 2form
-        b[0] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        b[1] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        b[2] = eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
+        b[0] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
+        b[1] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
+        b[2] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
 
         # curl_norm_b; 2form
-        curl_norm_b[0] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
+        curl_norm_b[0] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
+        curl_norm_b[1] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
+        curl_norm_b[2] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
 
         # grad_abs_b; 1form
-        grad_abs_b[0] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
-        grad_abs_b[1] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
-        grad_abs_b[2] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
+        grad_abs_b[0] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
+        grad_abs_b[1] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
+        grad_abs_b[2] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
 
         # transform to H1vec
         b_star[:] = b + 1/kappa*v_mid*curl_norm_b
         b_star[:] = b_star/det_df
 
         # calculate abs_b_star_para
         abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
 
         # save at the markers
         markers[ip, 13:16] = b_star[:]/abs_b_star_para
         markers[ip, 20:23] = mu*grad_abs_b[:]
 
+
 @stack_array('df', 'dfinv', 'g', 'g_inv', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3', 'e')
 def push_gc1_discrete_gradients_Itoh_Newton_prepare(markers: 'float[:,:]', dt: float,
                                                     domain_array: 'float[:]',
                                                     pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                                                     starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
                                                     kind_map: int, params_map: 'float[:]',
                                                     p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
                                                     ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
                                                     cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                                    kappa: float, 
+                                                    kappa: float,
                                                     abs_b: 'float[:,:,:]',
                                                     b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
                                                     norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
                                                     norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
                                                     curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
                                                     grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]'):
     r"""
@@ -1513,35 +1617,35 @@
     bn2 = empty(pn[1] + 1, dtype=float)
     bn3 = empty(pn[2] + 1, dtype=float)
 
     bd1 = empty(pn[0], dtype=float)
     bd2 = empty(pn[1], dtype=float)
     bd3 = empty(pn[2], dtype=float)
 
-    # containers 
+    # containers
     b = empty(3, dtype=float)
     curl_norm_b = empty(3, dtype=float)
     S = zeros((3, 3), dtype=float)
     temp = empty(3, dtype=float)
     bcross = empty((3, 3), dtype=float)
     temp1 = empty((3, 3), dtype=float)
     norm_b2 = empty(3, dtype=float)
     temp2 = empty((3, 3), dtype=float)
     b_star = empty(3, dtype=float)
     norm_b1 = empty(3, dtype=float)
     grad_abs_b = empty(3, dtype=float)
 
     # marker position e
     e = empty(3, dtype=float)
-    
+
     # get number of markers
     n_markers = shape(markers)[0]
 
     for ip in range(n_markers):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         e[:] = markers[ip, 0:3]
         v = markers[ip, 3]
         mu = markers[ip, 4]
@@ -1569,84 +1673,101 @@
 
         bsp.b_d_splines_slim(tn1, pn[0], e[0], span1, bn1, bd1)
         bsp.b_d_splines_slim(tn2, pn[1], e[1], span2, bn2, bd2)
         bsp.b_d_splines_slim(tn3, pn[2], e[2], span3, bn3, bd3)
 
         # eval all the needed field
         # abs_b; 0form
-        abs_b0 = eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
+        abs_b0 = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
 
         # norm_b1; 1form
-        norm_b1[0] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
+        norm_b1[0] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
+        norm_b1[1] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
+        norm_b1[2] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
 
         # norm_b2; 2form
-        norm_b2[0] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, norm_b21, starts2[0])
-        norm_b2[1] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, norm_b22, starts2[1])
-        norm_b2[2] = eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, norm_b23, starts2[2])
+        norm_b2[0] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, norm_b21, starts2[0])
+        norm_b2[1] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, norm_b22, starts2[1])
+        norm_b2[2] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, norm_b23, starts2[2])
 
         # b; 2form
-        b[0] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        b[1] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        b[2] = eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
+        b[0] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
+        b[1] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
+        b[2] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
 
         # curl_norm_b; 2form
-        curl_norm_b[0] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
+        curl_norm_b[0] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
+        curl_norm_b[1] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
+        curl_norm_b[2] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
 
         # grad_abs_b; 1form
-        grad_abs_b[0] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
-        grad_abs_b[1] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
-        grad_abs_b[2] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
+        grad_abs_b[0] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
+        grad_abs_b[1] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
+        grad_abs_b[2] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
 
         # transform to H1vec
         b_star[:] = b + 1/kappa*v*curl_norm_b
         b_star[:] = b_star/det_df
 
         # calculate abs_b_star_para
         abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
 
         # assemble b cross (.) as 3x3 matrix
-        bcross[:,:] = ( (     0.     ,  -norm_b2[2],   norm_b2[1]), 
-                        (  norm_b2[2],      0.     ,  -norm_b2[0]), 
-                        ( -norm_b2[1],   norm_b2[0],      0.     ) )
+        bcross[:, :] = ((0.,  -norm_b2[2],   norm_b2[1]),
+                        (norm_b2[2],      0.,  -norm_b2[0]),
+                        (-norm_b2[1],   norm_b2[0],      0.))
 
-        # calculate G^-1 b cross G^-1 
+        # calculate G^-1 b cross G^-1
         linalg.matrix_matrix(bcross, g_inv, temp1)
         linalg.matrix_matrix(g_inv, temp1, temp2)
 
         # calculate S
-        S[:,:] = (1/kappa*temp2)/abs_b_star_para
+        S[:, :] = (1/kappa*temp2)/abs_b_star_para
 
         # save at the markers
-        markers[ip, 13:15] = S[0,1:3]
-        markers[ip, 15] = S[1,2]
-        markers[ip, 19]    = abs_b0
+        markers[ip, 13:15] = S[0, 1:3]
+        markers[ip, 15] = S[1, 2]
+        markers[ip, 19] = abs_b0
 
         # calculate S1 * grad I1
         linalg.matrix_vector(S, grad_abs_b, temp)
 
         # save at the markers
         markers[ip, 16:19] = markers[ip, 0:3] + dt*temp[:]*mu
-        
+
         # send particles to the (eta^0_n+1,eta_n, eta_n)
         markers[ip, 0] = markers[ip, 16]
 
+
 @stack_array('df', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3', 'e')
 def push_gc1_discrete_gradients_Itoh_Newton_prepare1(markers: 'float[:,:]', dt: float,
                                                      domain_array: 'float[:]',
                                                      pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                                                      starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
                                                      kind_map: int, params_map: 'float[:]',
                                                      p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
                                                      ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
                                                      cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                                     kappa: float, 
+                                                     kappa: float,
                                                      abs_b: 'float[:,:,:]',
                                                      b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
                                                      norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
                                                      norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
                                                      curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
                                                      grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]'):
     r"""TODO
@@ -1662,25 +1783,25 @@
 
     bd1 = empty(pn[0], dtype=float)
     bd2 = empty(pn[1], dtype=float)
     bd3 = empty(pn[2], dtype=float)
 
     # marker position e
     e = empty(3, dtype=float)
-    
+
     # get number of markers
     n_markers = shape(markers)[0]
 
     for ip in range(n_markers):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
-        if markers[ip, 13] == -1.:
+        if markers[ip, 23] == -1.:
             continue
 
         e[:] = markers[ip, 0:3]
 
         # evaluate Jacobian, result in df
         map_eval.df(e[0], e[1], e[2],
                     kind_map, params_map,
@@ -1696,32 +1817,35 @@
 
         bsp.b_d_splines_slim(tn1, pn[0], e[0], span1, bn1, bd1)
         bsp.b_d_splines_slim(tn2, pn[1], e[1], span2, bn2, bd2)
         bsp.b_d_splines_slim(tn3, pn[2], e[2], span3, bn3, bd3)
 
         # eval all the needed field
         # abs_b; 0form
-        markers[ip, 20] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
+        markers[ip, 20] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
 
         # grad_abs_b; 1form
-        markers[ip, 21] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
+        markers[ip, 21] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
 
         # send particles to the (eta^0_n+1,eta^0_n+1, eta_n)
         markers[ip, 1] = markers[ip, 17]
-        
+
+
 @stack_array('df', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3', 'e')
 def push_gc1_discrete_gradients_Itoh_Newton_prepare2(markers: 'float[:,:]', dt: float,
                                                      domain_array: 'float[:]',
                                                      pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                                                      starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
                                                      kind_map: int, params_map: 'float[:]',
                                                      p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
                                                      ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
                                                      cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                                     kappa: float, 
+                                                     kappa: float,
                                                      abs_b: 'float[:,:,:]',
                                                      b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
                                                      norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
                                                      norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
                                                      curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
                                                      grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]'):
     r"""TODO
@@ -1737,25 +1861,25 @@
 
     bd1 = empty(pn[0], dtype=float)
     bd2 = empty(pn[1], dtype=float)
     bd3 = empty(pn[2], dtype=float)
 
     # marker position e
     e = empty(3, dtype=float)
-    
+
     # get number of markers
     n_markers = shape(markers)[0]
 
     for ip in range(n_markers):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
-        if markers[ip, 13] == -1.:
+        if markers[ip, 23] == -1.:
             continue
 
         e[:] = markers[ip, 0:3]
 
         # evaluate Jacobian, result in df
         map_eval.df(e[0], e[1], e[2],
                     kind_map, params_map,
@@ -1771,33 +1895,37 @@
 
         bsp.b_d_splines_slim(tn1, pn[0], e[0], span1, bn1, bd1)
         bsp.b_d_splines_slim(tn2, pn[1], e[1], span2, bn2, bd2)
         bsp.b_d_splines_slim(tn3, pn[2], e[2], span3, bn3, bd3)
 
         # eval all the needed field
         # abs_b; 0form
-        markers[ip, 22] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
+        markers[ip, 22] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
 
         # grad_abs_b; 1form
-        markers[ip, 23] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
-        markers[ip, 24] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
+        markers[ip, 23] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
+        markers[ip, 24] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
 
         # send particles to the (eta^0_n+1,eta^0_n+1, eta^0_n+1)
         markers[ip, 2] = markers[ip, 18]
 
+
 @stack_array('df', 'dfinv', 'g', 'g_inv', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3', 'e')
 def push_gc2_discrete_gradients_Itoh_Newton_prepare(markers: 'float[:,:]', dt: float,
                                                     domain_array: 'float[:]',
                                                     pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                                                     starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
                                                     kind_map: int, params_map: 'float[:]',
                                                     p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
                                                     ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
                                                     cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                                    kappa: float, 
+                                                    kappa: float,
                                                     abs_b: 'float[:,:,:]',
                                                     b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
                                                     norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
                                                     norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
                                                     curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
                                                     grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]'):
     r"""
@@ -1811,29 +1939,29 @@
     bn2 = empty(pn[1] + 1, dtype=float)
     bn3 = empty(pn[2] + 1, dtype=float)
 
     bd1 = empty(pn[0], dtype=float)
     bd2 = empty(pn[1], dtype=float)
     bd3 = empty(pn[2], dtype=float)
 
-    # containers 
+    # containers
     b = empty(3, dtype=float)
     curl_norm_b = empty(3, dtype=float)
     b_star = empty(3, dtype=float)
     norm_b1 = empty(3, dtype=float)
     grad_abs_b = empty(3, dtype=float)
 
     # marker position e
     e = empty(3, dtype=float)
-    
+
     # get number of markers
     n_markers = shape(markers)[0]
 
     for ip in range(n_markers):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         e[:] = markers[ip, 0:3]
         v = markers[ip, 3]
         mu = markers[ip, 4]
@@ -1856,67 +1984,82 @@
 
         bsp.b_d_splines_slim(tn1, pn[0], e[0], span1, bn1, bd1)
         bsp.b_d_splines_slim(tn2, pn[1], e[1], span2, bn2, bd2)
         bsp.b_d_splines_slim(tn3, pn[2], e[2], span3, bn3, bd3)
 
         # eval all the needed field
         # abs_b; 0form
-        abs_b0 = eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
+        abs_b0 = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
 
         # norm_b1; 1form
-        norm_b1[0] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
-        norm_b1[1] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
-        norm_b1[2] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
+        norm_b1[0] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts1[0])
+        norm_b1[1] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts1[1])
+        norm_b1[2] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts1[2])
 
         # b; 2form
-        b[0] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
-        b[1] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
-        b[2] = eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
+        b[0] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts2[0])
+        b[1] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts2[1])
+        b[2] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, b3, starts2[2])
 
         # curl_norm_b; 2form
-        curl_norm_b[0] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
-        curl_norm_b[1] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
-        curl_norm_b[2] = eval_spline_mpi_kernel(pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
+        curl_norm_b[0] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2] - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts2[0])
+        curl_norm_b[1] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2] - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts2[1])
+        curl_norm_b[2] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1] - 1, pn[2], bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts2[2])
 
         # grad_abs_b; 1form
-        grad_abs_b[0] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
-        grad_abs_b[1] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
-        grad_abs_b[2] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
+        grad_abs_b[0] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
+        grad_abs_b[1] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
+        grad_abs_b[2] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_abs_b3, starts1[2])
 
         # transform to H1vec
         b_star[:] = b + 1/kappa*v*curl_norm_b
         b_star[:] = b_star/det_df
 
         # calculate abs_b_star_para
         abs_b_star_para = linalg.scalar_dot(norm_b1, b_star)
 
         # save at the markers
         markers[ip, 13:16] = b_star[:]/abs_b_star_para
-        markers[ip, 19]    = abs_b0
+        markers[ip, 19] = abs_b0
 
         # calculate b_star . grad_abs_b
         b_star_dot_grad_abs_b = linalg.scalar_dot(b_star, grad_abs_b)*mu
 
         # save at the markers
         markers[ip, 16:19] = markers[ip, 0:3] + dt*b_star[:]/abs_b_star_para*v
-        markers[ip, 3] = markers[ip, 12] - dt*b_star_dot_grad_abs_b/abs_b_star_para
-        
+        markers[ip, 3] = markers[ip, 12] - dt * \
+            b_star_dot_grad_abs_b/abs_b_star_para
+
         # send particles to the (eta^0_n+1,eta_n, eta_n)
         markers[ip, 0] = markers[ip, 16]
 
+
 @stack_array('df', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3', 'e')
 def push_gc2_discrete_gradients_Itoh_Newton_prepare1(markers: 'float[:,:]', dt: float,
                                                      domain_array: 'float[:]',
                                                      pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                                                      starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
                                                      kind_map: int, params_map: 'float[:]',
                                                      p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
                                                      ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
                                                      cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                                     kappa: float, 
+                                                     kappa: float,
                                                      abs_b: 'float[:,:,:]',
                                                      b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
                                                      norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
                                                      norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
                                                      curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
                                                      grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]'):
     r"""TODO
@@ -1932,25 +2075,25 @@
 
     bd1 = empty(pn[0], dtype=float)
     bd2 = empty(pn[1], dtype=float)
     bd3 = empty(pn[2], dtype=float)
 
     # marker position e
     e = empty(3, dtype=float)
-    
+
     # get number of markers
     n_markers = shape(markers)[0]
 
     for ip in range(n_markers):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
-        if markers[ip, 13] == -1.:
+        if markers[ip, 23] == -1.:
             continue
 
         e[:] = markers[ip, 0:3]
 
         # evaluate Jacobian, result in df
         map_eval.df(e[0], e[1], e[2],
                     kind_map, params_map,
@@ -1966,32 +2109,35 @@
 
         bsp.b_d_splines_slim(tn1, pn[0], e[0], span1, bn1, bd1)
         bsp.b_d_splines_slim(tn2, pn[1], e[1], span2, bn2, bd2)
         bsp.b_d_splines_slim(tn3, pn[2], e[2], span3, bn3, bd3)
 
         # eval all the needed field
         # abs_b; 0form
-        markers[ip, 20] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
+        markers[ip, 20] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
 
         # grad_abs_b; 1form
-        markers[ip, 21] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
+        markers[ip, 21] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
 
         # send particles to the (eta^0_n+1,eta^0_n+1, eta_n)
         markers[ip, 1] = markers[ip, 17]
 
+
 @stack_array('df', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3', 'e')
 def push_gc2_discrete_gradients_Itoh_Newton_prepare2(markers: 'float[:,:]', dt: float,
                                                      domain_array: 'float[:]',
                                                      pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                                                      starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
                                                      kind_map: int, params_map: 'float[:]',
                                                      p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
                                                      ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
                                                      cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                                                     kappa: float, 
+                                                     kappa: float,
                                                      abs_b: 'float[:,:,:]',
                                                      b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
                                                      norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
                                                      norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
                                                      curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
                                                      grad_abs_b1: 'float[:,:,:]', grad_abs_b2: 'float[:,:,:]', grad_abs_b3: 'float[:,:,:]'):
     r"""TODO
@@ -2007,25 +2153,25 @@
 
     bd1 = empty(pn[0], dtype=float)
     bd2 = empty(pn[1], dtype=float)
     bd3 = empty(pn[2], dtype=float)
 
     # marker position e
     e = empty(3, dtype=float)
-    
+
     # get number of markers
     n_markers = shape(markers)[0]
 
     for ip in range(n_markers):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
-        if markers[ip, 13] == -1.:
+        if markers[ip, 23] == -1.:
             continue
 
         e[:] = markers[ip, 0:3]
 
         # evaluate Jacobian, result in df
         map_eval.df(e[0], e[1], e[2],
                     kind_map, params_map,
@@ -2041,30 +2187,33 @@
 
         bsp.b_d_splines_slim(tn1, pn[0], e[0], span1, bn1, bd1)
         bsp.b_d_splines_slim(tn2, pn[1], e[1], span2, bn2, bd2)
         bsp.b_d_splines_slim(tn3, pn[2], e[2], span3, bn3, bd3)
 
         # eval all the needed field
         # abs_b; 0form
-        markers[ip, 22] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
+        markers[ip, 22] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_b, starts0)
 
         # grad_abs_b; 1form
-        markers[ip, 23] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
-        markers[ip, 24] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
+        markers[ip, 23] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_abs_b1, starts1[0])
+        markers[ip, 24] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_abs_b2, starts1[1])
 
         # send particles to the (eta^0_n+1,eta^0_n+1, eta^0_n+1)
         markers[ip, 2] = markers[ip, 18]
 
+
 @stack_array('grad_PB', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3')
 def accum_gradI_const(markers: 'float[:,:]', n_markers_tot: 'int',
                       pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                       starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
                       grad_PB1: 'float[:,:,:]', grad_PB2: 'float[:,:,:]', grad_PB3: 'float[:,:,:]',
                       scale: 'float'):
-    
     r"""TODO
     """
     # allocate for magnetic field evaluation
     grad_PB = empty(3, dtype=float)
 
     bn1 = empty(pn[0] + 1, dtype=float)
     bn2 = empty(pn[1] + 1, dtype=float)
@@ -2075,25 +2224,25 @@
     bd3 = empty(pn[2], dtype=float)
 
     # allocate for filling
     res = zeros(1, dtype=float)
 
     # get number of markers
     n_markers_loc = shape(markers)[0]
-    
+
     for ip in range(n_markers_loc):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         # marker positions
-        eta1 = markers[ip, 0] # mid
-        eta2 = markers[ip, 1] # mid
-        eta3 = markers[ip, 2] # mid
+        eta1 = markers[ip, 0]  # mid
+        eta2 = markers[ip, 1]  # mid
+        eta3 = markers[ip, 2]  # mid
 
         # marker weight and velocity
         weight = markers[ip, 5]
         mu = markers[ip, 4]
 
         # b-field evaluation
         span1 = bsp.find_span(tn1, pn[0], eta1)
@@ -2101,43 +2250,47 @@
         span3 = bsp.find_span(tn3, pn[2], eta3)
 
         bsp.b_d_splines_slim(tn1, pn[0], eta1, span1, bn1, bd1)
         bsp.b_d_splines_slim(tn2, pn[1], eta2, span2, bn2, bd2)
         bsp.b_d_splines_slim(tn3, pn[2], eta3, span3, bn3, bd3)
 
         # grad_PB; 1form
-        grad_PB[0] = eval_spline_mpi_kernel(pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_PB1, starts1[0])
-        grad_PB[1] = eval_spline_mpi_kernel(pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_PB2, starts1[1])
-        grad_PB[2] = eval_spline_mpi_kernel(pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_PB3, starts1[2])
+        grad_PB[0] = eval_spline_mpi_kernel(
+            pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, grad_PB1, starts1[0])
+        grad_PB[1] = eval_spline_mpi_kernel(
+            pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, grad_PB2, starts1[1])
+        grad_PB[2] = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, grad_PB3, starts1[2])
+
+        res += linalg.scalar_dot(markers[ip, 15:18],
+                                 grad_PB) * weight * mu * scale
 
-        res += linalg.scalar_dot(markers[ip, 15:18] , grad_PB) * weight * mu * scale
-        
     return res/n_markers_tot
 
+
 @stack_array('PB', 'bn1', 'bn2', 'bn3')
 def accum_en_fB(markers: 'float[:,:]', n_markers_tot: 'int',
                 pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                 starts0: 'int[:]', starts1: 'int[:,:]', starts2: 'int[:,:]', starts3: 'int[:]',
                 PB: 'float[:,:,:]'):
-    
     r"""TODO
     """
     # allocate for magnetic field evaluation
     bn1 = empty(pn[0] + 1, dtype=float)
     bn2 = empty(pn[1] + 1, dtype=float)
     bn3 = empty(pn[2] + 1, dtype=float)
 
     # allocate for filling
     res = zeros(1, dtype=float)
 
     # get number of markers
     n_markers_loc = shape(markers)[0]
-    
+
     for ip in range(n_markers_loc):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         # marker positions
         eta1 = markers[ip, 0]
         eta2 = markers[ip, 1]
@@ -2152,90 +2305,94 @@
         span2 = bsp.find_span(tn2, pn[1], eta2)
         span3 = bsp.find_span(tn3, pn[2], eta3)
 
         bsp.b_splines_slim(tn1, pn[0], eta1, span1, bn1)
         bsp.b_splines_slim(tn2, pn[1], eta2, span2, bn2)
         bsp.b_splines_slim(tn3, pn[2], eta3, span3, bn3)
 
-        B0 = eval_spline_mpi_kernel(pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, PB, starts0)
+        B0 = eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, PB, starts0)
 
         res += abs(B0)*mu*weight
-        
+
     return res/n_markers_tot
 
+
 @stack_array('e', 'e_diff')
 def check_eta_diff(markers: 'float[:,:]'):
     r'''TODO
     '''
     # marker position e
     e = empty(3, dtype=float)
     e_diff = empty(3, dtype=float)
 
     # get number of markers
     n_markers_loc = shape(markers)[0]
 
     for ip in range(n_markers_loc):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         e[:] = markers[ip, 0:3]
         e_diff[:] = e[:] - markers[ip, 9:12]
 
         for axis in range(3):
             if e_diff[axis] > 0.5:
                 e_diff[axis] -= 1.
             elif e_diff[axis] < -0.5:
                 e_diff[axis] += 1.
 
-        markers[ip,15:18] = e_diff[:]
+        markers[ip, 15:18] = e_diff[:]
+
 
 @stack_array('e', 'e_diff')
 def check_eta_diff2(markers: 'float[:,:]'):
     r'''TODO
     '''
     # marker position e
     e = empty(3, dtype=float)
     e_diff = empty(3, dtype=float)
 
     # get number of markers
     n_markers_loc = shape(markers)[0]
 
     for ip in range(n_markers_loc):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         e[:] = markers[ip, 0:3]
         e_diff[:] = e[:] - markers[ip, 12:15]
 
         for axis in range(3):
             if e_diff[axis] > 0.5:
                 e_diff[axis] -= 1.
             elif e_diff[axis] < -0.5:
                 e_diff[axis] += 1.
 
-        markers[ip,15:18] = e_diff[:]
+        markers[ip, 15:18] = e_diff[:]
+
 
 @stack_array('e', 'e_diff', 'e_mid')
 def check_eta_mid(markers: 'float[:,:]'):
     r'''TODO
     '''
     # marker position e
     e = empty(3, dtype=float)
     e_diff = empty(3, dtype=float)
     e_mid = empty(3, dtype=float)
 
     # get number of markers
     n_markers_loc = shape(markers)[0]
 
     for ip in range(n_markers_loc):
-        
+
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         e[:] = markers[ip, 0:3]
         markers[ip, 12:15] = e[:]
 
@@ -2244,33 +2401,33 @@
 
         for axis in range(3):
             if e_diff[axis] > 0.5:
                 e_mid[axis] += 0.5
             elif e_diff[axis] < -0.5:
                 e_mid[axis] += 0.5
 
-        markers[ip,0:3] = e_mid[:]
+        markers[ip, 0:3] = e_mid[:]
+
 
 @stack_array('df', 'dfinv', 'dfinv_t', 'e', 'v', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3', 'a_form', 'dfta_form')
 def canonical_kinetic_particles(res: 'float[:]', markers: 'float[:,:]',
-                      pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                      starts1: 'int[:,:]',
-                      kind_map: int, params_map: 'float[:]',
-                      p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                      ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                      cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                      a1_1: 'float[:,:,:]', a1_2: 'float[:,:,:]', a1_3: 'float[:,:,:]'):
-    
+                                pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
+                                starts1: 'int[:,:]',
+                                kind_map: int, params_map: 'float[:]',
+                                p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
+                                ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
+                                cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
+                                a1_1: 'float[:,:,:]', a1_2: 'float[:,:,:]', a1_3: 'float[:,:,:]'):
     r'''
     Calculate kinetic energy of each particle and sum up the result.
 
     Parameters
     ----------
-    	res : array[float]
-    		array to store the sum of kinetic energy of particles
+        res : array[float]
+                array to store the sum of kinetic energy of particles
 
         markers : array[float]
             markers attribute of a struphy.pic.particles.Particles object
 
         pn : array[int]
             spline degrees
 
@@ -2280,31 +2437,31 @@
         starts1 : array[int]
             starts of the stencil objects
 
         kind_map ->  cz:
             domain information
 
         a1_1, a1_2, a1_3 : array[float]
-        	coefficients of one form (vector potential)
+                coefficients of one form (vector potential)
 
     .. math:: 
-    	\begin{align*}
-			\frac{1}{2} \sum_p w_p |{\mathbf p} -  \hat{\mathbf A}^1({\boldsymbol \eta}_p)|^2.
+        \begin{align*}
+                        \frac{1}{2} \sum_p w_p |{\mathbf p} -  \hat{\mathbf A}^1({\boldsymbol \eta}_p)|^2.
         \end{align*}
     '''
 
-    res[:] = 0.0 
+    res[:] = 0.0
     # allocate metric coeffs
     df = empty((3, 3), dtype=float)
     dfinv = empty((3, 3), dtype=float)
     dfinv_t = empty((3, 3), dtype=float)
 
     # allocate for field evaluations (1-form components)
     a_form = empty(3, dtype=float)
-    dfta_form =  empty(3, dtype=float)
+    dfta_form = empty(3, dtype=float)
     # particle position and velocity
     e = empty(3, dtype=float)
     v = empty(3, dtype=float)
 
     # allocate spline values
     bn1 = empty(pn[0] + 1, dtype=float)
     bn2 = empty(pn[1] + 1, dtype=float)
@@ -2323,15 +2480,15 @@
 
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         e[:] = markers[ip, 0:3]
         v[:] = markers[ip, 3:6]
-        w    = markers[ip,   6]
+        w = markers[ip,   6]
         # evaluate Jacobian, result in df
         map_eval.df(e[0], e[1], e[2],
                     kind_map, params_map,
                     t1_map, t2_map, t3_map, p_map,
                     ind1_map, ind2_map, ind3_map,
                     cx, cy, cz,
                     df)
@@ -2352,38 +2509,38 @@
         a_form[0] = eval_spline_mpi_kernel(
             pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, a1_1, starts1[0])
         a_form[1] = eval_spline_mpi_kernel(
             pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, a1_2, starts1[1])
         a_form[2] = eval_spline_mpi_kernel(
             pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, a1_3, starts1[2])
 
-        dfta_form[0] = dfinv_t[0,0] * a_form[0] + dfinv_t[0,1] * a_form[1] + dfinv_t[0,2] * a_form[2]
-        dfta_form[1] = dfinv_t[1,0] * a_form[0] + dfinv_t[1,1] * a_form[1] + dfinv_t[1,2] * a_form[2]
-        dfta_form[2] = dfinv_t[2,0] * a_form[0] + dfinv_t[2,1] * a_form[1] + dfinv_t[2,2] * a_form[2]
+        dfta_form[0] = dfinv_t[0, 0] * a_form[0] + \
+            dfinv_t[0, 1] * a_form[1] + dfinv_t[0, 2] * a_form[2]
+        dfta_form[1] = dfinv_t[1, 0] * a_form[0] + \
+            dfinv_t[1, 1] * a_form[1] + dfinv_t[1, 2] * a_form[2]
+        dfta_form[2] = dfinv_t[2, 0] * a_form[0] + \
+            dfinv_t[2, 1] * a_form[1] + dfinv_t[2, 2] * a_form[2]
 
-        res[0] += 0.5 * w * ( (v[0] - dfta_form[0]) ** 2.0 + (v[1] - dfta_form[1]) ** 2.0 + (v[2] - dfta_form[2]) ** 2.0 )
+        res[0] += 0.5 * w * ((v[0] - dfta_form[0]) ** 2.0 +
+                             (v[1] - dfta_form[1]) ** 2.0 + (v[2] - dfta_form[2]) ** 2.0)
 
     #$ omp end parallel
 
 
-
-
-
 @stack_array('det_df', 'df')
-def thermal_energy(res: 'float[:]', density: 'float[:,:,:,:,:,:]', 
-                  pads1 : int, pads2 : int, pads3 : int,
-                  nel1 : 'int', nel2 : 'int', nel3 : 'int', 
-                  nq1 : int, nq2 : int, nq3 : int, 
-                  w1 : 'float[:,:]', w2 : 'float[:,:]', w3 : 'float[:,:]', 
-                  pts1 : 'float[:,:]', pts2 : 'float[:,:]', pts3 : 'float[:,:]', 
-                  kind_map: int, params_map: 'float[:]',
-                  p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                  ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                  cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]'):
-    
+def thermal_energy(res: 'float[:]', density: 'float[:,:,:,:,:,:]',
+                   pads1: int, pads2: int, pads3: int,
+                   nel1: 'int', nel2: 'int', nel3: 'int',
+                   nq1: int, nq2: int, nq3: int,
+                   w1: 'float[:,:]', w2: 'float[:,:]', w3: 'float[:,:]',
+                   pts1: 'float[:,:]', pts2: 'float[:,:]', pts3: 'float[:,:]',
+                   kind_map: int, params_map: 'float[:]',
+                   p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
+                   ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
+                   cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]'):
     r'''
     Calculate thermal energy of electron.
 
     Parameters
     ----------
         res : array[float]
             array to store the thermal energy of electrons
@@ -2436,20 +2593,22 @@
 
                             eta1 = pts1[iel1, q1]
                             eta2 = pts2[iel2, q2]
                             eta3 = pts3[iel3, q3]
 
                             wvol = w1[iel1, q1] * w2[iel2, q2] * w3[iel3, q3]
 
-                            vv   = density[pads1 + iel1, pads2 + iel2, pads3 + iel3, q1, q2, q3]
-                                
+                            vv = density[pads1 + iel1, pads2 +
+                                         iel2, pads3 + iel3, q1, q2, q3]
+
                             if abs(vv) < 0.00001:
-                                vv = 1.0 
+                                vv = 1.0
 
                             # evaluate Jacobian, result in df
-                            map_eval.df(eta1, eta2, eta3, kind_map, params_map, t1_map, t2_map, t3_map, p_map, ind1_map, ind2_map, ind3_map, cx, cy, cz, df)
+                            map_eval.df(eta1, eta2, eta3, kind_map, params_map, t1_map, t2_map,
+                                        t3_map, p_map, ind1_map, ind2_map, ind3_map, cx, cy, cz, df)
 
                             det_df = linalg.det(df)
 
                             res[0] += vv * det_df * log(vv) * wvol
 
     #$ omp end parallel
```

### Comparing `struphy-2.0.1/src/struphy/polar/basic.py` & `struphy-2.0.2/src/struphy/polar/basic.py`

 * *Files 1% similar despite different names*

```diff
@@ -500,14 +500,18 @@
         Parameters
         ----------
         direction : int
             Single direction along which to operate (if not specified, all of them).
 
         """
         self._tp.update_ghost_regions(direction=direction)
+        
+    def conjugate(self):
+        '''No need for complex conjugate'''
+        pass
 
     
 def set_tp_rings_to_zero(v, n_rings):
     """
     Sets a certain number of rings of a Stencil-/BlockVector in eta_1 direction to zero.
     
     Parameters
```

### Comparing `struphy-2.0.1/src/struphy/polar/extraction_operators.py` & `struphy-2.0.2/src/struphy/polar/extraction_operators.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/polar/linear_operators.py` & `struphy-2.0.2/src/struphy/polar/linear_operators.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/post_processing/cprofile_analyser.py` & `struphy-2.0.2/src/struphy/post_processing/cprofile_analyser.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/post_processing/post_processing_tools.py` & `struphy-2.0.2/src/struphy/post_processing/post_processing_tools.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/post_processing/pproc_struphy.py` & `struphy-2.0.2/src/struphy/post_processing/pproc_struphy.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/post_processing/profile_struphy.py` & `struphy-2.0.2/src/struphy/console/profile.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,165 +1,195 @@
-import sys
-import pickle
-import yaml
-import numpy as np
-from matplotlib import pyplot as plt
-
-from struphy.post_processing.cprofile_analyser import get_cprofile_data, replace_keys
-
-
-def main():
+def struphy_profile(dirs, replace, all, n_lines, print_callers, savefig_dir):
     """
-    TODO
+    Profile finished Struphy runs.
     """
-    print(sys.argv)
+
+    import os
+    import pickle
+    import yaml
+    import numpy as np
+    from matplotlib import pyplot as plt
+    from struphy.post_processing.cprofile_analyser import get_cprofile_data, replace_keys
+    import struphy
+
+    libpath = struphy.__path__[0]
+    
+    with open(os.path.join(libpath, 'o_path.txt')) as f:
+        o_path = f.readlines()[0]
+
+    # absolute paths
+    abs_paths = []
+    for d in dirs:
+        abs_paths += [os.path.join(o_path, d)]
+
+    # define the function filter
+    list_of_funcs = ['assemble_',
+                     'propagator',
+                     'accumulate',
+                     '_fill',
+                     'pusher',
+                     'update_ghost_regions',
+                     'solver',
+                     'class ',
+                     'stencil',
+                     'block',
+                     'integrate_in_time']
 
     # check --all option
-    if sys.argv[1] == 'true':
+    if all:
         list_of_funcs = None
     else:
-        list_of_funcs = ['assemble_',
-                         'propagator',
-                         'accumulate',
-                         '_fill',
-                         'pusher',
-                         'update_ghost_regions',
-                         'solver',
-                         'class ',
-                         'stencil',
-                         'block',
-                         'integrate_in_time']
-        print('\nKeyword search enabled with keywords:')
-        print('-------------------------------------')
+        print('\nKeyword search enabled with the following filter:')
+        print('-------------------------------------------------')
         print(list_of_funcs)
-        
+
     print('\nLoad profiling data:')
     print('--------------------')
 
-    # replace propagator keys or not
-    do_replace_keys = sys.argv[2] == 'true'
-
-    # plot n_lines most time consuming calls in profiling analysis
-    n_lines = int(sys.argv[3])
-
     # load data
     sim_names = []
     dicts_pre = []
     nproc = []
     Nel = []
-    for path in sys.argv[4:]:
+    for path in abs_paths:
 
         print('')
-        get_cprofile_data(path)
-        
-        sim_names += [path.split('/')[-2]]
+        get_cprofile_data(path, print_callers)
+
+        sim_names += [path.split('/')[-1]]
 
-        with open(path + 'profile_dict.sav', 'rb') as f:
+        with open(os.path.join(path, 'profile_dict.sav'), 'rb') as f:
             dicts_pre += [pickle.load(f)]
 
-        with open(path + 'meta.txt', 'r') as f:
+        with open(os.path.join(path, 'meta.txt'), 'r') as f:
             lines = f.readlines()
 
         nproc += [int(lines[4].split()[-1])]
 
-        with open(path + 'parameters.yml', 'r') as f:
+        with open(os.path.join(path, 'parameters.yml'), 'r') as f:
             params = yaml.load(f, Loader=yaml.FullLoader)
 
         Nel += [params['grid']['Nel']]
 
     # Nicer key names for output:
     dicts = []
     for d in dicts_pre:
 
         tmp = {}
         for key, val in d.items():
-            #tmp[key] = float(val['cumtime'])
+            # tmp[key] = float(val['cumtime'])
             tmp[key] = val
 
-        if do_replace_keys:
+        if replace:
             tmp2 = replace_keys(tmp)
         else:
             tmp2 = tmp
 
         dicts += [tmp2]
 
+    # runtime of the main
+    runtime = dicts[0]['main.py:1(<module>)']['cumtime']
+
     # loop over keys (should be same in each dict)
     d_saved = {}
-    print('simulation'.ljust(20) + '#proc'.ljust(7) + 'pos'.ljust(5) + 'function'.ljust(70) + 'ncalls'.ljust(15) + 'totime'.ljust(15) + 'percall'.ljust(15) + 'cumtime'.ljust(15))
+    print('simulation'.ljust(20) + '#proc'.ljust(7) + 'pos'.ljust(5) + 'function'.ljust(70) +
+          'ncalls'.ljust(15) + 'tottime'.ljust(15) + 'percall'.ljust(15) + 'cumtime'.ljust(15))
     print('-'*154)
     for position, key in enumerate(dicts[0].keys()):
 
         if list_of_funcs == None:
 
             for dict, sim_name, n, dim in zip(dicts, sim_names, nproc, Nel):
 
-                string = f'{sim_name}'.ljust(20) + f'{n}'.ljust(7) + f'{position:2d}'.ljust(5) + str(key.ljust(70))
+                string = f'{sim_name}'.ljust(
+                    20) + f'{n}'.ljust(7) + f'{position:2d}'.ljust(5) + str(key.ljust(70))
                 for value in dict[key].values():
                     string += str(value).ljust(15)
                     # if len(str(value)) < 7:
                     #     string += '\t\t'
                     # else:
                     #     string += '\t'
                 print(string)
             print('')
 
             if position == 50:
-
-                exit()
+                break
 
         elif any(func in key for func in list_of_funcs) and 'dependencies_' not in key and '_dot' not in key:
 
             d_saved[key] = {'mpi_size': [], 'Nel': [], 'time': []}
 
             for dict, sim_name, n, dim in zip(dicts, sim_names, nproc, Nel):
 
-                string = f'{sim_name}'.ljust(20) + f'{n}'.ljust(7) + f'{position:2d}'.ljust(5) + str(key.ljust(70))
+                string = f'{sim_name}'.ljust(
+                    20) + f'{n}'.ljust(7) + f'{position:2d}'.ljust(5) + str(key.ljust(70))
                 for value in dict[key].values():
                     string += str(value).ljust(15)
-                    #string += '\t\t'
+                    # string += '\t\t'
                 print(string)
 
                 d_saved[key]['mpi_size'] += [n]
                 d_saved[key]['Nel'] += [dim]
-                d_saved[key]['time'] += [dict[key]]
+                d_saved[key]['time'] += [dict[key]['cumtime']]
             print('')
 
             if position >= 200:
-                exit()
+                break
 
     # save profiling date in each sim path
-    for path in sys.argv[4:]:
-        with open(path + 'comparison_dict.sav', 'w+b') as f:
+    for path in abs_paths:
+        with open(os.path.join(path, 'comparison_dict.sav'), 'w+b') as f:
             pickle.dump(d_saved, f)
 
     # plot results
-    fig = plt.figure(figsize=(10, 10))
+    fig, ax = plt.subplots(figsize=(10, 10))
+    plt.rcParams.update({'font.size': 13})
+
     for n, (key, val) in enumerate(d_saved.items()):
         if n < n_lines and '__init__' not in key and 'mass' not in key and 'set_backend' not in key:
-            #print(key, val)
+
+            # runtime of the main
+            runtime = float(dicts[0]['main.py:1(<module>)']['cumtime'])
+
+            # calculate relative cumtime and the ratio (cumtime/runtime)
+            min_time = float(val['time'][0])
+            relative_times = []
+            ratio = []
+            for t in val['time']:
+                relative_times.append(float(t)/min_time)
+                ratio.append(str(int(float(t)/runtime*100))+'%')
 
             # strong scaling plot
-            if all([Nel == val['Nel'][0] for Nel in val['Nel']]):
-                plt.loglog(val['mpi_size'], val['time'], label=key)
-                plt.xlabel('mpi_size')
-                plt.ylabel('time [s]')
-                plt.title('Strong scaling for Nel=' +
+            if np.all([Nel == val['Nel'][0] for Nel in val['Nel']]):
+                
+                # ideal scaling
+                if n == 0:
+                    ax.loglog(val['mpi_size'], 1/2 **np.arange(len(val['time'])), 'k--', 
+                              alpha=0.3, label='ideal')
+
+                ax.loglog(val['mpi_size'], relative_times, 'o' '-', label=key+', '+''.join(ratio[0]))
+                # plt.loglog(val['mpi_size'], val['time'], label=key)
+                ax.set_xlabel('MPI #', fontsize=13)
+                ax.set_ylabel('Relative time [Total time with MPI #' + str(val['mpi_size'][0]) + ']', fontsize=13)
+                ax.set(title='Strong scaling for Nel=' +
                           str(val['Nel'][0]) + ' cells')
-                plt.legend(loc='lower left')
-                plt.loglog(val['mpi_size'], val['time'][0]/2 **
-                           np.arange(len(val['time'])), 'k--', alpha=0.3)
+                ax.legend(loc='lower left')
+
             # weak scaling plot
             else:
-                plt.plot(val['mpi_size'], val['time'], label=key)
-                plt.xlabel('mpi_size')
-                plt.ylabel('time [s]')
-                plt.title('Weak scaling for cells/mpi_size=' +
+                ax.plot(val['mpi_size'], val['time'], label=key)
+                ax.set_xlabel('mpi_size')
+                ax.set_ylabel('time [s]')
+                ax.set(title='Weak scaling for cells/mpi_size=' +
                           str(np.prod(val['Nel'][0])/val['mpi_size'][0]) + '=const.')
-                plt.legend(loc='upper left')
-                #plt.loglog(val['mpi_size'], val['time'][0]*np.ones_like(val['time']), 'k--', alpha=0.3)
-                plt.xscale('log')
+                ax.legend(loc='upper left')
+                # ax.loglog(val['mpi_size'], val['time'][0]*np.ones_like(val['time']), 'k--', alpha=0.3)
+                ax.xscale('log')
 
-    plt.show()
+    if savefig_dir is None:
+        plt.show()
 
+    else:
+        # savefig paths
+        save_path = os.path.join(o_path, savefig_dir)
 
-if __name__ == '__main__':
-    main()
+        plt.savefig(save_path)
```

### Comparing `struphy-2.0.1/src/struphy/propagators/base.py` & `struphy-2.0.2/src/struphy/propagators/base.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,34 +1,64 @@
 from abc import ABCMeta, abstractmethod
 import numpy as np
 
+from psydac.linalg.basic import Vector
+from struphy.pic.particles import Particles
+
 
 class Propagator(metaclass=ABCMeta):
-    '''Base class for Struphy propagators used in Struphy models.
+    '''Base class for Struphy propagators used in Struphy models. 
 
     Note
     ---- 
         All Struphy propagators are subclasses of ``Propagator``.
         
-        The ``__init__`` of child classes must take as first arguments the variables to be updated.
+        The ``__init__`` of child classes must take as arguments the variables to be updated.
         All additional arguments MUST be passed as **keyword arguments**.
+        The variables (not the other arguments) must then be passed to `super().__init__()`.
     '''
 
+    def __init__(self, *vars):
+        '''
+        Create an instance of a Propagator.
+        
+        Parameters
+        ----------
+        vars : Vector or Particles
+            :attr:`struphy.models.base.StruphyModel.pointer` of variables to be updated.'''
+        
+        self._feec_vars = []
+        self._particles = []
+        
+        for var in vars:
+            if isinstance(var, Vector):
+                self._feec_vars += [var]
+            elif isinstance(var, Particles):
+                self._particles += [var]
+            else:
+                ValueError(f'Variable {var} must be of type "Vector" or "Particles".')
+        
     @property
-    @abstractmethod
-    def variables(self):
+    def feec_vars(self):
         '''List of FEEC variables (not particles) to be updated by the propagator. 
-        Contains FE coefficients from the ``Field.vector`` property of :ref:`fields`.
+        Contains FE coefficients from :attr:`struphy.psydac_api_fields.Field.vector`.
         '''
-        pass
+        return self._feec_vars
+    
+    @property
+    def particles(self):
+        '''List of kinetic variables (not FEEC) to be updated by the propagator. 
+        Contains :class:`struphy.pic.particles.Particles`.
+        '''
+        return self._particles
 
     @abstractmethod
     def __call__(self, dt):
         '''Update from t -> t + dt.
-        Use ``Propagators.in_place_update`` to write to FE variables to ``Propagator.variables``.
+        Use ``Propagators.feec_vars_update`` to write to FEEC variables to ``Propagator.feec_vars``.
 
         Parameters
         ----------
             dt : float
                 Time step size.
         '''
         pass
@@ -77,37 +107,37 @@
             'Basis projection operators not set. Please do obj.basis_ops = ...'
         return self._basis_ops
 
     @basis_ops.setter
     def basis_ops(self, basis_ops):
         self._basis_ops = basis_ops
 
-    def in_place_update(self, *variables_new):
-        '''Writes new entries into the FEEC variables in ``Propagator.variables``.
+    def feec_vars_update(self, *variables_new):
+        '''Writes new entries into the FEEC variables in ``Propagator.feec_vars``.
 
         Parameters
         ----------
             variables_new : list
-                Same sequence as in ``Propagator.variables`` but with the updated variables, 
-                i.e. for variables = [e, b] we must have variables_new = [e_updated, b_updated].
+                Same sequence as in ``Propagator.feec_vars`` but with the updated variables, 
+                i.e. for feec_vars = [e, b] we must have variables_new = [e_updated, b_updated].
 
         Returns
         -------
             diffs : list
-                A list [max(abs(self.variables - variables_new)), ...] for all variables in self.variables and variables_new.'''
+                A list [max(abs(self.feec_vars - variables_new)), ...] for all variables in self.feec_vars and variables_new.'''
 
         diffs = []
 
         for i, new in enumerate(variables_new):
 
-            assert type(new) is type(self.variables[i])
+            assert type(new) is type(self.feec_vars[i])
 
             # calculate maximum of difference abs(old - new)
-            diffs += [np.max(np.abs(self.variables[i].toarray() - new.toarray()))]
+            diffs += [np.max(np.abs(self.feec_vars[i].toarray() - new.toarray()))]
 
-            # copy new variables into self.variables
-            new.copy(out=self.variables[i])
+            # copy new variables into self.feec_vars
+            new.copy(out=self.feec_vars[i])
 
             # important: sync processes!
-            self.variables[i].update_ghost_regions()
+            self.feec_vars[i].update_ghost_regions()
 
         return diffs
```

### Comparing `struphy-2.0.1/src/struphy/propagators/propagators_coupling.py` & `struphy-2.0.2/src/struphy/propagators/propagators_coupling.py`

 * *Files 14% similar despite different names*

```diff
@@ -17,15 +17,170 @@
 from struphy.psydac_api.linear_operators import ScalarTimesLinearOperator as Multiply
 from struphy.psydac_api.linear_operators import InverseLinearOperator as Inverse
 from struphy.psydac_api import preconditioner
 from struphy.psydac_api.linear_operators import LinOpWithTransp
 from struphy.psydac_api.mass import WeightedMassOperator
 import struphy.linear_algebra.iterative_solvers as it_solvers
 
-from psydac.linalg.iterative_solvers import pcg
+from struphy.linear_algebra.iterative_solvers import PConjugateGradient as pcg
+
+
+class VlasovMaxwell(Propagator):
+    r'''Solve the following Crank-Nicolson step
+
+    .. math::
+
+        \begin{bmatrix}
+            \mathbb{M}_1 \left( \mathbf{e}^{n+1} - \mathbf{e}^n \right) \\
+            \mathbf{V}^{n+1} - \mathbf{V}^n
+        \end{bmatrix}
+        =
+        \frac{\Delta t}{2}
+        \begin{bmatrix}
+            0 & - c_1 \left(\mathbb{\Lambda}^1\right)^\top \overline{DF^{-1}} \mathbb{W} \\
+            c_2 \overline{DF^{-\top}} \mathbb{\Lambda}^1 & 0
+        \end{bmatrix}
+        \begin{bmatrix}
+            \mathbf{e}^{n+1} + \mathbf{e}^n \\
+            \mathbf{V}^{n+1} + \mathbf{V}^n
+        \end{bmatrix}
+
+    based on the :ref:`Schur complement <schur_solver>` where
+
+    .. math::
+        \begin{align}
+        \mathbb{W} & = \text{diag}(w_p) \,,
+        \end{align}
+
+    and the accumulation matrix writes
+
+    .. math::
+        \mathbb{A} = -\frac{{\Delta t}^2}{4} c_1 c_2 \, \left( \mathbb{\Lambda}^1 \right)^\top \overline{G^{-1}} \mathbb{W} \mathbb{\Lambda}^1 \,.
+
+    Parameters
+    ---------- 
+    e : psydac.linalg.block.BlockVector
+        FE coefficients of a 1-form.
+
+    particles : struphy.pic.particles.Particles6D
+        Particles object.
+
+    **params : dict
+        Solver- and/or other parameters for this splitting step.
+
+    Note
+    ----------
+    For VlasovMaxwell :math:`c_1 = \alpha^2/\varepsilon \,, \, c_2 = 1/\varepsilon`
+    '''
+
+    def __init__(self, e, particles, **params):
+
+        super().__init__(e, particles)
+
+        # parameters
+        params_default = {'c1': 1.,
+                          'c2': 1.,
+                          'type': 'PConjugateGradient',
+                          'pc': 'MassMatrixPreconditioner',
+                          'tol': 1e-8,
+                          'maxiter': 3000,
+                          'info': False,
+                          'verbose': False}
+
+        params = set_defaults(params, params_default)
+
+        self._c1 = params['c1']
+        self._c2 = params['c2']
+        self._info = params['info']
+
+        # Initialize Accumulator object
+        self._accum = Accumulator(self.derham, self.domain, 'Hcurl', 'vlasov_maxwell',
+                                  add_vector=True, symmetry='symm')
+
+        # Create buffers to store temporarily _e and its sum with old e
+        self._e_temp = e.copy()
+        self._e_sum = e.copy()
+
+        # store old weights to compute difference
+        self._old_v_sq = np.empty(particles.markers.shape[0], dtype=float)
+        self._new_v_sq = np.empty(particles.markers.shape[0], dtype=float)
+
+        # ================================
+        # ========= Schur Solver =========
+        # ================================
+
+        # Preconditioner
+        if params['pc'] == None:
+            self._pc = None
+        else:
+            pc_class = getattr(preconditioner, params['pc'])
+            self._pc = pc_class(self.mass_ops.M1)
+
+        # Define block matrix [[A B], [C I]] (without time step size dt in the diagonals)
+        _A = self.mass_ops.M1
+        _BC = - self._accum.operators[0].matrix / 4.
+
+        # Instantiate Schur solver
+        self._schur_solver = SchurSolver(_A, _BC, pc=self._pc, solver_name=params['type'],
+                                         tol=params['tol'], maxiter=params['maxiter'],
+                                         verbose=params['verbose'])
+
+        # Instantiate particle pusher
+        self._pusher = Pusher(self.derham, self.domain,
+                              'push_v_with_efield')
+
+    def __call__(self, dt):
+        # accumulate
+        self._accum.accumulate(self.particles[0])
+
+        # Update Schur solver
+        self._schur_solver.BC = - self._c1 * self._c2 / \
+            4. * self._accum.operators[0].matrix
+
+        # allocate temporary BlockVector during solution
+        self._e_temp, info = self._schur_solver(
+            self.feec_vars[0], self._c1 / 2. * self._accum.vectors[0], dt)
+
+        # Store old velocity magnitudes
+        self._old_v_sq[~self.particles[0].holes] = np.sqrt(self.particles[0].markers[~self.particles[0].holes, 3]**2 +
+                                                           self.particles[0].markers[~self.particles[0].holes, 4]**2 +
+                                                           self.particles[0].markers[~self.particles[0].holes, 5]**2)
+
+        # reset _e_sum
+        self._e_sum *= 0.
+
+        # self._e_sum = self._e_temp + self.feec_vars[0]
+        self._e_sum += self._e_temp
+        self._e_sum += self.feec_vars[0]
+        self._e_sum *= 1/2
+
+        # Update velocities
+        self._pusher(self.particles[0], dt,
+                     self._e_sum.blocks[0]._data,
+                     self._e_sum.blocks[1]._data,
+                     self._e_sum.blocks[2]._data,
+                     self._c2)
+
+        # Store new velocity magnitudes
+        self._new_v_sq[~self.particles[0].holes] = np.sqrt(self.particles[0].markers[~self.particles[0].holes, 3]**2 +
+                                                           self.particles[0].markers[~self.particles[0].holes, 4]**2 +
+                                                           self.particles[0].markers[~self.particles[0].holes, 5]**2)
+
+        # write new coeffs into self.variables
+        max_de, = self.feec_vars_update(self._e_temp)
+
+        # Print out max differences for weights and e-field
+        if self._info:
+            print('Status      for VlasovMaxwell:', info['success'])
+            print('Iterations  for VlasovMaxwell:', info['niter'])
+            print('Maxdiff e1  for VlasovMaxwell:', max_de)
+            max_diff = np.max(np.abs(self._old_v_sq[~self.particles[0].holes]
+                                     - self._new_v_sq[~self.particles[0].holes]))
+            print('Maxdiff |v| for VlasovMaxwell:', max_diff)
+            print()
 
 
 class EfieldWeightsImplicit(Propagator):
     r'''Solve the following Crank-Nicolson step
 
     .. math::
 
@@ -68,20 +223,15 @@
         Solver- and/or other parameters for this splitting step.
     '''
 
     def __init__(self, e, particles, **params):
 
         from struphy.kinetic_background.maxwellians import Maxwellian6DUniform
 
-        # pointers to variables
-        assert isinstance(e, (BlockVector, PolarVector))
-        self._e = e
-
-        assert isinstance(particles, Particles6D)
-        self._particles = particles
+        super().__init__(e, particles)
 
         # parameters
         params_default = {'alpha': 1.,
                           'kappa': 1.,
                           'f0': Maxwellian6DUniform(),
                           'type': 'PConjugateGradient',
                           'pc': 'MassMatrixPreconditioner',
@@ -138,68 +288,64 @@
                                          tol=params['tol'], maxiter=params['maxiter'],
                                          verbose=params['verbose'])
 
         # Instantiate particle pusher
         self._pusher = Pusher(self.derham, self.domain,
                               'push_weights_with_efield_lin_vm')
 
-    @property
-    def variables(self):
-        return [self._e]
-
     def __call__(self, dt):
         # evaluate f0 and accumulate
-        f0_values = self._f0(self._particles.markers[:, 0],
-                             self._particles.markers[:, 1],
-                             self._particles.markers[:, 2],
-                             self._particles.markers[:, 3],
-                             self._particles.markers[:, 4],
-                             self._particles.markers[:, 5])
+        f0_values = self._f0(self.particles[0].markers[:, 0],
+                             self.particles[0].markers[:, 1],
+                             self.particles[0].markers[:, 2],
+                             self.particles[0].markers[:, 3],
+                             self.particles[0].markers[:, 4],
+                             self.particles[0].markers[:, 5])
 
-        self._accum.accumulate(self._particles, f0_values,
+        self._accum.accumulate(self.particles[0], f0_values,
                                self._f0_params, self._alpha, self._kappa)
 
         # Update Schur solver
         self._schur_solver.BC = - self._accum.operators[0].matrix / 4
 
         # allocate temporary BlockVector during solution
         self._e_temp, info = self._schur_solver(
-            self._e, self._accum.vectors[0] / 2., dt,
+            self.feec_vars[0], self._accum.vectors[0] / 2., dt,
             out=self._e_temp)
 
         # Store old weights
-        self._old_weights[~self._particles.holes] = self._particles.markers[~self._particles.holes, 6]
+        self._old_weights[~self.particles[0].holes] = self.particles[0].markers[~self.particles[0].holes, 6]
 
         # reset _e_sum
         self._e_sum *= 0.
 
         # Compute e^{n+1} + e^n
         self._e_sum += self._e_temp
-        self._e_sum += self._e
+        self._e_sum += self.feec_vars[0]
 
         # Update weights
-        self._pusher(self._particles, dt,
+        self._pusher(self.particles[0], dt,
                      self._e_sum.blocks[0]._data,
                      self._e_sum.blocks[1]._data,
                      self._e_sum.blocks[2]._data,
                      f0_values,
                      self._f0_params,
-                     int(self._particles.n_mks),
+                     int(self.particles[0].n_mks),
                      self._kappa)
 
         # write new coeffs into self.variables
-        max_de, = self.in_place_update(self._e_temp)
+        max_de, = self.feec_vars_update(self._e_temp)
 
         # Print out max differences for weights and e-field
         if self._info:
             print('Status          for StepEfieldWeights:', info['success'])
             print('Iterations      for StepEfieldWeights:', info['niter'])
             print('Maxdiff    e1   for StepEfieldWeights:', max_de)
-            max_diff = np.max(np.abs(self._old_weights[~self._particles.holes]
-                                     - self._particles.markers[~self._particles.holes, 6]))
+            max_diff = np.max(np.abs(self._old_weights[~self.particles[0].holes]
+                                     - self.particles[0].markers[~self.particles[0].holes, 6]))
             print('Maxdiff weights for StepEfieldWeights:', max_diff)
             print()
 
 
 class EfieldWeightsExplicit(Propagator):
     r'''Solve the following system analytically
 
@@ -224,20 +370,15 @@
         Solver- and/or other parameters for this splitting step.
     '''
 
     def __init__(self, e, particles, **params):
 
         from struphy.kinetic_background.maxwellians import Maxwellian6DUniform
 
-        # pointers to variables
-        assert isinstance(e, (BlockVector, PolarVector))
-        self._e = e
-
-        assert isinstance(particles, Particles6D)
-        self._particles = particles
+        super().__init__(e, particles)
 
         # parameters
         params_default = {'alpha': 1e2,
                           'kappa': 1.,
                           'f0': Maxwellian6DUniform(),
                           'type': 'PConjugateGradient',
                           'pc': 'MassMatrixPreconditioner',
@@ -282,74 +423,73 @@
 
         # Preconditioner
         if params['pc'] == None:
             self._pc = None
         else:
             pc_class = getattr(preconditioner, params['pc'])
             self._pc = pc_class(self.mass_ops.M1)
+            
+        # solver
+        self.solver =pcg(e.space)
 
         self._pusher = Pusher(self.derham, self.domain,
                               'push_weights_with_efield_deltaf_vm')
 
-    @property
-    def variables(self):
-        return [self._e]
-
     def __call__(self, dt):
         # evaluate f0 and accumulate
-        f0_values = self._f0(self._particles.markers[:, 0],
-                             self._particles.markers[:, 1],
-                             self._particles.markers[:, 2],
-                             self._particles.markers[:, 3],
-                             self._particles.markers[:, 4],
-                             self._particles.markers[:, 5])
+        f0_values = self._f0(self.particles[0].markers[:, 0],
+                             self.particles[0].markers[:, 1],
+                             self.particles[0].markers[:, 2],
+                             self.particles[0].markers[:, 3],
+                             self.particles[0].markers[:, 4],
+                             self.particles[0].markers[:, 5])
 
-        self._accum.accumulate(self._particles, f0_values,
+        self._accum.accumulate(self.particles[0], f0_values,
                                self._f0_params, self._alpha, self._kappa)
 
-        self._m1_acc_vec, info = pcg(self.mass_ops.M1,
+        self._m1_acc_vec, info = self.solver.solve(self.mass_ops.M1,
                                      self._accum.vectors[0],
                                      self._pc,
-                                     self._e,
+                                     x0=self.feec_vars[0],
                                      tol=self._params['tol'],
                                      maxiter=self._params['maxiter'],
                                      verbose=self._params['verbose']
                                      )
 
         # Store old weights
-        self._old_weights[~self._particles.holes] = self._particles.markers[~self._particles.holes, 6]
+        self._old_weights[~self.particles[0].holes] = self.particles[0].markers[~self.particles[0].holes, 6]
 
         # Compute vector for particle pushing
         self._e_dt2 *= 0.
         self._e_dt2 -= self._m1_acc_vec
         self._e_dt2 *= dt / 2
-        self._e_dt2 += self._e
+        self._e_dt2 += self.feec_vars[0]
 
         # Update weights
-        self._pusher(self._particles, dt,
+        self._pusher(self.particles[0], dt,
                      self._e_dt2.blocks[0]._data,
                      self._e_dt2.blocks[1]._data,
                      self._e_dt2.blocks[2]._data,
                      f0_values,
                      self._f0_params,
-                     int(self._particles.n_mks),
+                     int(self.particles[0].n_mks),
                      self._kappa)
 
         # Update e-field and compute max difference
         self._m1_acc_vec *= dt
         max_de = np.max(np.abs(self._m1_acc_vec.toarray()))
-        self._e -= self._m1_acc_vec
+        self.feec_vars[0] -= self._m1_acc_vec
 
         # Print out max differences for weights and e-field
         if self._info:
             print('Status          for StepEfieldWeights:', info['success'])
             print('Iterations      for StepEfieldWeights:', info['niter'])
             print('Maxdiff    e1   for StepEfieldWeights:', max_de)
-            max_diff = np.max(np.abs(self._old_weights[~self._particles.holes]
-                                     - self._particles.markers[~self._particles.holes, 6]))
+            max_diff = np.max(np.abs(self._old_weights[~self.particles[0].holes]
+                                     - self.particles[0].markers[~self.particles[0].holes, 6]))
             print('Maxdiff weights for StepEfieldWeights:', max_diff)
             print()
 
 
 class PressureCoupling6D(Propagator):
     r'''Crank-Nicolson step for pressure coupling term in MHD equations and velocity update with the force term :math:`\nabla \mathbf U \cdot \mathbf v`.
 
@@ -385,20 +525,15 @@
 
         coupling_solver: dict
                          Solver parameters for this splitting step.
     '''
 
     def __init__(self, particles, u, **params):
 
-        # pointers to variables
-        assert isinstance(particles, Particles6D)
-        self._particles = particles
-
-        assert isinstance(u, (BlockVector, PolarVector))
-        self._u = u
+        super().__init__(particles, u)
 
         # parameters
         params_default = {'u_space': 'Hdiv',
                           'use_perp_model': True,
                           'f0': Maxwellian6DUniform(),
                           'type': 'PConjugateGradient',
                           'pc': 'MassMatrixPreconditioner',
@@ -474,25 +609,21 @@
         self._A = getattr(self.mass_ops, id_Mn)
         self._X = getattr(self.basis_ops, id_X)
         self._XT = self._X.transpose()
 
         self.u_temp = u.space.zeros()
         self._BV = u.space.zeros()
 
-    @property
-    def variables(self):
-        return [self._u]
-
     def __call__(self, dt):
-        un = self.variables[0]
+        un = self.feec_vars[0]
         un.update_ghost_regions()
 
         # acuumulate MAT and VEC
         self._ACC.accumulate(
-            self._particles, self._coupling_mat, self._coupling_vec)
+            self.particles[0], self._coupling_mat, self._coupling_vec)
 
         MAT = [[self._ACC.operators[0].matrix, self._ACC.operators[1].matrix, self._ACC.operators[2].matrix],
                [self._ACC.operators[1].matrix, self._ACC.operators[3].matrix,
                    self._ACC.operators[4].matrix],
                [self._ACC.operators[2].matrix, self._ACC.operators[4].matrix, self._ACC.operators[5].matrix]]
         VEC = [self._ACC.vectors[0], self._ACC.vectors[1], self._ACC.vectors[2]]
 
@@ -522,21 +653,21 @@
         GXu_3 = self._G.dot(self._X.dot((un + self.u_temp))[2])
 
         GXu_1.update_ghost_regions()
         GXu_2.update_ghost_regions()
         GXu_3.update_ghost_regions()
 
         # push particles
-        self._pusher(self._particles, dt,
+        self._pusher(self.particles[0], dt,
                      GXu_1[0]._data, GXu_1[1]._data, GXu_1[2]._data,
                      GXu_2[0]._data, GXu_2[1]._data, GXu_2[2]._data,
                      GXu_3[0]._data, GXu_3[1]._data, GXu_3[2]._data)
 
         # write new coeffs into Propagator.variables
-        max_du, = self.in_place_update(self.u_temp)
+        max_du, = self.feec_vars_update(self.u_temp)
 
         if self._info and self._rank == 0:
             print('Status     for StepPressurecoupling:', info['success'])
             print('Iterations for StepPressurecoupling:', info['niter'])
             print('Maxdiff u1 for StepPressurecoupling:', max_du)
             print()
 
@@ -639,20 +770,15 @@
 
     **params : dict
         Solver- and/or other parameters for this splitting step.
     """
 
     def __init__(self, particles, u, **params):
 
-        # pointers to variables
-        assert isinstance(particles, Particles6D)
-        self._particles = particles
-
-        assert isinstance(u, (BlockVector, PolarVector))
-        self._u = u
+        super().__init__(particles, u)
 
         # parameters
         params_default = {'u_space': 'Hdiv',
                           'b_eq': None,
                           'b_tilde': None,
                           'f0': Maxwellian6DUniform(),
                           'type': 'PConjugateGradient',
@@ -684,16 +810,16 @@
         self._b_tilde = params['b_tilde']
         self._f0 = params['f0']
 
         if self._f0 is not None:
             assert isinstance(self._f0, Maxwellian)
 
             # evaluate and save nh0 (0-form) * uh0 (2-form if H1vec or vector if Hdiv) at quadrature points for control variate
-            quad_pts = [quad_grid.points.flatten()
-                        for quad_grid in self.derham.Vh_fem['0'].quad_grids]
+            quad_pts = [quad_grid[nquad].points.flatten()
+                        for quad_grid, nquad in zip(self.derham.Vh_fem['0']._quad_grids, self.derham.Vh_fem['0'].nquads)]
 
             uh0_cart = self._f0.u
 
             if params['u_space'] == 'H1vec':
                 self._nuh0_at_quad = self.domain.pull(
                     uh0_cart, *quad_pts, kind='2_form', squeeze_out=False, coordinates='logical')
             else:
@@ -753,30 +879,26 @@
                                          tol=params['tol'], maxiter=params['maxiter'],
                                          verbose=params['verbose'])
 
         # temporary vectors to avoid memory allocation
         self._b_full1 = self._b_eq.space.zeros()
         self._b_full2 = self._EbT.codomain.zeros()
 
-        self._u_new = self._u.space.zeros()
+        self._u_new = u.space.zeros()
 
-        self._u_avg1 = self._u.space.zeros()
+        self._u_avg1 = u.space.zeros()
         self._u_avg2 = self._EuT.codomain.zeros()
 
-    @property
-    def variables(self):
-        return [self._u]
-
     def __call__(self, dt):
         """
         TODO
         """
 
         # pointer to old coefficients
-        un = self.variables[0]
+        un = self.feec_vars[0]
 
         # sum up total magnetic field b_full1 = b_eq + b_tilde (in-place)
         self._b_eq.copy(out=self._b_full1)
 
         if self._b_tilde is not None:
             self._b_full1 += self._b_tilde
 
@@ -799,20 +921,20 @@
             self._vec2[:, :, :] = self._coupling_vec * \
                 (self._b_quad3 *
                  self._nuh0_at_quad[0] - self._b_quad1*self._nuh0_at_quad[2])
             self._vec3[:, :, :] = self._coupling_vec * \
                 (self._b_quad1 *
                  self._nuh0_at_quad[1] - self._b_quad2*self._nuh0_at_quad[0])
 
-            self._accumulator.accumulate(self._particles,
+            self._accumulator.accumulate(self.particles[0],
                                          self._b_full2[0]._data, self._b_full2[1]._data, self._b_full2[2]._data,
                                          self._space_key_int, self._coupling_mat, self._coupling_vec,
                                          control_vec=[self._vec1, self._vec2, self._vec3])
         else:
-            self._accumulator.accumulate(self._particles,
+            self._accumulator.accumulate(self.particles[0],
                                          self._b_full2[0]._data, self._b_full2[1]._data, self._b_full2[2]._data,
                                          self._space_key_int, self._coupling_mat, self._coupling_vec)
 
         # solve linear system for updated u coefficients (in-place)
         info = self._schur_solver(un, -self._accumulator.vectors[0]/2, dt,
                                   out=self._u_new)[1]
 
@@ -822,24 +944,24 @@
         self._u_avg1 /= 2
 
         self._EuT.dot(self._u_avg1, out=self._u_avg2)
 
         self._u_avg2.update_ghost_regions()
 
         # push particles
-        self._pusher(self._particles, self._scale_push*dt,
+        self._pusher(self.particles[0], self._scale_push*dt,
                      self._b_full2[0]._data, self._b_full2[1]._data, self._b_full2[2]._data,
                      self._u_avg2[0]._data, self._u_avg2[1]._data, self._u_avg2[2]._data)
 
         # write new coeffs into Propagator.variables
-        max_du = self.in_place_update(self._u_new)
+        max_du = self.feec_vars_update(self._u_new)
 
         # update weights in case of control variate
         if self._f0 is not None:
-            self._particles.update_weights(self._f0)
+            self.particles[0].update_weights(self._f0)
 
         if self._info and self._rank == 0:
             print('Status     for CurrentCoupling6DCurrent:', info['success'])
             print('Iterations for CurrentCoupling6DCurrent:', info['niter'])
             print('Maxdiff up for CurrentCoupling6DCurrent:', max_du)
             print()
 
@@ -847,21 +969,15 @@
 class CurrentCoupling5DCurrent1(Propagator):
     r'''
     TODO
     '''
 
     def __init__(self, particles, u, **params):
 
-        from struphy.pic.particles import Particles5D
-        assert isinstance(particles, Particles5D)
-        self._particles = particles
-
-        # pointers to variables
-        assert isinstance(u, (BlockVector, PolarVector))
-        self._u = u
+        super().__init__(particles, u)
 
         # parameters
         params_default = {'u_space': 'Hdiv',
                           'b': None,
                           'b_eq': None,
                           'unit_b1': None,
                           'f0': Maxwellian5DUniform(),
@@ -892,28 +1008,31 @@
         self._b = params['b']
 
         assert isinstance(params['b_eq'], (BlockVector, PolarVector))
         self._b_eq = params['b_eq']
 
         assert isinstance(params['unit_b1'], (BlockVector, PolarVector))
         self._unit_b1 = params['unit_b1']
+        self._curl_norm_b = self.derham.curl.dot(self._unit_b1)
 
         self._info = params['info']
         self._rank = self.derham.comm.Get_rank()
 
         self._coupling_mat = params['Ah'] / params['Ab']
         self._coupling_vec = params['Ah'] / params['Ab']
         self._scale_push = 1
 
-        self._curl_norm_b = self.derham.curl.dot(self._unit_b1)
-        self._curl_norm_b.update_ghost_regions()
-
         u_id = self.derham.spaces_dict[params['u_space']]
         self._EuT = self.derham.E[u_id].transpose()
-        self._EbT = self.derham.E['2'].transpose()
+        self._E2T = self.derham.E['2'].transpose()
+        self._E1T = self.derham.E['1'].transpose()
+
+        self._unit_b1 = self._E1T.dot(self._unit_b1)
+        self._curl_norm_b = self._E2T.dot(self._curl_norm_b)
+        self._curl_norm_b.update_ghost_regions()
 
         # define system [[A B], [C I]] [u_new, v_new] = [[A -B], [-C I]] [u_old, v_old] (without time step size dt)
         _A = getattr(self.mass_ops, 'M' + u_id + 'n')
 
         # preconditioner
         if params['pc'] is None:
             pc = None
@@ -933,43 +1052,39 @@
         # call SchurSolver class
         self._schur_solver = SchurSolver(_A, _BC, pc=pc, solver_name=params['type'],
                                          tol=params['tol'], maxiter=params['maxiter'],
                                          verbose=params['verbose'])
 
         # temporary vectors to avoid memory allocation
         self._b_full1 = self._b_eq.space.zeros()
-        self._b_full2 = self._EbT.codomain.zeros()
+        self._b_full2 = self._E2T.codomain.zeros()
 
-        self._u_new = self._u.space.zeros()
+        self._u_new = u.space.zeros()
 
-        self._u_avg1 = self._u.space.zeros()
+        self._u_avg1 = u.space.zeros()
         self._u_avg2 = self._EuT.codomain.zeros()
 
-    @property
-    def variables(self):
-        return [self._u]
-
     def __call__(self, dt):
 
-        un = self.variables[0]
+        un = self.feec_vars[0]
 
         # sum up total magnetic field b_full1 = b_eq + b_tilde (in-place)
         self._b_eq.copy(out=self._b_full1)
 
         if self._b is not None:
             self._b_full1 += self._b
 
         # extract coefficients to tensor product space (in-place)
-        self._EbT.dot(self._b_full1, out=self._b_full2)
+        self._E2T.dot(self._b_full1, out=self._b_full2)
 
         # update ghost regions because of non-local access in accumulation kernel!
         self._b_full2.update_ghost_regions()
 
         # acuumulate MAT and VEC
-        self._ACC.accumulate(self._particles, self._kappa,
+        self._ACC.accumulate(self.particles[0], self._kappa,
                              self._b_full2[0]._data, self._b_full2[1]._data, self._b_full2[2]._data,
                              self._unit_b1[0]._data, self._unit_b1[1]._data, self._unit_b1[2]._data,
                              self._curl_norm_b[0]._data, self._curl_norm_b[1]._data, self._curl_norm_b[2]._data,
                              self._space_key_int, self._coupling_mat, self._coupling_vec)
 
         # solve linear system for updated u coefficients
         info = self._schur_solver(
@@ -980,23 +1095,23 @@
         self._u_avg1 += self._u_new
         self._u_avg1 /= 2
 
         self._EuT.dot(self._u_avg1, out=self._u_avg2)
 
         self._u_avg2.update_ghost_regions()
 
-        self._pusher(self._particles, self._scale_push*dt,
+        self._pusher(self.particles[0], self._scale_push*dt,
                      self._kappa,
                      self._b_full2[0]._data, self._b_full2[1]._data, self._b_full2[2]._data,
                      self._unit_b1[0]._data, self._unit_b1[1]._data, self._unit_b1[2]._data,
                      self._curl_norm_b[0]._data, self._curl_norm_b[1]._data, self._curl_norm_b[2]._data,
                      self._u_avg2[0]._data, self._u_avg2[1]._data, self._u_avg2[2]._data)
 
         # write new coeffs into Propagator.variables
-        max_du, = self.in_place_update(self._u_new)
+        max_du, = self.feec_vars_update(self._u_new)
 
         if self._info and self._rank == 0:
             print('Status     for CurrentCoupling5DCurrent1:', info['success'])
             print('Iterations for CurrentCoupling5DCurrent1:', info['niter'])
             print('Maxdiff up for CurrentCoupling5DCurrent1:', max_du)
             print()
 
@@ -1005,21 +1120,16 @@
     r'''
     TODO
     '''
 
     def __init__(self, particles, u, **params):
 
         from struphy.pic.pusher import ButcherTableau
-        from struphy.pic.particles import Particles5D
-        assert isinstance(particles, Particles5D)
-        self._particles = particles
-
-        # pointers to variables
-        assert isinstance(u, (BlockVector, PolarVector))
-        self._u = u
+
+        super().__init__(particles, u)
 
         # parameters
         params_default = {'u_space': 'Hdiv',
                           'b': None,
                           'b_eq': None,
                           'unit_b1': None,
                           'unit_b2': None,
@@ -1054,14 +1164,15 @@
         self._b = params['b']
 
         assert isinstance(params['b_eq'], (BlockVector, PolarVector))
         self._b_eq = params['b_eq']
 
         assert isinstance(params['unit_b1'], (BlockVector, PolarVector))
         self._unit_b1 = params['unit_b1']
+        self._curl_norm_b = self.derham.curl.dot(self._unit_b1)
 
         assert isinstance(params['unit_b2'], (BlockVector, PolarVector))
         self._unit_b2 = params['unit_b2']
 
         self._abs_b = params['abs_b']
 
         self._curl_norm_b = self.derham.curl.dot(self._unit_b1)
@@ -1072,20 +1183,26 @@
         self._rank = self.derham.comm.Get_rank()
 
         self._coupling_mat = params['Ah'] / params['Ab']
         self._coupling_vec = params['Ah'] / params['Ab']
         self._scale_push = 1
 
         u_id = self.derham.spaces_dict[params['u_space']]
+        self._E0T = self.derham.E['0'].transpose()
         self._EuT = self.derham.E[u_id].transpose()
         self._E1T = self.derham.E['1'].transpose()
-        self._EbT = self.derham.E['2'].transpose()
+        self._E2T = self.derham.E['2'].transpose()
 
         self._PB = getattr(self.basis_ops, 'PB')
 
+        self._unit_b1 = self._E1T.dot(self._unit_b1)
+        self._unit_b2 = self._E2T.dot(self._unit_b2)
+        self._curl_norm_b = self._E2T.dot(self._curl_norm_b)
+        self._curl_norm_b.update_ghost_regions()
+
         # define system [[A B], [C I]] [u_new, v_new] = [[A -B], [-C I]] [u_old, v_old] (without time step size dt)
         _A = getattr(self.mass_ops, 'M' + u_id + 'n')
 
         # preconditioner
         if params['pc'] is None:
             pc = None
         else:
@@ -1134,51 +1251,49 @@
         self._b_full1 = self._b_eq.space.zeros()
         self._b_full2 = self._EbT.codomain.zeros()
 
         self._PBb = self._abs_b.space.zeros()
         self._grad_PBb1 = self._unit_b1.space.zeros()
         self._grad_PBb2 = self._E1T.codomain.zeros()
 
-        self._u_new = self._u.space.zeros()
+        self._u_new = u.space.zeros()
 
-        self._u_avg1 = self._u.space.zeros()
+        self._u_avg1 = u.space.zeros()
         self._u_avg2 = self._EuT.codomain.zeros()
 
-    @property
-    def variables(self):
-        return [self._u]
-
     def __call__(self, dt):
 
-        un = self.variables[0]
+        un = self.feec_vars[0]
 
         # sum up total magnetic field b_full1 = b_eq + b_tilde (in-place)
         self._b_eq.copy(out=self._b_full1)
 
         if self._b is not None:
             self._b_full1 += self._b
 
         # extract coefficients to tensor product space (in-place)
-        self._EbT.dot(self._b_full1, out=self._b_full2)
+        self._E2T.dot(self._b_full1, out=self._b_full2)
+        self._E2T.dot(self._b, out=self._b)
 
         # update ghost regions because of non-local access in accumulation kernel!
         self._b_full2.update_ghost_regions()
 
         self._PBb = self._PB.dot(self._b_full1)
+        self._PBb = self._E0T.dot(self._PBb)
         self._PBb.update_ghost_regions()
 
         self._grad_PBb1 = self.derham.grad.dot(self._PBb)
 
         # extract coefficients to tensor product space (in-place)
         self._E1T.dot(self._grad_PBb1, out=self._grad_PBb2)
 
         self._grad_PBb2.update_ghost_regions()
 
         # acuumulate MAT and VEC
-        self._ACC.accumulate(self._particles, self._kappa,
+        self._ACC.accumulate(self.particles[0], self._kappa,
                              self._b_full2[0]._data, self._b_full2[1]._data, self._b_full2[2]._data,
                              self._unit_b1[0]._data, self._unit_b1[1]._data, self._unit_b1[2]._data,
                              self._unit_b2[0]._data, self._unit_b2[1]._data, self._unit_b2[2]._data,
                              self._curl_norm_b[0]._data, self._curl_norm_b[1]._data, self._curl_norm_b[2]._data,
                              self._grad_PBb2[0]._data, self._grad_PBb2[1]._data, self._grad_PBb2[2]._data,
                              self._space_key_int, self._coupling_mat, self._coupling_vec)
 
@@ -1191,26 +1306,26 @@
         self._u_avg1 += self._u_new
         self._u_avg1 /= 2
 
         self._EuT.dot(self._u_avg1, out=self._u_avg2)
 
         self._u_avg2.update_ghost_regions()
 
-        self._pusher(self._particles, dt,
+        self._pusher(self.particles[0], dt,
                      self._kappa,
                      self._b_full2[0]._data, self._b_full2[1]._data, self._b_full2[2]._data,
                      self._unit_b1[0]._data, self._unit_b1[1]._data, self._unit_b1[2]._data,
                      self._unit_b2[0]._data, self._unit_b2[1]._data, self._unit_b2[2]._data,
                      self._curl_norm_b[0]._data, self._curl_norm_b[1]._data, self._curl_norm_b[2]._data,
                      self._u_avg2[0]._data, self._u_avg2[1]._data, self._u_avg2[2]._data,
                      self._butcher.a, self._butcher.b, self._butcher.c,
                      mpi_sort='each')
 
         # write new coeffs into Propagator.variables
-        max_du, = self.in_place_update(self._u_new)
+        max_du, = self.feec_vars_update(self._u_new)
 
         if self._info and self._rank == 0:
             print('Status     for CurrentCoupling5DCurrent2:', info['success'])
             print('Iterations for CurrentCoupling5DCurrent2:', info['niter'])
             print('Maxdiff up for CurrentCoupling5DCurrent2:', max_du)
             print()
 
@@ -1218,21 +1333,15 @@
 class CurrentCoupling5DCurrent2dg(Propagator):
     r'''
     TODO
     '''
 
     def __init__(self, particles, u, **params):
 
-        from struphy.pic.particles import Particles5D
-        assert isinstance(particles, Particles5D)
-        self._particles = particles
-
-        # pointers to variables
-        assert isinstance(u, (BlockVector, PolarVector))
-        self._u = u
+        super().__init__(particles, u)
 
         # parameters
         params_default = {'u_space': 'Hdiv',
                           'b': None,
                           'b_eq': None,
                           'unit_b1': None,
                           'unit_b2': None,
@@ -1301,18 +1410,22 @@
         if params['pc'] is None:
             self._pc = None
         else:
             pc_class = getattr(preconditioner, params['pc'])
             self._pc = pc_class(self._A)
 
         # Call the accumulation and Pusher class
-        self._ACC_prepare = Accumulator(self.derham, self.domain, params['u_space'], 'cc_lin_mhd_5d_J2_dg_prepare', add_vector=True, symmetry='symm')
-        self._ACC = Accumulator(self.derham, self.domain, params['u_space'], 'cc_lin_mhd_5d_J2_dg', add_vector=True, symmetry='symm')
-        self._pusher_prepare = Pusher(self.derham, self.domain, 'push_gc_cc_J2_dg_prepare_' + params['u_space'])
-        self._pusher = Pusher(self.derham, self.domain, 'push_gc_cc_J2_dg_' + params['u_space'])
+        self._ACC_prepare = Accumulator(
+            self.derham, self.domain, params['u_space'], 'cc_lin_mhd_5d_J2_dg_prepare', add_vector=True, symmetry='symm')
+        self._ACC = Accumulator(
+            self.derham, self.domain, params['u_space'], 'cc_lin_mhd_5d_J2_dg', add_vector=True, symmetry='symm')
+        self._pusher_prepare = Pusher(
+            self.derham, self.domain, 'push_gc_cc_J2_dg_prepare_' + params['u_space'])
+        self._pusher = Pusher(self.derham, self.domain,
+                              'push_gc_cc_J2_dg_' + params['u_space'])
 
         # self._ACC_prepare = Accumulator(self.derham, self.domain, params['u_space'], 'cc_lin_mhd_5d_J2_dg_prepare_faster', add_vector=True, symmetry='symm')
         # self._ACC = Accumulator(self.derham, self.domain,  params['u_space'], 'cc_lin_mhd_5d_J2_dg_faster', add_vector=True, symmetry='symm')
         # self._pusher = Pusher(self.derham, self.domain,'push_gc_cc_J2_dg_faster_' + params['u_space'])
 
         # linear solver
         self._solver = getattr(it_solvers, params['type'])(self._A.domain)
@@ -1332,22 +1445,18 @@
         self._en_fB_loc = np.empty(1, dtype=float)
         self._sum_H_diff_loc = np.empty(1, dtype=float)
         self._u_norm_loc = np.empty(1, dtype=float)
         self._denominator = np.empty(1, dtype=float)
         self._accum_gradI_const_loc = np.empty(1, dtype=float)
         self._gradI_const = np.empty(1, dtype=float)
 
-    @property
-    def variables(self):
-        return [self._u]
-
     def __call__(self, dt):
 
         # save old u
-        self.variables[0].copy(out=self._u_old)
+        self.feec_vars[0].copy(out=self._u_old)
 
         self._u_old.update_ghost_regions()
 
         # sum up total magnetic field b_full1 = b_eq + b_tilde (in-place)
         self._b_eq.copy(out=self._b_full)
 
         # sum up total magnetic field
@@ -1362,21 +1471,21 @@
         self._grad_PBb = self.derham.grad.dot(self._PBb)
         self._grad_PBb.update_ghost_regions()
 
         #####################################
         # discrete gradient solver(mid point)#
         #####################################
         # eval initial particle energy
-        self._particles.save_magnetic_energy(self.derham, self._PBb)
-        self._en_fB_old = self._particles.markers[~self._particles.holes, 5].dot(
-            self._particles.markers[~self._particles.holes, 8])/self._particles.n_mks
+        self.particles[0].save_magnetic_energy(self.derham, self._PBb)
+        self._en_fB_old = self.particles[0].markers[~self.particles[0].holes, 5].dot(
+            self.particles[0].markers[~self.particles[0].holes, 8])/self.particles[0].n_mks
 
         # ------------ initial guess of u ------------#
         # accumulate S*gradI
-        self._ACC_prepare.accumulate(self._particles, self._kappa,
+        self._ACC_prepare.accumulate(self.particles[0], self._kappa,
                                      self._b_full[0]._data, self._b_full[1]._data, self._b_full[2]._data,
                                      self._unit_b1[0]._data, self._unit_b1[1]._data, self._unit_b1[2]._data,
                                      self._unit_b2[0]._data, self._unit_b2[1]._data, self._unit_b2[2]._data,
                                      self._curl_norm_b[0]._data, self._curl_norm_b[1]._data, self._curl_norm_b[2]._data,
                                      self._grad_PBb[0]._data, self._grad_PBb[1]._data, self._grad_PBb[2]._data,
                                      self._space_key_int, self._coupling_vec)
 
@@ -1393,71 +1502,72 @@
                                   maxiter=self._maxiter, verbose=self._verbose,
                                   out=self._u_new)[1]
 
         self._u_new.update_ghost_regions()
 
         # ------------ initial guess of H ------------#
         # save old etas in columns 9-11
-        self._particles.markers[~self._particles.holes,
-                                9:12] = self._particles.markers[~self._particles.holes, 0:3]
+        self.particles[0].markers[~self.particles[0].holes,
+                                  9:12] = self.particles[0].markers[~self.particles[0].holes, 0:3]
 
         # initial guess of eta is stored in columns 0:3
-        self._pusher_prepare._pusher(self._particles.markers, dt, 0, *self._pusher._args_fem, *self.domain.args_map,
+        self._pusher_prepare._pusher(self.particles[0].markers, dt, 0, *self._pusher._args_fem, *self.domain.args_map,
                                      self._kappa,
                                      self._b_full[0]._data, self._b_full[1]._data, self._b_full[2]._data,
                                      self._unit_b1[0]._data, self._unit_b1[1]._data, self._unit_b1[2]._data,
                                      self._unit_b2[0]._data, self._unit_b2[1]._data, self._unit_b2[2]._data,
                                      self._curl_norm_b[0]._data, self._curl_norm_b[1]._data, self._curl_norm_b[2]._data,
                                      self._u_old[0]._data, self._u_old[1]._data, self._u_old[2]._data)
 
-        self._particles.mpi_sort_markers()
+        self.particles[0].mpi_sort_markers()
 
-        # print('H initial guess', np.max(self._particles.markers[~self._particles.holes,0:3]))
+        # print('H initial guess', np.max(self.particles[0].markers[~self.particles[0].holes,0:3]))
 
         # ------------ fixed point iteration ------------#
         for stage in range(30):
 
-            # print(self._particles.markers[~self._particles.holes,0:8])
+            # print(self.particles[0].markers[~self.particles[0].holes,0:8])
 
             self._u_new.copy(out=self._u_temp)
 
             # save eta diff at markers[ip, 15:18]
-            utilities.check_eta_diff(self._particles.markers)
-            # self._particles.markers[~self._particles.holes, 15:18] = self._particles.markers[~self._particles.holes, 0:3] - self._particles.markers[~self._particles.holes, 9:12]
+            utilities.check_eta_diff(self.particles[0].markers)
+            # self.particles[0].markers[~self.particles[0].holes, 15:18] = self.particles[0].markers[~self.particles[0].holes, 0:3] - self.particles[0].markers[~self.particles[0].holes, 9:12]
 
             self._sum_H_diff_loc = np.sum(
-                self._particles.markers[~self._particles.holes, 15:18]**2)
+                self.particles[0].markers[~self.particles[0].holes, 15:18]**2)
             self._u_norm_loc = np.sum(
                 (self._u_new.toarray_local() - self._u_old.toarray_local())**2)
             self._denominator = self._sum_H_diff_loc + self._u_norm_loc
 
             # eval particle magnetic energy
-            self._en_fB_loc = utilities.accum_en_fB(self._particles.markers, self._particles.n_mks, *self._pusher._args_fem,
+            self._en_fB_loc = utilities.accum_en_fB(self.particles[0].markers, self.particles[0].n_mks, *self._pusher._args_fem,
                                                     self._PBb._data)[0]
-            # self._particles.save_magnetic_energy(self.derham, self._PBb)
-            # self._en_fB_loc = self._particles.markers[~self._particles.holes, 5].dot(
-            #     self._particles.markers[~self._particles.holes, 8])/self._particles.n_mks
+            # self.particles[0].save_magnetic_energy(self.derham, self._PBb)
+            # self._en_fB_loc = self.particles[0].markers[~self.particles[0].holes, 5].dot(
+            #     self.particles[0].markers[~self.particles[0].holes, 8])/self.particles[0].n_mks
 
             # move particle to the mid point position and then the real position is saved at markers[ip, 12:15]
-            utilities.check_eta_mid(self._particles.markers)
-            # self._particles.markers[~self._particles.holes, 0:3], self._particles.markers[~self._particles.holes,
-            #                                                                               12:15] = self._particles.markers[~self._particles.holes, 12:15].copy(), self._particles.markers[~self._particles.holes, 0:3].copy()
-            self._particles.mpi_sort_markers()
+            utilities.check_eta_mid(self.particles[0].markers)
+            # self.particles[0].markers[~self.particles[0].holes, 0:3], self.particles[0].markers[~self.particles[0].holes,
+            #                                                                               12:15] = self.particles[0].markers[~self.particles[0].holes, 12:15].copy(), self.particles[0].markers[~self.particles[0].holes, 0:3].copy()
+            self.particles[0].mpi_sort_markers()
 
             # Accumulate
-            self._accum_gradI_const_loc = utilities.accum_gradI_const(self._particles.markers, self._particles.n_mks, *self._pusher._args_fem,
-                                                                      self._grad_PBb[0]._data, self._grad_PBb[1]._data, self._grad_PBb[2]._data,
+            self._accum_gradI_const_loc = utilities.accum_gradI_const(self.particles[0].markers, self.particles[0].n_mks, *self._pusher._args_fem,
+                                                                      self._grad_PBb[0]._data, self._grad_PBb[
+                                                                          1]._data, self._grad_PBb[2]._data,
                                                                       self._coupling_vec)[0]
 
             # gradI_const = (en_u - en_u_old - u_diff.dot(self._A.dot(u_mid)) + np.sum(en_fB) - np.sum(en_fB_old) - np.sum(accum_gradI_const))/denominator
             self._gradI_const = (
                 self._en_fB_loc - self._en_fB_old - self._accum_gradI_const_loc)/self._denominator
 
             # Accumulate
-            self._ACC.accumulate(self._particles, self._kappa,
+            self._ACC.accumulate(self.particles[0], self._kappa,
                                  self._b_full[0]._data, self._b_full[1]._data, self._b_full[2]._data,
                                  self._unit_b1[0]._data, self._unit_b1[1]._data, self._unit_b1[2]._data,
                                  self._unit_b2[0]._data, self._unit_b2[1]._data, self._unit_b2[2]._data,
                                  self._curl_norm_b[0]._data, self._curl_norm_b[1]._data, self._curl_norm_b[2]._data,
                                  self._grad_PBb[0]._data, self._grad_PBb[1]._data, self._grad_PBb[2]._data,
                                  self._gradI_const,
                                  self._space_key_int, self._coupling_vec)
@@ -1471,16 +1581,16 @@
                                       x0=self._u_temp, tol=self._tol,
                                       maxiter=self._maxiter, verbose=self._verbose,
                                       out=self._u_new)[1]
 
             self._u_new.update_ghost_regions()
 
             # send particle back to the mid position
-            # self._particles.markers[~self._particles.holes, 0:3] = self._particles.markers[~self._particles.holes, 9:12].copy()
-            # self._particles.mpi_sort_markers()
+            # self.particles[0].markers[~self.particles[0].holes, 0:3] = self.particles[0].markers[~self.particles[0].holes, 9:12].copy()
+            # self.particles[0].mpi_sort_markers()
 
             # update H (1 step ealiler u is needed, u_temp)
             # calculate average u
             self._u_old.copy(out=self._u_pusher)
             self._u_pusher += self._u_temp
             self._u_pusher /= 2
 
@@ -1491,57 +1601,61 @@
             self._u_diff.update_ghost_regions()
 
             self._u_pusher += Inverse(self._A, pc=self._pc,
                                       tol=1e-15).dot(self._u_diff)
 
             self._u_pusher.update_ghost_regions()
 
-            self._pusher._pusher(self._particles.markers, dt, 0, *self._pusher._args_fem, *self.domain.args_map,
+            self._pusher._pusher(self.particles[0].markers, dt, 0, *self._pusher._args_fem, *self.domain.args_map,
                                  self._kappa,
                                  self._b_full[0]._data, self._b_full[1]._data, self._b_full[2]._data,
                                  self._unit_b1[0]._data, self._unit_b1[1]._data, self._unit_b1[2]._data,
                                  self._unit_b2[0]._data, self._unit_b2[1]._data, self._unit_b2[2]._data,
                                  self._curl_norm_b[0]._data, self._curl_norm_b[1]._data, self._curl_norm_b[2]._data,
                                  self._u_pusher[0]._data, self._u_pusher[1]._data, self._u_pusher[2]._data)
-            
-            n_lost_markers_before = self._particles.n_lost_markers
-            print('Number of lost markers before iteration push', n_lost_markers_before)
-            self._particles.mpi_sort_markers()
-            n_lost_markers_after = self._particles.n_lost_markers
-            print('Number of lost markers after iteration push', n_lost_markers_after)
+
+            n_lost_markers_before = self.particles[0].n_lost_markers
+            print('Number of lost markers before iteration push',
+                  n_lost_markers_before)
+            self.particles[0].mpi_sort_markers()
+            n_lost_markers_after = self.particles[0].n_lost_markers
+            print('Number of lost markers after iteration push',
+                  n_lost_markers_after)
             print()
 
             if n_lost_markers_after != n_lost_markers_before:
                 # go back to former step
-                self._particles.markers[~self._particles.holes, 0:3] = self._particles.markers[~self._particles.holes, 12:15].copy()
+                self.particles[0].markers[~self.particles[0].holes,
+                                          0:3] = self.particles[0].markers[~self.particles[0].holes, 12:15].copy()
                 self._u_temp.copy(out=self._u_new)
                 continue
             print('stage', stage+1)
 
             self._u_norm_loc = np.sum(
                 (self._u_new.toarray_local() - self._u_temp.toarray_local())**2)
             print('u differences',  np.sqrt(self._u_norm_loc))
 
             # self._sum_H_diff_loc = np.sum(
-            #     (self._particles.markers[~self._particles.holes, 0:3] - self._particles.markers[~self._particles.holes, 12:15])**2)
-            utilities.check_eta_diff2(self._particles.markers)
-            # self._particles.markers[~self._particles.holes, 15:18] = self._particles.markers[~self._particles.holes, 0:3] - self._particles.markers[~self._particles.holes, 9:12]
+            #     (self.particles[0].markers[~self.particles[0].holes, 0:3] - self.particles[0].markers[~self.particles[0].holes, 12:15])**2)
+            utilities.check_eta_diff2(self.particles[0].markers)
+            # self.particles[0].markers[~self.particles[0].holes, 15:18] = self.particles[0].markers[~self.particles[0].holes, 0:3] - self.particles[0].markers[~self.particles[0].holes, 9:12]
 
             self._sum_H_diff_loc = np.sum(
-                self._particles.markers[~self._particles.holes, 15:18]**2)
+                self.particles[0].markers[~self.particles[0].holes, 15:18]**2)
             print('H differences', np.sqrt(self._sum_H_diff_loc))
 
             diff = np.sqrt(self._u_norm_loc + self._sum_H_diff_loc)
             print('diff', diff)
 
             if diff < 1e-11:
                 print('converged!')
                 break
 
         # write new coeffs into Propagator.variables
-        max_du, = self.in_place_update(self._u_new)
+        max_du, = self.feec_vars_update(self._u_new)
 
         if self._info and self._rank == 0:
-            print('Status     for CurrentCoupling5DCurrent2dg:', info['success'])
+            print('Status     for CurrentCoupling5DCurrent2dg:',
+                  info['success'])
             print('Iterations for CurrentCoupling5DCurrent2dg:', info['niter'])
             print('Maxdiff up for CurrentCoupling5DCurrent2dg:', max_du)
             print()
```

### Comparing `struphy-2.0.1/src/struphy/propagators/propagators_fields.py` & `struphy-2.0.2/src/struphy/propagators/propagators_fields.py`

 * *Files 5% similar despite different names*

```diff
@@ -13,19 +13,20 @@
 from struphy.psydac_api.linear_operators import SumLinearOperator as Sum
 from struphy.psydac_api.linear_operators import ScalarTimesLinearOperator as Multiply
 from struphy.psydac_api.linear_operators import InverseLinearOperator as Inverse
 from struphy.psydac_api.linear_operators import IdentityOperator
 from struphy.psydac_api import preconditioner
 from struphy.psydac_api.mass import WeightedMassOperator
 import struphy.linear_algebra.iterative_solvers as it_solvers
-from psydac.linalg.iterative_solvers import pcg
+from struphy.linear_algebra.iterative_solvers import PConjugateGradient as pcg
 
 from psydac.linalg.stencil import StencilVector
 from psydac.linalg.block import BlockVector
 import struphy.psydac_api.utilities as util
+from mpi4py import MPI
 
 
 class Maxwell(Propagator):
     r'''Crank-Nicolson step
 
     .. math::
 
@@ -45,19 +46,15 @@
 
     **params : dict
         Solver- and/or other parameters for this splitting step.
     '''
 
     def __init__(self, e, b, **params):
 
-        # pointers to variables
-        assert isinstance(e, (BlockVector, PolarVector))
-        assert isinstance(b, (BlockVector, PolarVector))
-        self._e = e
-        self._b = b
+        super().__init__(e, b)
 
         # parameters
         params_default = {'type': 'PConjugateGradient',
                           'pc': 'MassMatrixPreconditioner',
                           'tol': 1e-8,
                           'maxiter': 3000,
                           'info': False,
@@ -91,38 +88,34 @@
         # allocate place-holder vectors to avoid temporary array allocations in __call__
         self._e_tmp1 = e.space.zeros()
         self._e_tmp2 = e.space.zeros()
         self._b_tmp1 = b.space.zeros()
 
         self._byn = self._B.codomain.zeros()
 
-    @property
-    def variables(self):
-        return [self._e, self._b]
-
     def __call__(self, dt):
 
         # current variables
-        en = self.variables[0]
-        bn = self.variables[1]
+        en = self.feec_vars[0]
+        bn = self.feec_vars[1]
 
         # solve for new e coeffs
         self._B.dot(bn, out=self._byn)
 
         info = self._schur_solver(en, self._byn, dt, out=self._e_tmp1)[1]
 
         # new b coeffs
         en.copy(out=self._e_tmp2)
         self._e_tmp2 += self._e_tmp1
         self._C.dot(self._e_tmp2, out=self._b_tmp1)
         self._b_tmp1 *= -dt
         self._b_tmp1 += bn
 
-        # write new coeffs into self.variables
-        max_de, max_db = self.in_place_update(self._e_tmp1, self._b_tmp1)
+        # write new coeffs into self.feec_vars
+        max_de, max_db = self.feec_vars_update(self._e_tmp1, self._b_tmp1)
 
         if self._info:
             print('Status     for Maxwell:', info['success'])
             print('Iterations for Maxwell:', info['niter'])
             print('Maxdiff e1 for Maxwell:', max_de)
             print('Maxdiff b2 for Maxwell:', max_db)
             print()
@@ -134,20 +127,20 @@
     .. math::
 
         \begin{bmatrix}
             \mathbf j^{n+1} - \mathbf j^n \\
             \mathbf e^{n+1} - \mathbf e^n
         \end{bmatrix}
         = \frac{\Delta t}{2} \begin{bmatrix}
-            0 & \frac{\alpha}{\varepsilon_c} \mathbb M_{1,1/n}^{-1} \\
-            - \frac{\alpha}{\varepsilon_c} \mathbb M_{1,1/n}^{-1} & 0
+            0 & \frac{1}{\varepsilon_c} \mathbb M_{1,1/n}^{-1} \\
+            - \frac{1}{\varepsilon_c} \mathbb M_{1,1/n}^{-1} & 0
         \end{bmatrix}
         \begin{bmatrix}
-            \mathbb M_{1,1/n} (\mathbf j^n + \mathbf j^{n+1}) \\
-            \mathbb M_1 (\mathbf e^n + \mathbf e^{n+1})
+            \mathbb \alpha^2 M_{1,1/n} (\mathbf j^{n+1} + \mathbf j^{n}) \\
+            \mathbb M_1 (\mathbf e^{n+1} + \mathbf e^{n})
         \end{bmatrix} ,
 
     based on the :ref:`Schur complement <schur_solver>`.
 
     Parameters
     ----------
         j : psydac.linalg.block.BlockVector
@@ -156,41 +149,39 @@
         e : psydac.linalg.block.BlockVector
             FE coefficients of a 1-form.
 
         params : dict
             Solver parameters for this splitting step.
     '''
 
-    def __init__(self, e, j, **params):
+    def __init__(self, j, e, **params):
 
-        assert isinstance(e, (BlockVector, PolarVector))
-        assert isinstance(j, (BlockVector, PolarVector))
-        self._e = e
-        self._j = j
+        super().__init__(e, j)
 
         # parameters
         params_default = {'type': 'PConjugateGradient',
                           'pc': 'MassMatrixPreconditioner',
                           'tol': 1e-8,
                           'maxiter': 3000,
                           'info': False,
                           'verbose': False,
                           'alpha': 1.0,
                           'epsilon': 1.0}
 
         params = set_defaults(params, params_default)
 
         self._info = params['info']
-        self._prefactor = params['alpha'] / params['epsilon']
+        self._alpha = params['alpha']
+        self._epsilon = params['epsilon']
 
         # Define block matrix [[A B], [C I]] (without time step size dt in the diagonals)
         _A = self.mass_ops.M1ninv
 
-        self._B = Multiply(-1/2 * self._prefactor, self.mass_ops.M1)  # no dt
-        self._C = Multiply(1/2 * self._prefactor,
+        self._B = Multiply(-1/2 * 1/self._epsilon, self.mass_ops.M1)  # no dt
+        self._C = Multiply(1/2 * self._alpha**2 / self._epsilon,
                            IdentityOperator(self.derham._Vh["1"]))  # no dt
 
         # Preconditioner
         if params['pc'] is None:
             pc = None
         else:
             pc_class = getattr(preconditioner, params['pc'])
@@ -199,30 +190,26 @@
         # Instantiate Schur solver (constant in this case)
         _BC = Compose(self._B, self._C)
 
         self._schur_solver = SchurSolver(_A, _BC, pc=pc, solver_name=params['type'],
                                          tol=params['tol'], maxiter=params['maxiter'],
                                          verbose=params['verbose'])
 
-    @property
-    def variables(self):
-        return [self._e, self._j]
-
     def __call__(self, dt):
 
         # current variables
-        en = self.variables[0]
-        jn = self.variables[1]
+        en = self.feec_vars[0]
+        jn = self.feec_vars[1]
 
         # allocate temporary FemFields _e, _j during solution
         _j, info = self._schur_solver(jn, self._B.dot(en), dt)
-        _e = en - dt/2 * self._prefactor * (_j + jn)
+        _e = en - dt * self._C.dot(_j + jn)
 
         # write new coeffs into Propagator.variables
-        max_de, max_dj = self.in_place_update(_e, _j)
+        max_de, max_dj = self.feec_vars_update(_e, _j)
 
         if self._info:
             print('Status     for OhmCold:', info['success'])
             print('Iterations for OhmCold:', info['niter'])
             print('Maxdiff e1 for OhmCold:', max_de)
             print('Maxdiff j1 for OhmCold:', max_dj)
             print()
@@ -242,16 +229,15 @@
 
         params : dict
             Solver parameters for this splitting step.
     '''
 
     def __init__(self, j, **params):
 
-        assert isinstance(j, (BlockVector, PolarVector))
-        self._j = j
+        super().__init__(j)
 
         # parameters
         params_default = {'type': 'PConjugateGradient',
                           'pc': 'MassMatrixPreconditioner',
                           'tol': 1e-8,
                           'maxiter': 3000,
                           'info': False,
@@ -281,37 +267,33 @@
         # Instantiate linear solver
         self._solver = getattr(it_solvers, params['type'])(self._M.domain)
 
         # allocate dummy vectors to avoid temporary array allocations
         self._rhs_j = self._M.codomain.zeros()
         self._j_new = j.space.zeros()
 
-    @property
-    def variables(self):
-        return [self._j]
-
     def __call__(self, dt):
 
         # current variables
-        jn = self.variables[0]
+        jn = self.feec_vars[0]
 
         # define system (M - dt/2 * A)*b^(n + 1) = (M + dt/2 * A)*b^n
         lhs = Sum(self._M, Multiply(-dt/2.0, self._A))
         rhs = Sum(self._M, Multiply(dt/2.0, self._A))
 
         # solve linear system for updated u coefficients (in-place)
         rhs.dot(jn, out=self._rhs_j)
 
         info = self._solver.solve(lhs, self._rhs_j, self._pc,
                                   x0=jn, tol=self._tol,
                                   maxiter=self._maxiter, verbose=self._verbose,
                                   out=self._j_new)[1]
 
         # write new coeffs into Propagator.variables
-        max_dj = self.in_place_update(self._j_new)[0]
+        max_dj = self.feec_vars_update(self._j_new)[0]
 
         if self._info:
             print('Status     for FluidCold:', info['success'])
             print('Iterations for FluidCold:', info['niter'])
             print('Maxdiff j1 for FluidCold:', max_dj)
             print()
 
@@ -338,19 +320,15 @@
 
         **params : dict
             Solver- and/or other parameters for this splitting step.
     '''
 
     def __init__(self, u, b, **params):
 
-        # pointers to variables
-        assert isinstance(u, (BlockVector, PolarVector))
-        assert isinstance(b, (BlockVector, PolarVector))
-        self._u = u
-        self._b = b
+        super().__init__(u, b)
 
         # parameters
         params_default = {'u_space': 'Hdiv',
                           'type': 'PConjugateGradient',
                           'pc': 'MassMatrixPreconditioner',
                           'tol': 1e-8,
                           'maxiter': 3000,
@@ -392,38 +370,34 @@
         # allocate dummy vectors to avoid temporary array allocations
         self._u_tmp1 = u.space.zeros()
         self._u_tmp2 = u.space.zeros()
         self._b_tmp1 = b.space.zeros()
 
         self._byn = self._B.codomain.zeros()
 
-    @property
-    def variables(self):
-        return [self._u, self._b]
-
     def __call__(self, dt):
 
         # current variables
-        un = self.variables[0]
-        bn = self.variables[1]
+        un = self.feec_vars[0]
+        bn = self.feec_vars[1]
 
         # solve for new u coeffs
         self._B.dot(bn, out=self._byn)
 
         info = self._schur_solver(un, self._byn, dt, out=self._u_tmp1)[1]
 
         # new b coeffs
         un.copy(out=self._u_tmp2)
         self._u_tmp2 += self._u_tmp1
         self._C.dot(self._u_tmp2, out=self._b_tmp1)
         self._b_tmp1 *= -dt
         self._b_tmp1 += bn
 
-        # write new coeffs into self.variables
-        max_du, max_db = self.in_place_update(self._u_tmp1, self._b_tmp1)
+        # write new coeffs into self.feec_vars
+        max_du, max_db = self.feec_vars_update(self._u_tmp1, self._b_tmp1)
 
         if self._info and self._rank == 0:
             print('Status     for ShearAlfvn:', info['success'])
             print('Iterations for ShearAlfvn:', info['niter'])
             print('Maxdiff up for ShearAlfvn:', max_du)
             print('Maxdiff b2 for ShearAlfvn:', max_db)
             print()
@@ -451,19 +425,15 @@
 
         **params : dict
             Solver- and/or other parameters for this splitting step.
     '''
 
     def __init__(self, u, b, **params):
 
-        # pointers to variables
-        assert isinstance(u, (BlockVector, PolarVector))
-        assert isinstance(b, (BlockVector, PolarVector))
-        self._u = u
-        self._b = b
+        super().__init__(u, b)
 
         # parameters
         params_default = {'type': 'PConjugateGradient',
                           'pc': 'MassMatrixPreconditioner',
                           'tol': 1e-8,
                           'maxiter': 3000,
                           'info': False,
@@ -500,38 +470,34 @@
         # allocate dummy vectors to avoid temporary array allocations
         self._u_tmp1 = u.space.zeros()
         self._u_tmp2 = u.space.zeros()
         self._b_tmp1 = b.space.zeros()
 
         self._byn = self._B.codomain.zeros()
 
-    @property
-    def variables(self):
-        return [self._u, self._b]
-
     def __call__(self, dt):
 
         # current variables
-        un = self.variables[0]
-        bn = self.variables[1]
+        un = self.feec_vars[0]
+        bn = self.feec_vars[1]
 
         # solve for new u coeffs
         self._B.dot(bn, out=self._byn)
 
         info = self._schur_solver(un, self._byn, dt, out=self._u_tmp1)[1]
 
         # new b coeffs
         un.copy(out=self._u_tmp2)
         self._u_tmp2 += self._u_tmp1
         self._C.dot(self._u_tmp2, out=self._b_tmp1)
         self._b_tmp1 *= -dt
         self._b_tmp1 += bn
 
-        # write new coeffs into self.variables
-        max_du, max_db = self.in_place_update(self._u_tmp1, self._b_tmp1)
+        # write new coeffs into self.feec_vars
+        max_du, max_db = self.feec_vars_update(self._u_tmp1, self._b_tmp1)
 
         if self._info and self._rank == 0:
             print('Status     for ShearAlfvnB1:', info['success'])
             print('Iterations for ShearAlfvnB1:', info['niter'])
             print('Maxdiff up for ShearAlfvnB1:', max_du)
             print('Maxdiff b2 for ShearAlfvnB1:', max_db)
             print()
@@ -556,17 +522,15 @@
 
         **params : dict
             Solver- and/or other parameters for this splitting step.
     '''
 
     def __init__(self, b, **params):
 
-        # pointers to variables
-        assert isinstance(b, (BlockVector, PolarVector))
-        self._b = b
+        super().__init__(b)
 
         # parameters
         params_default = {'type': 'PBiConjugateGradientStab',
                           'pc': 'MassMatrixPreconditioner',
                           'tol': 1e-8,
                           'maxiter': 3000,
                           'info': False,
@@ -600,37 +564,33 @@
         # Instantiate linear solver
         self._solver = getattr(it_solvers, params['type'])(self._M.domain)
 
         # allocate dummy vectors to avoid temporary array allocations
         self._rhs_b = self._M.codomain.zeros()
         self._b_new = b.space.zeros()
 
-    @property
-    def variables(self):
-        return [self._b]
-
     def __call__(self, dt):
 
         # current variables
-        bn = self.variables[0]
+        bn = self.feec_vars[0]
 
         # define system (M - dt/2 * A)*b^(n + 1) = (M + dt/2 * A)*b^n
         lhs = Sum(self._M, Multiply(-dt/2.0, self._A))
         rhs = Sum(self._M, Multiply(dt/2.0, self._A))
 
         # solve linear system for updated u coefficients (in-place)
         rhs.dot(bn, out=self._rhs_b)
 
         info = self._solver.solve(lhs, self._rhs_b, self._pc,
                                   x0=bn, tol=self._tol,
                                   maxiter=self._maxiter, verbose=self._verbose,
                                   out=self._b_new)[1]
 
-        # write new coeffs into self.variables
-        max_db = self.in_place_update(self._b_new)
+        # write new coeffs into self.feec_vars
+        max_db = self.feec_vars_update(self._b_new)
 
         if self._info and self._rank == 0:
             print('Status     for Hall:', info['success'])
             print('Iterations for Hall:', info['niter'])
             print('Maxdiff b1 for Hall:', max_db)
             print()
 
@@ -663,27 +623,21 @@
 
     u : psydac.linalg.block.BlockVector
         FE coefficients of MHD velocity.
 
     p : psydac.linalg.stencil.StencilVector
         FE coefficients of a discrete 3-form.
 
-        **params : dict
-            Solver- and/or other parameters for this splitting step.
+    **params : dict
+        Solver- and/or other parameters for this splitting step.
     '''
 
     def __init__(self, n, u, p, **params):
 
-        # pointers to variables
-        assert isinstance(n, (StencilVector, PolarVector))
-        assert isinstance(u, (BlockVector, PolarVector))
-        assert isinstance(p, (StencilVector, PolarVector))
-        self._n = n
-        self._u = u
-        self._p = p
+        super().__init__(n, u, p)
 
         # parameters
         params_default = {'u_space': 'Hdiv',
                           'b': self.derham.Vh['2'].zeros(),
                           'type': 'PBiConjugateGradientStab',
                           'pc': 'MassMatrixPreconditioner',
                           'tol': 1e-8,
@@ -750,24 +704,20 @@
         self._p_tmp1 = p.space.zeros()
         self._n_tmp1 = n.space.zeros()
         self._b_tmp1 = self._b.space.zeros()
 
         self._byn1 = self._B.codomain.zeros()
         self._byn2 = self._B.codomain.zeros()
 
-    @property
-    def variables(self):
-        return [self._n, self._u, self._p]
-
     def __call__(self, dt):
 
         # current variables
-        nn = self.variables[0]
-        un = self.variables[1]
-        pn = self.variables[2]
+        nn = self.feec_vars[0]
+        un = self.feec_vars[1]
+        pn = self.feec_vars[2]
 
         # solve for new u coeffs
         self._B.dot(pn, out=self._byn1)
         self._MJ.dot(self._b, out=self._byn2)
         self._byn2 *= 1/2
         self._byn1 -= self._byn2
 
@@ -780,18 +730,18 @@
         self._p_tmp1 *= -dt
         self._p_tmp1 += pn
 
         self._DQ.dot(self._u_tmp2, out=self._n_tmp1)
         self._n_tmp1 *= -dt/2
         self._n_tmp1 += nn
 
-        # write new coeffs into self.variables
-        max_dn, max_du, max_dp = self.in_place_update(self._n_tmp1,
-                                                      self._u_tmp1,
-                                                      self._p_tmp1)
+        # write new coeffs into self.feec_vars
+        max_dn, max_du, max_dp = self.feec_vars_update(self._n_tmp1,
+                                                       self._u_tmp1,
+                                                       self._p_tmp1)
 
         if self._info and self._rank == 0:
             print('Status     for Magnetosonic:', info['success'])
             print('Iterations for Magnetosonic:', info['niter'])
             print('Maxdiff n3 for Magnetosonic:', max_dn)
             print('Maxdiff up for Magnetosonic:', max_du)
             print('Maxdiff p3 for Magnetosonic:', max_dp)
@@ -834,21 +784,15 @@
 
         **params : dict
             Solver- and/or other parameters for this splitting step.
     '''
 
     def __init__(self, n, u, p, **params):
 
-        # pointers to variables
-        assert isinstance(n, (StencilVector, PolarVector))
-        assert isinstance(u, (BlockVector, PolarVector))
-        assert isinstance(p, (StencilVector, PolarVector))
-        self._n = n
-        self._u = u
-        self._p = p
+        super().__init__(n, u, p)
 
         # parameters
         params_default = {'type': 'PBiConjugateGradientStab',
                           'pc': 'MassMatrixPreconditioner',
                           'tol': 1e-8,
                           'maxiter': 3000,
                           'info': False,
@@ -890,24 +834,20 @@
         self._u_tmp1 = u.space.zeros()
         self._u_tmp2 = u.space.zeros()
         self._p_tmp1 = p.space.zeros()
         self._n_tmp1 = n.space.zeros()
 
         self._byn1 = self._B.codomain.zeros()
 
-    @property
-    def variables(self):
-        return [self._n, self._u, self._p]
-
     def __call__(self, dt):
 
         # current variables
-        nn = self.variables[0]
-        un = self.variables[1]
-        pn = self.variables[2]
+        nn = self.feec_vars[0]
+        un = self.feec_vars[1]
+        pn = self.feec_vars[2]
 
         # solve for new u coeffs
         self._B.dot(pn, out=self._byn1)
 
         info = self._schur_solver(un, self._byn1, dt, out=self._u_tmp1)[1]
 
         # new p, n, b coeffs
@@ -917,18 +857,18 @@
         self._p_tmp1 *= -dt
         self._p_tmp1 += pn
 
         self._QD.dot(self._u_tmp2, out=self._n_tmp1)
         self._n_tmp1 *= -dt/2.0
         self._n_tmp1 += nn
 
-        # write new coeffs into self.variables
-        max_dn, max_du, max_dp = self.in_place_update(self._n_tmp1,
-                                                      self._u_tmp1,
-                                                      self._p_tmp1)
+        # write new coeffs into self.feec_vars
+        max_dn, max_du, max_dp = self.feec_vars_update(self._n_tmp1,
+                                                       self._u_tmp1,
+                                                       self._p_tmp1)
 
         if self._info and self._rank == 0:
             print('Status     for Magnetosonic:', info['success'])
             print('Iterations for Magnetosonic:', info['niter'])
             print('Maxdiff n3 for Magnetosonic:', max_dn)
             print('Maxdiff up for Magnetosonic:', max_du)
             print('Maxdiff p3 for Magnetosonic:', max_dp)
@@ -971,21 +911,15 @@
 
         **params : dict
             Solver- and/or other parameters for this splitting step.
     '''
 
     def __init__(self, n, u, p, **params):
 
-        # pointers to variables
-        assert isinstance(n, (StencilVector, PolarVector))
-        assert isinstance(u, (BlockVector, PolarVector))
-        assert isinstance(p, (StencilVector, PolarVector))
-        self._n = n
-        self._u = u
-        self._p = p
+        super().__init__(n, u, p)
 
         # parameters
         params_default = {'type': 'PBiConjugateGradientStab',
                           'pc': 'MassMatrixPreconditioner',
                           'tol': 1e-8,
                           'maxiter': 3000,
                           'info': False,
@@ -1029,24 +963,20 @@
         self._u_tmp1 = u.space.zeros()
         self._u_tmp2 = u.space.zeros()
         self._p_tmp1 = p.space.zeros()
         self._n_tmp1 = n.space.zeros()
 
         self._byn1 = self._B.codomain.zeros()
 
-    @property
-    def variables(self):
-        return [self._n, self._u, self._p]
-
     def __call__(self, dt):
 
         # current variables
-        nn = self.variables[0]
-        un = self.variables[1]
-        pn = self.variables[2]
+        nn = self.feec_vars[0]
+        un = self.feec_vars[1]
+        pn = self.feec_vars[2]
 
         # solve for new u coeffs
         self._B.dot(pn, out=self._byn1)
 
         info = self._schur_solver(un, self._byn1, dt, out=self._u_tmp1)[1]
 
         # new p, n, b coeffs
@@ -1056,18 +986,18 @@
         self._p_tmp1 *= -dt
         self._p_tmp1 += pn
 
         self._QD.dot(self._u_tmp2, out=self._n_tmp1)
         self._n_tmp1 *= -dt/2.0
         self._n_tmp1 += nn
 
-        # write new coeffs into self.variables
-        max_dn, max_du, max_dp = self.in_place_update(self._n_tmp1,
-                                                      self._u_tmp1,
-                                                      self._p_tmp1)
+        # write new coeffs into self.feec_vars
+        max_dn, max_du, max_dp = self.feec_vars_update(self._n_tmp1,
+                                                       self._u_tmp1,
+                                                       self._p_tmp1)
 
         if self._info and self._rank == 0:
             print('Status     for Magnetosonic:', info['success'])
             print('Iterations for Magnetosonic:', info['niter'])
             print('Maxdiff n3 for Magnetosonic:', max_dn)
             print('Maxdiff up for Magnetosonic:', max_du)
             print('Maxdiff p3 for Magnetosonic:', max_dp)
@@ -1219,15 +1149,15 @@
             _LHS = Sum(self._M1, Compose(HybridM1, self._L2))
             _RHS2 = HybridM1.dot(self._RHS) + self._rhs
 
             a_new, info = pcg(_LHS, _RHS2, self._pc, x0=self._a, tol=self._solver_params['tol'],
                               maxiter=self._solver_params['maxiter'], verbose=self._solver_params['verbose'])
 
             # write new coeffs into Propagator.variables
-            max_da = self.in_place_update(a_new)
+            max_da = self.feec_vars_update(a_new)
             print('++++====check_iteration_error=====+++++', max_da)
             # we can modify the diff function in in_place_update to get another type errors
             if max_da[0] < 10**(-6):
                 break
 
 
 class CurrentCoupling6DDensity(Propagator):
@@ -1241,17 +1171,15 @@
             Solver- and/or other parameters for this splitting step.
     """
 
     def __init__(self, u, **params):
 
         from struphy.pic.particles import Particles6D
 
-        # pointers to variables
-        assert isinstance(u, (BlockVector, PolarVector))
-        self._u = u
+        super().__init__(u)
 
         # parameters
         params_default = {'particles': None,
                           'u_space': 'Hdiv',
                           'b_eq': None,
                           'b_tilde': None,
                           'f0': Maxwellian6DUniform(),
@@ -1288,16 +1216,16 @@
         self._f0 = params['f0']
 
         if self._f0 is not None:
 
             assert isinstance(self._f0, Maxwellian)
 
             # evaluate and save nh0*|det(DF)| (H1vec) or nh0/|det(DF)| (Hdiv) at quadrature points for control variate
-            quad_pts = [quad_grid.points.flatten()
-                        for quad_grid in self.derham.Vh_fem['0'].quad_grids]
+            quad_pts = [quad_grid[nquad].points.flatten()
+                        for quad_grid, nquad in zip(self.derham.Vh_fem['0']._quad_grids, self.derham.Vh_fem['0'].nquads)]
 
             if params['u_space'] == 'H1vec':
                 self._nh0_at_quad = self.domain.pull(
                     [self._f0.n], *quad_pts, kind='3_form', squeeze_out=False, coordinates='logical')
             else:
                 self._nh0_at_quad = self.domain.push(
                     [self._f0.n], *quad_pts, kind='3_form', squeeze_out=False)
@@ -1345,28 +1273,24 @@
         # linear solver
         self._solver = getattr(it_solvers, params['type'])(self._M.domain)
 
         # temporary vectors to avoid memory allocation
         self._b_full1 = self._b_eq.space.zeros()
         self._b_full2 = self._E2T.codomain.zeros()
 
-        self._rhs_v = self._u.space.zeros()
-        self._u_new = self._u.space.zeros()
-
-    @property
-    def variables(self):
-        return [self._u]
+        self._rhs_v = u.space.zeros()
+        self._u_new = u.space.zeros()
 
     def __call__(self, dt):
         """
         TODO
         """
 
         # pointer to old coefficients
-        un = self.variables[0]
+        un = self.feec_vars[0]
 
         # sum up total magnetic field b_full1 = b_eq + b_tilde (in-place)
         self._b_eq.copy(out=self._b_full1)
 
         if self._b_tilde is not None:
             self._b_full1 += self._b_tilde
 
@@ -1415,15 +1339,15 @@
 
         info = self._solver.solve(lhs, self._rhs_v, self._pc,
                                   x0=un, tol=self._tol,
                                   maxiter=self._maxiter, verbose=self._verbose,
                                   out=self._u_new)[1]
 
         # write new coeffs into Propagator.variables
-        max_du = self.in_place_update(self._u_new)
+        max_du = self.feec_vars_update(self._u_new)
 
         if self._info and self._rank == 0:
             print('Status     for CurrentCoupling6DDensity:', info['success'])
             print('Iterations for CurrentCoupling6DDensity:', info['niter'])
             print('Maxdiff up for CurrentCoupling6DDensity:', max_du)
             print()
 
@@ -1452,19 +1376,15 @@
             Solver- and/or other parameters for this splitting step.
     '''
 
     def __init__(self, u, b, **params):
 
         from struphy.pic.particles import Particles5D
 
-        # pointers to variables
-        assert isinstance(u, (BlockVector, PolarVector))
-        assert isinstance(b, (BlockVector, PolarVector))
-        self._u = u
-        self._b = b
+        super().__init__(u, b)
 
         # parameters
         params_default = {'particles': None,
                           'u_space': 'Hdiv',
                           'b_eq': None,
                           'f0': Maxwellian5DUniform(),
                           'type': 'PConjugateGradient',
@@ -1531,23 +1451,19 @@
         # allocate dummy vectors to avoid temporary array allocations
         self._u_tmp1 = u.space.zeros()
         self._u_tmp2 = u.space.zeros()
         self._b_tmp1 = b.space.zeros()
 
         self._byn = self._B.codomain.zeros()
 
-    @property
-    def variables(self):
-        return [self._u, self._b]
-
     def __call__(self, dt):
 
         # current variables
-        un = self.variables[0]
-        bn = self.variables[1]
+        un = self.feec_vars[0]
+        bn = self.feec_vars[1]
 
         # accumulate scalar
         self._ACC.accumulate(self._particles, self._coupling_const)
 
         # solve for new u coeffs
         self._B.dot(bn, out=self._byn)
         self._byn += self._B2.dot(self._ACC.vectors[0])
@@ -1557,16 +1473,16 @@
         # new b coeffs
         un.copy(out=self._u_tmp2)
         self._u_tmp2 += self._u_tmp1
         self._C.dot(self._u_tmp2, out=self._b_tmp1)
         self._b_tmp1 *= -dt
         self._b_tmp1 += bn
 
-        # write new coeffs into self.variables
-        max_du, max_db = self.in_place_update(self._u_tmp1, self._b_tmp1)
+        # write new coeffs into self.feec_vars
+        max_du, max_db = self.feec_vars_update(self._u_tmp1, self._b_tmp1)
 
         if self._info and self._rank == 0:
             print('Status     for ShearAlfvn:', info['success'])
             print('Iterations for ShearAlfvn:', info['niter'])
             print('Maxdiff up for ShearAlfvn:', max_du)
             print('Maxdiff b2 for ShearAlfvn:', max_db)
             print()
@@ -1575,20 +1491,15 @@
 class MagnetosonicCurrentCoupling5D(Propagator):
     r'''TODO'''
 
     def __init__(self, n, u, p, **params):
 
         from struphy.pic.particles import Particles5D
 
-        assert isinstance(n, (StencilVector, PolarVector))
-        assert isinstance(u, (BlockVector, PolarVector))
-        assert isinstance(p, (StencilVector, PolarVector))
-        self._n = n
-        self._u = u
-        self._p = p
+        super().__init__(n, u, p)
 
         # parameters
         params_default = {'b': self.derham.Vh['2'].zeros(),
                           'particles': None,
                           'u_space': 'Hdiv',
                           'unit_b1': None,
                           'f0': Maxwellian5DUniform(),
@@ -1684,24 +1595,20 @@
         self._p_tmp1 = p.space.zeros()
         self._n_tmp1 = n.space.zeros()
         self._b_tmp1 = self._b.space.zeros()
 
         self._byn1 = self._B.codomain.zeros()
         self._byn2 = self._B.codomain.zeros()
 
-    @property
-    def variables(self):
-        return [self._n, self._u, self._p]
-
     def __call__(self, dt):
 
         # current variables
-        nn = self.variables[0]
-        un = self.variables[1]
-        pn = self.variables[2]
+        nn = self.feec_vars[0]
+        un = self.feec_vars[1]
+        pn = self.feec_vars[2]
 
         # accumulate
         self._ACC.accumulate(self._particles,
                              self._b[0]._data, self._b[1]._data, self._b[2]._data,
                              self._curl_norm_b[0]._data, self._curl_norm_b[1]._data, self._curl_norm_b[2]._data,
                              self._space_key_int, self._coupling_const)
 
@@ -1721,18 +1628,18 @@
         self._p_tmp1 *= -dt
         self._p_tmp1 += pn
 
         self._DQ.dot(self._u_tmp2, out=self._n_tmp1)
         self._n_tmp1 *= -dt/2
         self._n_tmp1 += nn
 
-        # write new coeffs into self.variables
-        max_dn, max_du, max_dp = self.in_place_update(self._n_tmp1,
-                                                      self._u_tmp1,
-                                                      self._p_tmp1)
+        # write new coeffs into self.feec_vars
+        max_dn, max_du, max_dp = self.feec_vars_update(self._n_tmp1,
+                                                       self._u_tmp1,
+                                                       self._p_tmp1)
 
         if self._info and self._rank == 0:
             print('Status     for Magnetosonic:', info['success'])
             print('Iterations for Magnetosonic:', info['niter'])
             print('Maxdiff n3 for Magnetosonic:', max_dn)
             print('Maxdiff up for Magnetosonic:', max_du)
             print('Maxdiff p3 for Magnetosonic:', max_dp)
@@ -1743,17 +1650,15 @@
     """
     """
 
     def __init__(self, u, **params):
 
         from struphy.pic.particles import Particles5D
 
-        # pointers to variables
-        assert isinstance(u, (BlockVector, PolarVector))
-        self._u = u
+        super().__init__(u)
 
         # parameters
         params_default = {'particles': None,
                           'u_space': 'Hdiv',
                           'b_eq': None,
                           'b_tilde': None,
                           'f0': Maxwellian5DUniform(),
@@ -1818,28 +1723,28 @@
         # linear solver
         self._solver = getattr(it_solvers, params['type'])(self._M.domain)
 
         # temporary vectors to avoid memory allocation
         self._b_full1 = self._b_eq.space.zeros()
         self._b_full2 = self._E2T.codomain.zeros()
 
-        self._rhs_v = self._u.space.zeros()
-        self._u_new = self._u.space.zeros()
+        self._rhs_v = u.space.zeros()
+        self._u_new = u.space.zeros()
 
     @property
     def variables(self):
         return [self._u]
 
     def __call__(self, dt):
         """
         TODO
         """
 
         # pointer to old coefficients
-        un = self.variables[0]
+        un = self.feec_vars[0]
 
         # sum up total magnetic field b_full1 = b_eq + b_tilde (in-place)
         self._b_eq.copy(out=self._b_full1)
 
         if self._b_tilde is not None:
             self._b_full1 += self._b_tilde
 
@@ -1862,14 +1767,169 @@
 
         info = self._solver.solve(lhs, self._rhs_v, self._pc,
                                   x0=un, tol=self._tol,
                                   maxiter=self._maxiter, verbose=self._verbose,
                                   out=self._u_new)[1]
 
         # write new coeffs into Propagator.variables
-        max_du = self.in_place_update(self._u_new)
+        max_du = self.feec_vars_update(self._u_new)
 
         if self._info and self._rank == 0:
             print('Status     for CurrentCoupling5DDensity:', info['success'])
             print('Iterations for CurrentCoupling5DDensity:', info['niter'])
             print('Maxdiff up for CurrentCoupling5DDensity:', max_du)
             print()
+
+
+class ImplicitDiffusion(Propagator):
+    r"""
+    Weak, implicit discretization of the diffusion (or heat) equation (can be used as a Poisson solver too),
+
+    .. math::
+
+        \frac{\partial \phi}{\partial t} - \Delta \phi = 0\,,
+
+    which is discretized as
+
+    .. math::
+
+        (\sigma \mathbb M_0 + \Delta t\,\mathbb G^\top \mathbb M_1 \mathbb G)\, \phi^{n+1} = \int_{(0,1)^3} \Lambda^0 \phi^n\, \textnormal d\eta\,,
+
+    where :math:`\Lambda^0 \in H^1` are the FEEC basis functions and :math:`\sigma \in \mathbb R` is a parameter.
+    The solution is :math:`\phi^{n+1}\,\in H^1` and the right-hand side is :math:`\phi^n\,\in H^1`.
+    For the choice :math:`\sigma=0` and :math:`\Delta t = 1` this is a Poisson solver,
+    where :math:`\phi^n` corresponds to the charge density.
+    Boundary terms are assumed to vanish.
+
+    Parameters
+    ----------
+    phi : psydac.linalg.stencil.StencilVector
+        FE coefficients of a discrete 0-form, the solution.
+    
+    sigma : float
+        Stabilization parameter: :math:`\sigma=1` for the heat equation and :math:`\sigma=0` for the Poisson equation.
+
+    phi_n : psydac.linalg.stencil.StencilVector
+        FE coefficients of a 0-form (optional, can be set with a setter later).
+
+    x0 : psydac.linalg.stencil.StencilVector
+        Initial guess for the iterative solver (optional, can be set with a setter later).
+
+    **solver_params : dict
+        Parameters for the iteravtive solver.
+    """
+
+    def __init__(self, phi, sigma=1., phi_n=None, x0=None, **solver_params):
+
+        super().__init__(phi)
+        
+        # parameters
+        params_default = {'type': 'PConjugateGradient',
+                          'pc': 'MassMatrixPreconditioner',
+                          'tol': 1e-8,
+                          'maxiter': 3000,
+                          'info': False,
+                          'verbose': False}
+
+        solver_params = set_defaults(solver_params, params_default)
+
+        # allocate memory for solution and rhs
+        self._phi_n = StencilVector(self.derham.Vh['0'])
+
+        # check the rhs
+        if phi_n is not None:
+
+            assert type(phi_n) == type(self._phi_n)
+            self._phi_n[:] = phi_n[:]
+            self._phi_n.update_ghost_regions()
+
+            # check solvability condition
+            if np.abs(sigma) < 1e-14:
+                sigma = 1e-14
+                self.check_rhs(phi_n) 
+
+        # initial guess and solver params
+        self._x0 = x0
+        self._solver_params = solver_params
+
+        # Set lhs matrices
+        print('{0:6.3e}'.format(sigma))
+        self._A1 = sigma * self.mass_ops.M0
+        self._A2 = Compose(self.derham.grad.T,
+                           self.mass_ops.M1,
+                           self.derham.grad)
+
+        # preconditioner
+        if self._solver_params['pc'] is None:
+            self._pc = None
+        else:
+            pc_class = getattr(preconditioner, self._solver_params['pc'])
+            self._pc = pc_class(self.mass_ops.M0)
+            
+        # solver for Ax=b with A=const.
+        self.solver = pcg(self.derham.Vh['0'])
+
+    def check_rhs(self, phi_n):
+        '''Checks space of rhs and, for periodic boundary conditions and sigma=0,
+        checks whether the integral over phi_n is zero.
+        
+        Parameters
+        ----------
+        phi_n : psydac.linalg.stencil.StencilVector
+            FE coefficients of a 0-form.'''
+        
+        assert type(phi_n) == type(self._phi_n)
+        
+        if np.all(phi_n.space.periods): 
+            solvability = np.zeros(1)
+            self.derham.comm.Allreduce(
+                np.sum(phi_n.toarray()), solvability, op=MPI.SUM)
+            assert np.abs(solvability[0]) <= 1e-11, f'Solvability condition not met: {solvability[0]}'
+
+    @property
+    def phi_n(self):
+        """
+        psydac.linalg.stencil.StencilVector or struphy.polar.basic.PolarVector.
+        """
+        return self._phi_n
+
+    @phi_n.setter
+    def phi_n(self, value):
+        """ In-place setter for StencilVector/PolarVector.
+        """
+        self.check_rhs(value)
+        self._phi_n[:] = value[:]
+
+    @property
+    def x0(self):
+        """
+        psydac.linalg.stencil.StencilVector or struphy.polar.basic.PolarVector. First guess of the iterative solver.
+        """
+        return self._x0
+
+    @x0.setter
+    def x0(self, value):
+        """ In-place setter for StencilVector/PolarVector. First guess of the iterative solver.
+        """
+        assert type(value) == type(self._phi_n)
+        assert value.space.symbolic_space == 'H1', f'Right-hand side must be in H1, but is in {value.space.symbolic_space}.'
+
+        if self._x0 is None:
+            self._x0 = value
+        else:
+            self._x0[:] = value[:]
+
+    def __call__(self, dt):
+
+        res, info = self.solver.solve(self._A1 + dt * self._A2,
+                        self._phi_n,
+                        pc=self._pc,
+                        x0=self._x0,
+                        tol=self._solver_params['tol'],
+                        maxiter=self._solver_params['maxiter'],
+                        verbose=self._solver_params['verbose']
+                        )
+
+        if self._solver_params['info']:
+            print(info)
+
+        self.feec_vars_update(res)
```

### Comparing `struphy-2.0.1/src/struphy/propagators/propagators_markers.py` & `struphy-2.0.2/src/struphy/propagators/propagators_markers.py`

 * *Files 3% similar despite different names*

```diff
@@ -33,17 +33,15 @@
 
     **params : dict
         Solver- and/or other parameters for this splitting step.
     """
 
     def __init__(self, particles, **params):
 
-        # pointer to variable
-        assert isinstance(particles, Particles6D)
-        self._particles = particles
+        super().__init__(particles)
 
         # parameters
         params_default = {'algo': 'rk4',
                           'bc_type': ['reflect', 'periodic', 'periodic'],
                           'f0': Maxwellian6DUniform()}
 
         params = set_defaults(params, params_default)
@@ -78,31 +76,27 @@
         else:
             raise NotImplementedError('Chosen algorithm is not implemented.')
 
         self._butcher = ButcherTableau(a, b, c)
         self._pusher = Pusher(self.derham, self.domain,
                               'push_eta_stage', self._butcher.n_stages)
 
-    @property
-    def variables(self):
-        return self._particles
-
     def __call__(self, dt):
         """
         TODO
         """
 
         # push markers
-        self._pusher(self._particles, dt,
+        self._pusher(self.particles[0], dt,
                      self._butcher.a, self._butcher.b, self._butcher.c,
                      mpi_sort='last')
 
         # update_weights
         if self._f0 is not None:
-            self._particles.update_weights(self._f0)
+            self.particles[0].update_weights(self._f0)
 
 
 class PushVxB(Propagator):
     r"""Solves
 
     .. math::
 
@@ -120,17 +114,15 @@
 
     **params : dict
         Solver- and/or other parameters for this splitting step.
     """
 
     def __init__(self, particles, **params):
 
-        # pointer to variable
-        assert isinstance(particles, Particles6D)
-        self._particles = particles
+        super().__init__(particles)
 
         # parameters
         params_default = {'algo': 'analytic',
                           'scale_fac': 1.,
                           'b_eq': None,
                           'b_tilde': None,
                           'f0': Maxwellian6DUniform()}
@@ -153,18 +145,14 @@
         # load pusher
         kernel_name = 'push_vxb_' + params['algo']
         self._pusher = Pusher(self.derham, self.domain, kernel_name)
 
         # transposed extraction operator PolarVector --> BlockVector (identity map in case of no polar splines)
         self._E2T = self.derham.E['2'].transpose()
 
-    @property
-    def variables(self):
-        return self._particles
-
     def __call__(self, dt):
         """
         TODO
         """
 
         # sum up total magnetic field
         b_full = self._b_eq.copy()
@@ -174,22 +162,22 @@
         # extract coefficients to tensor product space
         b_full = self._E2T.dot(b_full)
 
         # update ghost regions because of non-local access in pusher kernel
         b_full.update_ghost_regions()
 
         # call pusher kernel
-        self._pusher(self._particles, self._scale_fac*dt,
+        self._pusher(self.particles[0], self._scale_fac*dt,
                      b_full[0]._data,
                      b_full[1]._data,
                      b_full[2]._data)
 
         # update_weights
         if self._f0 is not None:
-            self._particles.update_weights(self._f0)
+            self.particles[0].update_weights(self._f0)
 
 
 class StepPushpxBHybrid(Propagator):
     r"""Solves
 
     .. math::
 
@@ -206,45 +194,41 @@
 
     **params : dict
         Solver- and/or other parameters for this splitting step.
     """
 
     def __init__(self, particles, **params):
 
+        super().__init__(particles)
+
         # parameters
         params_default = {'b_eq': None,
                           'a': None,
                           'method': None
                           }
 
         params = set_defaults(params, params_default)
 
         self._b_eq = params['b_eq']
         self._a = params['a']
         self._algo = params['method']
 
         self._C = self.derham.curl
 
-        self._particles = particles
-
         # load pusher
         kernel_name = 'push_pxb_' + self._algo
 
         self._pusher = Pusher(self.derham, self.domain, kernel_name)
 
         assert isinstance(self._b_eq, (BlockVector, PolarVector))
         assert isinstance(self._a,    (BlockVector, PolarVector))
 
         # transposed extraction operator PolarVector --> BlockVector (identity map in case of no polar splines)
         self._E2T = self.derham.E['2'].transpose()
 
-    @property
-    def variables(self):
-        return self._particles
-
     def __call__(self, dt):
         """
         TODO
         """
 
         # sum up total magnetic field
         b_full = self._b_eq.space.zeros()
@@ -255,15 +239,15 @@
         b_full = self._E2T.dot(b_full)
 
         # update ghost regions because of non-local access in pusher kernel
         b_full.update_ghost_regions()
         self._a.update_ghost_regions()
 
         # call pusher kernel
-        self._pusher(self._particles, dt,
+        self._pusher(self.particles[0], dt,
                      b_full[0]._data,
                      b_full[1]._data,
                      b_full[2]._data,
                      self._a[0]._data,
                      self._a[1]._data,
                      self._a[2]._data)
 
@@ -283,15 +267,15 @@
 
         **params : dict
         Solver- and/or other parameters for this splitting step.
     '''
 
     def __init__(self, particles, **params):
 
-        self._particles = particles
+        super().__init__(particles)
 
         # parameters
         params_default = {'a': None,
                           'particle_bc': None,
                           'quad_number': None,
                           'shape_degree': None,
                           'shape_size': None,
@@ -334,39 +318,35 @@
         self._pusher_lnn = Pusher(
             self.derham, self.domain, 'push_hybrid_xp_lnn')
         self._pusher_ap = Pusher(self.derham, self.domain, 'push_hybrid_xp_ap')
 
         self._pusher_inputs = (
             self._a[0]._data, self._a[1]._data, self._a[2]._data)
 
-    @property
-    def variables(self):
-        return
-
     def __call__(self, dt):
         """
         TODO
         """
         # get density from particles
-        self._accum_density.accumulate(self._particles, array(self.derham.Nel), array(self._nqs), array(
+        self._accum_density.accumulate(self.particles[0], array(self.derham.Nel), array(self._nqs), array(
             self._pts_x), array(self._pts_y), array(self._pts_z), array(self._p_shape), array(self._p_size))
         if not self._accum_density._operators[0].matrix.ghost_regions_in_sync:
             self._accum_density._operators[0].matrix.update_ghost_regions()
         # print('++++++check_density+++++++++', self._accum_density._operators[0].matrix._data)
-        self._pusher_lnn(self._particles, dt, array(self._p_shape), array(self._p_size), array(self.derham.Nel), array(self._pts_x), array(self._pts_y), array(
+        self._pusher_lnn(self.particles[0], dt, array(self._p_shape), array(self._p_size), array(self.derham.Nel), array(self._pts_x), array(self._pts_y), array(
             self._pts_z), array(self._wts_x), array(self._wts_y), array(self._wts_z), self._accum_density._operators[0].matrix._data, self._thermal, array(self._nqs))
 
         if not self._a[0].ghost_regions_in_sync:
             self._a[0].update_ghost_regions()
         if not self._a[1].ghost_regions_in_sync:
             self._a[1].update_ghost_regions()
         if not self._a[2].ghost_regions_in_sync:
             self._a[2].update_ghost_regions()
         self._pusher_ap(
-            self._particles, dt, self._a[0]._data, self._a[1]._data, self._a[2]._data, mpi_sort='last')
+            self.particles[0], dt, self._a[0]._data, self._a[1]._data, self._a[2]._data, mpi_sort='last')
 
 
 class PushEtaPC(Propagator):
     r'''Step for the update of particles' positions with the RK4 method which solves
 
     .. math::
 
@@ -397,17 +377,15 @@
 
     bc : list[str]
         Kinetic boundary conditions in each direction.
     '''
 
     def __init__(self, particles, **params):
 
-        # pointer to variable
-        assert isinstance(particles, Particles6D)
-        self._particles = particles
+        super().__init__(particles)
 
         # parameters
         params_default = {'u_mhd': None,
                           'u_space': 'Hdiv',
                           'bc_type': ['reflect', 'periodic', 'periodic'],
                           'use_perp_model': True
                           }
@@ -424,32 +402,28 @@
         pusher_ker = 'push_pc_eta_rk4_' + self._u_space
         if not params['use_perp_model']:
             pusher_ker += '_full'
 
         self._pusher = Pusher(
             self.derham, self.domain, pusher_ker, n_stages=4)
 
-    @property
-    def variables(self):
-        return
-
     def __call__(self, dt):
         """
         TODO
         """
         # push particles
         # check if ghost regions are synchronized
         if not self._u[0].ghost_regions_in_sync:
             self._u[0].update_ghost_regions()
         if not self._u[1].ghost_regions_in_sync:
             self._u[1].update_ghost_regions()
         if not self._u[2].ghost_regions_in_sync:
             self._u[2].update_ghost_regions()
 
-        self._pusher(self._particles, dt,
+        self._pusher(self.particles[0], dt,
                      self._u[0]._data, self._u[1]._data, self._u[2]._data,
                      mpi_sort='last')
 
 
 class StepPushGuidingCenter1(Propagator):
     r"""Solves
 
@@ -479,17 +453,15 @@
 
     **params : dict
         Solver- and/or other parameters for this splitting step.
     """
 
     def __init__(self, particles, **params):
 
-        # pointer to variable
-        assert isinstance(particles, Particles5D)
-        self._particles = particles
+        super().__init__(particles)
 
         # parameters
         params_default = {'kappa': 1.,
                           'b_eq': None,
                           'unit_b1': None,
                           'unit_b2': None,
                           'abs_b': None,
@@ -567,15 +539,15 @@
             if params['method'] == 'discrete_gradients':
                 self._pusher = Pusher_iteration_Gonzalez(
                     self.derham, self.domain, 'push_gc1_discrete_gradients', params['maxiter'], params['tol'])
 
             elif params['method'] == 'discrete_gradients_faster':
                 self._pusher = Pusher_iteration_Gonzalez(
                     self.derham, self.domain, 'push_gc1_discrete_gradients_faster', params['maxiter'], params['tol'])
-                
+
             elif params['method'] == 'discrete_gradients_Itoh_Newton':
                 self._pusher = Pusher_iteration_Itoh(
                     self.derham, self.domain, 'push_gc1_discrete_gradients_Itoh_Newton', params['maxiter'], params['tol'])
 
             else:
                 raise NotImplementedError(
                     'Chosen implicit method is not implemented.')
@@ -586,27 +558,23 @@
                                    self._unit_b2[0]._data, self._unit_b2[1]._data, self._unit_b2[2]._data,
                                    self._curl_norm_b[0]._data, self._curl_norm_b[1]._data, self._curl_norm_b[2]._data,
                                    self._grad_abs_b[0]._data, self._grad_abs_b[1]._data, self._grad_abs_b[2]._data)
 
         else:
             raise NotImplementedError('Chosen integrator is not implemented.')
 
-    @property
-    def variables(self):
-        return self._particles
-
     def __call__(self, dt):
         """
         TODO
         """
-        self._pusher(self._particles, dt,
-                     *self._pusher_inputs, mpi_sort='each', verbose=True)
+        self._pusher(self.particles[0], dt,
+                     *self._pusher_inputs, mpi_sort='each', verbose=False)
 
         # save magnetic field at each particles' position
-        self._particles.save_magnetic_energy(self.derham, self._abs_b)
+        self.particles[0].save_magnetic_energy(self.derham, self._abs_b)
 
 
 class StepPushGuidingCenter2(Propagator):
     r"""Solves
 
     .. math::
 
@@ -629,17 +597,15 @@
 
     **params : dict
         Solver- and/or other parameters for this splitting step.
     """
 
     def __init__(self, particles, **params):
 
-        # pointer to variable
-        assert isinstance(particles, Particles5D)
-        self._particles = particles
+        super().__init__(particles)
 
         # parameters
         params_default = {'kappa': 1.,
                           'b_eq': None,
                           'unit_b1': None,
                           'unit_b2': None,
                           'abs_b': None,
@@ -717,18 +683,18 @@
             if params['method'] == 'discrete_gradients':
                 self._pusher = Pusher_iteration_Gonzalez(
                     self.derham, self.domain, 'push_gc2_discrete_gradients', params['maxiter'], params['tol'])
 
             elif params['method'] == 'discrete_gradients_faster':
                 self._pusher = Pusher_iteration_Gonzalez(
                     self.derham, self.domain, 'push_gc2_discrete_gradients_faster', params['maxiter'], params['tol'])
-                
+
             elif params['method'] == 'discrete_gradients_Itoh_Newton':
                 self._pusher = Pusher_iteration_Itoh(
-                     self.derham, self.domain, 'push_gc2_discrete_gradients_Itoh_Newton', params['maxiter'], params['tol'])
+                    self.derham, self.domain, 'push_gc2_discrete_gradients_Itoh_Newton', params['maxiter'], params['tol'])
 
             else:
                 raise NotImplementedError(
                     'Chosen implicit method is not implemented.')
 
             self._pusher_inputs = (self._kappa, self._abs_b._data,
                                    self._b_eq[0]._data, self._b_eq[1]._data, self._b_eq[2]._data,
@@ -736,27 +702,23 @@
                                    self._unit_b2[0]._data, self._unit_b2[1]._data, self._unit_b2[2]._data,
                                    self._curl_norm_b[0]._data, self._curl_norm_b[1]._data, self._curl_norm_b[2]._data,
                                    self._grad_abs_b[0]._data, self._grad_abs_b[1]._data, self._grad_abs_b[2]._data)
 
         else:
             raise NotImplementedError('Chosen integrator is not implemented.')
 
-    @property
-    def variables(self):
-        return self._particles
-
     def __call__(self, dt):
         """
         TODO
         """
-        self._pusher(self._particles, dt,
-                     *self._pusher_inputs, mpi_sort='each', verbose=True)
+        self._pusher(self.particles[0], dt,
+                     *self._pusher_inputs, mpi_sort='each', verbose=False)
 
         # save magnetic field at each particles' position
-        self._particles.save_magnetic_energy(self.derham, self._abs_b)
+        self.particles[0].save_magnetic_energy(self.derham, self._abs_b)
 
 
 class StepVinEfield(Propagator):
     r'''Push the velocities according to
 
     .. math::
 
@@ -771,19 +733,15 @@
 
     **params : dict
         Solver- and/or other parameters for this splitting step.
     '''
 
     def __init__(self, particles, **params):
 
-        from numpy import polynomial, floor
-
-        # pointer to variable
-        assert isinstance(particles, Particles6D)
-        self._particles = particles
+        super().__init__(particles)
 
         # parameters
         params_default = {
             'e_field': BlockVector(self.derham.Vh_fem['1'].vector_space),
             'method': 'analytical',
             'kappa': 1e2
         }
@@ -793,31 +751,27 @@
         method = params['method']
 
         assert isinstance(params['e_field'], (BlockVector, PolarVector))
         self._e_field = params['e_field']
 
         if method == 'analytical':
             self._pusher = Pusher(self.derham, self.domain,
-                                'push_v_with_efield')
+                                  'push_v_with_efield')
         elif method == 'discrete_gradient':
             raise NotImplementedError('Not yet implemented.')
             # self._pusher = Pusher(self.derham, self.domain,
             #                     'push_v_in_static_efield_dg')
         else:
             raise ValueError(f'Method {method} not known.')
 
-    @property
-    def variables(self):
-        return [self._particles]
-
     def __call__(self, dt):
         """
         TODO
         """
-        self._pusher(self._particles, dt,
+        self._pusher(self.particles[0], dt,
                      self._e_field.blocks[0]._data, self._e_field.blocks[1]._data, self._e_field.blocks[2]._data,
                      self.kappa)
 
 
 class StepStaticEfield(Propagator):
     r'''Solve the following system
 
@@ -847,17 +801,15 @@
         Solver- and/or other parameters for this splitting step.
     '''
 
     def __init__(self, particles, **params):
 
         from numpy import polynomial, floor
 
-        # pointer to variable
-        assert isinstance(particles, Particles6D)
-        self._particles = particles
+        super().__init__(particles)
 
         # parameters
         params_default = {
             'e_field': BlockVector(self.derham.Vh_fem['1'].vector_space),
             'kappa': 1e2
         }
 
@@ -885,23 +837,19 @@
         self._loc1, self._weight1 = polynomial.legendre.leggauss(n_quad1)
         self._loc2, self._weight2 = polynomial.legendre.leggauss(n_quad2)
         self._loc3, self._weight3 = polynomial.legendre.leggauss(n_quad3)
 
         self._pusher = Pusher(self.derham, self.domain,
                               'push_x_v_static_efield')
 
-    @property
-    def variables(self):
-        return [self._particles]
-
     def __call__(self, dt):
         """
         TODO
         """
-        self._pusher(self._particles, dt,
+        self._pusher(self.particles[0], dt,
                      self._loc1, self._loc2, self._loc3, self._weight1, self._weight2, self._weight3,
                      self._e_field.blocks[0]._data, self._e_field.blocks[1]._data, self._e_field.blocks[2]._data,
                      self.kappa,
                      array([1e-10, 1e-10]), 100)
 
 
 class StepPushDriftKinetic1(Propagator):
@@ -933,17 +881,15 @@
 
     **params : dict
         Solver- and/or other parameters for this splitting step.
     """
 
     def __init__(self, particles, **params):
 
-        # pointer to variable
-        assert isinstance(particles, Particles5D)
-        self._particles = particles
+        super().__init__(particles)
 
         # parameters
         params_default = {'kappa': 1.,
                           'b': None,
                           'b_eq': None,
                           'unit_b1': None,
                           'unit_b2': None,
@@ -960,36 +906,37 @@
         self._b = params['b']
         self._b_eq = params['b_eq']
         self._unit_b1 = params['unit_b1']
         self._unit_b2 = params['unit_b2']
         self._abs_b = params['abs_b']
 
         self._curl_norm_b = self.derham.curl.dot(self._unit_b1)
-        self._grad_abs_b = self.derham.grad.dot(self._abs_b)
-
-        self._curl_norm_b.update_ghost_regions()
-        self._grad_abs_b.update_ghost_regions()
 
         # sum up total magnetic field
         self._b_full = self._b_eq.copy()
-        if self._b is not None:
-            self._b_full += self._b
-
-        self._b_full.update_ghost_regions()
 
         # define gradient of absolute value of parallel magnetic field
         self._PB = getattr(self.basis_ops, 'PB')
         self._PBb = self._PB.dot(self._b_full)
-        self._PBb.update_ghost_regions()
-
         self._grad_PBb = self.derham.grad.dot(self._PBb)
-        self._grad_PBb.update_ghost_regions()
+
+        # transposed extraction operator PolarVector --> BlockVector (identity map in case of no polar splines)
+        self._E0T = self.derham.E['0'].transpose()
+        self._E1T = self.derham.E['1'].transpose()
+        self._E2T = self.derham.E['2'].transpose()
+
+        self._b_eq = self._E2T.dot(self._b_eq)
+        self._unit_b1 = self._E1T.dot(self._unit_b1)
+        self._unit_b2 = self._E2T.dot(self._unit_b2)
+        self._curl_norm_b = self._E2T.dot(self._curl_norm_b)
+
+        self._curl_norm_b.update_ghost_regions()
 
         self._integrator = params['integrator']
-        
+
         if params['integrator'] == 'explicit':
 
             if params['method'] == 'forward_euler':
                 a = []
                 b = [1.]
                 c = [0.]
             elif params['method'] == 'heun2':
@@ -1021,67 +968,66 @@
             if params['method'] == 'discrete_gradients':
                 self._pusher = Pusher_iteration_Gonzalez(
                     self.derham, self.domain, 'push_gc1_discrete_gradients', params['maxiter'], params['tol'])
 
             elif params['method'] == 'discrete_gradients_faster':
                 self._pusher = Pusher_iteration_Gonzalez(
                     self.derham, self.domain, 'push_gc1_discrete_gradients_faster', params['maxiter'], params['tol'])
-                
+
             elif params['method'] == 'discrete_gradients_Itoh_Newton':
                 self._pusher = Pusher_iteration_Itoh(
                     self.derham, self.domain, 'push_gc1_discrete_gradients_Itoh_Newton', params['maxiter'], params['tol'])
 
             else:
                 raise NotImplementedError(
                     'Chosen implicit method is not implemented.')
 
         else:
             raise NotImplementedError('Chosen integrator is not implemented.')
 
-    @property
-    def variables(self):
-        return self._particles
-
     def __call__(self, dt):
         """
         TODO
         """
 
         # sum up total magnetic field
         self._b_full = self._b_eq.copy()
         if self._b is not None:
             self._b_full += self._b
 
-        self._b_full.update_ghost_regions()
-
         # define gradient of absolute value of parallel magnetic field
         self._PBb = self._PB.dot(self._b_full)
-        self._PBb.update_ghost_regions()
-
         self._grad_PBb = self.derham.grad.dot(self._PBb)
+
+        self._b_full = self._E2T.dot(self._b_full)
+        self._PBb = self._E0T.dot(self._PBb)
+        self._grad_PBb = self._E1T.dot(self._grad_PBb)
+
+        self._b_full.update_ghost_regions()
+        self._PBb.update_ghost_regions()
         self._grad_PBb.update_ghost_regions()
 
         if self._integrator == 'explicit':
-            self._pusher_inputs = (self._kappa, 
+            self._pusher_inputs = (self._kappa,
                                    self._b_full[0]._data, self._b_full[1]._data, self._b_full[2]._data,
                                    self._unit_b1[0]._data, self._unit_b1[1]._data, self._unit_b1[2]._data,
                                    self._unit_b2[0]._data, self._unit_b2[1]._data, self._unit_b2[2]._data,
                                    self._curl_norm_b[0]._data, self._curl_norm_b[1]._data, self._curl_norm_b[2]._data,
                                    self._grad_PBb[0]._data, self._grad_PBb[1]._data, self._grad_PBb[2]._data,
                                    self._butcher.a, self._butcher.b, self._butcher.c)
         else:
             self._pusher_inputs = (self._kappa, self._PBb._data,
                                    self._b_full[0]._data, self._b_full[1]._data, self._b_full[2]._data,
                                    self._unit_b1[0]._data, self._unit_b1[1]._data, self._unit_b1[2]._data,
                                    self._unit_b2[0]._data, self._unit_b2[1]._data, self._unit_b2[2]._data,
                                    self._curl_norm_b[0]._data, self._curl_norm_b[1]._data, self._curl_norm_b[2]._data,
                                    self._grad_PBb[0]._data, self._grad_PBb[1]._data, self._grad_PBb[2]._data)
 
-        self._pusher(self._particles, dt,
-                     *self._pusher_inputs, mpi_sort='each', verbose=True)
+        self._pusher(self.particles[0], dt,
+                     *self._pusher_inputs, mpi_sort='each', verbose=False)
 
 
 class StepPushDriftKinetic2(Propagator):
     r"""Solves
 
     .. math::
 
@@ -1104,17 +1050,15 @@
 
     **params : dict
         Solver- and/or other parameters for this splitting step.
     """
 
     def __init__(self, particles, **params):
 
-        # pointer to variable
-        assert isinstance(particles, Particles5D)
-        self._particles = particles
+        super().__init__(particles)
 
         # parameters
         params_default = {'kappa': 1.,
                           'b': None,
                           'b_eq': None,
                           'unit_b1': None,
                           'unit_b2': None,
@@ -1131,33 +1075,34 @@
         self._b = params['b']
         self._b_eq = params['b_eq']
         self._unit_b1 = params['unit_b1']
         self._unit_b2 = params['unit_b2']
         self._abs_b = params['abs_b']
 
         self._curl_norm_b = self.derham.curl.dot(self._unit_b1)
-        self._grad_abs_b = self.derham.grad.dot(self._abs_b)
-
-        self._curl_norm_b.update_ghost_regions()
-        self._grad_abs_b.update_ghost_regions()
 
         # sum up total magnetic field
         self._b_full = self._b_eq.copy()
-        if self._b is not None:
-            self._b_full += self._b
-
-        self._b_full.update_ghost_regions()
 
         # define gradient of absolute value of parallel magnetic field
         self._PB = getattr(self.basis_ops, 'PB')
         self._PBb = self._PB.dot(self._b_full)
-        self._PBb.update_ghost_regions()
 
         self._grad_PBb = self.derham.grad.dot(self._PBb)
-        self._grad_PBb.update_ghost_regions()
+
+        # transposed extraction operator PolarVector --> BlockVector (identity map in case of no polar splines)
+        self._E0T = self.derham.E['0'].transpose()
+        self._E1T = self.derham.E['1'].transpose()
+        self._E2T = self.derham.E['2'].transpose()
+
+        self._unit_b1 = self._E1T.dot(self._unit_b1)
+        self._unit_b2 = self._E2T.dot(self._unit_b2)
+        self._curl_norm_b = self._E2T.dot(self._curl_norm_b)
+
+        self._curl_norm_b.update_ghost_regions()
 
         self._integrator = params['integrator']
 
         if params['integrator'] == 'explicit':
 
             if params['method'] == 'forward_euler':
                 a = []
@@ -1192,59 +1137,58 @@
             if params['method'] == 'discrete_gradients':
                 self._pusher = Pusher_iteration_Gonzalez(
                     self.derham, self.domain, 'push_gc2_discrete_gradients', params['maxiter'], params['tol'])
 
             elif params['method'] == 'discrete_gradients_faster':
                 self._pusher = Pusher_iteration_Gonzalez(
                     self.derham, self.domain, 'push_gc2_discrete_gradients_faster', params['maxiter'], params['tol'])
-                
+
             elif params['method'] == 'discrete_gradients_Itoh_Newton':
                 self._pusher = Pusher_iteration_Itoh(
-                     self.derham, self.domain, 'push_gc2_discrete_gradients_Itoh_Newton', params['maxiter'], params['tol'])
+                    self.derham, self.domain, 'push_gc2_discrete_gradients_Itoh_Newton', params['maxiter'], params['tol'])
 
             else:
                 raise NotImplementedError(
                     'Chosen implicit method is not implemented.')
 
         else:
             raise NotImplementedError('Chosen integrator is not implemented.')
 
-    @property
-    def variables(self):
-        return self._particles
-
     def __call__(self, dt):
         """
         TODO
         """
         # sum up total magnetic field
         self._b_full = self._b_eq.copy()
         if self._b is not None:
             self._b_full += self._b
 
-        self._b_full.update_ghost_regions()
-
         # define gradient of absolute value of parallel magnetic field
         self._PBb = self._PB.dot(self._b_full)
-        self._PBb.update_ghost_regions()
-
         self._grad_PBb = self.derham.grad.dot(self._PBb)
+
+        self._b_full = self._E2T.dot(self._b_full)
+        self._PBb = self._E0T.dot(self._PBb)
+        self._grad_PBb = self._E1T.dot(self._grad_PBb)
+
+        self._b_full.update_ghost_regions()
+        self._PBb.update_ghost_regions()
         self._grad_PBb.update_ghost_regions()
 
         if self._integrator == 'explicit':
-            self._pusher_inputs = (self._kappa, 
+            self._pusher_inputs = (self._kappa,
                                    self._b_full[0]._data, self._b_full[1]._data, self._b_full[2]._data,
                                    self._unit_b1[0]._data, self._unit_b1[1]._data, self._unit_b1[2]._data,
                                    self._unit_b2[0]._data, self._unit_b2[1]._data, self._unit_b2[2]._data,
                                    self._curl_norm_b[0]._data, self._curl_norm_b[1]._data, self._curl_norm_b[2]._data,
                                    self._grad_PBb[0]._data, self._grad_PBb[1]._data, self._grad_PBb[2]._data,
                                    self._butcher.a, self._butcher.b, self._butcher.c)
         else:
             self._pusher_inputs = (self._kappa, self._PBb._data,
                                    self._b_full[0]._data, self._b_full[1]._data, self._b_full[2]._data,
                                    self._unit_b1[0]._data, self._unit_b1[1]._data, self._unit_b1[2]._data,
                                    self._unit_b2[0]._data, self._unit_b2[1]._data, self._unit_b2[2]._data,
                                    self._curl_norm_b[0]._data, self._curl_norm_b[1]._data, self._curl_norm_b[2]._data,
                                    self._grad_PBb[0]._data, self._grad_PBb[1]._data, self._grad_PBb[2]._data)
 
-        self._pusher(self._particles, dt,
-                     *self._pusher_inputs, mpi_sort='each', verbose=True)
+        self._pusher(self.particles[0], dt,
+                     *self._pusher_inputs, mpi_sort='each', verbose=False)
```

### Comparing `struphy-2.0.1/src/struphy/psydac_api/banded_to_stencil_kernels.py` & `struphy-2.0.2/src/struphy/psydac_api/banded_to_stencil_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/psydac_api/basis_projection_kernels.py` & `struphy-2.0.2/src/struphy/psydac_api/basis_projection_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/psydac_api/basis_projection_ops.py` & `struphy-2.0.2/src/struphy/psydac_api/basis_projection_ops.py`

 * *Files 2% similar despite different names*

```diff
@@ -58,16 +58,17 @@
     Possible choices for key-value pairs in ****weights** are, at the moment:
 
     - eq_mhd: :class:`struphy.fields_background.mhd_equil.base.MHDequilibrium`
     """
 
     def __init__(self, derham, domain, **weights):
 
-        assert np.all(np.array(
-            derham.p) > 1), 'Spline degrees must be >1 to use basis projection operators (-> avoid interpolation of piece-wise constants).'
+        if np.any(np.array(derham.p) == 1):
+            if derham.comm.Get_rank() == 0:
+                print(f'\nWARNING: Class "BasisProjectionOperators" called with p={derham.p} (interpolation of piece-wise constants should be avoided).\n')
 
         self._derham = derham
         self._domain = domain
         self._weights = weights
 
     @property
     def derham(self):
@@ -668,15 +669,15 @@
         Here, :math:`\alpha \in \{0, 1, 2, 3, v\}` indicates the domain and :math:`\beta \in \{0, 1, 2, 3, v\}` indicates the co-domain 
         of the operator.
 
         Parameters
         ----------
         fun : list[list[callable | ndarray]]
             2d list of either all 3d arrays or all scalar functions of eta1, eta2, eta3 (must allow matrix evaluations). 
-            3d arrays must have shape corresponding to the 1d quad_grids of V1-ProductFemSpace.
+            3d arrays must have shape corresponding to the 1d quad_grids of V1-VectorFemSpace.
 
         V_id : str
             Specifier for the domain of the operator ('H1', 'Hcurl', 'Hdiv', 'L2' or 'H1vec').
 
         W_id : str
             Specifier for the co-domain of the operator ('H1', 'Hcurl', 'Hdiv', 'L2' or 'H1vec').
 
@@ -718,15 +719,15 @@
 class BasisProjectionOperator(LinOpWithTransp):
     """
     Class for "basis projection operators" PI_ijk(fun Lambda_mno) in the general form BP * P * DOF * EV^T * BV^T.
 
     Parameters
     ----------
     P : struphy.psydac_api.projectors.Projector
-        Global commuting projector mapping into TensorFemSpace/ProductFemSpace W = P.space (codomain of operator).
+        Global commuting projector mapping into TensorFemSpace/VectorFemSpace W = P.space (codomain of operator).
 
     V : psydac.fem.basic.FemSpace
         Finite element spline space (domain, input space).
 
     fun : list
         Weight function(s) (callables) in a 2d list of shape corresponding to number of components of domain/codomain.
 
@@ -928,15 +929,15 @@
         Assembles the tensor-product DOF matrix sigma_i(fun*Lambda_j), where i=(i1, i2, ...) and j=(j1, j2, ...) depending on the number of spatial dimensions (1d, 2d or 3d).
 
         Parameters
         ----------
         P : GlobalProjector
             The psydac global tensor product projector defining the space onto which the input shall be projected.
 
-        V : TensorFemSpace | ProductFemSpace
+        V : TensorFemSpace | VectorFemSpace
             The spline space which shall be projected.
 
         fun : list
             Weight function(s) (callables) in a 2d list of shape corresponding to number of components of domain/codomain.
 
         polar_shift : bool
             Whether there are metric coefficients contained in "fun" which are singular at eta1=0. If True, interpolation points at eta1=0 are shifted away from the singularity by 1e-5.
```

### Comparing `struphy-2.0.1/src/struphy/psydac_api/fields.py` & `struphy-2.0.2/src/struphy/psydac_api/projectors.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,638 +1,510 @@
-#!/usr/bin/env python3
-
-from xml import dom
-from psydac.linalg.stencil import StencilVector
-from psydac.linalg.block import BlockVector
-
-from struphy.initial import perturbations
-from struphy.initial import analytic
-from struphy.initial import eigenfunctions
-
-from struphy.polar.basic import PolarVector
-from struphy.geometry.base import Domain
-from struphy.b_splines import bspline_evaluation_3d as eval_3d
+from psydac.linalg.stencil import StencilVector, StencilMatrix
+from psydac.linalg.block import BlockLinearOperator
+from psydac.linalg.kron import KroneckerStencilMatrix
+from psydac.linalg.basic import Vector
+from psydac.feec.global_projectors import GlobalProjector
+from psydac.api.settings import PSYDAC_BACKEND_GPYCCEL
+
+from struphy.psydac_api.linear_operators import CompositeLinearOperator, BoundaryOperator, IdentityOperator
+from struphy.psydac_api.preconditioner import ProjectorPreconditioner
+from struphy.polar.linear_operators import PolarExtractionOperator
+from struphy.linear_algebra.iterative_solvers import PBiConjugateGradientStab
 
 import numpy as np
-from mpi4py import MPI
 
 
-class Field:
+class Projector:
     """
-    Initializes a field variable (i.e. its FE coefficients) in memory and creates a method for assigning initial condition.
-
+    A commuting projector in a 3d (polar) de Rham diagram. The general structure of the inter-/histopolation problem reads
+    
+         (B * P * I * E^T * B^T) * coeffs = B * P * dofs,
+    
+    with the following linear operators:
+    
+        * B : boundary operator,
+        * P : polar degrees of freedom extraction operator,
+        * I : tensor product inter-/histopolation matrix,
+        * E : polar basis extraction operator.
+        
+    P and E (and B in case of no boundary conditions) can be identity operators.
+    
     Parameters
     ----------
-        name : str
-            Field's key to be used for saving in the hdf5 file.
-
-        space_id : str
-            Space identifier for the field ("H1", "Hcurl", "Hdiv", "L2" or "H1vec").
-
-        derham : struphy.psydac_api.psydac_derham.Derham
-            Discrete Derham complex.
-    """
-
-    def __init__(self, name, space_id, derham):
-
-        self._name = name
-        self._space_id = space_id
-        self._derham = derham
-
-        # initialize field in memory (FEM space, vector and tensor product (stencil) vector)
-        self._space_key = derham.spaces_dict[space_id]
-        self._space = derham.Vh_fem[self._space_key]
-
-        self._vector = derham.Vh_pol[self._space_key].zeros()
+    projector_tensor : psydac.feec.global_projectors.GlobalProjector
+        The pure tensor product projector.
 
-        self._vector_stencil = self._space.vector_space.zeros()
+    dofs_extraction_op : struphy.polar.linear_operators.PolarExtractionOperator, optional
+        The degrees of freedom extraction operator mapping tensor product DOFs to polar DOFs. If not given, is set to identity.
 
-        # transposed basis extraction operator for PolarVector --> Stencil-/BlockVector
-        self._ET = derham.E[self._space_key].transpose()
+    base_extraction_op : struphy.polar.linear_operators.PolarExtractionOperator, optional
+        The basis extraction operator mapping tensor product basis functions to polar basis functions. If not given, is set to identity.
 
-        # global indices of each process, and paddings
-        if self._space_id in {'H1', 'L2'}:
-            self._gl_s = self._space.vector_space.starts
-            self._gl_e = self._space.vector_space.ends
-            self._pads = self._space.vector_space.pads
+    boundary_op : struphy.psydac_api.linear_operators.BoundaryOperator.
+        The boundary operator applying essential boundary conditions to a vector. If not given, is set to identity.
+    """
+    
+    def __init__(self, projector_tensor, dofs_extraction_op=None, base_extraction_op=None, boundary_op=None):
+        
+        assert isinstance(projector_tensor, GlobalProjector)
+        
+        self._projector_tensor = projector_tensor
+        
+        if dofs_extraction_op is not None:
+            assert isinstance(dofs_extraction_op, (PolarExtractionOperator, IdentityOperator))
+            self._dofs_extraction_op = dofs_extraction_op
         else:
-            self._gl_s = [
-                comp.starts for comp in self._space.vector_space.spaces]
-            self._gl_e = [
-                comp.ends for comp in self._space.vector_space.spaces]
-            self._pads = [
-                comp.pads for comp in self._space.vector_space.spaces]
-
-        # dimensions in each direction
-        # self._nbasis = derham.nbasis[self._space_key]
-
-        if self._space_id in {'H1', 'L2'}:
-            self._nbasis = tuple(
-                [space.nbasis for space in self._space.spaces])
+            self._dofs_extraction_op = IdentityOperator(self.space.vector_space)
+            
+        if base_extraction_op is not None:
+            assert isinstance(base_extraction_op, (PolarExtractionOperator, IdentityOperator))
+            self._base_extraction_op = base_extraction_op
         else:
-            self._nbasis = [tuple([space.nbasis for space in vec_space.spaces])
-                            for vec_space in self._space.spaces]
-
+            self._base_extraction_op = IdentityOperator(self.space.vector_space)
+        
+        if boundary_op is not None:
+            assert isinstance(boundary_op, (BoundaryOperator, IdentityOperator))
+            self._boundary_op = boundary_op
+        else:
+            self._boundary_op = IdentityOperator(self.space.vector_space)
+        
+        # convert Kronecker inter-/histopolation matrix to Stencil-/BlockLinearOperator (only needed in polar case)
+        if isinstance(self.dofs_extraction_op, PolarExtractionOperator):
+            
+            self._is_polar = True
+            
+            if isinstance(projector_tensor.imat_kronecker, KroneckerStencilMatrix):
+                self._imat = projector_tensor.imat_kronecker.tostencil()
+                self._imat.set_backend(PSYDAC_BACKEND_GPYCCEL, precompiled=True)
+            else:
+                
+                b11 = projector_tensor.imat_kronecker.blocks[0][0].tostencil()
+                b11.set_backend(PSYDAC_BACKEND_GPYCCEL, precompiled=True)
+                b22 = projector_tensor.imat_kronecker.blocks[1][1].tostencil()
+                b22.set_backend(PSYDAC_BACKEND_GPYCCEL, precompiled=True)
+                b33 = projector_tensor.imat_kronecker.blocks[2][2].tostencil()
+                b33.set_backend(PSYDAC_BACKEND_GPYCCEL, precompiled=True)
+                
+                blocks = [[b11, None, None],
+                          [None, b22, None],
+                          [None, None, b33]]
+                
+                self._imat = BlockLinearOperator(self.space.vector_space, self.space.vector_space, blocks)
+            
+        else:
+            
+            self._is_polar = False
+            
+            self._imat = projector_tensor.imat_kronecker
+            
+        # transposed
+        self._imatT = self._imat.T
+        
+        # some shortcuts
+        P = self._dofs_extraction_op
+        E = self._base_extraction_op
+        
+        B = self._boundary_op
+
+        # build inter-/histopolation matrix I = ID * P * I * E^T * ID^T and I0 = B * P * I * E^T * B^T as ComposedLinearOperator
+        self._I  = CompositeLinearOperator(IdentityOperator(P.codomain), P, self._imat, E.T, IdentityOperator(E.codomain).T)
+        self._I0 = CompositeLinearOperator(B, P, self._imat, E.T, B.T)
+
+        # transposed
+        self._IT  = CompositeLinearOperator(IdentityOperator(E.codomain), E, self._imatT, P.T, IdentityOperator(P.codomain).T)
+        self._I0T = CompositeLinearOperator(B, E, self._imatT, P.T, B.T)
+
+        # preconditioner ID * P * I^(-1) * E^T * ID^T and B * P * I^(-1) * E^T * B^T for iterative polar projections
+        self._pc  = ProjectorPreconditioner(self, transposed=False, apply_bc=False)
+        self._pc0 = ProjectorPreconditioner(self, transposed=False, apply_bc=True)
+        
+        # transposed
+        self._pcT  = ProjectorPreconditioner(self, transposed=True, apply_bc=False)
+        self._pc0T = ProjectorPreconditioner(self, transposed=True, apply_bc=True)
+        
+        # linear solver used for polar projections
+        if self._is_polar:
+            self._polar_solver = PBiConjugateGradientStab(self._I.domain)
+        else:
+            self._polar_solver = None
+            
+        self._polar_info = None
+                
     @property
-    def name(self):
-        """ Name of the field in data container (string).
+    def projector_tensor(self):
+        """ Tensor product projector.
         """
-        return self._name
-
+        return self._projector_tensor
+    
     @property
-    def space_id(self):
-        """ String identifying the continuous space of the field: 'H1', 'Hcurl', 'Hdiv', 'L2' or 'H1vec'.
+    def space(self):
+        """ Tensor product FEM space corresponding to projector.
         """
-        return self._space_id
+        return self._projector_tensor.space
 
-    @property
-    def space_key(self):
-        """ String identifying the discrete space of the field: '0', '1', '2', '3' or 'v'.
+    @property 
+    def dofs_extraction_op(self):
+        """ Degrees of freedom extraction operator (tensor product DOFs --> polar DOFs).
         """
-        return self._space_key
+        return self._dofs_extraction_op
 
     @property
-    def derham(self):
-        """ 3d Derham complex struphy.psydac_api.psydac_derham.Derham.
+    def base_extraction_op(self):
+        """ Basis functions extraction operator (tensor product basis functions --> polar basis functions).
         """
-        return self._derham
-
+        return self._base_extraction_op
+    
     @property
-    def space(self):
-        """ Discrete space of the field, either psydac.fem.tensor.TensorFemSpace or psydac.fem.vector.ProductFemSpace.
+    def boundary_op(self):
+        """ Boundary operator seeting essential boundary conditions to array.
         """
-        return self._space
-
+        return self._boundary_op
+    
     @property
-    def ET(self):
-        """ Transposed PolarExtractionOperator (or IdentityOperator) for mapping polar coeffs to polar tensor product rings.
+    def is_polar(self):
+        """ Whether the projector maps to polar splines (True) or pure tensor product splines.
         """
-        return self._ET
+        return self._is_polar
 
     @property
-    def vector(self):
-        """ psydac.linalg.stencil.StencilVector or psydac.linalg.block.BlockVector or struphy.polar.basic.PolarVector.
-        """
-        return self._vector
-
-    @vector.setter
-    def vector(self, value):
-        """ In-place setter for Stencil-/Block-/PolarVector.
+    def I(self):
+        """ Inter-/histopolation matrix ID * P * I * E^T * ID^T as ComposedLinearOperator (ID = IdentityOperator).
         """
-
-        if isinstance(self._vector, StencilVector):
-
-            assert isinstance(value, (StencilVector, np.ndarray))
-
-            s1, s2, s3 = self.starts
-            e1, e2, e3 = self.ends
-
-            self._vector[s1:e1 + 1, s2:e2 + 1, s3:e3 + 1] = \
-                value[s1:e1 + 1, s2:e2 + 1, s3:e3 + 1]
-
-        elif isinstance(self._vector, BlockVector):
-
-            assert isinstance(value, (BlockVector, list, tuple))
-
-            for n in range(3):
-
-                s1, s2, s3 = self.starts[n]
-                e1, e2, e3 = self.ends[n]
-
-                self._vector[n][s1:e1 + 1, s2:e2 + 1, s3:e3 + 1] = \
-                    value[n][s1:e1 + 1, s2:e2 + 1, s3:e3 + 1]
-
-        elif isinstance(self._vector, PolarVector):
-
-            assert isinstance(value, (PolarVector, list, tuple))
-
-            if isinstance(value, PolarVector):
-                self._vector.set_vector(value)
-            else:
-
-                if isinstance(self._vector.tp, StencilVector):
-
-                    assert isinstance(value[0], np.ndarray)
-                    assert isinstance(value[1], (StencilVector, np.ndarray))
-
-                    self._vector.pol[0][:] = value[0][:]
-
-                    s1, s2, s3 = self.starts
-                    e1, e2, e3 = self.ends
-
-                    self._vector.tp[s1:e1 + 1, s2:e2 + 1, s3:e3 + 1] = \
-                        value[1][s1:e1 + 1, s2:e2 + 1, s3:e3 + 1]
-                else:
-                    for n in range(3):
-
-                        assert isinstance(value[n][0], np.ndarray)
-                        assert isinstance(
-                            value[n][1], (StencilVector, np.ndarray))
-
-                        self._vector.pol[n][:] = value[n][0][:]
-
-                        s1, s2, s3 = self.starts[n]
-                        e1, e2, e3 = self.ends[n]
-
-                        self._vector.tp[n][s1:e1 + 1, s2:e2 + 1, s3:e3 + 1] = \
-                            value[n][1][s1:e1 + 1, s2:e2 + 1, s3:e3 + 1]
-
+        return self._I
+    
     @property
-    def starts(self):
-        """ Global indices of the first FE coefficient on the process, in each direction.
+    def I0(self):
+        """ Inter-/histopolation matrix B * P * I * E^T * B^T as ComposedLinearOperator.
         """
-        return self._gl_s
+        return self._I0
 
     @property
-    def ends(self):
-        """ Global indices of the last FE coefficient on the process, in each direction.
+    def IT(self):
+        """ Transposed inter-/histopolation matrix ID * E * I^T * P^T * ID^T as ComposedLinearOperator (ID = IdentityOperator).
         """
-        return self._gl_e
-
+        return self._IT
+    
     @property
-    def pads(self):
-        """ Paddings for ghost regions, in each direction.
+    def I0T(self):
+        """ Transposed inter-/histopolation matrix B * E * I^T * P^T * B^T as ComposedLinearOperator.
         """
-        return self._pads
-
+        return self._I0T
+    
     @property
-    def nbasis(self):
-        """ Tuple(s) of 1d dimensions for each direction.
+    def pc(self):
+        """ Preconditioner P * I^(-1) * E^T for iterative polar projections.
         """
-        return self._nbasis
-
+        return self._pc
+    
     @property
-    def vector_stencil(self):
-        """ Tensor-product Stencil-/BlockVector corresponding to a copy of self.vector in case of Stencil-/Blockvector 
-
-            OR 
-
-            the extracted coefficients in case of PolarVector. Call self.extract_coeffs() beforehand.
+    def pc0(self):
+        """ Preconditioner B * P * I^(-1) * E^T * B^T for iterative polar projections.
         """
-        return self._vector_stencil
-
-    def extract_coeffs(self, update_ghost_regions=True):
+        return self._pc0
+    
+    @property
+    def pcT(self):
+        """ Transposed preconditioner P * I^(-T) * E^T for iterative polar projections.
         """
-        Maps polar coeffs to polar tensor product rings in case of PolarVector (written in-place to self.vector_stencil) and updates ghost regions.
-
-        Parameters
-        ----------
-            update_ghost_regions : bool
-                If the ghost regions shall be updated (needed in case of non-local acccess, e.g. in field evaluation).
+        return self._pcT
+    
+    @property
+    def pc0T(self):
+        """ Transposed preconditioner B * P * I^(-T) * E^T * B^T for iterative polar projections.
         """
-        self._ET.dot(self._vector, out=self._vector_stencil)
+        return self._pc0T
 
-        if update_ghost_regions:
-            self._vector_stencil.update_ghost_regions()
-
-    def initialize_coeffs(self, init_params, domain=None):
+    def solve(self, rhs, transposed=False, apply_bc=False, tol=1e-14, maxiter=1000, verbose=False, out=None):
         """
-        Sets the initial conditions for self.vector.
-
+        Solves the linear system I * x = rhs, resp. I^T * x = rhs for x, where I is the composite inter-/histopolation matrix.
+        
         Parameters
         ----------
-        init_params : dict
-            Parameters of initial condition, see from :ref:`params_yml`.
-
-        domain : struphy.geometry.domains (optional)
-            Domain object for metric coefficients. Needed if init_params[init_params['type']]['coords'] == 'physical'.
-        """
+        rhs : psydac.linalg.basic.vector
+            The right-hand side of the linear system.
 
-        # set initial conditions for each component
-        init_type = init_params['type']
+        transposed : bool, optional
+            Whether to invert the transposed inter-/histopolation matrix.
 
-        if init_type is not None:
-            fun_params = init_params[init_type]
+        apply_bc : bool, optional
+            Whether to apply essential boundary conditions to degrees of freedom and coefficients.
 
-            # white noise in logical space for different components
-            if init_type == 'noise':
-
-                # component(s) to perturb
-                if isinstance(fun_params['comps'][self._name], bool):
-                    comps = [fun_params['comps'][self._name]]
+        tol : float, optional
+            Stop tolerance in iterative solve (only used in polar case).
+
+        maxiter : int, optional
+            Maximum number of iterations in iterative solve (only used in polar case).
+
+        verbose : bool, optional
+            Whether to print some information in each iteration in iterative solve (only used in polar case).
+            
+        out : psydac.linalg.basic.vector, optional
+            If given, the result will be written into this vector in-place.
+                
+        Returns
+        -------
+        x : psydac.linalg.basic.vector
+            Output vector (result of linear system).
+        """
+        
+        assert isinstance(rhs, Vector)
+        assert rhs.space == self._I.domain
+            
+        if transposed:
+            
+            # polar case (iterative solve with PBiConjugateGradientStab)
+            if self.is_polar:
+                if apply_bc:
+                    x, self._polar_info = self._polar_solver.solve(
+                        self.I0T, self.I0T.operators[0].dot(rhs),
+                        self.pc0T, tol=tol, maxiter=maxiter,
+                        verbose=verbose, out=out)
                 else:
-                    comps = fun_params['comps'][self._name]
-
-                # set white noise FE coefficients
-                if self.space_id in {'H1', 'L2'}:
-                    if comps[0]:
-                        self._add_noise(fun_params)
-
-                elif self.space_id in {'Hcurl', 'Hdiv', 'H1vec'}:
-                    for n, comp in enumerate(comps):
-                        if comp:
-                            self._add_noise(fun_params, n=n)
-
-            # Fourier modes
-            elif 'ModesSin' in init_type or 'ModesCos' in init_type:
-
-                # component(s) to perturb
-                if isinstance(fun_params['comps'][self._name], bool):
-                    comps = [fun_params['comps'][self._name]]
+                    x, self._polar_info = self._polar_solver.solve(
+                        self.IT, self.IT.operators[0].dot(rhs),
+                        self.pcT, tol=tol, maxiter=maxiter,
+                        verbose=verbose, out=out)
+                    
+            # standard (tensor product) case (Kronecker solver)
+            else:
+                if apply_bc:
+                    x = self.pc0T.solve(rhs, out=out)
                 else:
-                    comps = fun_params['comps'][self._name]
-
-                # coordinates: logical or physical
-                coords = fun_params['coords']
-
-                # get callable(s) for specified init type
-                fun_tmp = [None] * len(comps)
-                for n, comp in enumerate(comps):
-                    assert isinstance(comp, bool)
-                    if comp:
-                        fun_class = getattr(perturbations, init_type)
-                        fun_tmp[n] = fun_class(*list(fun_params.values())[2:])
-
-                # pullback callable
-                form_str = self.derham.forms_dict[self.space_id]
-
-                if self.space_id in {'H1', 'L2'}:
-                    fun = PulledPform(coords, fun_tmp,
-                                      domain, form_str)
-                elif self.space_id in {'Hcurl', 'Hdiv', 'H1vec'}:
-                    fun = []
-
-                    fun += [PulledPform(coords, fun_tmp, domain,
-                                        form_str + '_1')]
-                    fun += [PulledPform(coords, fun_tmp, domain,
-                                        form_str + '_2')]
-                    fun += [PulledPform(coords, fun_tmp, domain,
-                                        form_str + '_3')]
-
-                # peform projection
-                self.vector = self.derham.P[self.space_key](fun)
-
-            # loading of eigenfunction
-            elif init_type[-6:] == 'EigFun':
-
-                # select class
-                funs = getattr(eigenfunctions, init_type)(
-                    self.derham, **fun_params)
-
-                # select eigenvector and set coefficients
-                if hasattr(funs, self.name):
-
-                    eig_vec = getattr(funs, self.name)
-
-                    self.vector = eig_vec
+                    x = self.pcT.solve(rhs, out=out)
+            
+        else:
 
-            # projection of analytical function
+            # polar case (iterative solve with PBiConjugateGradientStab)
+            if self.is_polar:
+                if apply_bc:
+                    x, self._polar_info = self._polar_solver.solve(
+                        self.I0, self.I0.operators[0].dot(rhs),
+                        self.pc0, tol=tol, maxiter=maxiter,
+                        verbose=verbose, out=out)
+                else:
+                    x, self._polar_info = self._polar_solver.solve(
+                        self.I, self.I.operators[0].dot(rhs),
+                        self.pc, tol=tol, maxiter=maxiter,
+                        verbose=verbose, out=out)
+                    
+            # standard (tensor product) case (Kronecker solver)
             else:
+                if apply_bc:
+                    x = self.pc0.solve(rhs, out=out)
+                else:
+                    x = self.pc.solve(rhs, out=out)
 
-                # select class
-                funs = getattr(analytic, init_type)(fun_params, domain)
-
-                # select function and project project
-                if hasattr(funs, self.name):
-                    self.vector = self.derham.P[self.space_key](
-                        getattr(funs, self.name))
-
-        # apply boundary operator (in-place)
-        self.derham.B[self.space_key].dot(
-            self._vector.copy(), out=self._vector)
-
-        # update ghost regions
-        self._vector.update_ghost_regions()
+        return x
 
-    def initialize_coeffs_from_restart_file(self, file, species=None):
+    def get_dofs(self, fun, apply_bc=False):
         """
-        TODO
+        Computes the geometric degrees of freedom associated to given callable(s).
+        
+        Parameters
+        ----------
+        fun : callable | list
+            The function for which the geometric degrees of freedom shall be computed. List of callables for vector-valued functions.
+
+        apply_bc : bool, optional
+            Whether to apply essential boundary conditions to degrees of freedom.
+                
+        Returns
+        -------
+        dofs : psydac.linalg.basic.vector
+            The geometric degrees of freedom associated to given callable(s) "fun".
         """
 
-        if species is None:
-            key = 'restart/' + self.name
-        else:
-            key = 'restart/' + species + '_' + self.name
+        # get dofs on tensor-product grid + apply polar DOF extraction operator
+        dofs = self.dofs_extraction_op.dot(self.projector_tensor(fun, dofs_only=True))
 
-        if isinstance(self.vector, StencilVector):
-            self.vector._data[:] = file[key][-1]
-        else:
-            for n in range(3):
-                self.vector[n]._data[:] = file[key + '/' + str(n + 1)][-1]
+        # apply boundary operator
+        if apply_bc:
+            dofs = self.boundary_op.dot(dofs)
 
-        self._vector.update_ghost_regions()
+        return dofs
 
-    def __call__(self, eta1, eta2, eta3, squeeze_output=False, local=False):
+    def __call__(self, fun, apply_bc=False, tol=1e-14, maxiter=1000, verbose=False):
         """
-        Evaluates the spline function on the global domain, unless local is given to True (in which case the spline function is evaluated only on the local domain).
-
+        Applies projector to given callable(s).
+        
         Parameters
         ----------
-            eta1, eta2, eta3 : array-like
-                Logical coordinates at which to evaluate.
+        fun : callable | list
+            The function to be projected. List of three callables for vector-valued functions.
 
-            flat_eval : bool
-                Whether to do a flat evaluation, i.e. f([e11, e12], [e21, e22]) = [f(e11, e21), f(e12, e22)].
+        apply_bc : bool, optional
+            Whether to apply essential boundary conditions to degrees of freedom and coefficients.
 
-            squeeze_output : bool
-                Whether to remove singleton dimensions in output "values".
+        tol : float, optional
+            Stop tolerance in iterative solve (only used in polar case).
 
+        maxiter : int, optional
+            Maximum number of iterations in iterative solve (only used in polar case).
+
+        verbose : bool, optional
+            Whether to print some information in each iteration in iterative solve (only used in polar case).
+                
         Returns
         -------
-            values : array[float] or list
-                The values of the spline function at the given point set (list in case of vector-valued spaces).
+        coeffs : psydac.linalg.basic.vector
+            The FEM spline coefficients after projection.
         """
+        return self.solve(self.get_dofs(fun, apply_bc), transposed=False,
+                          apply_bc=apply_bc, tol=tol,
+                          maxiter=maxiter, verbose=verbose)
+    
+    
+def evaluate_fun_weights_1d(pts, wts, fun):
+    """
+    Pre-evaluates the given function at the quadrature points,
+    and multiplies the result with the quadrature weights of this point.
+    Quadrature weights and coordinates are given in a tensor-product format.
 
-        # all eval points
-        E1, E2, E3, is_sparse_meshgrid = Domain.prepare_eval_pts(
-            eta1, eta2, eta3)
-
-        # check if eval points are "interior points" in domain_array; if so, add small offset
-        dom_arr = self.derham.domain_array
-        if self.derham.comm is not None:
-            rank = self.derham.comm.Get_rank()
-        else:
-            rank = 0
+    This version of the function loops over all elements and is fixed to dimension 1.
 
-        if dom_arr[rank, 0] != 0.:
-            E1[E1 == dom_arr[rank, 0]] += 1e-8
-        if dom_arr[rank, 1] != 1.:
-            E1[E1 == dom_arr[rank, 1]] += 1e-8
-
-        if dom_arr[rank, 3] != 0.:
-            E2[E2 == dom_arr[rank, 3]] += 1e-8
-        if dom_arr[rank, 4] != 1.:
-            E2[E2 == dom_arr[rank, 4]] += 1e-8
-
-        if dom_arr[rank, 6] != 0.:
-            E3[E3 == dom_arr[rank, 6]] += 1e-8
-        if dom_arr[rank, 7] != 1.:
-            E3[E3 == dom_arr[rank, 7]] += 1e-8
-
-        # True for eval points on current process
-        E1_on_proc = np.logical_and(
-            E1 >= dom_arr[rank, 0], E1 <= dom_arr[rank, 1])
-        E2_on_proc = np.logical_and(
-            E2 >= dom_arr[rank, 3], E2 <= dom_arr[rank, 4])
-        E3_on_proc = np.logical_and(
-            E3 >= dom_arr[rank, 6], E3 <= dom_arr[rank, 7])
-
-        # flag eval points not on current process
-        E1[~E1_on_proc] = -1.
-        E2[~E2_on_proc] = -1.
-        E3[~E3_on_proc] = -1.
-
-        # prepare arrays for AllReduce
-        tmp = np.zeros((E1.shape[0], E2.shape[1], E3.shape[2]), dtype=float)
-
-        # extract coefficients and update ghost regions
-        self.extract_coeffs(update_ghost_regions=True)
-
-        # call pyccel kernels
-        T1, T2, T3 = self.derham.Vh_fem['0'].knots
-
-        if isinstance(self._vector_stencil, StencilVector):
-
-            kind = self.derham.spline_types_pyccel[self.space_key]
-
-            if is_sparse_meshgrid:
-                # eval_mpi needs flagged arrays E1, E2, E3 as input
-                eval_3d.eval_spline_mpi_sparse_meshgrid(E1, E2, E3, self._vector_stencil._data, kind,
-                                                        np.array(self.derham.p), T1, T2, T3, np.array(self.starts), tmp)
-            else:
-                # eval_mpi needs flagged arrays E1, E2, E3 as input
-                eval_3d.eval_spline_mpi_matrix(E1, E2, E3, self._vector_stencil._data, kind,
-                                               np.array(self.derham.p), T1, T2, T3, np.array(self.starts), tmp)
-
-            if self.derham.comm is not None:
-                if local == False :
-                    self.derham.comm.Allreduce(MPI.IN_PLACE, tmp, op=MPI.SUM)
-
-            # all processes have all values
-            values = tmp
+    Parameters
+    ----------
+    pts : 1-tuple of 2d float arrays
+        Quadrature points in each dimension in format (element, quadrature point).
 
-            if squeeze_output:
-                values = np.squeeze(values)
+    wts : 1-tuple of 2d float arrays
+        Quadrature weights in each dimension in format (element, quadrature point).
 
-            if values.ndim == 0:
-                values = values.item()
+    fun : callable
+        The function which shall be evaluated at eta1.
+    
+    Returns
+    -------
+    values : ndarray[float]
+        A 2d array (1 cell grid dimension, 1 quadrature point dimension) which contains all the pre-evaluated values.
+    """
 
-        else:
+    # will not be pyccelized, due to dependence on func (or could we call back to Python?)
+    values = np.zeros((pts[0].shape[0], pts[0].shape[1]), dtype=float)
+                      
+    for i in range(pts[0].shape[0]): # element index
+        for iq in range(pts[0].shape[1]): # quadrature point index
+            values[i, iq] = fun(pts[0][i, iq]) *  wts[0][i, iq]
+            
+    return values
 
-            values = []
-            for n, kind in enumerate(self.derham.spline_types_pyccel[self.space_key]):
 
-                if is_sparse_meshgrid:
-                    eval_3d.eval_spline_mpi_sparse_meshgrid(E1, E2, E3, self._vector_stencil[n]._data, kind,
-                                                            np.array(self.derham.p), T1, T2, T3, np.array(self.starts[n]), tmp)
-                else:
-                    eval_3d.eval_spline_mpi_matrix(E1, E2, E3, self._vector_stencil[n]._data, kind,
-                                                   np.array(self.derham.p), T1, T2, T3, np.array(self.starts[n]), tmp)
+def evaluate_fun_weights_2d(pts, wts, fun):
+    """
+    Pre-evaluates the given function at the quadrature points,
+    and multiplies the result with the quadrature weights of this point.
+    Quadrature weights and coordinates are given in a tensor-product format.
 
-                if self.derham.comm is not None:
-                    if local == False:
-                        self.derham.comm.Allreduce(MPI.IN_PLACE, tmp, op=MPI.SUM)
+    This version of the function loops over all elements and is fixed to dimension 2.
 
-                # all processes have all values
-                values += [tmp.copy()]
-                tmp[:] = 0.
+    Parameters
+    ----------
+    pts : 2-tuple of 2d float arrays
+        Quadrature points in each dimension in format (element, quadrature point).
 
-                if squeeze_output:
-                    values[-1] = np.squeeze(values[-1])
+    wts : 2-tuple of 2d float arrays
+        Quadrature weights in each dimension in format (element, quadrature point).
 
-                if values[-1].ndim == 0:
-                    values[-1] = values[-1].item()
+    fun : callable
+        The function which shall be evaluated at eta1, eta2.
+    
+    Returns
+    -------
+    values : ndarray[float]
+        A 4d array (2 cell grid dimensions, 2 quadrature point dimensions) which contains all the pre-evaluated values.
+    """
 
-        return values
+    # will not be pyccelized, due to dependence on func (or could we call back to Python?)
+    values = np.zeros((pts[0].shape[0], pts[1].shape[0], 
+                       pts[0].shape[1], pts[1].shape[1]), dtype=float)
+    
+    for i in range(pts[0].shape[0]): # element index
+        for j in range(pts[1].shape[0]):
+            for iq in range(pts[0].shape[1]): # quadrature point index
+                for jq in range(pts[1].shape[1]):
+                        funval = fun(pts[0][i, iq], pts[1][j, jq])
+                        weightval = wts[0][i, iq] * wts[1][j, jq]
+                        values[i, j, iq, jq] = weightval * funval
+                            
+    return values
 
-    def _add_noise(self, fun_params, n=None):
-        """ Add noise to a vector component where init_comps==True, otherwise leave at zero.
 
-        Parameters
-        ----------
-            fun_params : dict
-                From parameters/fields/init/noise.
-        """
-
-        _direction = fun_params['variation_in']
-        _ampsize = fun_params['amp']
+def evaluate_fun_weights_3d(pts, wts, fun):
+    """
+    Pre-evaluates the given function at the quadrature points,
+    and multiplies the result with the quadrature weights of this point.
+    Quadrature weights and coordinates are given in a tensor-product format.
 
-        if n == None:
-            _shape_w_pads = self._vector[:].shape
-            _shape = (self._gl_e[0] + 1 - self._gl_s[0], self._gl_e
-                      [1] + 1 - self._gl_s[1], self._gl_e[2] + 1 - self._gl_s[2])
-        else:
-            _shape_w_pads = self._vector[n][:].shape
-            _shape = (self._gl_e[n][0] + 1 - self._gl_s[n][0], self._gl_e[n]
-                      [1] + 1 - self._gl_s[n][1], self._gl_e[n][2] + 1 - self._gl_s[n][2])
-
-        if _direction == 'e1':
-            _amps = (np.random.rand(_shape_w_pads[0]) - .5) * 2. * _ampsize
-            for j in range(_shape[1]):
-                for k in range(_shape[2]):
-                    if n == None:
-                        self._vector[:, self._gl_s[1] +
-                                     j, self._gl_s[2] + k] = _amps
-                    else:
-                        self._vector[n][:, self._gl_s[n][1] +
-                                        j, self._gl_s[n][2] + k] = _amps
-
-        elif _direction == 'e2':
-            _amps = (np.random.rand(_shape_w_pads[1]) - .5) * 2. * _ampsize
-            for j in range(_shape[0]):
-                for k in range(_shape[2]):
-                    if n == None:
-                        self._vector[self._gl_s[0] + j,
-                                     :, self._gl_s[2] + k] = _amps
-                    else:
-                        self._vector[n][self._gl_s[n][0] + j,
-                                        :, self._gl_s[n][2] + k] = _amps
-
-        elif _direction == 'e3':
-            _amps = (np.random.rand(_shape_w_pads[2]) - .5) * 2. * _ampsize
-            for j in range(_shape[0]):
-                for k in range(_shape[1]):
-                    if n == None:
-                        self._vector[self._gl_s[0] + j,
-                                     self._gl_s[1] + k, :] = _amps
-                    else:
-                        self._vector[n][self._gl_s[n][0] + j,
-                                        self._gl_s[n][1] + k, :] = _amps
-
-        elif _direction == 'e1e2':
-            _amps = (np.random.rand(
-                _shape_w_pads[0], _shape_w_pads[1]) - .5) * 2. * _ampsize
-            for j in range(_shape[2]):
-                if n == None:
-                    self._vector[:, :, self._gl_s[2] + j] = _amps
-                else:
-                    self._vector[n][:, :, self._gl_s[n][2] + j] = _amps
+    This version of the function loops over all elements and is fixed to dimension 3.
 
-        elif _direction == 'e1e3':
-            _amps = (np.random.rand(
-                _shape_w_pads[0], _shape_w_pads[2]) - .5) * 2. * _ampsize
-            for j in range(_shape[1]):
-                if n == None:
-                    self._vector[:, self._gl_s[1] + j, :] = _amps
-                else:
-                    self._vector[n][:, self._gl_s[n][1] + j, :] = _amps
+    Parameters
+    ----------
+    pts : 3-tuple of 2d float arrays
+        Quadrature points in each dimension in format (element, quadrature point).
 
-        elif _direction == 'e2e3':
-            _amps = (np.random.rand(
-                _shape_w_pads[1], _shape_w_pads[2]) - .5) * 2. * _ampsize
-            for j in range(_shape[0]):
-                if n == None:
-                    self._vector[self._gl_s[0] + j, :, :] = _amps
-                else:
-                    self._vector[n][self._gl_s[n][0] + j, :, :] = _amps
+    wts : 3-tuple of 2d float arrays
+        Quadrature weights in each dimension in format (element, quadrature point).
 
-        elif _direction == 'e1e2e3':
-            _amps = (np.random.rand(
-                _shape_w_pads[0], _shape_w_pads[1], _shape_w_pads[2]) - .5) * 2. * _ampsize
-            if n == None:
-                self._vector[:, :, :] = _amps
-            else:
-                self._vector[n][:, :, :] = _amps
+    fun : callable
+        The function which shall be evaluated at eta1, eta2, eta3.
+    
+    Returns
+    -------
+    values : ndarray[float]
+        A 6d array (3 cell grid dimensions, 3 quadrature point dimensions) which contains all the pre-evaluated values.
+    """
 
-        else:
-            raise ValueError('Invalid direction for noise.')
+    # will not be pyccelized, due to dependence on func (or could we call back to Python?)
+    values = np.zeros((pts[0].shape[0], pts[1].shape[0], pts[2].shape[0], 
+                       pts[0].shape[1], pts[1].shape[1], pts[2].shape[1]), dtype=float)
+    
+    for i in range(pts[0].shape[0]): # element index
+        for j in range(pts[1].shape[0]):
+            for k in range(pts[2].shape[0]):
+                for iq in range(pts[0].shape[1]): # quadrature point index
+                    for jq in range(pts[1].shape[1]):
+                        for kq in range(pts[2].shape[1]):
+                            funval = fun(pts[0][i, iq], pts[1][j, jq], pts[2][k, kq])
+                            weightval = wts[0][i, iq] * wts[1][j, jq] * wts[2][k, kq]
+                            values[i, j, k, iq, jq, kq] = weightval * funval
+                            
+    return values
 
 
-class PulledPform:
+def assemble_funccache_numpy(u, w, func):
     """
-    Construct callable (component of) p-form on logical domain (unit cube).
+    Pre-evaluates the given function at the quadrature points,
+    and multiplies the result with the quadrature weights of this point.
+    Quadrature weights and coordinates are given in a tensor-product format.
 
-    Depending on the dimension of eta1 either point-wise, tensor-product, slice plane or general (see :ref:`struphy.geometry.map_eval.prepare_args`).
+    This version tries to use numpy where possible, and is usable in arbitrary dimensions.
 
     Parameters
     ----------
-        coords : str
-            From which coordinate representation to pull, either 'logical' or 'physical'.
+    u : three-tuple of two-dimensional numpy arrays
+        The quadrature points in each dimension.
 
-        fun : list
-            Callable function components. Has to be length 3 for 1- and 2-forms, length 1 otherwise.
-
-        domain: struphy.geometry.domains
-            All things mapping.
-
-        form : str
-            Which form to pull: '0_form', '1_form_1', '1_form_2', '1_form_3', '2_form_1', '2_form_2', '2_form_3', '3_form'.
+    w : three-tuple of two-dimensional numpy arrays
+        The quadrature weights in each dimension for the respective points.
 
+    func : callable, with three parameters
+        The function which shall be evaluated.
+    
     Returns
     -------
-        f : array[float]
-            Array holding the values.
+    values : ndarray[float]
+        A 6d array (3 cell grid dimensions, 3 quadrature point dimensions) which contains all the pre-evaluated values.
     """
 
-    def __init__(self, coords, fun, domain, form):
+    import numpy as np
 
-        assert len(fun) == 1 or len(fun) == 3
-
-        self._fun = []
-        for f in fun:
-            if f is None:
-                def f_zero(x, y, z): return 0*x
-                self._fun += [f_zero]
-            else:
-                assert callable(f)
-                self._fun += [f]
-
-        self._coords = coords
-        self._domain = domain
-        self._form = form
-
-        # define which component of the field is evaluated (=0 for scalar fields)
-        if len(self._fun) == 1:
-            self._comp = 0
-        else:
-            self._comp = int(self._form[-1]) - 1
-
-        assert isinstance(self._fun, list)
-
-    def __call__(self, eta1, eta2, eta3):
-        """ Evaluate the component of the p-form specified in self._form.
-        """
-
-        if self._coords == 'logical':
-            f = self._fun[self._comp](eta1, eta2, eta3)
-        elif self._coords == 'physical':
-            if self._form[0] == '0' or self._form[0] == '3':
-                f = self._domain.pull(
-                    self._fun, eta1, eta2, eta3, kind=self._form)
-            else:
-                f = self._domain.pull(
-                    self._fun, eta1, eta2, eta3, kind=self._form[:-2])[self._comp]
-        else:
-            raise ValueError(
-                'Coordinates to be used for p-form pullback not properly specified.')
+    funcvec = np.vectorize(func)
+    grid = np.meshgrid(*u, sparse=True, indexing='ij')
+    funceval = funcvec(*grid)
+
+    for wg in np.meshgrid(*w, sparse=True, indexing='ij'):
+        funceval *= wg
+    
+    funceval.shape = tuple(uxx for ux in u for uxx in ux.shape)
 
-        return f
+    n = len(u)
+    return funceval.transpose([2*i for i in range(n)] + [2*i+1 for i in range(n)])
```

### Comparing `struphy-2.0.1/src/struphy/psydac_api/linear_operators.py` & `struphy-2.0.2/src/struphy/psydac_api/linear_operators.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/psydac_api/mass.py` & `struphy-2.0.2/src/struphy/psydac_api/mass.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import numpy as np
 
 from psydac.linalg.stencil import StencilVector, StencilMatrix
 from psydac.linalg.block import BlockVector, BlockLinearOperator
 from psydac.linalg.basic import Vector
 
 from psydac.fem.tensor import TensorFemSpace
-from psydac.fem.vector import ProductFemSpace
+from psydac.fem.vector import VectorFemSpace
 
 from psydac.api.settings import PSYDAC_BACKEND_GPYCCEL
 
 from struphy.psydac_api import mass_kernels
 from struphy.psydac_api.utilities import RotationMatrix
 from struphy.psydac_api.linear_operators import LinOpWithTransp, BoundaryOperator, IdentityOperator
 from struphy.psydac_api.linear_operators import CompositeLinearOperator as Compose
@@ -533,15 +533,15 @@
         Here, :math:`\alpha \in \{0, 1, 2, 3, v\}` indicates the domain and :math:`\beta \in \{0, 1, 2, 3, v\}` indicates the co-domain 
         of the operator.
 
         Parameters
         ----------
         fun : list[list[callable | ndarray]]
             2d list of either all 3d arrays or all scalar functions of eta1, eta2, eta3 (must allow matrix evaluations). 
-            3d arrays must have shape corresponding to the 1d quad_grids of V1-ProductFemSpace.
+            3d arrays must have shape corresponding to the 1d quad_grids of V1-VectorFemSpace.
 
         V_id : str
             Specifier for the domain of the operator ('H1', 'Hcurl', 'Hdiv', 'L2' or 'H1vec').
 
         W_id : str
             Specifier for the co-domain of the operator ('H1', 'Hcurl', 'Hdiv', 'L2' or 'H1vec').
         
@@ -582,18 +582,18 @@
 
 class WeightedMassOperator(LinOpWithTransp):
     """
     Weighted mass matrix of the form B * E * M * E^T * B^T, with E and B being basis extraction and boundary operators, respectively.
 
     Parameters
     ----------
-    V : TensorFemSpace | ProductFemSpace
+    V : TensorFemSpace | VectorFemSpace
         Tensor product spline space from psydac.fem.tensor (domain, input space).
 
-    W : TensorFemSpace | ProductFemSpace
+    W : TensorFemSpace | VectorFemSpace
         Tensor product spline space from psydac.fem.tensor (codomain, output space).
 
     V_extraction_op : PolarExtractionOperator | IdentityOperator
         Extraction operator to polar sub-space of V.
 
     W_extraction_op : PolarExtractionOperator | IdentityOperator
         Extraction operator to polar sub-space of W.
@@ -618,16 +618,16 @@
     """
 
     def __init__(self, V, W, V_extraction_op=None, W_extraction_op=None, V_boundary_op=None, W_boundary_op=None, weights_info=None, transposed=False):
 
         # only for M1 Mac users
         PSYDAC_BACKEND_GPYCCEL['flags'] = '-O3 -march=native -mtune=native -ffast-math -ffree-line-length-none'
 
-        assert isinstance(V, (TensorFemSpace, ProductFemSpace))
-        assert isinstance(W, (TensorFemSpace, ProductFemSpace))
+        assert isinstance(V, (TensorFemSpace, VectorFemSpace))
+        assert isinstance(W, (TensorFemSpace, VectorFemSpace))
 
         self._V = V
         self._W = W
 
         # set basis extraction operators
         if V_extraction_op is not None:
             assert isinstance(
@@ -777,16 +777,16 @@
                         if weights_info[a][b] is None:
                             blocks[-1] += [None]
                             self._weights[-1] += [None]
 
                         else:
 
                             # test weight function at quadrature points to identify zero blocks
-                            pts = [quad_grid.points.flatten()
-                                   for quad_grid in wspace.quad_grids]
+                            pts = [quad_grid[nquad].points.flatten()
+                                   for quad_grid, nquad in zip(wspace._quad_grids, wspace.nquads)]
 
                             if callable(weights_info[a][b]):
                                 PTS = np.meshgrid(*pts, indexing='ij')
                                 mat_w = weights_info[a][b](*PTS).copy()
                             elif isinstance(weights_info[a][b], np.ndarray):
                                 mat_w = weights_info[a][b]
 
@@ -1077,31 +1077,31 @@
             self._weights = weights
 
         # loop over codomain spaces (rows)
         for a, codomain_space in enumerate(codomain_spaces):
 
             # knot span indices of elements of local domain
             codomain_spans = [
-                quad_grid.spans for quad_grid in codomain_space.quad_grids]
+                quad_grid[nquad].spans for quad_grid, nquad in zip(codomain_space._quad_grids, codomain_space.nquads)]
 
             # global start spline index on process
             codomain_starts = [int(start)
                                for start in codomain_space.vector_space.starts]
 
             # pads (ghost regions)
             codomain_pads = codomain_space.vector_space.pads
 
             # global quadrature points (flattened) and weights in format (local element, local weight)
-            pts = [quad_grid.points.flatten()
-                   for quad_grid in codomain_space.quad_grids]
-            wts = [quad_grid.weights for quad_grid in codomain_space.quad_grids]
+            pts = [quad_grid[nquad].points.flatten()
+                   for quad_grid, nquad in zip(codomain_space._quad_grids, codomain_space.nquads)]
+            wts = [quad_grid[nquad].weights for quad_grid, nquad in zip(codomain_space._quad_grids, codomain_space.nquads)]
 
             # evaluated basis functions at quadrature points of codomain space
             codomain_basis = [
-                quad_grid.basis for quad_grid in codomain_space.quad_grids]
+                quad_grid[nquad].basis for quad_grid, nquad in zip(codomain_space._quad_grids, codomain_space.nquads)]
 
             # loop over domain spaces (columns)
             for b, domain_space in enumerate(domain_spaces):
 
                 # skip None and redundant blocks (lower half for symmetric and anti-symmetric)
                 if isinstance(self._mat, BlockLinearOperator):
                     if self._mat[a, b] is None:
@@ -1120,15 +1120,15 @@
                 elif isinstance(self._weights[a][b], np.ndarray):
                     mat_w = self._weights[a][b]
 
                 assert mat_w.shape == tuple([pt.size for pt in pts])
 
                 # evaluated basis functions at quadrature points of domain space
                 domain_basis = [
-                    quad_grid.basis for quad_grid in domain_space.quad_grids]
+                    quad_grid[nquad].basis for quad_grid, nquad in zip(domain_space._quad_grids, domain_space.nquads)]
 
                 # assemble matrix (if mat_w is not zero) by calling the appropriate kernel (1d, 2d or 3d)
                 if np.any(np.abs(mat_w) > 1e-14):
                     if isinstance(self._mat, StencilMatrix):
                         self._assembly_kernel(*codomain_spans, *codomain_space.degree, *domain_space.degree, *
                                               codomain_starts, *codomain_pads, *wts, *codomain_basis, *domain_basis, mat_w, self._mat._data)
                     else:
@@ -1164,28 +1164,28 @@
         Assembles (in 3d) vec_ijk = integral[ weight * Lambda_ijk ] into the Stencil-/BlockVector vec,
         where Lambda_ijk are the basis functions of the spline space and weight is some weight function.
 
         The integration is performed with Gauss-Legendre quadrature over the whole logical domain.
 
         Parameters
         ----------
-        W : TensorFemSpace | ProductFemSpace
+        W : TensorFemSpace | VectorFemSpace
             Tensor product spline space from psydac.fem.tensor.
 
         vec : StencilVector | BlockVector
             The vector to be filled.
 
         weight : list | NoneType
             Weight function(s) (callables or np.ndarrays) in a 1d list of shape corresponding to number of components.
 
         clear : bool
             Whether to first set all data to zero before assembly. If False, the new contributions are added to existing ones in vec.
         """
 
-        assert isinstance(W, (TensorFemSpace, ProductFemSpace))
+        assert isinstance(W, (TensorFemSpace, VectorFemSpace))
         assert isinstance(vec, (StencilVector, BlockVector))
         assert W.vector_space == vec.space
 
         # collect TensorFemSpaces for each component in tuple
         if isinstance(W, TensorFemSpace):
             Wspaces = (W,)
         else:
@@ -1202,29 +1202,29 @@
                 for block in vec.blocks:
                     block._data[:] = 0.
 
         # loop over components
         for a, wspace in enumerate(Wspaces):
 
             # knot span indices of elements of local domain
-            spans = [quad_grid.spans for quad_grid in wspace.quad_grids]
+            spans = [quad_grid[nquad].spans for quad_grid, nquad in zip(wspace._quad_grids, wspace.nquads)]
 
             # global start spline index on process
             starts = [int(start) for start in wspace.vector_space.starts]
 
             # pads (ghost regions)
             pads = wspace.vector_space.pads
 
             # global quadrature points (flattened) and weights in format (local element, local weight)
-            pts = [quad_grid.points.flatten()
-                   for quad_grid in wspace.quad_grids]
-            wts = [quad_grid.weights for quad_grid in wspace.quad_grids]
+            pts = [quad_grid[nquad].points.flatten()
+                   for quad_grid, nquad in zip(wspace._quad_grids, wspace.nquads)]
+            wts = [quad_grid[nquad].weights for quad_grid, nquad in zip(wspace._quad_grids, wspace.nquads)]
 
             # evaluated basis functions at quadrature points of codomain space
-            basis = [quad_grid.basis for quad_grid in wspace.quad_grids]
+            basis = [quad_grid[nquad].basis for quad_grid, nquad in zip(wspace._quad_grids, wspace.nquads)]
 
             if weight is not None:
                 if weight[a] is not None:
 
                     if callable(weight[a]):
                         PTS = np.meshgrid(*pts, indexing='ij')
                         mat_w = weight[a](*PTS).copy()
@@ -1254,47 +1254,47 @@
     @staticmethod
     def eval_quad(W, coeffs, out=None):
         """
         Evaluates a given FEM field defined by its coefficients at the L2 quadrature points.
 
         Parameters
         ----------
-        W : TensorFemSpace | ProductFemSpace
+        W : TensorFemSpace | VectorFemSpace
             Tensor product spline space from psydac.fem.tensor.
 
         coeffs : StencilVector | BlockVector
             The coefficient vector corresponding to the FEM field. Ghost regions must be up-to-date!
 
         out : np.ndarray | list/tuple of np.ndarrays, optional
             If given, the result will be written into these arrays in-place. Number of outs must be compatible with number of components of FEM field.
 
         Returns
         -------
         out : np.ndarray | list/tuple of np.ndarrays
             The values of the FEM field at the quadrature points.
         """
 
-        assert isinstance(W, (TensorFemSpace, ProductFemSpace))
+        assert isinstance(W, (TensorFemSpace, VectorFemSpace))
         assert isinstance(coeffs, (StencilVector, BlockVector))
         assert W.vector_space == coeffs.space
 
         # collect TensorFemSpaces for each component in tuple
         if isinstance(W, TensorFemSpace):
             Wspaces = (W,)
         else:
             Wspaces = W.spaces
 
         # prepare output
         if out is None:
             out = ()
             if isinstance(W, TensorFemSpace):
-                out += (np.zeros([q_grid.points.size for q_grid in W.quad_grids], dtype=float),)
+                out += (np.zeros([q_grid[nquad].points.size for q_grid, nquad in zip(W._quad_grids, W.nquads)], dtype=float),)
             else:
                 for space in W.spaces:
-                    out += (np.zeros([q_grid.points.size for q_grid in space.quad_grids], dtype=float),)
+                    out += (np.zeros([q_grid[nquad].points.size for q_grid, nquad in zip(space._quad_grids, space.nquad)], dtype=float),)
 
         else:
             if isinstance(W, TensorFemSpace):
                 assert isinstance(out, np.ndarray)
                 out = (out,)
             else:
                 assert isinstance(out, (list, tuple))
@@ -1302,29 +1302,29 @@
         # load assembly kernel
         kernel = getattr(mass_kernels, 'kernel_' + str(W.ldim) + 'd_eval')
 
         # loop over components
         for a, wspace in enumerate(Wspaces):
 
             # knot span indices of elements of local domain
-            spans = [quad_grid.spans for quad_grid in wspace.quad_grids]
+            spans = [quad_grid[nquad].spans for quad_grid, nquad in zip(wspace._quad_grids, wspace.nquads)]
 
             # global start spline index on process
             starts = [int(start) for start in wspace.vector_space.starts]
 
             # pads (ghost regions)
             pads = wspace.vector_space.pads
 
             # global quadrature points (flattened) and weights in format (local element, local weight)
-            pts = [quad_grid.points.flatten()
-                   for quad_grid in wspace.quad_grids]
-            wts = [quad_grid.weights for quad_grid in wspace.quad_grids]
+            pts = [quad_grid[nquad].points.flatten()
+                   for quad_grid, nquad in zip(wspace._quad_grids, wspace.nquads)]
+            wts = [quad_grid[nquad].weights for quad_grid, nquad in zip(wspace._quad_grids, wspace.nquads)]
 
             # evaluated basis functions at quadrature points of codomain space
-            basis = [quad_grid.basis for quad_grid in wspace.quad_grids]
+            basis = [quad_grid[nquad].basis for quad_grid, nquad in zip(wspace._quad_grids, wspace.nquads)]
 
             if isinstance(coeffs, StencilVector):
                 kernel(*spans, *wspace.degree, *starts, *
                        pads, *basis, coeffs._data, out[a])
             else:
                 kernel(*spans, *wspace.degree, *starts, *
                        pads, *basis, coeffs[a]._data, out[a])
```

### Comparing `struphy-2.0.1/src/struphy/psydac_api/mass_kernels.py` & `struphy-2.0.2/src/struphy/psydac_api/mass_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/psydac_api/preconditioner.py` & `struphy-2.0.2/src/struphy/psydac_api/preconditioner.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 from psydac.linalg.basic import Vector, LinearSolver
 from psydac.linalg.direct_solvers import DirectSolver, SparseSolver
 from psydac.linalg.stencil import StencilMatrix, StencilVector, StencilVectorSpace
 from psydac.linalg.block import BlockLinearOperator, BlockDiagonalSolver
 from psydac.linalg.kron import KroneckerLinearSolver, KroneckerStencilMatrix
 
 from psydac.fem.tensor import TensorFemSpace
-from psydac.fem.vector import ProductFemSpace
 
 from psydac.ddm.cart import DomainDecomposition, CartDecomposition
 from psydac.api.essential_bc import apply_essential_bc_stencil
 
 from struphy.psydac_api.linear_operators import CompositeLinearOperator, BoundaryOperator, IdentityOperator
 from struphy.psydac_api.mass import WeightedMassOperator
 
@@ -77,21 +76,21 @@
                     fun = [[lambda e1: mass_operator.weights[c][c](
                         e1, np.array([.5]), np.array([.5])).squeeze()]]
                 else:
                     fun = [[lambda e: np.ones(e.size, dtype=float)]]
 
                 # get 1D FEM space (serial, not distributed) and quadrature order
                 femspace_1d = femspaces[c].spaces[d]
-                qu_order_1d = femspaces[c].quad_order[d]
+                qu_order_1d = femspaces[c].nquads[d]
 
                 # assemble 1d weighted mass matrix
                 domain_decompos_1d = DomainDecomposition(
                     [femspace_1d.ncells], [femspace_1d.periodic])
                 femspace_1d_tensor = TensorFemSpace(
-                    domain_decompos_1d, femspace_1d, quad_order=[qu_order_1d])
+                    domain_decompos_1d, femspace_1d, nquads=[qu_order_1d])
 
                 M = WeightedMassOperator(
                     femspace_1d_tensor, femspace_1d_tensor, weights_info=fun)
                 M.assemble(verbose=False)
                 M = M.matrix
 
                 # apply boundary conditions
```

### Comparing `struphy-2.0.1/src/struphy/psydac_api/psydac_derham.py` & `struphy-2.0.2/src/struphy/psydac_api/psydac_derham.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,15 @@
 #!/usr/bin/env python3
 
 from sympde.topology import Cube
 from sympde.topology import Derham as Derham_psy
 
 from psydac.api.discretization import discretize
-from psydac.fem.vector import ProductFemSpace
+from psydac.fem.vector import VectorFemSpace
 from psydac.feec.global_projectors import Projector_H1vec
-from psydac.ddm.cart import DomainDecomposition, CartDecomposition
 
 from struphy.psydac_api.linear_operators import BoundaryOperator, CompositeLinearOperator, IdentityOperator
 from struphy.psydac_api.projectors import Projector
 
 from struphy.polar.basic import PolarDerhamSpace
 from struphy.polar.extraction_operators import PolarExtractionBlocksC1
 from struphy.polar.linear_operators import PolarExtractionOperator, PolarLinearOperator
@@ -122,15 +121,15 @@
             ncells=Nel,
             comm=self._comm,
             periodic=self.spl_kind,
             mpi_dims_mask=mpi_dims_mask)
 
         # Psydac discrete de Rham, projectors and derivatives
         _derham = discretize(self._derham_symb, self._domain_log_h,
-                             degree=self.p, quad_order=self.quad_order)
+                             degree=self.p, nquads=self.quad_order)
 
         self._grad, self._curl, self._div = _derham.derivatives_as_matrices
 
         _projectors = _derham.projectors(nquads=self._nq_pr)
 
         # keys for continuous spaces
         self._V = {'0': 'H1',
@@ -155,15 +154,15 @@
         self._Vh = {}
         self._Vh_fem = {}
         self._P = {}
 
         for i, key in enumerate(self._V.keys()):
 
             if key == 'v':
-                self._Vh_fem[key] = ProductFemSpace(
+                self._Vh_fem[key] = VectorFemSpace(
                     _derham.V0, _derham.V0, _derham.V0)
                 self._P[key] = Projector_H1vec(self._Vh_fem[key])
             else:
                 self._Vh_fem[key] = getattr(_derham, 'V' + str(i))
                 self._P[key] = _projectors[i]
 
             self._Vh[key] = self._Vh_fem[key].vector_space
@@ -418,15 +417,15 @@
     def Vh(self):
         """ Dictionary containing finite-dimensional vector spaces (sub-spaces of continuous spaces, Stencil-/BlockVectorSpace).
         """
         return self._Vh
 
     @property
     def Vh_fem(self):
-        """ Dictionary containing FEM spline spaces (TensorFem-/ProductFemSpace).
+        """ Dictionary containing FEM spline spaces (TensorFem-/VectorFemSpace).
         """
         return self._Vh_fem
 
     @property
     def nbasis(self):
         """ Dictionary containing number of 1d basis functions for each component and spatial direction.
         """
```

### Comparing `struphy-2.0.1/src/struphy/psydac_api/quadrature_evaluation_kernels.py` & `struphy-2.0.2/src/struphy/psydac_api/quadrature_evaluation_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/psydac_api/utilities.py` & `struphy-2.0.2/src/struphy/psydac_api/utilities.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from psydac.linalg.stencil import StencilVector, StencilMatrix
 from psydac.linalg.block import BlockVector, BlockLinearOperator
 
 from psydac.fem.tensor import TensorFemSpace
-from psydac.fem.vector import ProductFemSpace
+from psydac.fem.vector import VectorFemSpace
 
 from psydac.api.essential_bc import apply_essential_bc_stencil
 
 from struphy.polar.basic import PolarVector
 from struphy.psydac_api import banded_to_stencil_kernels as bts
 import struphy.psydac_api.utilities_kernels as kernels
 
@@ -49,15 +49,15 @@
 
 
 def create_equal_random_arrays(V, seed=123, flattened=False):
     '''Creates two equal random arrays, where one array is a numpy array and the other one a distributed psydac array.
 
     Parameters
     ----------
-        V : TensorFemSpace or ProductFemSpace
+        V : TensorFemSpace or VectorFemSpace
             The FEM space to which the arrays belong to.
 
         seed : int
             The seed used in the radom number generator.
 
         flattened : bool
             Whether to return flattened arrays or 3d arrays.
@@ -67,15 +67,15 @@
         arr : list or array (if flattened)
             The 3d numpy arrays for each component of the space.
 
         arr_psy : StencilVector of BlockVector
             The distributed psydac array.
     '''
 
-    assert isinstance(V, (TensorFemSpace, ProductFemSpace))
+    assert isinstance(V, (TensorFemSpace, VectorFemSpace))
 
     np.random.seed(seed)
 
     arr = []
 
     if hasattr(V.symbolic_space, 'name'):
         V_name = V.symbolic_space.name
@@ -402,31 +402,36 @@
 
     Returns
     -------
         self._weight_pre : list of 3D arrays storing weights
 
     '''
 
-    nqs = [quad_grid.num_quad_pts for quad_grid in derham.Vh_fem['0'].quad_grids]
+    nqs = [quad_grid[nquad].num_quad_pts for quad_grid, nquad in zip(
+        derham.Vh_fem['0']._quad_grids, derham.Vh_fem['0'].nquads)]
 
     for aa, wspace in enumerate(derham.Vh_fem['2'].spaces):
         # knot span indices of elements of local domain
-        spans_out = [quad_grid.spans for quad_grid in wspace.quad_grids]
+        spans_out = [quad_grid[nquad].spans for quad_grid,
+                     nquad in zip(wspace._quad_grids, wspace.nquads)]
         # global start spline index on process
         starts_out = [int(start) for start in wspace.vector_space.starts]
 
         # Iniitialize hybrid linear operators
         # global quadrature points (flattened) and weights in format (local element, local weight)
-        pts = [quad_grid.points for quad_grid in wspace.quad_grids]
-        wts = [quad_grid.weights for quad_grid in wspace.quad_grids]
+        pts = [quad_grid[nquad].points for quad_grid,
+               nquad in zip(wspace._quad_grids, wspace.nquads)]
+        wts = [quad_grid[nquad].weights for quad_grid,
+               nquad in zip(wspace._quad_grids, wspace.nquads)]
 
         p = wspace.degree
 
         # evaluated basis functions at quadrature points of the space
-        basis_o = [quad_grid.basis for quad_grid in wspace.quad_grids]
+        basis_o = [quad_grid[nquad].basis for quad_grid,
+                   nquad in zip(wspace._quad_grids, wspace.nquads)]
 
         pads_out = wspace.vector_space.pads
 
         kernels.hybrid_curlA(
             *starts_out, *spans_out, p[0], p[1], p[2], nqs[0], nqs[1], nqs[2], *basis_o, weight_pre[aa], b[aa]._data)
     # generate the weight for generating the matrix
     kernels.hybrid_weight(*pads_out, *pts, *spans_out, nqs[0], nqs[1], nqs[2], wts[0], wts[1], wts[2],
```

### Comparing `struphy-2.0.1/src/struphy/psydac_api/utilities_kernels.py` & `struphy-2.0.2/src/struphy/psydac_api/utilities_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_accumulation.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_accumulation.py`

 * *Files 1% similar despite different names*

```diff
@@ -747,14 +747,8 @@
         print('full block vector_2 passed test')
     compare_arrays(ACC.vectors[2], vec_temp3, rank, atol=atol, verbose=verbose)
     if verbose:
         print('full block vector_3 passed test')
 
 
 if __name__ == '__main__':
-    import itertools
-
-    for kind in itertools.product([True, False], repeat=2):
-        print(kind)
-        spl_kind = list(kind) + [False]
-        test_accumulation([18, 10, 10], [2, 3, 4], spl_kind, ['Cuboid', {
-                          'l1': 0., 'r1': 2., 'l2': 0., 'r2': 3., 'l3': 0., 'r3': 4.}], Np=40, verbose=True)
+    pass
```

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_basis_operators.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_basis_operators.py`

 * *Files 0% similar despite different names*

```diff
@@ -692,11 +692,11 @@
     np.allclose(space.B2.T.dot(r_str), r_psy.toarray(True))
     print(f'Rank {mpi_rank} | Assertion passed.')
 
 
 if __name__ == '__main__':
     #test_basis_ops([8, 6, 4], [2, 2, 2], [False, True, True], ['Cuboid', {'l1': 0., 'r1': 1., 'l2': 0., 'r2': 6., 'l3': 0., 'r3': 10.}], False)
     #test_basis_ops([8, 6, 4], [2, 2, 2], [False, True, True], ['Colella', {'Lx' : 1., 'Ly' : 6., 'alpha' : .1, 'Lz' : 10.}], False)
-    test_basis_ops([6, 7, 4], [2, 3, 2], [False, True, True], ['HollowCylinder', {'a1': .1, 'a2': 1., 'Lz': 2*np.pi*3.}], False)
+    #test_basis_ops([6, 7, 4], [2, 3, 2], [False, True, True], ['HollowCylinder', {'a1': .1, 'a2': 1., 'Lz': 2*np.pi*3.}], False)
 
-    # test_basis_ops_polar([5, 9, 6], [2, 3, 2], [False, True, False], [[None, 'd'], [
-                        #  None, None], ['d', None]], ['IGAPolarCylinder', {'a': 1., 'Lz': 3.}], False)
+    test_basis_ops_polar([5, 9, 6], [2, 3, 2], [False, True, False], [[None, 'd'], [
+                        None, None], ['d', None]], ['IGAPolarCylinder', {'a': 1., 'Lz': 3.}], False)
```

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_draw_parallel.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_draw_parallel.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_eval_spline_mpi.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_eval_spline_mpi.py`

 * *Files 0% similar despite different names*

```diff
@@ -174,15 +174,15 @@
     comps = {'pressure':  True,
              'e_field': [True, True, True],
              'b_field': [True, True, True],
              'density':  True,
              'velocity': [True, True, True]}
 
     init_params = {'type': 'ModesCos', 'ModesCos': {'coords': 'logical',
-                                                    'comps': comps, 'ls': [0], 'ms': [0], 'ns': [1], 'amp': [5.]}}
+                                                    'comps': comps, 'ls': [0], 'ms': [0], 'ns': [1], 'amps': [5.]}}
 
     p0.initialize_coeffs(init_params)
     E1.initialize_coeffs(init_params)
     B2.initialize_coeffs(init_params)
     n3.initialize_coeffs(init_params)
     uv.initialize_coeffs(init_params)
```

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_iterative_solvers.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_iterative_solvers.py`

 * *Files 8% similar despite different names*

```diff
@@ -22,15 +22,17 @@
     from struphy.fields_background.mhd_equil.equils import ShearedSlab
     
     from struphy.linear_algebra.iterative_solvers import ConjugateGradient, PConjugateGradient, BiConjugateGradientStab, PBiConjugateGradientStab
     from struphy.psydac_api.preconditioner import MassMatrixPreconditioner
     
     from struphy.eigenvalue_solvers.spline_space import Spline_space_1d, Tensor_spline_space
 
-    from psydac.linalg.iterative_solvers import pcg, cg, bicg, lsmr, minres
+    from psydac.linalg.solvers import PConjugateGradient as pcg
+    from psydac.linalg.solvers import ConjugateGradient as cg
+    from psydac.linalg.solvers import MinimumResidual as minres
 
     from mpi4py import MPI
 
     mpi_comm = MPI.COMM_WORLD
     mpi_rank = mpi_comm.Get_rank()
     mpi_size = mpi_comm.Get_size()
 
@@ -107,65 +109,70 @@
     pbicgstab_solver1 = PBiConjugateGradientStab(M1.domain)
 
     # create random right-hand side vectors
     b0_str, b0 = create_equal_random_arrays(derham.Vh_fem['0'], 1234)
     b1_str, b1 = create_equal_random_arrays(derham.Vh_fem['1'], 1607)
 
     # ============ solve systems (M0) ==============
-    res, info0_1 = cg(M0, b0)
-    res, info0_2 = pcg(M0, b0, pc0)
-    res, info0_3 = minres(M0, b0)
+    solver_1 = cg(M0)
+    solver_2 = pcg(M0)
+    solver_3 = minres(M0)
+    
+    res = solver_1.solve(b0)
+    res = solver_2.solve(b0)
+    res = solver_3.solve(b0)
     
     res, info0_4 = cg_solver0.solve(M0, b0)
     res, info0_5 = pcg_solver0.solve(M0, b0, pc0)
     res, info0_6 = bicgstab_solver0.solve(M0, b0)
     res, info0_7 = pbicgstab_solver0.solve(M0, b0, pc0)
     
     # ============ solve systems (M1) (only ones with preconditioner) ============
+    solver_4 = pcg(M1)
     #res, info1_1 = cg(M1, b1)
-    res, info1_2 = pcg(M1, b1, pc1)
+    res = solver_4.solve(b1)
     #res, info1_3 = minres(M1, b1)
     
     #res, info1_4 = cg_solver1.solve(M1, b1)
     res, info1_5 = pcg_solver1.solve(M1, b1, pc1)
     #res, info1_6 = bicgstab_solver1.solve(M1, b1)
     res, info1_7 = pbicgstab_solver1.solve(M1, b1, pc1)
 
-    assert info0_1['success']
-    assert info0_2['success']
-    assert info0_3['success']
+    # assert info0_1['success']
+    # assert info0_2['success']
+    # assert info0_3['success']
     assert info0_4['success']
     assert info0_5['success']
     assert info0_6['success']
     assert info0_7['success']
 
     #assert info1_1['success']
-    assert info1_2['success']
+    #assert info1_2['success']
     #assert info1_3['success']
     #assert info1_4['success']
     assert info1_5['success']
     #assert info1_6['success']
     assert info1_7['success']
 
     if verbose and mpi_rank == 0:
-        print('info for cg                       (M0) : ', info0_1)
-        print('info for pcg                      (M0) : ', info0_2)
-        print('info for minres                   (M0) : ', info0_3)
+        # print('info for cg                       (M0) : ', info0_1)
+        # print('info for pcg                      (M0) : ', info0_2)
+        # print('info for minres                   (M0) : ', info0_3)
         
         print()
         
         print('info for ConjugateGradient        (M0) : ', info0_4)
         print('info for PConjugateGradient       (M0) : ', info0_5)
         print('info for BiConjugateGradientStab  (M0) : ', info0_6)
         print('info for PBiConjugateGradientStab (M0) : ', info0_7)
         
         print('-----------------------------')
         
         #print('info for cg                       (M1) : ', info1_1)
-        print('info for pcg                      (M1) : ', info1_2)
+        #print('info for pcg                      (M1) : ', info1_2)
         #print('info for minres                   (M1) : ', info1_3)
         
         print()
         
         #print('info for ConjugateGradient        (M1) : ', info1_4)
         print('info for PConjugateGradient       (M1) : ', info1_5)
         #print('info for BiConjugateGradientStab  (M1) : ', info1_6)
```

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_mass_matrices.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_mass_matrices.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_mat_vec_filler.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_mat_vec_filler.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/accumulation.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/accumulation.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/accumulation_kernels_3d.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/accumulation_kernels_3d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/mappings_3d.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/mappings_3d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/mappings_3d_fast.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/mappings_3d_fast.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/pusher.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/pusher.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/pusher_pos.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/pusher_pos.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/pusher_vel_2d.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/pusher_vel_2d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/pusher_vel_3d.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/pusher_vel_3d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/spline_evaluation_2d.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/spline_evaluation_2d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_pic_legacy_files/spline_evaluation_3d.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_pic_legacy_files/spline_evaluation_3d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_polar.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_polar.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_prop_solvers.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_implicit_diffusion.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 import numpy as np
 
 from struphy.geometry import domains
 from struphy.psydac_api.psydac_derham import Derham
 from struphy.psydac_api.mass import WeightedMassOperators
 from struphy.psydac_api.mass import WeightedMassOperator
 from struphy.propagators.base import Propagator
-from struphy.propagators.solvers import PoissonSolver
+from struphy.propagators.propagators_fields import ImplicitDiffusion
 from struphy.psydac_api.utilities import compare_arrays
 from psydac.linalg.stencil import StencilVector
 
 
 @pytest.mark.mpi(min_size=2)
 @pytest.mark.parametrize('Nel', [[10, 2, 2], [40, 2, 2]])
 @pytest.mark.parametrize('p', [[1, 1, 1], [3, 1, 1]])
@@ -63,25 +63,31 @@
     mass_ops = WeightedMassOperators(derham, domain)
 
     Propagator.derham = derham
     Propagator.domain = domain
     Propagator.mass_ops = mass_ops
 
     # Create Poisson solver
-    poisson_solver = PoissonSolver(rho=rho_vec, **solver_params)
+    _phi = StencilVector(derham.Vh['0'])
+    poisson_solver = ImplicitDiffusion(_phi,
+                                       sigma=0.,
+                                       phi_n=rho_vec,
+                                       x0=rho_vec,
+                                       **solver_params)
 
-    # Solve Poisson equation
-    poisson_solver(0.1)
+    # Solve Poisson equation (call with dt=1.)
+    poisson_solver(1.)
 
     # Compare to analytical solution
     compare_arrays(
-        poisson_solver._phi,
+        _phi,
         sol_vec.toarray(),
         MPI.COMM_WORLD.Get_rank(),
-        atol=1e-5
+        atol=1e-5,
+        verbose=True
     )
 
 
 if __name__ == '__main__':
     Nel = [10, 2, 2]
     p = [1, 1, 1]
     spl_kind = [True, True, True]
```

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_psydac_basics.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_psydac_basics.py`

 * *Files 0% similar despite different names*

```diff
@@ -203,36 +203,37 @@
         print(f'x0.shape={x0.shape}')
         print(f'x0[:, :, :].shape={x0[:, :, :].shape}')
         print(f'x0[:].shape={x0[:].shape}')
         print(f'x0._data.shape={x0._data.shape}')
         print(f'x0.toarray().shape={x0.toarray().shape}')
         print(f'x0.toarray_local().shape={x0.toarray_local().shape}')
 
-        print('\n###### Attributes of StencilMatrix A0 (rank 0) ######')
-        for k in dir(A0):
-            if (k[0] != '_' or k == '_data'):
-                if k == '_data':
-                    v = f'array of shape {getattr(A0, k).shape}'
-                elif k == 'T':
-                    v = 'transpose matrix'
-                else:
-                    v = getattr(A0, k)
-                print(k, v)
-        print('\n###### Attributes of BlockLinearOperator A1 (rank 0) ######')
-        for k in dir(A1):
-            if (k[0] != '_' or k == '_data'):
-                if k == '_data':
-                    v = f'array of shape {getattr(A1, k).shape}'
-                elif k == 'T':
-                    v = 'transpose matrix'
-                else:
-                    v = getattr(A1, k)
-                print(k, v)
+        # print('\n###### Attributes of StencilMatrix A0 (rank 0) ######')
+        # for k in dir(A0):
+        #     print('-------------------->', k)
+        #     if (k[0] != '_' or k == '_data'):
+        #         if k == '_data':
+        #             v = f'array of shape {getattr(A0, k).shape}'
+        #         elif k == 'T':
+        #             v = 'transpose matrix'
+        #         else:
+        #             v = getattr(A0, k)
+        #         print(k, v)
+        # print('\n###### Attributes of BlockLinearOperator A1 (rank 0) ######')
+        # for k in dir(A1):
+        #     if (k[0] != '_' or k == '_data'):
+        #         if k == '_data':
+        #             v = f'array of shape {getattr(A1, k).shape}'
+        #         elif k == 'T':
+        #             v = 'transpose matrix'
+        #         else:
+        #             v = getattr(A1, k)
+        #         print(k, v)
 
-        print('\nBlockMatrices have the attribute "blocks", which at creation is a nested tuple of None, but can be filled with StencilMatrices.')
+        # print('\nBlockMatrices have the attribute "blocks", which at creation is a nested tuple of None, but can be filled with StencilMatrices.')
 
         print('\n###### Data of Stencil Matrix A0 (rank 0) ######')
         print(f'type(A0)={type(A0)}')
         print(f'type(A0[:, :, :, :, :, :])={type(A0[:, :, :, :, :, :])}')
         print(f'type(A0[:, :])={type(A0[:, :])}')
         print(f'type(A0._data)={type(A0._data)}')
         print(f'type(A0.toarray())={type(A0.toarray())}')
```

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_psydac_derham.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_psydac_derham.py`

 * *Files 1% similar despite different names*

```diff
@@ -236,8 +236,8 @@
     if rank == 0:
         print('\nCompare P3:')
     compare_arrays(fh3_PSY, fh3_STR, rank, atol=1e-5)
     comm.Barrier()
 
 
 if __name__ == '__main__':
-    test_psydac_derham([8, 8, 12], [2, 3, 4], [False, False, True])
+    test_psydac_derham([8, 8, 12], [1, 2, 3], [False, False, True])
```

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_pushers.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_pushers.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_stencil_dot_kernels.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_stencil_dot_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_mpi/test_stencil_transpose_kernels.py` & `struphy-2.0.2/src/struphy/tests/tests_mpi/test_stencil_transpose_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/test_bsplines_kernels.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/test_bsplines_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/test_domain.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/test_domain.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/test_gvec_equil.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/test_gvec_equil.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/test_legacy_mhd_projectors.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/test_legacy_mhd_projectors.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/test_legacy_polar_splines.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/test_legacy_polar_splines.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/test_mhd_equils.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/test_mhd_equils.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/test_numerical_MHD_equil.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/test_numerical_MHD_equil.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/test_projectors_global.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/test_projectors_global.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/test_psydac_basis_operators.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/test_psydac_basis_operators.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/test_psydac_linear_operators.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/test_psydac_linear_operators.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/test_psydac_mapping.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/test_psydac_mapping.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/test_spline_space_1d.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/test_spline_space_1d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/xx_psydac_lin_ops.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/xx_psydac_lin_ops.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_GVEC.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_GVEC.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_codes.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_codes.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_cprofiler.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_cprofiler.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_divB.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_divB.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_filler_kernel.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_filler_kernel.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_mappings.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_mappings.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_mat_vec_filler.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_mat_vec_filler.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_mhd_equil.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_mhd_equil.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_paraview.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_paraview.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_polar_splines_3D.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_polar_splines_3D.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_preconditioner.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_preconditioner.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_psydac_lin_ops_loop.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_psydac_lin_ops_loop.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_spline_evaluation.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_spline_evaluation.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_spline_interpolation.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_spline_interpolation.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy/tests/tests_serial/xx_test_template_gvec.py` & `struphy-2.0.2/src/struphy/tests/tests_serial/xx_test_template_gvec.py`

 * *Files identical despite different names*

### Comparing `struphy-2.0.1/src/struphy.egg-info/PKG-INFO` & `struphy-2.0.2/src/struphy.egg-info/PKG-INFO`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,16 @@
 Metadata-Version: 2.1
 Name: struphy
-Version: 2.0.1
+Version: 2.0.2
 Summary: Multi-model plasma physics package
 Author: Max Planck Institute for Plasma Physics
-Author-email: stefan.possanner@ipp.mpg.de, florian.holderied@ipp.mpg.de
-License: Copyright 2019 (c) Struphy dev team | Max Planck Institute for Plasma Physics
+Author-email: stefan.possanner@ipp.mpg.de, eric.sonnendruecker@ipp.mpg.de
+License: MIT license
+        
+        Copyright (c) 2019-2023, Struphy developers, Max Planck Institute for Plasma Physics
         
         Permission is hereby granted, free of charge, to any person obtaining a copy of this software and 
         associated documentation files (the "Software"), to deal in the Software without restriction, 
         including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, 
         and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, 
         subject to the following conditions:
         
@@ -31,15 +33,15 @@
 Project-URL: homepage, https://struphy.pages.mpcdf.de/struphy/
 Project-URL: documentation, https://struphy.pages.mpcdf.de/struphy/
 Project-URL: repository, https://gitlab.mpcdf.mpg.de/struphy/struphy
 Project-URL: changelog, https://gitlab.mpcdf.mpg.de/struphy/struphy/-/blob/devel/CHANGELOG.md
 Project-URL: Bug Tracker, https://gitlab.mpcdf.mpg.de/struphy/struphy/-/issues
 Keywords: plasma physics, fusion, numerical modeling, partial differential equations, energetic particles
 Classifier: Programming Language :: Python :: 3
-Requires-Python: <3.11,>=3.7
+Requires-Python: <3.12,>=3.7
 Description-Content-Type: text/markdown
 License-File: LICENSE
 
 # STRUPHY - STRUcture-Preserving HYbrid codes
 
 A Python package for energetic particles in plasma.
 
@@ -105,10 +107,10 @@
 In addition, we ask you to cite the following reference in scientific publications which contain results obtained with
 this software and developments:
 
 F. Holderied, S. Possanner, X. Wang, "MHD-kinetic hybrid code based on structure-preserving finite elements with particles-in-cell", J. Comp. Phys. 433 (2021) 110143
 
 ## Contact
 
-* Stefan Possanner [spossann@ipp.mpg.de](spossann@ipp.mpg.de)
-* Eric Sonnendrcker [spossann@ipp.mpg.de](eric.sonnendruecker@ipp.mpg.de)
+* Stefan Possanner [stefan.possanner@ipp.mpg.de](spossann@ipp.mpg.de)
+* Eric Sonnendrcker [eric.sonnendruecker@ipp.mpg.de](eric.sonnendruecker@ipp.mpg.de)
 * Xin Wang [xin.wang@ipp.mpg.de](xin.wang@ipp.mpg.de)
```

### Comparing `struphy-2.0.1/src/struphy.egg-info/SOURCES.txt` & `struphy-2.0.2/src/struphy.egg-info/SOURCES.txt`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 LICENSE
 README.md
 pyproject.toml
 setup.cfg
 src/struphy/__init__.py
 src/struphy/compile_struphy.mk
-src/struphy/psydac-0.1-py3-none-any.whl
+src/struphy/psydac-0.1.2-py3-none-any.whl
 src/struphy.egg-info/PKG-INFO
 src/struphy.egg-info/SOURCES.txt
 src/struphy.egg-info/dependency_links.txt
 src/struphy.egg-info/entry_points.txt
 src/struphy.egg-info/requires.txt
 src/struphy.egg-info/top_level.txt
 src/struphy/b_splines/Bspline.py
@@ -134,21 +134,17 @@
 src/struphy/geometry/kernels.py
 src/struphy/geometry/map_eval.py
 src/struphy/geometry/mappings_fast.py
 src/struphy/geometry/transform.py
 src/struphy/geometry/utilities.py
 src/struphy/geometry/map_coef/__init__.py
 src/struphy/initial/__init__.py
-src/struphy/initial/analytic.py
-src/struphy/initial/base.py
 src/struphy/initial/eigenfunctions.py
-src/struphy/initial/initialize.py
 src/struphy/initial/perturbations.py
 src/struphy/io/__init__.py
-src/struphy/io/batch/__init__.py
 src/struphy/io/batch/batch_cobra.sh
 src/struphy/io/batch/p_016.sh
 src/struphy/io/batch/p_032.sh
 src/struphy/io/batch/p_064.sh
 src/struphy/io/batch/p_128.sh
 src/struphy/io/batch/p_256.sh
 src/struphy/io/batch/p_512.sh
@@ -165,25 +161,27 @@
 src/struphy/io/inp/examples/params_linvlasovmaxwell_streaming_weibel.yml
 src/struphy/io/inp/examples/params_linvlasovmaxwell_weibel.yml
 src/struphy/io/inp/examples/params_maxwell.yml
 src/struphy/io/inp/examples/params_orbits_tokamak.yml
 src/struphy/io/inp/tests/__init__.py
 src/struphy/io/inp/tests/params_cc_linmhd_5d.yml
 src/struphy/io/inp/tests/params_coldplasma.yml
+src/struphy/io/inp/tests/params_coldplasmavlasov.yml
 src/struphy/io/inp/tests/params_deltafvlasovmaxwell.yml
 src/struphy/io/inp/tests/params_hybrid_fA.yml
 src/struphy/io/inp/tests/params_hybridmhdvlasovcc.yml
 src/struphy/io/inp/tests/params_hybridmhdvlasovcc_control.yml
 src/struphy/io/inp/tests/params_hybridmhdvlasovcc_gvec.yml
 src/struphy/io/inp/tests/params_hybridmhdvlasovpc.yml
 src/struphy/io/inp/tests/params_linearmhd.yml
 src/struphy/io/inp/tests/params_linearmhd_gvec.yml
 src/struphy/io/inp/tests/params_linvlasovmaxwell.yml
 src/struphy/io/inp/tests/params_maxwell_1.yml
 src/struphy/io/inp/tests/params_maxwell_2.yml
+src/struphy/io/inp/tests/params_vlasovmaxwell.yml
 src/struphy/io/inp/tests/strscl.yml
 src/struphy/io/inp/tests/wkscl_1.yml
 src/struphy/io/inp/tests/wkscl_2.yml
 src/struphy/io/inp/tests/wkscl_3.yml
 src/struphy/io/inp/tests/wkscl_4.yml
 src/struphy/io/inp/tests/wkscl_5.yml
 src/struphy/io/inp/tests/wkscl_6.yml
@@ -210,20 +208,23 @@
 src/struphy/models/kinetic.py
 src/struphy/models/main.py
 src/struphy/models/output_handling.py
 src/struphy/models/setup.py
 src/struphy/models/toy.py
 src/struphy/pic/__init__.py
 src/struphy/pic/accum_kernels.py
+src/struphy/pic/accum_kernels_gc.py
+src/struphy/pic/base.py
 src/struphy/pic/filler_kernels.py
 src/struphy/pic/mat_vec_filler.py
 src/struphy/pic/particles.py
 src/struphy/pic/particles_to_grid.py
 src/struphy/pic/pusher.py
 src/struphy/pic/pusher_kernels.py
+src/struphy/pic/pusher_kernels_gc.py
 src/struphy/pic/pusher_utilities.py
 src/struphy/pic/sampling.py
 src/struphy/pic/sobol_seq.py
 src/struphy/pic/utilities.py
 src/struphy/pic/utilities_kernels.py
 src/struphy/polar/__init__.py
 src/struphy/polar/basic.py
@@ -235,15 +236,14 @@
 src/struphy/post_processing/pproc_struphy.py
 src/struphy/post_processing/profile_struphy.py
 src/struphy/propagators/__init__.py
 src/struphy/propagators/base.py
 src/struphy/propagators/propagators_coupling.py
 src/struphy/propagators/propagators_fields.py
 src/struphy/propagators/propagators_markers.py
-src/struphy/propagators/solvers.py
 src/struphy/psydac_api/__init__.py
 src/struphy/psydac_api/banded_to_stencil_kernels.py
 src/struphy/psydac_api/basis_projection_kernels.py
 src/struphy/psydac_api/basis_projection_ops.py
 src/struphy/psydac_api/fields.py
 src/struphy/psydac_api/linear_operators.py
 src/struphy/psydac_api/mass.py
@@ -256,19 +256,21 @@
 src/struphy/psydac_api/utilities_kernels.py
 src/struphy/tests/__init__.py
 src/struphy/tests/tests_mpi/__init__.py
 src/struphy/tests/tests_mpi/test_accumulation.py
 src/struphy/tests/tests_mpi/test_basis_operators.py
 src/struphy/tests/tests_mpi/test_draw_parallel.py
 src/struphy/tests/tests_mpi/test_eval_spline_mpi.py
+src/struphy/tests/tests_mpi/test_implicit_diffusion.py
 src/struphy/tests/tests_mpi/test_iterative_solvers.py
 src/struphy/tests/tests_mpi/test_mass_matrices.py
 src/struphy/tests/tests_mpi/test_mat_vec_filler.py
+src/struphy/tests/tests_mpi/test_noise_init.py
+src/struphy/tests/tests_mpi/test_poisson.py
 src/struphy/tests/tests_mpi/test_polar.py
-src/struphy/tests/tests_mpi/test_prop_solvers.py
 src/struphy/tests/tests_mpi/test_psydac_basics.py
 src/struphy/tests/tests_mpi/test_psydac_derham.py
 src/struphy/tests/tests_mpi/test_pushers.py
 src/struphy/tests/tests_mpi/test_stencil_dot_kernels.py
 src/struphy/tests/tests_mpi/test_stencil_transpose_kernels.py
 src/struphy/tests/tests_mpi/test_pic_legacy_files/__init__.py
 src/struphy/tests/tests_mpi/test_pic_legacy_files/accumulation.py
```

