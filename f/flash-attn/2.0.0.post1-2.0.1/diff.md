# Comparing `tmp/flash_attn-2.0.0.post1.tar.gz` & `tmp/flash_attn-2.0.1.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "flash_attn-2.0.0.post1.tar", last modified: Mon Jul 17 13:04:48 2023, max compression
+gzip compressed data, was "flash_attn-2.0.1.tar", last modified: Mon Jul 24 08:09:18 2023, max compression
```

## Comparing `flash_attn-2.0.0.post1.tar` & `flash_attn-2.0.1.tar`

### file list

```diff
@@ -1,1758 +1,1786 @@
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:48.002014 flash_attn-2.0.0.post1/
--rw-r--r--   0 root         (0) root         (0)       29 2023-07-17 10:25:58.000000 flash_attn-2.0.0.post1/AUTHORS
--rw-r--r--   0 root         (0) root         (0)     1558 2022-09-09 19:08:03.000000 flash_attn-2.0.0.post1/LICENSE
--rw-r--r--   0 root         (0) root         (0)      315 2023-07-17 13:04:07.000000 flash_attn-2.0.0.post1/MANIFEST.in
--rw-rw-r--   0 root         (0) root         (0)      482 2023-07-17 13:04:47.998393 flash_attn-2.0.0.post1/PKG-INFO
--rw-r--r--   0 root         (0) root         (0)     8742 2023-07-17 12:34:39.000000 flash_attn-2.0.0.post1/README.md
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.483896 flash_attn-2.0.0.post1/csrc/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.452689 flash_attn-2.0.0.post1/csrc/cutlass/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.505379 flash_attn-2.0.0.post1/csrc/cutlass/cmake/
--rw-rw-r--   0 root         (0) root         (0)     2023 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/cmake/nop.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.378476 flash_attn-2.0.0.post1/csrc/cutlass/examples/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.507795 flash_attn-2.0.0.post1/csrc/cutlass/examples/00_basic_gemm/
--rw-r--r--   0 root         (0) root         (0)    14698 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/00_basic_gemm/basic_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.510253 flash_attn-2.0.0.post1/csrc/cutlass/examples/01_cutlass_utilities/
--rw-rw-r--   0 root         (0) root         (0)    13255 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/01_cutlass_utilities/cutlass_utilities.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.512775 flash_attn-2.0.0.post1/csrc/cutlass/examples/02_dump_reg_shmem/
--rw-rw-r--   0 root         (0) root         (0)     7157 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/02_dump_reg_shmem/dump_reg_shmem.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.523339 flash_attn-2.0.0.post1/csrc/cutlass/examples/03_visualize_layout/
--rw-rw-r--   0 root         (0) root         (0)     4478 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/03_visualize_layout/options.h
--rw-rw-r--   0 root         (0) root         (0)     7081 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/03_visualize_layout/register_layout.cu
--rw-rw-r--   0 root         (0) root         (0)     2691 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/03_visualize_layout/register_layout.h
--rw-rw-r--   0 root         (0) root         (0)     5819 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/03_visualize_layout/visualize_layout.cpp
--rw-rw-r--   0 root         (0) root         (0)    11415 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/03_visualize_layout/visualize_layout.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.525804 flash_attn-2.0.0.post1/csrc/cutlass/examples/04_tile_iterator/
--rw-rw-r--   0 root         (0) root         (0)     8226 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/04_tile_iterator/tile_iterator.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.528303 flash_attn-2.0.0.post1/csrc/cutlass/examples/05_batched_gemm/
--rw-rw-r--   0 root         (0) root         (0)    15161 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/05_batched_gemm/batched_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.530836 flash_attn-2.0.0.post1/csrc/cutlass/examples/06_splitK_gemm/
--rw-rw-r--   0 root         (0) root         (0)    17570 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/06_splitK_gemm/splitk_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.533837 flash_attn-2.0.0.post1/csrc/cutlass/examples/07_volta_tensorop_gemm/
--rw-r--r--   0 root         (0) root         (0)    18280 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/07_volta_tensorop_gemm/volta_tensorop_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.536377 flash_attn-2.0.0.post1/csrc/cutlass/examples/08_turing_tensorop_gemm/
--rw-r--r--   0 root         (0) root         (0)    18226 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/08_turing_tensorop_gemm/turing_tensorop_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.538827 flash_attn-2.0.0.post1/csrc/cutlass/examples/09_turing_tensorop_conv2dfprop/
--rw-r--r--   0 root         (0) root         (0)    28124 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/09_turing_tensorop_conv2dfprop/turing_tensorop_conv2dfprop.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.541318 flash_attn-2.0.0.post1/csrc/cutlass/examples/10_planar_complex/
--rw-rw-r--   0 root         (0) root         (0)    21947 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/10_planar_complex/planar_complex.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.543838 flash_attn-2.0.0.post1/csrc/cutlass/examples/11_planar_complex_array/
--rw-rw-r--   0 root         (0) root         (0)    23244 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/11_planar_complex_array/planar_complex_array.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.547473 flash_attn-2.0.0.post1/csrc/cutlass/examples/12_gemm_bias_relu/
--rw-rw-r--   0 root         (0) root         (0)    13151 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/12_gemm_bias_relu/gemm_bias_relu.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.590988 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/
--rw-rw-r--   0 root         (0) root         (0)    26102 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_conv2d_run.h
--rw-r--r--   0 root         (0) root         (0)    22877 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_gemm_run.h
--rw-rw-r--   0 root         (0) root         (0)    28268 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_conv2d_run.h
--rw-r--r--   0 root         (0) root         (0)    24493 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_gemm_run.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.597623 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/device/
--rw-r--r--   0 root         (0) root         (0)    15552 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/device/b2b_gemm.h
--rw-rw-r--   0 root         (0) root         (0)    11520 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/device/b2b_implicit_gemm_convolution.h
--rw-rw-r--   0 root         (0) root         (0)     8756 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_rf.cu
--rw-rw-r--   0 root         (0) root         (0)     8759 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_shmem.cu
--rw-rw-r--   0 root         (0) root         (0)     8712 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_rf.cu
--rw-rw-r--   0 root         (0) root         (0)     8762 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_shmem.cu
--rw-rw-r--   0 root         (0) root         (0)     8787 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_rf.cu
--rw-rw-r--   0 root         (0) root         (0)     8793 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_shmem.cu
--rw-rw-r--   0 root         (0) root         (0)     8711 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_rf.cu
--rw-rw-r--   0 root         (0) root         (0)     8775 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_shmem.cu
--rw-rw-r--   0 root         (0) root         (0)     7269 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_rf.cu
--rw-rw-r--   0 root         (0) root         (0)     7338 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_shmem.cu
--rw-rw-r--   0 root         (0) root         (0)     7294 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_rf.cu
--rw-rw-r--   0 root         (0) root         (0)     7359 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_shmem.cu
--rw-rw-r--   0 root         (0) root         (0)     7362 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_rf.cu
--rw-rw-r--   0 root         (0) root         (0)     7430 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_shmem.cu
--rw-r--r--   0 root         (0) root         (0)     7627 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_rf.cu
--rw-r--r--   0 root         (0) root         (0)     7634 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_shmem.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.618927 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/
--rw-r--r--   0 root         (0) root         (0)    16152 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_gemm.h
--rw-rw-r--   0 root         (0) root         (0)    18151 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_implicit_gemm_convolution.h
--rw-rw-r--   0 root         (0) root         (0)     3973 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop.h
--rw-rw-r--   0 root         (0) root         (0)    26762 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm75.h
--rw-rw-r--   0 root         (0) root         (0)    26775 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm80.h
--rw-rw-r--   0 root         (0) root         (0)    28422 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm75.h
--rw-rw-r--   0 root         (0) root         (0)    28073 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm80.h
--rw-r--r--   0 root         (0) root         (0)    17111 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm.h
--rw-r--r--   0 root         (0) root         (0)    15658 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm_smem_accumulator.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.342381 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/reference/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.622198 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/reference/device/
--rw-r--r--   0 root         (0) root         (0)    10368 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/reference/device/tensor_scale_bias.h
--rw-rw-r--   0 root         (0) root         (0)     3577 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/test_run.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.652676 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/
--rw-rw-r--   0 root         (0) root         (0)    31616 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage.h
--rw-rw-r--   0 root         (0) root         (0)    31443 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage_smem_accumulator.h
--rw-r--r--   0 root         (0) root         (0)    21010 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined.h
--rw-r--r--   0 root         (0) root         (0)    20493 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined_smem_accumulator.h
--rw-rw-r--   0 root         (0) root         (0)     7983 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base.h
--rw-rw-r--   0 root         (0) root         (0)     6047 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base_smem_accumulator.h
--rw-r--r--   0 root         (0) root         (0)    33788 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage.h
--rw-r--r--   0 root         (0) root         (0)    33506 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage_smem_accumulator.h
--rw-r--r--   0 root         (0) root         (0)    21451 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined.h
--rw-r--r--   0 root         (0) root         (0)    21065 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined_smem_accumulator.h
--rw-rw-r--   0 root         (0) root         (0)    27144 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma.h
--rw-rw-r--   0 root         (0) root         (0)    27400 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma_smem_accumulator.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.655525 flash_attn-2.0.0.post1/csrc/cutlass/examples/14_ampere_tf32_tensorop_gemm/
--rw-rw-r--   0 root         (0) root         (0)    18020 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/14_ampere_tf32_tensorop_gemm/ampere_tf32_tensorop_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.658343 flash_attn-2.0.0.post1/csrc/cutlass/examples/15_ampere_sparse_tensorop_gemm/
--rw-rw-r--   0 root         (0) root         (0)    15042 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/15_ampere_sparse_tensorop_gemm/ampere_sparse_tensorop_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.661160 flash_attn-2.0.0.post1/csrc/cutlass/examples/16_ampere_tensorop_conv2dfprop/
--rw-r--r--   0 root         (0) root         (0)    27755 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/16_ampere_tensorop_conv2dfprop/ampere_tensorop_conv2dfprop.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.664340 flash_attn-2.0.0.post1/csrc/cutlass/examples/17_fprop_per_channel_bias/
--rw-rw-r--   0 root         (0) root         (0)    12580 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/17_fprop_per_channel_bias/fprop_per_channel_bias.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.667076 flash_attn-2.0.0.post1/csrc/cutlass/examples/18_ampere_fp64_tensorop_affine2_gemm/
--rw-rw-r--   0 root         (0) root         (0)    14007 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/18_ampere_fp64_tensorop_affine2_gemm/ampere_fp64_tensorop_affine2_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.671016 flash_attn-2.0.0.post1/csrc/cutlass/examples/19_tensorop_canonical/
--rw-rw-r--   0 root         (0) root         (0)    13401 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/19_tensorop_canonical/tensorop_canonical.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.673771 flash_attn-2.0.0.post1/csrc/cutlass/examples/20_simt_canonical/
--rw-rw-r--   0 root         (0) root         (0)    12556 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/20_simt_canonical/simt_canonical.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.676816 flash_attn-2.0.0.post1/csrc/cutlass/examples/21_quaternion_gemm/
--rw-rw-r--   0 root         (0) root         (0)    17319 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/21_quaternion_gemm/quaternion_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.679560 flash_attn-2.0.0.post1/csrc/cutlass/examples/22_quaternion_conv/
--rw-r--r--   0 root         (0) root         (0)    21495 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/22_quaternion_conv/quaternion_conv.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.682585 flash_attn-2.0.0.post1/csrc/cutlass/examples/23_ampere_gemm_operand_reduction_fusion/
--rw-r--r--   0 root         (0) root         (0)    27530 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/23_ampere_gemm_operand_reduction_fusion/ampere_gemm_operand_reduction_fusion.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.686147 flash_attn-2.0.0.post1/csrc/cutlass/examples/24_gemm_grouped/
--rw-r--r--   0 root         (0) root         (0)    50967 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/24_gemm_grouped/gemm_grouped.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.689306 flash_attn-2.0.0.post1/csrc/cutlass/examples/25_ampere_fprop_mainloop_fusion/
--rw-rw-r--   0 root         (0) root         (0)    26547 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_3d_fprop_mainloop_fusion.cu
--rw-rw-r--   0 root         (0) root         (0)    25628 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_fprop_mainloop_fusion.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.694463 flash_attn-2.0.0.post1/csrc/cutlass/examples/26_ampere_wgrad_mainloop_fusion/
--rw-rw-r--   0 root         (0) root         (0)    25538 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/26_ampere_wgrad_mainloop_fusion/ampere_wgrad_mainloop_fusion.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.697281 flash_attn-2.0.0.post1/csrc/cutlass/examples/27_ampere_3xtf32_fast_accurate_tensorop_gemm/
--rw-rw-r--   0 root         (0) root         (0)    30446 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/27_ampere_3xtf32_fast_accurate_tensorop_gemm/27_ampere_3xtf32_fast_accurate_tensorop_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.700172 flash_attn-2.0.0.post1/csrc/cutlass/examples/28_ampere_3xtf32_fast_accurate_tensorop_fprop/
--rw-rw-r--   0 root         (0) root         (0)    28159 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/28_ampere_3xtf32_fast_accurate_tensorop_fprop/ampere_3xtf32_fast_accurate_tensorop_fprop.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.703086 flash_attn-2.0.0.post1/csrc/cutlass/examples/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm/
--rw-r--r--   0 root         (0) root         (0)    28403 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.705929 flash_attn-2.0.0.post1/csrc/cutlass/examples/30_wgrad_split_k/
--rw-rw-r--   0 root         (0) root         (0)    27329 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/30_wgrad_split_k/30_wgrad_split_k.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.708769 flash_attn-2.0.0.post1/csrc/cutlass/examples/31_basic_syrk/
--rw-r--r--   0 root         (0) root         (0)    15206 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/31_basic_syrk/basic_syrk.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.711640 flash_attn-2.0.0.post1/csrc/cutlass/examples/32_basic_trmm/
--rw-r--r--   0 root         (0) root         (0)    15907 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/32_basic_trmm/basic_trmm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.714347 flash_attn-2.0.0.post1/csrc/cutlass/examples/33_ampere_3xtf32_tensorop_symm/
--rw-rw-r--   0 root         (0) root         (0)    31803 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/33_ampere_3xtf32_tensorop_symm/ampere_3xtf32_tensorop_symm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.717327 flash_attn-2.0.0.post1/csrc/cutlass/examples/34_transposed_conv2d/
--rw-rw-r--   0 root         (0) root         (0)    22378 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/34_transposed_conv2d/34_transposed_conv2d.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.720216 flash_attn-2.0.0.post1/csrc/cutlass/examples/35_gemm_softmax/
--rw-rw-r--   0 root         (0) root         (0)    23114 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/35_gemm_softmax/gemm_softmax.cu
--rw-rw-r--   0 root         (0) root         (0)    16723 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/35_gemm_softmax/gemm_with_epilogue_visitor.h
--rw-r--r--   0 root         (0) root         (0)    18713 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/35_gemm_softmax/gemm_with_softmax.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.727105 flash_attn-2.0.0.post1/csrc/cutlass/examples/36_gather_scatter_fusion/
--rw-rw-r--   0 root         (0) root         (0)    20795 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/36_gather_scatter_fusion/gather_scatter_fusion.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.729925 flash_attn-2.0.0.post1/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/
--rw-rw-r--   0 root         (0) root         (0)    31111 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_layernorm.cu
--rw-rw-r--   0 root         (0) root         (0)    13982 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_epilogue_visitor.h
--rw-rw-r--   0 root         (0) root         (0)    33905 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_layernorm.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.737359 flash_attn-2.0.0.post1/csrc/cutlass/examples/38_syr2k_grouped/
--rw-rw-r--   0 root         (0) root         (0)    47455 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/38_syr2k_grouped/syr2k_grouped.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.740656 flash_attn-2.0.0.post1/csrc/cutlass/examples/39_gemm_permute/
--rw-r--r--   0 root         (0) root         (0)    37896 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/39_gemm_permute/gemm_permute.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.752131 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/
--rw-rw-r--   0 root         (0) root         (0)    11865 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/debug_utils.h
--rw-r--r--   0 root         (0) root         (0)     9885 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/default_fmha_grouped.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.760939 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/
--rw-rw-r--   0 root         (0) root         (0)    22349 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_pipelined.h
--rw-rw-r--   0 root         (0) root         (0)     9162 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_rescale_output.h
--rw-rw-r--   0 root         (0) root         (0)     6111 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_thread_apply_logsumexp.h
--rw-r--r--   0 root         (0) root         (0)    34379 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/fmha_grouped.h
--rw-rw-r--   0 root         (0) root         (0)     6666 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/fmha_grouped_problem_visitor.h
--rw-r--r--   0 root         (0) root         (0)    38173 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_fixed_seqlen.cu
--rw-r--r--   0 root         (0) root         (0)    39997 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_variable_seqlen.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.775982 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/
--rw-rw-r--   0 root         (0) root         (0)     3994 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma.h
--rw-rw-r--   0 root         (0) root         (0)     6241 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_base.h
--rw-r--r--   0 root         (0) root         (0)    27198 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_multistage.h
--rw-r--r--   0 root         (0) root         (0)    14090 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_pipelined.h
--rw-rw-r--   0 root         (0) root         (0)     6782 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/find_default_mma.h
--rw-rw-r--   0 root         (0) root         (0)    13959 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/mma_accum_lambda_iterator.h
--rw-r--r--   0 root         (0) root         (0)    72983 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/mma_from_smem.h
--rw-r--r--   0 root         (0) root         (0)    10878 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm_kernel_utils.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.793027 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/
--rw-rw-r--   0 root         (0) root         (0)    23855 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/epilogue_predicated_tile_iterator.h
--rw-rw-r--   0 root         (0) root         (0)     3142 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/make_residual_last.h
--rw-r--r--   0 root         (0) root         (0)    64480 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_access_iterator_residual_last.h
--rw-rw-r--   0 root         (0) root         (0)    64500 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_iterator_residual_last.h
--rw-r--r--   0 root         (0) root         (0)     2435 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/transpose_warp_iterator.h
--rw-r--r--   0 root         (0) root         (0)     9497 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/warp_iterator_from_smem.h
--rw-r--r--   0 root         (0) root         (0)    48655 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/kernel_forward.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.798469 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/transform/
--rw-r--r--   0 root         (0) root         (0)     3747 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/transform/tile_smem_loader.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.801224 flash_attn-2.0.0.post1/csrc/cutlass/examples/42_ampere_tensorop_group_conv/
--rw-rw-r--   0 root         (0) root         (0)    23901 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/42_ampere_tensorop_group_conv/ampere_tensorop_group_conv.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.804019 flash_attn-2.0.0.post1/csrc/cutlass/examples/43_ell_block_sparse_gemm/
--rw-rw-r--   0 root         (0) root         (0)    23867 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/43_ell_block_sparse_gemm/ell_block_sparse_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.806440 flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.366184 flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.367214 flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.811774 flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/
--rw-rw-r--   0 root         (0) root         (0)     6370 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_bias_act_epilogue_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     4099 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_thread_map_tensor_op_for_fused_bias.h
--rw-rw-r--   0 root         (0) root         (0)     8285 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/fused_bias_act_epilogue.h
--rw-rw-r--   0 root         (0) root         (0)    10439 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/output_tile_thread_map_for_fused_bias.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.820958 flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/warp/
--rw-rw-r--   0 root         (0) root         (0)     6848 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/warp/fused_bias_act_fragment_iterator_tensor_op.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.369524 flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.823994 flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/warp/
--rw-rw-r--   0 root         (0) root         (0)    14747 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/warp/mma_tensor_op_fragment_iterator_without_output_op.h
--rw-rw-r--   0 root         (0) root         (0)    10231 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/leaky_bias.h
--rw-rw-r--   0 root         (0) root         (0)     3745 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/utils.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.826453 flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.835617 flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/device/
--rw-r--r--   0 root         (0) root         (0)    16955 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/device/dual_gemm.h
--rw-r--r--   0 root         (0) root         (0)    12669 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/dual_gemm.cu
--rw-rw-r--   0 root         (0) root         (0)     2366 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/dual_gemm_common.h
--rw-r--r--   0 root         (0) root         (0)    31360 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/dual_gemm_run.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.838423 flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/kernel/
--rw-r--r--   0 root         (0) root         (0)    18422 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/kernel/dual_gemm.h
--rw-rw-r--   0 root         (0) root         (0)     3577 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/test_run.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.841261 flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/thread/
--rw-rw-r--   0 root         (0) root         (0)     5818 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/thread/left_silu_and_mul.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.844036 flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/threadblock/
--rw-rw-r--   0 root         (0) root         (0)    15613 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_epilogue.h
--rw-rw-r--   0 root         (0) root         (0)     7920 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_mma_base.h
--rw-r--r--   0 root         (0) root         (0)    29976 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_mma_multistage.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.850905 flash_attn-2.0.0.post1/csrc/cutlass/examples/46_depthwise_simt_conv2dfprop/
--rw-r--r--   0 root         (0) root         (0)    24464 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/46_depthwise_simt_conv2dfprop/depthwise_simt_conv2dfprop.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.853843 flash_attn-2.0.0.post1/csrc/cutlass/examples/47_ampere_gemm_universal_streamk/
--rw-r--r--   0 root         (0) root         (0)    22676 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/47_ampere_gemm_universal_streamk/ampere_gemm_universal_streamk.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.860510 flash_attn-2.0.0.post1/csrc/cutlass/examples/48_hopper_warp_specialized_gemm/
--rw-r--r--   0 root         (0) root         (0)    16736 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/48_hopper_warp_specialized_gemm/48_hopper_warp_specialized_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.863637 flash_attn-2.0.0.post1/csrc/cutlass/examples/49_hopper_gemm_schedules_with_collective_builder/
--rw-r--r--   0 root         (0) root         (0)    22631 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/49_hopper_gemm_schedules_with_collective_builder/49_hopper_gemm_schedules_with_collective_builder.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.866678 flash_attn-2.0.0.post1/csrc/cutlass/examples/50_hopper_gemm_with_epilogue_swizzle/
--rw-r--r--   0 root         (0) root         (0)    18635 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/50_hopper_gemm_with_epilogue_swizzle/50_hopper_gemm_with_epilogue_swizzle.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.869616 flash_attn-2.0.0.post1/csrc/cutlass/examples/60_cutlass_import/
--rw-rw-r--   0 root         (0) root         (0)     2849 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/60_cutlass_import/main.cpp
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.872800 flash_attn-2.0.0.post1/csrc/cutlass/examples/common/
--rw-r--r--   0 root         (0) root         (0)     4449 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/common/helper.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.380215 flash_attn-2.0.0.post1/csrc/cutlass/examples/cute/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.875822 flash_attn-2.0.0.post1/csrc/cutlass/examples/cute/tutorial/
--rw-rw-r--   0 root         (0) root         (0)    14342 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/examples/cute/tutorial/sgemm_nt_1.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.382130 flash_attn-2.0.0.post1/csrc/cutlass/include/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.906281 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.927178 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/algorithm/
--rw-rw-r--   0 root         (0) root         (0)     2838 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/algorithm/axpby.hpp
--rw-rw-r--   0 root         (0) root         (0)     2351 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/algorithm/clear.hpp
--rw-r--r--   0 root         (0) root         (0)     8058 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/algorithm/copy.hpp
--rw-rw-r--   0 root         (0) root         (0)     2906 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/algorithm/fill.hpp
--rw-r--r--   0 root         (0) root         (0)     7206 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/algorithm/functional.hpp
--rw-r--r--   0 root         (0) root         (0)    25632 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/algorithm/gemm.hpp
--rw-r--r--   0 root         (0) root         (0)     2129 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/algorithm/prefer.hpp
--rw-r--r--   0 root         (0) root         (0)     3332 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/algorithm/tensor_algorithms.hpp
--rw-r--r--   0 root         (0) root         (0)    20772 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/algorithm/tuple_algorithms.hpp
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:38.970762 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/
--rw-r--r--   0 root         (0) root         (0)     5809 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/cluster_sm90.hpp
--rw-rw-r--   0 root         (0) root         (0)     2453 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/copy.hpp
--rw-r--r--   0 root         (0) root         (0)     6785 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/copy_sm75.hpp
--rw-rw-r--   0 root         (0) root         (0)     4812 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/copy_sm80.hpp
--rw-rw-r--   0 root         (0) root         (0)     7325 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/copy_sm90.hpp
--rw-r--r--   0 root         (0) root         (0)     7973 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/copy_sm90_desc.hpp
--rw-r--r--   0 root         (0) root         (0)    20296 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/copy_sm90_tma.hpp
--rw-rw-r--   0 root         (0) root         (0)     2393 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/mma.hpp
--rw-rw-r--   0 root         (0) root         (0)     3160 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/mma_sm61.hpp
--rw-rw-r--   0 root         (0) root         (0)    12452 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/mma_sm70.hpp
--rw-rw-r--   0 root         (0) root         (0)     4262 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/mma_sm75.hpp
--rw-rw-r--   0 root         (0) root         (0)    68248 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/mma_sm80.hpp
--rw-r--r--   0 root         (0) root         (0)    36696 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/mma_sm90.hpp
--rw-r--r--   0 root         (0) root         (0)     5323 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/mma_sm90_desc.hpp
--rw-r--r--   0 root         (0) root         (0)   581439 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/mma_sm90_gmma.hpp
--rw-r--r--   0 root         (0) root         (0)     5815 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/util.hpp
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:39.000928 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/
--rw-r--r--   0 root         (0) root         (0)    23436 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/copy_atom.hpp
--rw-r--r--   0 root         (0) root         (0)     2950 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/copy_traits.hpp
--rw-rw-r--   0 root         (0) root         (0)     5087 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/copy_traits_sm75.hpp
--rw-rw-r--   0 root         (0) root         (0)     3689 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/copy_traits_sm80.hpp
--rw-rw-r--   0 root         (0) root         (0)     4589 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/copy_traits_sm90.hpp
--rw-r--r--   0 root         (0) root         (0)    32901 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/copy_traits_sm90_tma.hpp
--rw-r--r--   0 root         (0) root         (0)    38366 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/mma_atom.hpp
--rw-r--r--   0 root         (0) root         (0)     2697 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/mma_traits.hpp
--rw-rw-r--   0 root         (0) root         (0)     2797 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/mma_traits_sm61.hpp
--rw-rw-r--   0 root         (0) root         (0)     6188 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/mma_traits_sm70.hpp
--rw-rw-r--   0 root         (0) root         (0)     3327 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/mma_traits_sm75.hpp
--rw-rw-r--   0 root         (0) root         (0)    14416 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/mma_traits_sm80.hpp
--rw-rw-r--   0 root         (0) root         (0)     5121 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/mma_traits_sm90.hpp
--rw-r--r--   0 root         (0) root         (0)   104752 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/mma_traits_sm90_gmma.hpp
--rw-r--r--   0 root         (0) root         (0)     4255 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/config.hpp
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:39.027625 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/container/
--rw-r--r--   0 root         (0) root         (0)     2988 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/container/alignment.hpp
--rw-r--r--   0 root         (0) root         (0)     5917 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/container/array.hpp
--rw-r--r--   0 root         (0) root         (0)     6508 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/container/array_aligned.hpp
--rw-r--r--   0 root         (0) root         (0)    14960 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/container/array_subbyte.hpp
--rw-r--r--   0 root         (0) root         (0)     5555 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/container/array_view.hpp
--rw-r--r--   0 root         (0) root         (0)     5485 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/container/bit_field.hpp
--rw-r--r--   0 root         (0) root         (0)    19389 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/container/tuple.hpp
--rw-r--r--   0 root         (0) root         (0)     2779 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/container/type_list.hpp
--rw-r--r--   0 root         (0) root         (0)    24937 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/int_tuple.hpp
--rw-r--r--   0 root         (0) root         (0)    50290 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/layout.hpp
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:39.060266 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/
--rw-r--r--   0 root         (0) root         (0)    10917 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/arithmetic_tuple.hpp
--rw-r--r--   0 root         (0) root         (0)     2134 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/bfloat.hpp
--rw-r--r--   0 root         (0) root         (0)     4516 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/complex.hpp
--rw-rw-r--   0 root         (0) root         (0)     2033 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/float8.hpp
--rw-rw-r--   0 root         (0) root         (0)     1997 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/half.hpp
--rw-r--r--   0 root         (0) root         (0)     4280 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/int.hpp
--rw-r--r--   0 root         (0) root         (0)     4216 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/integer_sequence.hpp
--rw-r--r--   0 root         (0) root         (0)     7139 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/integer_subbyte.hpp
--rw-r--r--   0 root         (0) root         (0)    12839 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/integral_constant.hpp
--rw-r--r--   0 root         (0) root         (0)     8826 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/math.hpp
--rw-rw-r--   0 root         (0) root         (0)     2259 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/real.hpp
--rw-r--r--   0 root         (0) root         (0)     2134 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/tfloat.hpp
--rw-rw-r--   0 root         (0) root         (0)     7531 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/uint128.hpp
--rw-r--r--   0 root         (0) root         (0)     7829 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/pointer.hpp
--rw-r--r--   0 root         (0) root         (0)    13950 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/stride.hpp
--rw-r--r--   0 root         (0) root         (0)    17168 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/swizzle.hpp
--rw-r--r--   0 root         (0) root         (0)    35450 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/swizzle_layout.hpp
--rw-r--r--   0 root         (0) root         (0)     9413 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/swizzle_ptr.hpp
--rw-r--r--   0 root         (0) root         (0)    25878 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/tensor.hpp
--rw-rw-r--   0 root         (0) root         (0)     2305 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/tensor_predicate.hpp
--rw-rw-r--   0 root         (0) root         (0)     2279 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/tile.hpp
--rw-r--r--   0 root         (0) root         (0)     5052 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/underscore.hpp
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:39.063414 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/util/
--rw-r--r--   0 root         (0) root         (0)     4867 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/util/debug.hpp
--rw-r--r--   0 root         (0) root         (0)     3486 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/util/print.hpp
--rw-r--r--   0 root         (0) root         (0)     3362 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cute/util/type_traits.hpp
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:40.162036 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/
--rw-rw-r--   0 root         (0) root         (0)     3793 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/aligned_buffer.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:40.206543 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/
--rw-r--r--   0 root         (0) root         (0)     3538 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/arch.h
--rw-r--r--   0 root         (0) root         (0)    12127 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/barrier.h
--rw-rw-r--   0 root         (0) root         (0)     2691 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/cache_operation.h
--rw-r--r--   0 root         (0) root         (0)    14313 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/memory.h
--rw-r--r--   0 root         (0) root         (0)     8511 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/memory_sm75.h
--rw-rw-r--   0 root         (0) root         (0)    15166 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/memory_sm80.h
--rw-r--r--   0 root         (0) root         (0)     8072 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/mma.h
--rw-rw-r--   0 root         (0) root         (0)    11096 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/mma_sm50.h
--rw-rw-r--   0 root         (0) root         (0)     7040 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/mma_sm60.h
--rw-rw-r--   0 root         (0) root         (0)     4193 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/mma_sm61.h
--rw-rw-r--   0 root         (0) root         (0)    16554 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/mma_sm70.h
--rw-rw-r--   0 root         (0) root         (0)    31682 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/mma_sm75.h
--rw-rw-r--   0 root         (0) root         (0)    55577 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/mma_sm80.h
--rw-r--r--   0 root         (0) root         (0)     8254 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/mma_sm90.h
--rw-rw-r--   0 root         (0) root         (0)    43978 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/mma_sparse_sm80.h
--rw-rw-r--   0 root         (0) root         (0)     2622 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/reg_reconfig.h
--rw-rw-r--   0 root         (0) root         (0)     3998 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/simd.h
--rw-rw-r--   0 root         (0) root         (0)     3656 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/simd_sm60.h
--rw-rw-r--   0 root         (0) root         (0)     5102 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/simd_sm61.h
--rw-rw-r--   0 root         (0) root         (0)     8473 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/wmma.h
--rw-rw-r--   0 root         (0) root         (0)     5286 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/wmma_sm70.h
--rw-rw-r--   0 root         (0) root         (0)     7746 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/wmma_sm72.h
--rw-rw-r--   0 root         (0) root         (0)     7616 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/wmma_sm75.h
--rw-rw-r--   0 root         (0) root         (0)    62709 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/array.h
--rw-rw-r--   0 root         (0) root         (0)     3662 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/array_planar_complex.h
--rw-rw-r--   0 root         (0) root         (0)    13128 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/array_subbyte.h
--rw-r--r--   0 root         (0) root         (0)     6371 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/barrier.h
--rw-rw-r--   0 root         (0) root         (0)    13371 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/bfloat16.h
--rw-rw-r--   0 root         (0) root         (0)     6338 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/blas3.h
--rw-rw-r--   0 root         (0) root         (0)     9372 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/block_striped.h
--rw-r--r--   0 root         (0) root         (0)     6113 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/cluster_launch.hpp
--rw-r--r--   0 root         (0) root         (0)    19422 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/complex.h
--rw-rw-r--   0 root         (0) root         (0)    47943 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/constants.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:40.214993 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/
--rw-r--r--   0 root         (0) root         (0)    22725 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/conv2d_problem_size.h
--rw-rw-r--   0 root         (0) root         (0)    16292 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/conv3d_problem_size.h
--rw-r--r--   0 root         (0) root         (0)     6664 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/convolution.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:40.221956 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/device/
--rw-rw-r--   0 root         (0) root         (0)     9744 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/device/direct_convolution.h
--rw-rw-r--   0 root         (0) root         (0)    12078 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/device/implicit_gemm_convolution.h
--rw-rw-r--   0 root         (0) root         (0)    10044 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/device/implicit_gemm_convolution_fusion.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:40.260585 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/
--rw-rw-r--   0 root         (0) root         (0)     7671 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d.h
--rw-rw-r--   0 root         (0) root         (0)    53546 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_dgrad.h
--rw-rw-r--   0 root         (0) root         (0)    56838 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop.h
--rw-rw-r--   0 root         (0) root         (0)    11953 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_fusion.h
--rw-r--r--   0 root         (0) root         (0)     4690 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_broadcast.h
--rw-r--r--   0 root         (0) root         (0)     4660 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_reduction.h
--rw-r--r--   0 root         (0) root         (0)    15891 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_group_fprop.h
--rw-rw-r--   0 root         (0) root         (0)    28745 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad.h
--rw-rw-r--   0 root         (0) root         (0)    10459 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad_fusion.h
--rw-rw-r--   0 root         (0) root         (0)     9324 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_dgrad.h
--rw-rw-r--   0 root         (0) root         (0)    14864 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop.h
--rw-rw-r--   0 root         (0) root         (0)    11980 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop_fusion.h
--rw-rw-r--   0 root         (0) root         (0)    14883 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_wgrad.h
--rw-r--r--   0 root         (0) root         (0)    19294 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_depthwise_fprop.h
--rw-rw-r--   0 root         (0) root         (0)    18048 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/direct_convolution.h
--rw-rw-r--   0 root         (0) root         (0)    15430 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution.h
--rw-rw-r--   0 root         (0) root         (0)    15685 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_fusion.h
--rw-rw-r--   0 root         (0) root         (0)    17107 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_strided_dgrad.h
--rw-rw-r--   0 root         (0) root         (0)    16725 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_with_fused_epilogue.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:40.267999 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/thread/
--rw-rw-r--   0 root         (0) root         (0)     9689 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/thread/depthwise_mma.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:40.357715 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/
--rw-rw-r--   0 root         (0) root         (0)    15306 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_analytic.h
--rw-rw-r--   0 root         (0) root         (0)    19735 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_optimized.h
--rw-rw-r--   0 root         (0) root         (0)    18940 2023-07-17 10:57:19.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_analytic.h
--rw-r--r--   0 root         (0) root         (0)    26137 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_optimized.h
--rw-r--r--   0 root         (0) root         (0)    10953 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_analytic.h
--rw-rw-r--   0 root         (0) root         (0)    11529 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_few_channels.h
--rw-rw-r--   0 root         (0) root         (0)    11333 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_fixed_channels.h
--rw-r--r--   0 root         (0) root         (0)    13664 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_optimized.h
--rw-r--r--   0 root         (0) root         (0)    10627 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_analytic.h
--rw-rw-r--   0 root         (0) root         (0)     9314 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_few_channels.h
--rw-rw-r--   0 root         (0) root         (0)     9018 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_fixed_channels.h
--rw-r--r--   0 root         (0) root         (0)    10387 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_optimized.h
--rw-rw-r--   0 root         (0) root         (0)    30197 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_params.h
--rw-rw-r--   0 root         (0) root         (0)    11202 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_tile_iterator.h
--rw-r--r--   0 root         (0) root         (0)    10350 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_analytic.h
--rw-r--r--   0 root         (0) root         (0)    11520 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_optimized.h
--rw-r--r--   0 root         (0) root         (0)     9043 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_analytic.h
--rw-r--r--   0 root         (0) root         (0)    10832 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_optimized.h
--rw-rw-r--   0 root         (0) root         (0)     8450 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_analytic.h
--rw-rw-r--   0 root         (0) root         (0)     9569 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_optimized.h
--rw-rw-r--   0 root         (0) root         (0)    11020 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_analytic.h
--rw-rw-r--   0 root         (0) root         (0)    15014 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_optimized.h
--rw-rw-r--   0 root         (0) root         (0)     9634 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_analytic.h
--rw-rw-r--   0 root         (0) root         (0)    15132 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_optimized.h
--rw-rw-r--   0 root         (0) root         (0)     7945 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_analytic.h
--rw-rw-r--   0 root         (0) root         (0)     8891 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_optimized.h
--rw-rw-r--   0 root         (0) root         (0)    18249 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_params.h
--rw-r--r--   0 root         (0) root         (0)     9971 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_analytic.h
--rw-r--r--   0 root         (0) root         (0)    12024 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_optimized.h
--rw-r--r--   0 root         (0) root         (0)     8821 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_analytic.h
--rw-r--r--   0 root         (0) root         (0)    10744 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_optimized.h
--rw-rw-r--   0 root         (0) root         (0)     8871 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_direct_conv_params.h
--rw-rw-r--   0 root         (0) root         (0)    10747 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_fixed_stride_dilation.h
--rw-rw-r--   0 root         (0) root         (0)     9899 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_optimized.h
--rw-rw-r--   0 root         (0) root         (0)    20899 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_direct_conv_multistage.h
--rw-rw-r--   0 root         (0) root         (0)     8921 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_filter_tile_access_iterator_direct_conv_optimized.h
--rw-r--r--   0 root         (0) root         (0)    12744 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_pipelined.h
--rw-rw-r--   0 root         (0) root         (0)     8097 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_mma_base.h
--rw-rw-r--   0 root         (0) root         (0)    36697 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_mma_core_with_lane_access_size.h
--rw-rw-r--   0 root         (0) root         (0)    30106 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_fprop_fusion_multistage.h
--rw-r--r--   0 root         (0) root         (0)    20086 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_multistage.h
--rw-r--r--   0 root         (0) root         (0)    12174 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_pipelined.h
--rw-rw-r--   0 root         (0) root         (0)    26320 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_wgrad_fusion_multistage.h
--rw-rw-r--   0 root         (0) root         (0)    16915 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_access_iterator.h
--rw-rw-r--   0 root         (0) root         (0)    12476 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_iterator.h
--rw-r--r--   0 root         (0) root         (0)     8050 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/threadblock_swizzle.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:40.362254 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/warp/
--rw-rw-r--   0 root         (0) root         (0)    12419 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/warp/mma_depthwise_simt.h
--rw-rw-r--   0 root         (0) root         (0)    30655 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/warp/mma_depthwise_simt_tile_iterator.h
--rw-rw-r--   0 root         (0) root         (0)     8772 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/warp/scale_bias_relu_transform.h
--rw-rw-r--   0 root         (0) root         (0)    11827 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/coord.h
--rw-r--r--   0 root         (0) root         (0)    11077 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/core_io.h
--rw-r--r--   0 root         (0) root         (0)     8697 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/cutlass.h
--rw-r--r--   0 root         (0) root         (0)     4216 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/device_kernel.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:40.368770 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:40.371832 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/collective/
--rw-r--r--   0 root         (0) root         (0)     2610 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/collective/collective_epilogue.hpp
--rw-r--r--   0 root         (0) root         (0)     7786 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/collective/default_epilogue.hpp
--rw-r--r--   0 root         (0) root         (0)     8109 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/collective/default_transposed_epilogue.hpp
--rw-r--r--   0 root         (0) root         (0)    13059 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/collective/epilogue.hpp
--rw-r--r--   0 root         (0) root         (0)     2134 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/dispatch_policy.hpp
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:40.422626 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/
--rw-r--r--   0 root         (0) root         (0)    18909 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/activation.h
--rw-rw-r--   0 root         (0) root         (0)     4691 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/conversion_op.h
--rw-r--r--   0 root         (0) root         (0)    11563 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination.h
--rw-r--r--   0 root         (0) root         (0)     8423 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_elementwise.h
--rw-r--r--   0 root         (0) root         (0)    13569 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_relu.h
--rw-r--r--   0 root         (0) root         (0)    23649 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_clamp.h
--rw-r--r--   0 root         (0) root         (0)     9067 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_dgelu.h
--rw-r--r--   0 root         (0) root         (0)    15195 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_drelu.h
--rw-rw-r--   0 root         (0) root         (0)     3669 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_gelu.h
--rw-r--r--   0 root         (0) root         (0)     8065 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_generic.h
--rw-rw-r--   0 root         (0) root         (0)     3693 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_hardswish.h
--rw-r--r--   0 root         (0) root         (0)     8344 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_leaky_relu.h
--rw-r--r--   0 root         (0) root         (0)     3058 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_params.h
--rw-rw-r--   0 root         (0) root         (0)     9351 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_planar_complex.h
--rw-r--r--   0 root         (0) root         (0)    20486 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_relu.h
--rw-r--r--   0 root         (0) root         (0)    19348 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_relu0.h
--rw-r--r--   0 root         (0) root         (0)    12033 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_residual_block.h
--rw-rw-r--   0 root         (0) root         (0)     3688 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_sigmoid.h
--rw-rw-r--   0 root         (0) root         (0)     3669 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_silu.h
--rw-r--r--   0 root         (0) root         (0)     8662 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_with_elementwise.h
--rw-rw-r--   0 root         (0) root         (0)     3416 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/reduction_op.h
--rw-rw-r--   0 root         (0) root         (0)     2656 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/scale_type.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:40.516937 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/
--rw-r--r--   0 root         (0) root         (0)     9142 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op.h
--rw-r--r--   0 root         (0) root         (0)     9441 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op_blas3.h
--rw-rw-r--   0 root         (0) root         (0)     3234 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_direct_store.h
--rw-rw-r--   0 root         (0) root         (0)     7209 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_planar_complex.h
--rw-rw-r--   0 root         (0) root         (0)    13385 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_simt.h
--rw-rw-r--   0 root         (0) root         (0)    28290 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     7129 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op_blas3.h
--rw-rw-r--   0 root         (0) root         (0)    10846 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_volta_tensor_op.h
--rw-r--r--   0 root         (0) root         (0)     5817 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_broadcast.h
--rw-rw-r--   0 root         (0) root         (0)     5763 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_reduction.h
--rw-rw-r--   0 root         (0) root         (0)     5947 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_wmma_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     4409 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_simt.h
--rw-rw-r--   0 root         (0) root         (0)     7398 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     7303 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_volta_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     4098 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_wmma_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     4678 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/direct_store_epilogue_iterator.h
--rw-r--r--   0 root         (0) root         (0)    20099 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue.h
--rw-rw-r--   0 root         (0) root         (0)     8279 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_base.h
--rw-rw-r--   0 root         (0) root         (0)     7455 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_base_streamk.h
--rw-rw-r--   0 root         (0) root         (0)    13424 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_depthwise.h
--rw-rw-r--   0 root         (0) root         (0)    13933 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_direct_store.h
--rw-rw-r--   0 root         (0) root         (0)     7401 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_gemm_k_reduction.h
--rw-rw-r--   0 root         (0) root         (0)    14610 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_planar_complex.h
--rw-rw-r--   0 root         (0) root         (0)     9073 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_smem_accumulator.h
--rw-rw-r--   0 root         (0) root         (0)    16804 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_visitor_with_softmax.h
--rw-r--r--   0 root         (0) root         (0)    52430 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_broadcast.h
--rw-rw-r--   0 root         (0) root         (0)    29199 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_reduction.h
--rw-rw-r--   0 root         (0) root         (0)    13454 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_visitor.h
--rw-rw-r--   0 root         (0) root         (0)     7308 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_workspace.h
--rw-rw-r--   0 root         (0) root         (0)    14359 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/interleaved_epilogue.h
--rw-rw-r--   0 root         (0) root         (0)     2912 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/output_iterator_parameter.h
--rw-rw-r--   0 root         (0) root         (0)    19750 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/output_tile_thread_map.h
--rw-r--r--   0 root         (0) root         (0)    40870 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator.h
--rw-rw-r--   0 root         (0) root         (0)    18821 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine.h
--rw-rw-r--   0 root         (0) root         (0)     5636 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine_layout_params.h
--rw-rw-r--   0 root         (0) root         (0)    21249 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_blas3.h
--rw-r--r--   0 root         (0) root         (0)    13872 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_direct_conv.h
--rw-rw-r--   0 root         (0) root         (0)    14496 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_params.h
--rw-rw-r--   0 root         (0) root         (0)     9146 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_predicates.h
--rw-r--r--   0 root         (0) root         (0)    15536 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_strided_dgrad.h
--rw-rw-r--   0 root         (0) root         (0)     7487 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator.h
--rw-r--r--   0 root         (0) root         (0)    17756 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_mixed.h
--rw-rw-r--   0 root         (0) root         (0)     7394 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_pitch_liner.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:40.551858 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/
--rw-rw-r--   0 root         (0) root         (0)     7055 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_complex_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     7736 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_gaussian_complex_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     5880 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_simt.h
--rw-rw-r--   0 root         (0) root         (0)     9883 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     8924 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_volta_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     6045 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_wmma_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     4864 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/simt_policy.h
--rw-rw-r--   0 root         (0) root         (0)     5979 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/tensor_op_policy.h
--rw-rw-r--   0 root         (0) root         (0)    25658 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_simt.h
--rw-rw-r--   0 root         (0) root         (0)    20290 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op.h
--rw-r--r--   0 root         (0) root         (0)    22922 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op_mixed.h
--rw-rw-r--   0 root         (0) root         (0)    14258 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_volta_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     7704 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_wmma_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     7485 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/volta_tensor_op_policy.h
--rw-rw-r--   0 root         (0) root         (0)     3916 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/wmma_tensor_op_policy.h
--rw-rw-r--   0 root         (0) root         (0)    26026 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/fast_math.h
--rw-r--r--   0 root         (0) root         (0)    35369 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/float8.h
--rw-rw-r--   0 root         (0) root         (0)     2645 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/floating_point_nvrtc.h
--rw-r--r--   0 root         (0) root         (0)    12668 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/functional.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:40.556826 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:40.571419 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/collective/
--rw-r--r--   0 root         (0) root         (0)     3406 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/collective/collective_builder.hpp
--rw-r--r--   0 root         (0) root         (0)     3055 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/collective/collective_mma.hpp
--rw-r--r--   0 root         (0) root         (0)    22013 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/collective/sm70_mma_twostage.hpp
--rw-r--r--   0 root         (0) root         (0)    27329 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/collective/sm80_mma_multistage.hpp
--rw-r--r--   0 root         (0) root         (0)    23874 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_multistage_gmma_ss.hpp
--rw-r--r--   0 root         (0) root         (0)    20444 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_ss.hpp
--rw-r--r--   0 root         (0) root         (0)    20900 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_ss_warpspecialized.hpp
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:42.638561 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/
--rw-r--r--   0 root         (0) root         (0)    17028 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/base_grouped.h
--rw-r--r--   0 root         (0) root         (0)    24413 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/default_gemm_configuration.h
--rw-r--r--   0 root         (0) root         (0)    27616 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/ell_gemm.h
--rw-r--r--   0 root         (0) root         (0)    25202 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm.h
--rw-r--r--   0 root         (0) root         (0)    22367 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_array.h
--rw-r--r--   0 root         (0) root         (0)    22375 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_batched.h
--rw-r--r--   0 root         (0) root         (0)    22725 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_complex.h
--rw-rw-r--   0 root         (0) root         (0)     2591 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_grouped.h
--rw-r--r--   0 root         (0) root         (0)    13736 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_layernorm_mainloop_fusion.h
--rw-rw-r--   0 root         (0) root         (0)    17329 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_sparse.h
--rw-rw-r--   0 root         (0) root         (0)    20450 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_splitk_parallel.h
--rw-r--r--   0 root         (0) root         (0)    14902 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal.h
--rw-r--r--   0 root         (0) root         (0)    21594 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_adapter.h
--rw-r--r--   0 root         (0) root         (0)    13362 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_base.h
--rw-r--r--   0 root         (0) root         (0)    13968 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_with_broadcast.h
--rw-r--r--   0 root         (0) root         (0)    14853 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_with_k_reduction.h
--rw-r--r--   0 root         (0) root         (0)     5690 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemv.h
--rw-r--r--   0 root         (0) root         (0)    18127 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/rank_2k.h
--rw-rw-r--   0 root         (0) root         (0)     2747 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/rank_2k_grouped.h
--rw-r--r--   0 root         (0) root         (0)    16719 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/rank_k.h
--rwxr-xr-x   0 root         (0) root         (0)    21050 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/symm.h
--rw-r--r--   0 root         (0) root         (0)    26464 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/trmm.h
--rw-r--r--   0 root         (0) root         (0)     5207 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/dispatch_policy.hpp
--rw-r--r--   0 root         (0) root         (0)    15946 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/gemm.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:42.765412 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/
--rw-rw-r--   0 root         (0) root         (0)    29360 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_ell_gemm.h
--rw-r--r--   0 root         (0) root         (0)    37758 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm.h
--rw-rw-r--   0 root         (0) root         (0)    16130 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_complex.h
--rw-rw-r--   0 root         (0) root         (0)    12385 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped.h
--rw-rw-r--   0 root         (0) root         (0)     6592 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped_softmax_mainloop_fusion.h
--rw-rw-r--   0 root         (0) root         (0)     5848 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_layernorm_mainloop_fusion.h
--rw-rw-r--   0 root         (0) root         (0)    11104 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_planar_complex_universal.h
--rw-rw-r--   0 root         (0) root         (0)     7983 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_sparse.h
--rw-rw-r--   0 root         (0) root         (0)     4932 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_splitk_parallel.h
--rw-r--r--   0 root         (0) root         (0)    11951 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_universal.h
--rw-r--r--   0 root         (0) root         (0)     8125 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_broadcast.h
--rw-rw-r--   0 root         (0) root         (0)     6457 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_k_reduction.h
--rw-r--r--   0 root         (0) root         (0)     8086 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_reduction.h
--rwxrwxr-x   0 root         (0) root         (0)     5349 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemv.h
--rw-rw-r--   0 root         (0) root         (0)    11560 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k.h
--rw-rw-r--   0 root         (0) root         (0)    20509 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_complex.h
--rw-rw-r--   0 root         (0) root         (0)    12470 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_grouped.h
--rw-rw-r--   0 root         (0) root         (0)    10620 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_universal.h
--rw-rw-r--   0 root         (0) root         (0)     9872 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k.h
--rw-rw-r--   0 root         (0) root         (0)    16990 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k_complex.h
--rw-rw-r--   0 root         (0) root         (0)     9444 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k_universal.h
--rwxrwxr-x   0 root         (0) root         (0)    13375 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_symm.h
--rwxrwxr-x   0 root         (0) root         (0)    21830 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_symm_complex.h
--rwxrwxr-x   0 root         (0) root         (0)    10315 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_symm_universal.h
--rw-rw-r--   0 root         (0) root         (0)    10873 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm.h
--rw-rw-r--   0 root         (0) root         (0)    10730 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm_complex.h
--rw-rw-r--   0 root         (0) root         (0)    10850 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm_universal.h
--rw-rw-r--   0 root         (0) root         (0)    28916 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/ell_gemm.h
--rw-rw-r--   0 root         (0) root         (0)    13357 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm.h
--rw-rw-r--   0 root         (0) root         (0)     8693 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_array.h
--rw-rw-r--   0 root         (0) root         (0)     8761 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_batched.h
--rw-rw-r--   0 root         (0) root         (0)    14687 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped.h
--rw-rw-r--   0 root         (0) root         (0)     4691 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped_problem_visitor.h
--rw-rw-r--   0 root         (0) root         (0)    15623 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped_softmax_mainloop_fusion.h
--rw-r--r--   0 root         (0) root         (0)    27281 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_layernorm_mainloop_fusion.h
--rwxrwxr-x   0 root         (0) root         (0)     6144 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_params.h
--rw-rw-r--   0 root         (0) root         (0)     5141 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_pipelined.h
--rw-r--r--   0 root         (0) root         (0)    22949 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex.h
--rw-r--r--   0 root         (0) root         (0)    18937 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex_array.h
--rw-rw-r--   0 root         (0) root         (0)     8142 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_splitk_parallel.h
--rw-rw-r--   0 root         (0) root         (0)     4291 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_transpose_operands.h
--rw-r--r--   0 root         (0) root         (0)    23216 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal.h
--rw-r--r--   0 root         (0) root         (0)     3418 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal.hpp
--rw-r--r--   0 root         (0) root         (0)    39288 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal_streamk.h
--rw-r--r--   0 root         (0) root         (0)    47186 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_with_fused_epilogue.h
--rw-r--r--   0 root         (0) root         (0)    23605 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_with_k_reduction.h
--rw-r--r--   0 root         (0) root         (0)     8090 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemv.h
--rwxrwxr-x   0 root         (0) root         (0)     8979 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemv_batched_strided.h
--rw-r--r--   0 root         (0) root         (0)    16849 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/grouped_problem_visitor.h
--rw-rw-r--   0 root         (0) root         (0)     7148 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/params_universal_base.h
--rw-rw-r--   0 root         (0) root         (0)    22938 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped.h
--rw-rw-r--   0 root         (0) root         (0)    16100 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped_problem_visitor.h
--rw-rw-r--   0 root         (0) root         (0)     4334 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_transpose_operands.h
--rw-rw-r--   0 root         (0) root         (0)    24138 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_universal.h
--rw-rw-r--   0 root         (0) root         (0)    17543 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/rank_k_universal.h
--rw-r--r--   0 root         (0) root         (0)     9808 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm70_gemm.hpp
--rw-r--r--   0 root         (0) root         (0)    11878 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma.hpp
--rw-r--r--   0 root         (0) root         (0)    14177 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma_warpspecialized.hpp
--rw-r--r--   0 root         (0) root         (0)    21143 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma_warpspecialized_persistent.hpp
--rw-r--r--   0 root         (0) root         (0)     5709 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_tile_scheduler.hpp
--rw-rw-r--   0 root         (0) root         (0)    13586 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/sparse_gemm.h
--rwxrwxr-x   0 root         (0) root         (0)    23876 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/symm_universal.h
--rw-rw-r--   0 root         (0) root         (0)    19513 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/trmm_universal.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:42.772275 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/thread/
--rw-rw-r--   0 root         (0) root         (0)     3567 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/thread/mma.h
--rw-rw-r--   0 root         (0) root         (0)    15373 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/thread/mma_sm50.h
--rw-rw-r--   0 root         (0) root         (0)    29987 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/thread/mma_sm60.h
--rw-rw-r--   0 root         (0) root         (0)     8142 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/thread/mma_sm61.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:42.880566 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/
--rw-rw-r--   0 root         (0) root         (0)    31930 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_ell_mma.h
--rwxrwxr-x   0 root         (0) root         (0)     6979 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_gemv_core.h
--rw-r--r--   0 root         (0) root         (0)    34241 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma.h
--rw-rw-r--   0 root         (0) root         (0)     5123 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core.h
--rw-rw-r--   0 root         (0) root         (0)    57426 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_simt.h
--rw-rw-r--   0 root         (0) root         (0)    19257 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm70.h
--rw-rw-r--   0 root         (0) root         (0)    42310 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm75.h
--rw-rw-r--   0 root         (0) root         (0)   103000 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm80.h
--rw-rw-r--   0 root         (0) root         (0)    32106 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sparse_sm80.h
--rw-r--r--   0 root         (0) root         (0)    12645 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_access_size.h
--rw-rw-r--   0 root         (0) root         (0)     7387 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_reduction.h
--rw-rw-r--   0 root         (0) root         (0)    20975 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_wmma.h
--rw-rw-r--   0 root         (0) root         (0)     7998 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_layernorm_mainloop_fusion.h
--rw-rw-r--   0 root         (0) root         (0)     5110 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_multistage.h
--rw-rw-r--   0 root         (0) root         (0)     4627 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_pipelined.h
--rw-rw-r--   0 root         (0) root         (0)     7113 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_softmax_mainloop_fusion.h
--rw-rw-r--   0 root         (0) root         (0)     6323 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_with_reduction.h
--rw-rw-r--   0 root         (0) root         (0)     7121 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex.h
--rw-rw-r--   0 root         (0) root         (0)     4959 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core.h
--rw-rw-r--   0 root         (0) root         (0)    65201 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core_sm80.h
--rw-rw-r--   0 root         (0) root         (0)    25495 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_trmm_complex.h
--rw-rw-r--   0 root         (0) root         (0)     8509 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_sparse_mma.h
--rw-rw-r--   0 root         (0) root         (0)    19515 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_trmm.h
--rw-r--r--   0 root         (0) root         (0)    24047 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/ell_mma_multistage.h
--rw-r--r--   0 root         (0) root         (0)    13836 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/ell_mma_pipelined.h
--rwxrwxr-x   0 root         (0) root         (0)     4726 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/gemv.h
--rw-rw-r--   0 root         (0) root         (0)     3652 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/index_remat.h
--rw-rw-r--   0 root         (0) root         (0)     7823 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_base.h
--rw-r--r--   0 root         (0) root         (0)    27415 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_blas3_multistage.h
--rw-r--r--   0 root         (0) root         (0)    32894 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_layernorm_mainloop_fusion_multistage.h
--rw-r--r--   0 root         (0) root         (0)    28015 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_multistage.h
--rw-rw-r--   0 root         (0) root         (0)    15995 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_pipelined.h
--rw-rw-r--   0 root         (0) root         (0)     6901 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_base.h
--rw-r--r--   0 root         (0) root         (0)    22653 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_multistage.h
--rw-r--r--   0 root         (0) root         (0)    14746 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_pipelined.h
--rw-rw-r--   0 root         (0) root         (0)     9864 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_singlestage.h
--rw-r--r--   0 root         (0) root         (0)    27061 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_softmax_mainloop_fusion_multistage.h
--rw-rw-r--   0 root         (0) root         (0)     9210 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_sparse_base.h
--rw-r--r--   0 root         (0) root         (0)    25333 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_sparse_multistage.h
--rw-r--r--   0 root         (0) root         (0)    20473 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_with_reduction_multistage.h
--rw-r--r--   0 root         (0) root         (0)    15007 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle.h
--rw-r--r--   0 root         (0) root         (0)    26450 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle_streamk.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:42.951177 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/
--rw-rw-r--   0 root         (0) root         (0)    20553 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_complex_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     6684 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_sparse_tensor_op.h
--rw-r--r--   0 root         (0) root         (0)     5160 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     9026 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op_sm80.h
--rw-rw-r--   0 root         (0) root         (0)     4053 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_with_reduction_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     4685 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_wmma_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     5725 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/layernorm_scale_bias_transform.h
--rw-rw-r--   0 root         (0) root         (0)     2619 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma.h
--rw-r--r--   0 root         (0) root         (0)    37705 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)    23132 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_fast_f32.h
--rw-rw-r--   0 root         (0) root         (0)    78615 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_tile_iterator_sm80.h
--rw-rw-r--   0 root         (0) root         (0)    21205 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)    14589 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op_tile_iterator_sm80.h
--rw-rw-r--   0 root         (0) root         (0)     6144 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_planar_complex.h
--rw-rw-r--   0 root         (0) root         (0)     8446 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_simt.h
--rw-rw-r--   0 root         (0) root         (0)     3079 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_simt_policy.h
--rw-rw-r--   0 root         (0) root         (0)    59793 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_simt_tile_iterator.h
--rw-rw-r--   0 root         (0) root         (0)    11758 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_sparse_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)    14407 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)    15721 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fast_f32.h
--rw-rw-r--   0 root         (0) root         (0)    18643 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fragment_iterator.h
--rw-rw-r--   0 root         (0) root         (0)     2939 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_policy.h
--rw-rw-r--   0 root         (0) root         (0)     8966 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_sm70.h
--rw-rw-r--   0 root         (0) root         (0)    11017 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_access_iterator.h
--rw-rw-r--   0 root         (0) root         (0)   136033 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator.h
--rw-rw-r--   0 root         (0) root         (0)    99649 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm70.h
--rw-rw-r--   0 root         (0) root         (0)    75179 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm80.h
--rw-rw-r--   0 root         (0) root         (0)    13151 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sparse.h
--rw-rw-r--   0 root         (0) root         (0)    27101 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_wmma.h
--rw-rw-r--   0 root         (0) root         (0)     7241 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_wmma.h
--rw-rw-r--   0 root         (0) root         (0)    17303 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_with_reduction_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)    19125 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/scale_bias_tile_iterator.h
--rw-rw-r--   0 root         (0) root         (0)     4610 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/softmax_scale_bias_transform.h
--rw-rw-r--   0 root         (0) root         (0)     8728 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/tile_iterator_planar_complex.h
--rw-rw-r--   0 root         (0) root         (0)    23615 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/half.h
--rw-rw-r--   0 root         (0) root         (0)     6893 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/integer_subbyte.h
--rw-r--r--   0 root         (0) root         (0)     2669 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/kernel_hardware_info.hpp
--rw-rw-r--   0 root         (0) root         (0)     2801 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/kernel_launch.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:42.981219 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/layout/
--rw-rw-r--   0 root         (0) root         (0)     3020 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/layout/layout.h
--rw-r--r--   0 root         (0) root         (0)    35369 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/layout/matrix.h
--rw-r--r--   0 root         (0) root         (0)     9133 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/layout/permute.h
--rw-rw-r--   0 root         (0) root         (0)     4696 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/layout/pitch_linear.h
--rw-rw-r--   0 root         (0) root         (0)    18295 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/layout/tensor.h
--rw-rw-r--   0 root         (0) root         (0)    29599 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm70.h
--rw-rw-r--   0 root         (0) root         (0)    33137 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm75.h
--rw-rw-r--   0 root         (0) root         (0)    29336 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm80.h
--rw-rw-r--   0 root         (0) root         (0)     3328 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/layout/vector.h
--rw-rw-r--   0 root         (0) root         (0)   364115 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/matrix.h
--rw-rw-r--   0 root         (0) root         (0)     4991 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/matrix_coord.h
--rw-rw-r--   0 root         (0) root         (0)     2726 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/matrix_shape.h
--rw-r--r--   0 root         (0) root         (0)    71278 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/numeric_conversion.h
--rw-rw-r--   0 root         (0) root         (0)     3505 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/numeric_types.h
--rw-r--r--   0 root         (0) root         (0)    16389 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/pipeline.hpp
--rw-rw-r--   0 root         (0) root         (0)     5492 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/pitch_linear_coord.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:42.984102 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/platform/
--rw-r--r--   0 root         (0) root         (0)    26097 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/platform/platform.h
--rw-rw-r--   0 root         (0) root         (0)    15565 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/predicate_vector.h
--rw-rw-r--   0 root         (0) root         (0)    20900 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/quaternion.h
--rw-rw-r--   0 root         (0) root         (0)     2369 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/real.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:42.986597 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:42.989356 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/device/
--rw-rw-r--   0 root         (0) root         (0)     6823 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/device/reduce_split_k.h
--rw-rw-r--   0 root         (0) root         (0)     8152 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce.h
--rw-rw-r--   0 root         (0) root         (0)    11579 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_contiguous.h
--rw-rw-r--   0 root         (0) root         (0)    11448 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_strided.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:42.998054 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/kernel/
--rw-rw-r--   0 root         (0) root         (0)     8762 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/kernel/reduce_softmax_final.h
--rw-rw-r--   0 root         (0) root         (0)     7897 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/kernel/reduce_split_k.h
--rw-r--r--   0 root         (0) root         (0)    20685 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_contiguous.h
--rw-r--r--   0 root         (0) root         (0)    21662 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_strided.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:43.006546 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/thread/
--rw-rw-r--   0 root         (0) root         (0)     7208 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/thread/reduce.h
--rw-rw-r--   0 root         (0) root         (0)     6790 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/thread/reduction_operators.h
--rw-rw-r--   0 root         (0) root         (0)     2936 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/threadblock_swizzle.h
--rw-r--r--   0 root         (0) root         (0)     5929 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/relatively_equal.h
--rw-r--r--   0 root         (0) root         (0)     4186 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/semaphore.h
--rw-rw-r--   0 root         (0) root         (0)    17243 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/subbyte_reference.h
--rw-rw-r--   0 root         (0) root         (0)     8964 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/tensor_coord.h
--rw-rw-r--   0 root         (0) root         (0)    12207 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/tensor_ref.h
--rw-rw-r--   0 root         (0) root         (0)    11201 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/tensor_ref_planar_complex.h
--rw-rw-r--   0 root         (0) root         (0)     9509 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/tensor_view.h
--rw-rw-r--   0 root         (0) root         (0)    10250 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/tensor_view_planar_complex.h
--rw-rw-r--   0 root         (0) root         (0)    13017 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/tfloat32.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:43.011265 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/thread/
--rw-rw-r--   0 root         (0) root         (0)     5931 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/thread/matrix.h
--rw-rw-r--   0 root         (0) root         (0)     2581 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/trace.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:43.013592 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/
--rw-rw-r--   0 root         (0) root         (0)    33349 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/pitch_linear_thread_map.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:43.016487 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/thread/
--rw-rw-r--   0 root         (0) root         (0)     3835 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/thread/transpose.h
--rw-rw-r--   0 root         (0) root         (0)     4309 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/thread/unary_op.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:43.072397 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/
--rw-rw-r--   0 root         (0) root         (0)     6181 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/ell_iterator.h
--rw-rw-r--   0 root         (0) root         (0)    44443 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_access_iterator.h
--rw-rw-r--   0 root         (0) root         (0)    44309 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_iterator.h
--rw-rw-r--   0 root         (0) root         (0)    12890 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_access_iterator.h
--rw-rw-r--   0 root         (0) root         (0)    11097 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_iterator.h
--rw-r--r--   0 root         (0) root         (0)    70684 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator.h
--rw-rw-r--   0 root         (0) root         (0)    28232 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_2dthreadtile.h
--rwxrwxr-x   0 root         (0) root         (0)    10243 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_params.h
--rw-rw-r--   0 root         (0) root         (0)    31412 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_triangular_matrix.h
--rw-r--r--   0 root         (0) root         (0)    62672 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator.h
--rw-rw-r--   0 root         (0) root         (0)    27175 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_2dthreadtile.h
--rw-rw-r--   0 root         (0) root         (0)    28064 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_triangular_matrix.h
--rw-rw-r--   0 root         (0) root         (0)    13088 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_vector_access_iterator.h
--rw-rw-r--   0 root         (0) root         (0)     8232 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_scale_bias_vector_access_iterator.h
--rw-rw-r--   0 root         (0) root         (0)     2638 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator.h
--rw-rw-r--   0 root         (0) root         (0)    13283 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear.h
--rw-rw-r--   0 root         (0) root         (0)    18623 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear_direct_conv.h
--rw-rw-r--   0 root         (0) root         (0)    27922 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)    47789 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op_sm80.h
--rw-rw-r--   0 root         (0) root         (0)     2616 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator.h
--rw-r--r--   0 root         (0) root         (0)    16510 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear.h
--rw-rw-r--   0 root         (0) root         (0)    15486 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear_2dthreadtile.h
--rw-rw-r--   0 root         (0) root         (0)    36050 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op.h
--rw-r--r--   0 root         (0) root         (0)    43663 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op_sm70.h
--rw-rw-r--   0 root         (0) root         (0)     5226 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/vector_iterator.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:43.077038 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/warp/
--rw-rw-r--   0 root         (0) root         (0)     8828 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/warp/vector_fragment_iterator.h
--rw-r--r--   0 root         (0) root         (0)     8179 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/uint128.h
--rw-rw-r--   0 root         (0) root         (0)     4543 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/wmma_array.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.412979 flash_attn-2.0.0.post1/csrc/cutlass/test/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:43.079628 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:43.082346 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/common/
--rw-rw-r--   0 root         (0) root         (0)     4900 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/common/cutlass_unit_test.h
--rw-rw-r--   0 root         (0) root         (0)     5381 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/common/filter_architecture.cpp
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.415796 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:43.219956 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/
--rw-rw-r--   0 root         (0) root         (0)    21797 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/cache_testbed_output.h
--rw-rw-r--   0 root         (0) root         (0)     5344 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     5443 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    11470 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5239 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     9110 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     8485 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5243 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5378 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12054 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_few_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     9603 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_fixed_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5267 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     5357 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5089 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
--rw-rw-r--   0 root         (0) root         (0)    13690 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5390 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5191 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    11136 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     5291 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     3551 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     5157 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
--rwxrwxr-x   0 root         (0) root         (0)     8278 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_qf32nhwc_qf32nhwc_qf32nhwc_simt_f32_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    20555 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    20647 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5155 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     5239 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    26114 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    26210 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5111 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     5194 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5738 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5439 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     7363 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     3984 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_reduction_sm75.cu
--rw-r--r--   0 root         (0) root         (0)    39452 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_problems.h
--rw-rw-r--   0 root         (0) root         (0)    14471 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4662 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    26224 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_testbed.h
--rw-r--r--   0 root         (0) root         (0)    22092 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_testbed_interleaved.h
--rw-rw-r--   0 root         (0) root         (0)     5179 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     5358 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5264 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     3615 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     7591 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    10514 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5157 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5772 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    23526 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_with_broadcast_testbed.h
--rw-r--r--   0 root         (0) root         (0)    21512 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_with_reduction_testbed.h
--rw-rw-r--   0 root         (0) root         (0)     5135 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5347 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     3736 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     6560 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5257 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12276 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv3d_problems.h
--rw-r--r--   0 root         (0) root         (0)    21643 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv3d_testbed.h
--rw-rw-r--   0 root         (0) root         (0)     3622 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     6560 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5256 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    17700 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_direct_conv_testbed.h
--rw-rw-r--   0 root         (0) root         (0)    18451 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
--rw-rw-r--   0 root         (0) root         (0)    22194 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_fixed_stride_dilation_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
--rw-rw-r--   0 root         (0) root         (0)     9383 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
--rw-r--r--   0 root         (0) root         (0)    16100 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/group_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:43.246880 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/
--rw-rw-r--   0 root         (0) root         (0)     7365 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/array.cu
--rw-rw-r--   0 root         (0) root         (0)     7353 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/bfloat16.cu
--rw-rw-r--   0 root         (0) root         (0)     6981 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/complex.cu
--rw-rw-r--   0 root         (0) root         (0)     4009 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/float8.cu
--rw-rw-r--   0 root         (0) root         (0)    13001 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/functional.cu
--rw-rw-r--   0 root         (0) root         (0)     3553 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/half.cu
--rw-rw-r--   0 root         (0) root         (0)     5295 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/matrix.cu
--rw-rw-r--   0 root         (0) root         (0)     8592 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/matrix_coord.cu
--rw-rw-r--   0 root         (0) root         (0)    10684 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/numeric_conversion.cu
--rw-rw-r--   0 root         (0) root         (0)     8148 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/predicate_vector.cu
--rw-rw-r--   0 root         (0) root         (0)     5777 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/quaternion.cu
--rw-rw-r--   0 root         (0) root         (0)     6746 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/tensor_ref.cu
--rw-rw-r--   0 root         (0) root         (0)     8885 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/tensor_view.cu
--rw-rw-r--   0 root         (0) root         (0)     2050 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/test_unit_core.cpp
--rw-rw-r--   0 root         (0) root         (0)     7088 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/tfloat32.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.423211 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:43.253647 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/ampere/
--rw-rw-r--   0 root         (0) root         (0)     3527 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/ampere/cp_async.cu
--rw-rw-r--   0 root         (0) root         (0)    14320 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/ampere/ldsm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:43.274487 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/
--rw-rw-r--   0 root         (0) root         (0)     3332 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/bitfield.cpp
--rw-rw-r--   0 root         (0) root         (0)     4861 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/coalesce.cpp
--rw-rw-r--   0 root         (0) root         (0)     5620 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/compare.cpp
--rw-rw-r--   0 root         (0) root         (0)     7178 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/complement.cpp
--rw-rw-r--   0 root         (0) root         (0)    12569 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/composition.cpp
--rw-rw-r--   0 root         (0) root         (0)     4856 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/inverse_left.cpp
--rw-rw-r--   0 root         (0) root         (0)     6702 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/inverse_right.cpp
--rw-rw-r--   0 root         (0) root         (0)     6734 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/logical_divide.cpp
--rw-rw-r--   0 root         (0) root         (0)     5914 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/logical_product.cpp
--rw-rw-r--   0 root         (0) root         (0)     3488 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/mixedbits.cpp
--rw-rw-r--   0 root         (0) root         (0)     2342 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/transform.cpp
--rw-rw-r--   0 root         (0) root         (0)    13304 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/tuple.cpp
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:43.282871 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/hopper/
--rw-r--r--   0 root         (0) root         (0)    14365 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/hopper/stsm.cu
--rw-r--r--   0 root         (0) root         (0)    18990 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/hopper/tma_load.cu
--rw-r--r--   0 root         (0) root         (0)    13875 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/hopper/tma_store.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:43.290604 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/layout/
--rw-rw-r--   0 root         (0) root         (0)     4544 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/layout/layout_operator.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.426766 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:43.293690 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/thread/
--rw-rw-r--   0 root         (0) root         (0)    15818 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/thread/activation.cu
--rw-rw-r--   0 root         (0) root         (0)     6534 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/thread/linear_combination.cu
--rw-rw-r--   0 root         (0) root         (0)     9964 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/thread/linear_combination_planar_complex.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:43.323722 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/
--rw-rw-r--   0 root         (0) root         (0)    13824 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_planar_complex.cu
--rw-rw-r--   0 root         (0) root         (0)    27176 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt.cu
--rw-rw-r--   0 root         (0) root         (0)    12061 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm60.cu
--rw-rw-r--   0 root         (0) root         (0)    25275 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm61.cu
--rw-rw-r--   0 root         (0) root         (0)    84612 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_tensor_op.cu
--rw-rw-r--   0 root         (0) root         (0)    70486 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_volta_tensor_op.cu
--rw-rw-r--   0 root         (0) root         (0)    25293 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_tensor_op.cu
--rw-rw-r--   0 root         (0) root         (0)    13012 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_testbed.h
--rw-rw-r--   0 root         (0) root         (0)     7743 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_wmma_tensor_op_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    19178 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/output_tile_threadmap.cu
--rw-rw-r--   0 root         (0) root         (0)    28433 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/predicated_tile_iterator.cu
--rw-rw-r--   0 root         (0) root         (0)    11038 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/testbed.h
--rw-rw-r--   0 root         (0) root         (0)    11734 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/testbed_planar_complex.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:43.328399 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/warp/
--rw-rw-r--   0 root         (0) root         (0)     6783 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_tensor_op.cu
--rw-rw-r--   0 root         (0) root         (0)     7275 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_volta_tensor_op.cu
--rw-rw-r--   0 root         (0) root         (0)     6616 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_wmma_tensor_op.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.429735 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.043092 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/
--rw-r--r--   0 root         (0) root         (0)    52269 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/default_gemm_configuration.hpp
--rw-rw-r--   0 root         (0) root         (0)    10189 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    17899 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8933 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_wmma_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    10164 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    17984 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8915 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_wmma_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16447 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_bf16n_bf16n_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    16575 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_bf16t_bf16t_bf16t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8318 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf32n_cf32t_cf32t_tensor_op_tf32_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8317 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf32t_cf32n_cf32t_tensor_op_tf32_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6714 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6747 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     7895 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7930 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     6516 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6549 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     9016 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     9053 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     4628 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_direct_store_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6165 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     6124 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     9634 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16357 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    13189 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8845 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_volta_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    13583 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    13464 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     9571 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16239 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6140 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     9544 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16417 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    13075 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8775 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_volta_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    11470 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     6156 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     6116 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     3528 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     3539 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7965 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16470 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    13273 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     3648 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8608 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_volta_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    13518 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     3645 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     6096 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32n_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     7845 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    18135 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    13008 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8505 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_volta_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    11497 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    11090 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_singlestage_wmma_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     6156 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     6116 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    11066 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_singlestage_wmma_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    17114 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_broadcast_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     3528 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     3540 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7964 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16457 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    13266 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8933 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_volta_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    13551 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    13540 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     6130 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32n_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     8160 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_singlestage_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     7847 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16131 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    13014 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8754 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_volta_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    11497 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     6147 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     6107 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    13518 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    13398 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     7845 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16149 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6119 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     7827 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16101 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     9526 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7898 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_volta_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    11470 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     3584 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_bf16_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     3473 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12967 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12931 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32t_f32t_tensor_op_f32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12930 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32t_f32n_f32t_tensor_op_f32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12895 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32t_f32t_f32t_tensor_op_f32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8349 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7300 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     8348 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7291 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)    10240 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_grouped_scheduler_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    26146 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_grouped_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    11339 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     7346 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    12397 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6859 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     7239 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8121 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16882 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8407 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_wmma_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     8103 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    17111 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12637 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8388 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_wmma_tensor_op_s32_sm75.cu
--rw-r--r--   0 root         (0) root         (0)    10044 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm75.cu
--rw-r--r--   0 root         (0) root         (0)    17544 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    10020 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm75.cu
--rw-r--r--   0 root         (0) root         (0)    17544 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     9588 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    11288 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7977 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16531 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5693 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_wmma_tensor_op_s32_sm72.cu
--rw-rw-r--   0 root         (0) root         (0)     7959 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16691 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12408 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6864 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_wmma_tensor_op_s32_sm72.cu
--rw-r--r--   0 root         (0) root         (0)     7744 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm75.cu
--rw-r--r--   0 root         (0) root         (0)    16531 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6675 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_wmma_tensor_op_s32_sm72.cu
--rw-r--r--   0 root         (0) root         (0)     7752 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm75.cu
--rw-r--r--   0 root         (0) root         (0)    16484 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6663 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_wmma_tensor_op_s32_sm72.cu
--rw-rw-r--   0 root         (0) root         (0)     4663 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_serial_tensor_op_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     4945 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_simt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     6616 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    10581 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm75.cu
--rw-r--r--   0 root         (0) root         (0)    24892 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_testbed_3x.hpp
--rw-rw-r--   0 root         (0) root         (0)    16950 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_tf32n_tf32n_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    16902 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_tf32n_tf32t_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    15131 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_tf32t_tf32n_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    16855 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_tf32t_tf32t_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6854 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_u8t_u8n_s32t_wmma_tensor_op_s32_sm72.cu
--rw-rw-r--   0 root         (0) root         (0)     6686 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf32n_cf32n_cf32n_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6755 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6687 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4726 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32n_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     4718 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32t_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16715 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_with_broadcast_f16n_f16n_f16n_tensorop_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    12841 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_with_reduction_f16n_f16n_f16n_tensorop_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     4544 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_with_reduction_f16t_f16n_f16n_tensorop_f32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    13157 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemv.cu
--rw-rw-r--   0 root         (0) root         (0)     6028 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6031 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6064 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6067 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4909 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf64_cf64_cf64_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     6088 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6037 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6040 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_rs_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5382 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5406 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_fast_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5402 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf64_cf64_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)    13055 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf64h_cf64n_tensor_op_f64_grouped_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    13027 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5388 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6939 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64t_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7677 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7725 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_fast_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     3854 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/herk_cf64_cf64_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     6396 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/herk_cf64h_cf64n_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    10157 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/multistage_testbed.h
--rw-rw-r--   0 root         (0) root         (0)    10306 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/multistage_testbed_interleaved.h
--rw-rw-r--   0 root         (0) root         (0)    11186 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/rank_2k_grouped_scheduler_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    46795 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    54085 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     8318 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    46687 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     8411 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    46578 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    40533 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_nn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    47656 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_nt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    40441 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_tn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    40354 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_tt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     3513 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_f8gemm_tn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    89517 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_nn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    89304 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_nt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    89304 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_tn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    89091 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_tt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    69175 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_igemm_nn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    71438 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_igemm_nt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    67796 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_igemm_tn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    70056 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_igemm_tt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     7156 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61.cu
--rw-rw-r--   0 root         (0) root         (0)     6067 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_perf.cu
--rw-rw-r--   0 root         (0) root         (0)     9063 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_sliced_k.cu
--rw-rw-r--   0 root         (0) root         (0)    35894 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_nn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    35813 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_nt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    35813 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_tn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    35732 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_tt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    70872 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    73136 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     8870 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    69488 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     8865 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    71755 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    33231 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_nn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    33156 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_nt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    33156 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_tn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    33081 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_tt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     5238 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm50_gemm_f32_f32_f32_simt.cu
--rw-rw-r--   0 root         (0) root         (0)     5253 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm50_gemm_f64_f64_f64_simt.cu
--rw-rw-r--   0 root         (0) root         (0)     5357 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm61_gemm_s8_s8_s32_simt.cu
--rw-rw-r--   0 root         (0) root         (0)     5479 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f16_f16_f32_tensor_op_f32.cu
--rw-rw-r--   0 root         (0) root         (0)     5238 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f32_f32_f32_simt.cu
--rw-rw-r--   0 root         (0) root         (0)     5253 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f64_f64_f64_simt.cu
--rw-rw-r--   0 root         (0) root         (0)     3875 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f64_f64_f64_tensor_op_f64.cu
--rw-rw-r--   0 root         (0) root         (0)     3734 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_s8_s8_s32_tensor_op.cu
--rw-rw-r--   0 root         (0) root         (0)     5387 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_tf32_tf32_f32_tensor_op_f32.cu
--rw-r--r--   0 root         (0) root         (0)     7436 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32.cu
--rw-r--r--   0 root         (0) root         (0)     7409 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_tensor_op_f32.cu
--rw-r--r--   0 root         (0) root         (0)    17391 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op.cu
--rw-r--r--   0 root         (0) root         (0)    42504 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op.cu
--rw-r--r--   0 root         (0) root         (0)    22602 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_unspecialized.cu
--rw-r--r--   0 root         (0) root         (0)    22874 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized.cu
--rw-r--r--   0 root         (0) root         (0)    42526 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_persistent.cu
--rw-r--r--   0 root         (0) root         (0)     3810 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f32_f32_f32_tensor_op_f32.cu
--rw-r--r--   0 root         (0) root         (0)     5976 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32.cu
--rw-r--r--   0 root         (0) root         (0)     9313 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_tensor_op_s32.cu
--rw-r--r--   0 root         (0) root         (0)     5986 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32.cu
--rw-r--r--   0 root         (0) root         (0)     7268 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_tensor_op_f32.cu
--rw-rw-r--   0 root         (0) root         (0)     5923 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5926 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5959 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5962 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4839 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_cf64_cf64_cf64_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     5983 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5932 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5935 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_rs_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    15203 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8623 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    15104 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4777 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f64_f64_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     8103 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8108 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8088 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8093 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8073 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8078 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8058 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8063 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    15071 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8551 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    14972 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_tf32t_f32t_tensor_op_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5362 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5386 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_fast_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5356 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5380 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_fast_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5379 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64_cf64_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)    12952 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5368 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7208 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_grouped_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5362 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7199 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64n_tensor_op_f64_grouped_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7190 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64t_tensor_op_f64_grouped_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4794 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f32n_f32n_tensor_op_fast_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4783 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f32t_f32n_tensor_op_fast_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4740 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64_f64_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)    19145 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_grouped_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7991 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    11015 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_grouped_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7976 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12342 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_grouped_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7961 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12321 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64t_tensor_op_f64_grouped_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4786 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_tf32n_f32n_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4775 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_tf32t_f32n_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4993 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5017 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_fast_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4987 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5011 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_fast_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5024 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf64_cf64_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     4996 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64n_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     3793 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4990 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    16083 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_f32n_f32t_tensor_op_fast_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    16041 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_f32t_f32t_tensor_op_fast_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4530 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_f64_f64_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     7451 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_f64n_f64t_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     9401 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_f64t_f64n_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    16027 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_tf32n_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    15985 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_tf32t_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    20465 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed.h
--rw-rw-r--   0 root         (0) root         (0)     8264 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_complex.h
--rw-rw-r--   0 root         (0) root         (0)    20736 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_gemm_with_broadcast.h
--rw-rw-r--   0 root         (0) root         (0)    19479 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_gemm_with_reduction.h
--rw-rw-r--   0 root         (0) root         (0)    16502 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_grouped.h
--rw-rw-r--   0 root         (0) root         (0)    16562 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k.h
--rw-rw-r--   0 root         (0) root         (0)    17002 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k_scheduler.h
--rw-rw-r--   0 root         (0) root         (0)    14698 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_grouped_scheduler.h
--rw-rw-r--   0 root         (0) root         (0)    10262 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_interleaved.h
--rw-rw-r--   0 root         (0) root         (0)     9481 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_planar_complex.h
--rw-rw-r--   0 root         (0) root         (0)    20898 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_rank2k_universal.h
--rw-rw-r--   0 root         (0) root         (0)    15652 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_rank_k_universal.h
--rw-rw-r--   0 root         (0) root         (0)     8639 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_sanity.h
--rw-r--r--   0 root         (0) root         (0)    15901 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_sparse.h
--rw-rw-r--   0 root         (0) root         (0)     6124 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_splitk.h
--rw-rw-r--   0 root         (0) root         (0)    19993 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_symm_universal.h
--rw-rw-r--   0 root         (0) root         (0)    20332 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_trmm_universal.h
--rw-rw-r--   0 root         (0) root         (0)    17443 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_universal.h
--rw-rw-r--   0 root         (0) root         (0)     2626 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_utils.h
--rw-rw-r--   0 root         (0) root         (0)     9916 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     9988 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_fast_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4989 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_cf64_cf64_cf64_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     4992 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     9762 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    15614 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8733 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    14089 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    14444 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32t_tensor_op_fast_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4608 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64_f64_f64_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)    12798 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12809 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12764 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64t_f64t_tensor_op_f64_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12768 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12779 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    15504 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8673 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    13989 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32n_tensor_op_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    14344 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32t_tensor_op_f32_ls_sm80.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.046910 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/kernel/
--rwxrwxr-x   0 root         (0) root         (0)    46470 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/kernel/batched_gemv.cu
--rwxrwxr-x   0 root         (0) root         (0)    14362 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/kernel/testbed_gemv.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.051342 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/thread/
--rw-rw-r--   0 root         (0) root         (0)     4847 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/thread/gemm_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    12503 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/thread/gemm_sm60.cu
--rw-rw-r--   0 root         (0) root         (0)     3109 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/thread/gemm_sm61.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.059805 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/thread/host/
--rw-rw-r--   0 root         (0) root         (0)     5198 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/thread/host/gemm_sm60_host.cu
--rw-rw-r--   0 root         (0) root         (0)     7161 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/thread/host/testbed_host.h
--rw-rw-r--   0 root         (0) root         (0)     7124 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/thread/testbed.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.105716 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/
--rw-rw-r--   0 root         (0) root         (0)    25036 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/batched_gemv.cu
--rw-rw-r--   0 root         (0) root         (0)     4345 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/epilogue_workspace.cu
--rw-rw-r--   0 root         (0) root         (0)   135045 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage.cu
--rw-rw-r--   0 root         (0) root         (0)     4644 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_slicedk.cu
--rw-rw-r--   0 root         (0) root         (0)    94442 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse.cu
--rw-rw-r--   0 root         (0) root         (0)    17090 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse_testbed.h
--rw-rw-r--   0 root         (0) root         (0)    13897 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed.h
--rw-rw-r--   0 root         (0) root         (0)    14539 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed_slicedk.h
--rw-rw-r--   0 root         (0) root         (0)    49052 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_simt.cu
--rw-rw-r--   0 root         (0) root         (0)     8407 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_slicedk.cu
--rw-rw-r--   0 root         (0) root         (0)    18705 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    78122 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    21051 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    13771 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed.h
--rw-rw-r--   0 root         (0) root         (0)    14239 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed_slicedk.h
--rw-rw-r--   0 root         (0) root         (0)    29772 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    12395 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     3502 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_planar_complex_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12138 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_planar_complex_testbed.h
--rw-rw-r--   0 root         (0) root         (0)    16308 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    12502 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm75.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.132125 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/
--rw-rw-r--   0 root         (0) root         (0)    22128 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_complex_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    10916 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_complex_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     9873 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_gaussian_complex_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    18220 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     4920 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm60.cu
--rw-rw-r--   0 root         (0) root         (0)     6291 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm61.cu
--rw-rw-r--   0 root         (0) root         (0)     9297 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    37942 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    81659 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     9089 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)    48928 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    49647 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/testbed.h
--rw-rw-r--   0 root         (0) root         (0)    25780 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/wmma_sm70.cu
--rw-r--r--   0 root         (0) root         (0)     7544 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/wmma_sm72.cu
--rw-rw-r--   0 root         (0) root         (0)     6487 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/wmma_sm75.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.139265 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/layout/
--rw-rw-r--   0 root         (0) root         (0)     5788 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/layout/matrix.cu
--rw-rw-r--   0 root         (0) root         (0)     5984 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/layout/tensor.cu
--rw-rw-r--   0 root         (0) root         (0)     7081 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/layout/tensor_nhwc.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.436110 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/nvrtc/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.437100 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/nvrtc/cutlass/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.146451 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/nvrtc/cutlass/nvrtc/
--rw-rw-r--   0 root         (0) root         (0)     2096 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/nvrtc/cutlass/nvrtc/environment.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.438745 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/nvrtc/kernel/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.149423 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/nvrtc/kernel/thread/
--rw-rw-r--   0 root         (0) root         (0)     2915 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/nvrtc/kernel/thread/testbed_kernel.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.151984 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/nvrtc/stdlib/
--rw-rw-r--   0 root         (0) root         (0)        0 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/nvrtc/stdlib/assert.h
--rw-rw-r--   0 root         (0) root         (0)     4250 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/nvrtc/stdlib/stdint.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.156254 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/nvrtc/thread/
--rw-rw-r--   0 root         (0) root         (0)     5727 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/nvrtc/thread/gemm_nvrtc.cu
--rw-rw-r--   0 root         (0) root         (0)    10328 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/nvrtc/thread/testbed.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.170158 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/pipeline/
--rw-r--r--   0 root         (0) root         (0)    15532 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/pipeline/pipeline_async.cu
--rw-r--r--   0 root         (0) root         (0)    15490 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/pipeline/pipeline_tma_async.cu
--rw-r--r--   0 root         (0) root         (0)    17098 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/pipeline/pipeline_tma_async_warp_specialized.cu
--rw-r--r--   0 root         (0) root         (0)    20252 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/pipeline/pipeline_tma_async_warp_specialized_persistent.cu
--rw-r--r--   0 root         (0) root         (0)     7623 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/pipeline/sequence_barrier.cu
--rw-rw-r--   0 root         (0) root         (0)     4327 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/pipeline/testbed.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.442424 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/reduction/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.175561 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/reduction/device/
--rw-rw-r--   0 root         (0) root         (0)    14684 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/reduction/device/tensor_reduce_contiguous.cu
--rw-rw-r--   0 root         (0) root         (0)    15609 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/reduction/device/tensor_reduce_strided.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.180714 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/reduction/kernel/
--rw-rw-r--   0 root         (0) root         (0)    11350 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/reduction/kernel/reduce_splitk.cu
--rw-rw-r--   0 root         (0) root         (0)     2228 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/reduction/kernel/reduce_splitk_testbed.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.185454 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/reduction/thread/
--rw-rw-r--   0 root         (0) root         (0)     3110 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/reduction/thread/reduction_thread.cu
--rw-rw-r--   0 root         (0) root         (0)     6657 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/reduction/thread/testbed.h
--rw-rw-r--   0 root         (0) root         (0)     2047 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/test_unit.cpp
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.445510 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/transform/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.190655 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/transform/threadblock/
--rw-rw-r--   0 root         (0) root         (0)    25527 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/transform/threadblock/predicated_tile_iterator.cu
--rw-rw-r--   0 root         (0) root         (0)     9501 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/transform/threadblock/regular_tile_iterator_tensor_op.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.195860 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/util/
--rw-rw-r--   0 root         (0) root         (0)     2663 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/util/cutlass_test_levels.cu
--rw-rw-r--   0 root         (0) root         (0)     7474 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/test/unit/util/tensor_reduce.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.472249 flash_attn-2.0.0.post1/csrc/cutlass/tools/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.469704 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.455702 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/include/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.456702 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/include/cutlass/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.210433 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/include/cutlass/library/
--rw-r--r--   0 root         (0) root         (0)     4118 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/include/cutlass/library/arch_mappings.h
--rw-r--r--   0 root         (0) root         (0)    16013 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/include/cutlass/library/handle.h
--rw-r--r--   0 root         (0) root         (0)    38761 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/include/cutlass/library/library.h
--rw-rw-r--   0 root         (0) root         (0)     4070 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/include/cutlass/library/manifest.h
--rw-r--r--   0 root         (0) root         (0)    17934 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/include/cutlass/library/operation_table.h
--rw-rw-r--   0 root         (0) root         (0)     2724 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/include/cutlass/library/singleton.h
--rw-rw-r--   0 root         (0) root         (0)     7904 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/include/cutlass/library/util.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.458646 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.460266 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.461355 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.221226 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/
--rw-r--r--   0 root         (0) root         (0)     2788 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/compiler.h
--rw-r--r--   0 root         (0) root         (0)     2460 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/cute.cpp
--rw-r--r--   0 root         (0) root         (0)     6224 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/cutlass.cpp
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.238477 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/
--rw-r--r--   0 root         (0) root         (0)     2851 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/arch.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.242159 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/
--rw-r--r--   0 root         (0) root         (0)     5897 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/conv_problem_size.h
--rw-r--r--   0 root         (0) root         (0)     4763 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/convolution.h
--rw-r--r--   0 root         (0) root         (0)     2650 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/host.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.249178 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/
--rw-r--r--   0 root         (0) root         (0)     6845 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_generic.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.290184 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/
--rw-r--r--   0 root         (0) root         (0)     3003 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/binary_ops.h
--rw-r--r--   0 root         (0) root         (0)     6103 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/unary_ops.h
--rw-r--r--   0 root         (0) root         (0)     4698 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_accumulator.h
--rw-r--r--   0 root         (0) root         (0)     8397 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_binary.h
--rw-r--r--   0 root         (0) root         (0)     8830 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_column_broadcast.h
--rw-r--r--   0 root         (0) root         (0)    12999 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_column_reduction.h
--rw-r--r--   0 root         (0) root         (0)     9454 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_linear_combination.h
--rw-r--r--   0 root         (0) root         (0)     9085 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_row_broadcast.h
--rw-r--r--   0 root         (0) root         (0)    11976 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_row_reduction.h
--rw-r--r--   0 root         (0) root         (0)     6177 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_tensor_input.h
--rw-r--r--   0 root         (0) root         (0)     8017 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_tensor_output.h
--rw-r--r--   0 root         (0) root         (0)     7201 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_unary.h
--rw-r--r--   0 root         (0) root         (0)    16970 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_with_layernorm.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.297285 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/
--rw-r--r--   0 root         (0) root         (0)     3673 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/gemm.h
--rw-r--r--   0 root         (0) root         (0)    21504 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/gemm_universal_with_visitor.h
--rw-r--r--   0 root         (0) root         (0)     2328 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/host.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.311487 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/
--rw-r--r--   0 root         (0) root         (0)     2115 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/layout.h
--rw-r--r--   0 root         (0) root         (0)     4337 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/matrix.h
--rw-r--r--   0 root         (0) root         (0)     3694 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/tensor.h
--rw-r--r--   0 root         (0) root         (0)     8565 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/swizzling.h
--rw-r--r--   0 root         (0) root         (0)     3902 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/tensor_coord.h
--rw-r--r--   0 root         (0) root         (0)     5563 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/tensor_ref_view.h
--rw-r--r--   0 root         (0) root         (0)     4855 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/types.h
--rw-r--r--   0 root         (0) root         (0)      811 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/library.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.468396 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.316074 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/
--rw-r--r--   0 root         (0) root         (0)     2651 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/conv_problems.h
--rw-r--r--   0 root         (0) root         (0)     2253 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/convolution.h
--rw-r--r--   0 root         (0) root         (0)     8826 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/host.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.322720 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/gemm/
--rw-r--r--   0 root         (0) root         (0)     2139 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/gemm/gemm.h
--rw-r--r--   0 root         (0) root         (0)    18930 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/gemm/host.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.356484 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/
--rw-r--r--   0 root         (0) root         (0)    22377 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/conv2d_operation.h
--rw-r--r--   0 root         (0) root         (0)    13851 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/conv3d_operation.h
--rw-r--r--   0 root         (0) root         (0)    42129 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/gemm_operation.h
--rw-r--r--   0 root         (0) root         (0)    11614 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/gemm_operation_3x.hpp
--rw-r--r--   0 root         (0) root         (0)    35777 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/handle.cu
--rw-r--r--   0 root         (0) root         (0)    12616 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/library_internal.h
--rw-r--r--   0 root         (0) root         (0)     3782 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/manifest.cpp
--rw-r--r--   0 root         (0) root         (0)     5468 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/operation_table.cu
--rw-r--r--   0 root         (0) root         (0)    12873 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/rank_2k_operation.h
--rw-rw-r--   0 root         (0) root         (0)    11367 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/rank_k_operation.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.359321 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/reduction/
--rw-r--r--   0 root         (0) root         (0)     3190 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/reduction/init_reduction_operations.cu
--rw-r--r--   0 root         (0) root         (0)     6367 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/reduction/reduction_device.cu
--rw-r--r--   0 root         (0) root         (0)    10270 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/reduction/reduction_operation.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.375548 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/reference/
--rw-rw-r--   0 root         (0) root         (0)     6746 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/reference/conv2d.cu
--rw-rw-r--   0 root         (0) root         (0)     6286 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/reference/conv3d.cu
--rw-r--r--   0 root         (0) root         (0)    17191 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/reference/conv_reference_operation.h
--rw-r--r--   0 root         (0) root         (0)     7199 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/reference/gemm.cu
--rw-r--r--   0 root         (0) root         (0)    14732 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/reference/gemm_reference_operation.h
--rw-rw-r--   0 root         (0) root         (0)     2857 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/reference/initialize_reference_operations.cu
--rw-rw-r--   0 root         (0) root         (0)     2669 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/singleton.cu
--rw-r--r--   0 root         (0) root         (0)    13134 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/symm_operation.h
--rw-rw-r--   0 root         (0) root         (0)    11698 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/trmm_operation.h
--rw-r--r--   0 root         (0) root         (0)    43704 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/util.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.473222 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.465610 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/
--rw-r--r--   0 root         (0) root         (0)    54128 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/conv2d_operation_profiler.cu
--rw-r--r--   0 root         (0) root         (0)    18170 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/conv2d_operation_profiler.h
--rw-r--r--   0 root         (0) root         (0)    48659 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/conv3d_operation_profiler.cu
--rw-r--r--   0 root         (0) root         (0)    16043 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/conv3d_operation_profiler.h
--rw-r--r--   0 root         (0) root         (0)    36462 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/cublas_helpers.cu
--rw-r--r--   0 root         (0) root         (0)    10627 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/cublas_helpers.h
--rw-r--r--   0 root         (0) root         (0)    17049 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/cudnn_helpers.cpp
--rw-r--r--   0 root         (0) root         (0)    20433 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/cudnn_helpers.h
--rw-r--r--   0 root         (0) root         (0)     7233 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/cutlass_profiler.cu
--rw-rw-r--   0 root         (0) root         (0)     3233 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/cutlass_profiler.h
--rw-r--r--   0 root         (0) root         (0)     2453 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/debug.h
--rw-r--r--   0 root         (0) root         (0)    53643 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/device_allocation.cu
--rw-r--r--   0 root         (0) root         (0)     7217 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/device_allocation.h
--rw-r--r--   0 root         (0) root         (0)     6841 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/device_context.cu
--rw-r--r--   0 root         (0) root         (0)     4300 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/device_context.h
--rw-rw-r--   0 root         (0) root         (0)     8296 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/enumerated_types.cpp
--rw-rw-r--   0 root         (0) root         (0)     6421 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/enumerated_types.h
--rw-r--r--   0 root         (0) root         (0)    42366 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/gemm_operation_profiler.cu
--rw-r--r--   0 root         (0) root         (0)     8544 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/gemm_operation_profiler.h
--rw-r--r--   0 root         (0) root         (0)     3874 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/gpu_timer.cpp
--rw-r--r--   0 root         (0) root         (0)     2724 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/gpu_timer.h
--rw-rw-r--   0 root         (0) root         (0)     2340 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/main.cpp
--rw-r--r--   0 root         (0) root         (0)    22087 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/operation_profiler.cu
--rw-r--r--   0 root         (0) root         (0)     7876 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/operation_profiler.h
--rw-r--r--   0 root         (0) root         (0)    27172 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/options.cu
--rw-r--r--   0 root         (0) root         (0)     8773 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/options.h
--rw-rw-r--   0 root         (0) root         (0)    14192 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/performance_report.cpp
--rw-rw-r--   0 root         (0) root         (0)     4337 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/performance_report.h
--rw-rw-r--   0 root         (0) root         (0)     2494 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/performance_result.cu
--rw-rw-r--   0 root         (0) root         (0)     3941 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/performance_result.h
--rw-rw-r--   0 root         (0) root         (0)    37487 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/problem_space.cpp
--rw-r--r--   0 root         (0) root         (0)    27747 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/problem_space.h
--rw-r--r--   0 root         (0) root         (0)    25014 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/rank_2k_operation_profiler.cu
--rw-rw-r--   0 root         (0) root         (0)     6891 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/rank_2k_operation_profiler.h
--rw-r--r--   0 root         (0) root         (0)    24253 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/rank_k_operation_profiler.cu
--rw-rw-r--   0 root         (0) root         (0)     6830 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/rank_k_operation_profiler.h
--rw-rw-r--   0 root         (0) root         (0)     5452 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/reduction_operation_profiler.h
--rw-r--r--   0 root         (0) root         (0)    20688 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/sparse_gemm_operation_profiler.cu
--rw-rw-r--   0 root         (0) root         (0)     6471 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/sparse_gemm_operation_profiler.h
--rw-r--r--   0 root         (0) root         (0)    26610 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/symm_operation_profiler.cu
--rw-rw-r--   0 root         (0) root         (0)     6933 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/symm_operation_profiler.h
--rw-r--r--   0 root         (0) root         (0)    24431 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/trmm_operation_profiler.cu
--rw-rw-r--   0 root         (0) root         (0)     6599 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/trmm_operation_profiler.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.475081 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.476532 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.477576 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.523683 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/
--rw-rw-r--   0 root         (0) root         (0)     2410 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/GPU_Clock.hpp
--rw-r--r--   0 root         (0) root         (0)     9774 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/command_line.h
--rw-rw-r--   0 root         (0) root         (0)    19866 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/cublas_wrappers.hpp
--rw-rw-r--   0 root         (0) root         (0)     5104 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/debug.h
--rw-rw-r--   0 root         (0) root         (0)     5953 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/device_dump.h
--rw-r--r--   0 root         (0) root         (0)    17695 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/device_groupnorm.h
--rw-rw-r--   0 root         (0) root         (0)    20881 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/device_layernorm.h
--rw-rw-r--   0 root         (0) root         (0)    10561 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/device_memory.h
--rw-rw-r--   0 root         (0) root         (0)     5219 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/device_nchw_to_nhwc.h
--rw-r--r--   0 root         (0) root         (0)    11067 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_padding.h
--rw-rw-r--   0 root         (0) root         (0)    18653 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_pooling.h
--rw-rw-r--   0 root         (0) root         (0)     5214 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_to_nchw.h
--rw-rw-r--   0 root         (0) root         (0)     4007 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/device_utils.h
--rw-rw-r--   0 root         (0) root         (0)     4597 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/distribution.h
--rw-rw-r--   0 root         (0) root         (0)     2674 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/exceptions.h
--rw-r--r--   0 root         (0) root         (0)     3946 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/helper_cuda.hpp
--rw-rw-r--   0 root         (0) root         (0)     4821 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/host_reorder.h
--rw-rw-r--   0 root         (0) root         (0)    16745 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/host_tensor.h
--rw-rw-r--   0 root         (0) root         (0)    20354 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/host_tensor_planar_complex.h
--rw-rw-r--   0 root         (0) root         (0)     5890 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/host_uncompress.h
--rw-rw-r--   0 root         (0) root         (0)     1962 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/index_sequence.h
--rw-rw-r--   0 root         (0) root         (0)     4589 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/packed_stride.hpp
--rw-r--r--   0 root         (0) root         (0)     9529 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/print_error.hpp
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:37.479823 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.528665 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/detail/
--rw-rw-r--   0 root         (0) root         (0)     4606 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/detail/inner_product.h
--rw-rw-r--   0 root         (0) root         (0)     3527 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/detail/linear_to_coordinate.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.550199 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/
--rw-rw-r--   0 root         (0) root         (0)    48350 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/convolution.h
--rw-r--r--   0 root         (0) root         (0)    14296 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm.h
--rw-r--r--   0 root         (0) root         (0)    10524 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm_complex.h
--rw-rw-r--   0 root         (0) root         (0)     9652 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm_planar_complex.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.554762 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/
--rw-rw-r--   0 root         (0) root         (0)     5381 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/gemm.h
--rw-rw-r--   0 root         (0) root         (0)     6198 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_elementwise.h
--rw-r--r--   0 root         (0) root         (0)     5126 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_foreach.h
--rw-rw-r--   0 root         (0) root         (0)    11615 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/rank_2k_complex.h
--rw-rw-r--   0 root         (0) root         (0)     7278 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_compare.h
--rw-r--r--   0 root         (0) root         (0)    46444 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_fill.h
--rw-r--r--   0 root         (0) root         (0)     5293 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_foreach.h
--rw-rw-r--   0 root         (0) root         (0)    15964 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_reduce.h
--rw-rw-r--   0 root         (0) root         (0)     4589 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_relu.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.561470 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/thread/
--rw-rw-r--   0 root         (0) root         (0)     5872 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/thread/gemm.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.605036 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/
--rw-r--r--   0 root         (0) root         (0)    28439 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/convolution.h
--rw-rw-r--   0 root         (0) root         (0)     2766 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/error_metrics.h
--rw-r--r--   0 root         (0) root         (0)    17163 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm.h
--rw-r--r--   0 root         (0) root         (0)     7097 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm_complex.h
--rw-rw-r--   0 root         (0) root         (0)     7708 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm_planar_complex.h
--rw-r--r--   0 root         (0) root         (0)    12983 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gett.hpp
--rw-rw-r--   0 root         (0) root         (0)     9441 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k.h
--rw-rw-r--   0 root         (0) root         (0)    11444 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k_complex.h
--rw-rw-r--   0 root         (0) root         (0)     8148 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_k_complex.h
--rw-rw-r--   0 root         (0) root         (0)    10509 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/symm.h
--rw-rw-r--   0 root         (0) root         (0)    12296 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/symm_complex.h
--rw-r--r--   0 root         (0) root         (0)     8440 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_compare.h
--rw-rw-r--   0 root         (0) root         (0)     3339 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_compare.hpp
--rw-rw-r--   0 root         (0) root         (0)     8317 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_copy.h
--rw-rw-r--   0 root         (0) root         (0)     9027 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_elementwise.h
--rw-r--r--   0 root         (0) root         (0)    43961 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_fill.h
--rw-rw-r--   0 root         (0) root         (0)    12875 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_fill.hpp
--rw-r--r--   0 root         (0) root         (0)     4756 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_foreach.h
--rw-rw-r--   0 root         (0) root         (0)     2133 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_norm.h
--rw-rw-r--   0 root         (0) root         (0)     6111 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.h
--rw-rw-r--   0 root         (0) root         (0)     5987 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.hpp
--rw-rw-r--   0 root         (0) root         (0)     7670 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/trmm.h
--rw-rw-r--   0 root         (0) root         (0)     9874 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/trmm_complex.h
--rw-r--r--   0 root         (0) root         (0)     8285 2023-07-17 10:57:41.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/tensor_view_io.h
--rw-rw-r--   0 root         (0) root         (0)     8809 2023-07-17 10:57:20.000000 flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/type_traits.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:45.612492 flash_attn-2.0.0.post1/csrc/flash_attn/
--rw-r--r--   0 root         (0) root         (0)    41827 2023-07-12 04:28:42.000000 flash_attn-2.0.0.post1/csrc/flash_attn/flash_api.cpp
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:46.699066 flash_attn-2.0.0.post1/csrc/flash_attn/src/
--rw-r--r--   0 root         (0) root         (0)     1664 2023-04-16 00:15:33.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/block_info.h
--rw-r--r--   0 root         (0) root         (0)     4109 2023-07-09 22:07:48.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash.h
--rw-r--r--   0 root         (0) root         (0)      879 2023-07-13 13:50:11.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim128_bf16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     1569 2023-07-13 13:50:11.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim128_fp16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)      361 2023-07-11 01:26:51.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim160_bf16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)      353 2023-07-11 01:26:38.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim160_fp16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)      361 2023-07-11 01:48:51.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim192_bf16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)      353 2023-07-11 01:48:58.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim192_fp16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)      361 2023-07-11 04:28:48.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim224_bf16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)      353 2023-07-11 04:28:56.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim224_fp16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)      361 2023-07-11 04:43:54.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim256_bf16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)      353 2023-07-11 04:44:02.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim256_fp16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)      667 2023-07-11 04:54:51.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim32_bf16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)      651 2023-07-11 04:54:51.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim32_fp16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)      667 2023-07-11 04:54:51.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim64_bf16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     2751 2023-07-11 04:54:51.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim64_fp16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)      874 2023-07-13 13:50:11.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim96_bf16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     1031 2023-07-13 13:50:11.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim96_fp16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    85689 2023-07-13 13:50:11.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_kernel.h
--rw-r--r--   0 root         (0) root         (0)    20375 2023-07-13 13:50:11.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_launch_template.h
--rw-r--r--   0 root         (0) root         (0)      783 2023-07-09 22:55:47.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim128_bf16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     1951 2023-07-09 22:55:33.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim128_fp16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)      682 2023-07-09 22:56:37.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim160_bf16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     1674 2023-07-09 22:56:52.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim160_fp16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)      682 2023-07-09 22:57:38.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim192_bf16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     1647 2023-07-09 22:57:25.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim192_fp16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)      329 2023-07-09 22:58:41.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim224_bf16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)      321 2023-07-09 22:58:59.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim224_fp16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)      329 2023-07-09 22:59:19.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim256_bf16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)      321 2023-07-09 22:59:41.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim256_fp16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)      326 2023-07-10 04:44:44.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim32_bf16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     1151 2023-07-09 23:04:52.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim32_fp16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)      777 2023-07-09 22:36:36.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim64_bf16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     1463 2023-07-09 22:35:48.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim64_fp16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)      677 2023-07-09 22:54:57.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim96_bf16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     1328 2023-07-09 22:55:13.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim96_fp16_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    30177 2023-07-11 22:09:11.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_kernel.h
--rw-r--r--   0 root         (0) root         (0)    15208 2023-07-12 09:05:19.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_launch_template.h
--rw-r--r--   0 root         (0) root         (0)    18396 2023-07-11 05:28:03.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/kernel_traits.h
--rw-r--r--   0 root         (0) root         (0)     7555 2023-04-22 02:44:59.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/kernel_traits_sm90.h
--rw-r--r--   0 root         (0) root         (0)     5372 2023-04-16 00:15:33.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/philox.cuh
--rw-r--r--   0 root         (0) root         (0)    14205 2023-04-16 00:15:33.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/softmax.h
--rw-r--r--   0 root         (0) root         (0)     2961 2023-07-09 23:03:20.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/static_switch.h
--rw-r--r--   0 root         (0) root         (0)    16378 2023-04-16 00:15:33.000000 flash_attn-2.0.0.post1/csrc/flash_attn/src/utils.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:46.704375 flash_attn-2.0.0.post1/csrc/flash_gen/
--rw-r--r--   0 root         (0) root         (0)     7018 2022-11-21 06:35:03.000000 flash_attn-2.0.0.post1/csrc/flash_gen/decoder_masked_multihead_attention.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:46.715844 flash_attn-2.0.0.post1/csrc/ft_attention/
--rw-r--r--   0 root         (0) root         (0)     8253 2023-04-16 00:48:36.000000 flash_attn-2.0.0.post1/csrc/ft_attention/cuda_bf16_fallbacks.cuh
--rw-r--r--   0 root         (0) root         (0)      867 2023-04-16 00:48:36.000000 flash_attn-2.0.0.post1/csrc/ft_attention/cuda_bf16_wrapper.h
--rw-r--r--   0 root         (0) root         (0)     7069 2023-06-06 06:13:59.000000 flash_attn-2.0.0.post1/csrc/ft_attention/decoder_masked_multihead_attention.cu
--rw-r--r--   0 root         (0) root         (0)     7627 2023-07-02 20:11:51.000000 flash_attn-2.0.0.post1/csrc/ft_attention/decoder_masked_multihead_attention.h
--rw-r--r--   0 root         (0) root         (0)    57401 2023-07-06 22:10:54.000000 flash_attn-2.0.0.post1/csrc/ft_attention/decoder_masked_multihead_attention_template.hpp
--rw-r--r--   0 root         (0) root         (0)    64946 2023-07-03 16:25:44.000000 flash_attn-2.0.0.post1/csrc/ft_attention/decoder_masked_multihead_attention_utils.h
--rw-r--r--   0 root         (0) root         (0)    10119 2023-07-06 22:24:25.000000 flash_attn-2.0.0.post1/csrc/ft_attention/ft_attention.cpp
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:46.723441 flash_attn-2.0.0.post1/csrc/fused_dense_lib/
--rw-r--r--   0 root         (0) root         (0)    10179 2023-05-30 21:13:46.000000 flash_attn-2.0.0.post1/csrc/fused_dense_lib/fused_dense.cpp
--rw-r--r--   0 root         (0) root         (0)    24690 2023-05-30 21:14:57.000000 flash_attn-2.0.0.post1/csrc/fused_dense_lib/fused_dense_cuda.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:46.736216 flash_attn-2.0.0.post1/csrc/fused_softmax/
--rw-r--r--   0 root         (0) root         (0)     5037 2023-04-16 00:48:36.000000 flash_attn-2.0.0.post1/csrc/fused_softmax/fused_softmax.cpp
--rw-r--r--   0 root         (0) root         (0)    23616 2023-04-16 00:48:36.000000 flash_attn-2.0.0.post1/csrc/fused_softmax/scaled_masked_softmax.h
--rw-r--r--   0 root         (0) root         (0)     4209 2023-04-16 00:48:36.000000 flash_attn-2.0.0.post1/csrc/fused_softmax/scaled_masked_softmax_cuda.cu
--rw-r--r--   0 root         (0) root         (0)    24659 2023-04-16 00:48:36.000000 flash_attn-2.0.0.post1/csrc/fused_softmax/scaled_upper_triang_masked_softmax.h
--rw-r--r--   0 root         (0) root         (0)     3154 2023-04-16 00:48:36.000000 flash_attn-2.0.0.post1/csrc/fused_softmax/scaled_upper_triang_masked_softmax_cuda.cu
--rw-r--r--   0 root         (0) root         (0)     1216 2023-04-16 00:48:36.000000 flash_attn-2.0.0.post1/csrc/fused_softmax/type_shim.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:47.886761 flash_attn-2.0.0.post1/csrc/layer_norm/
--rw-r--r--   0 root         (0) root         (0)     7248 2023-04-16 00:48:36.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln.h
--rw-r--r--   0 root         (0) root         (0)    36418 2023-04-16 00:48:36.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_api.cpp
--rw-r--r--   0 root         (0) root         (0)      987 2023-04-16 00:48:36.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_1024.cu
--rw-r--r--   0 root         (0) root         (0)      987 2023-04-16 00:48:36.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_1280.cu
--rw-r--r--   0 root         (0) root         (0)      977 2023-04-16 00:48:36.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_1536.cu
--rw-r--r--   0 root         (0) root         (0)      976 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_2048.cu
--rw-r--r--   0 root         (0) root         (0)      977 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_256.cu
--rw-r--r--   0 root         (0) root         (0)      977 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_2560.cu
--rw-r--r--   0 root         (0) root         (0)      976 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_3072.cu
--rw-r--r--   0 root         (0) root         (0)      976 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_4096.cu
--rw-r--r--   0 root         (0) root         (0)      977 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_512.cu
--rw-r--r--   0 root         (0) root         (0)      976 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_5120.cu
--rw-r--r--   0 root         (0) root         (0)      976 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_6144.cu
--rw-r--r--   0 root         (0) root         (0)      976 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_7168.cu
--rw-r--r--   0 root         (0) root         (0)      977 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_768.cu
--rw-r--r--   0 root         (0) root         (0)      976 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_8192.cu
--rw-r--r--   0 root         (0) root         (0)    25647 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_kernels.cuh
--rw-r--r--   0 root         (0) root         (0)    19944 2023-01-19 07:34:02.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_semi_cuda_kernel_old.cu
--rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_1024.cu
--rw-r--r--   0 root         (0) root         (0)      925 2023-01-22 09:05:55.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_10240.cu
--rw-r--r--   0 root         (0) root         (0)      925 2023-01-22 09:07:15.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_12288.cu
--rw-r--r--   0 root         (0) root         (0)      925 2022-12-05 08:45:58.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_128.cu
--rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_1280.cu
--rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_1536.cu
--rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_2048.cu
--rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_256.cu
--rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_2560.cu
--rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_3072.cu
--rw-r--r--   0 root         (0) root         (0)      925 2022-12-05 08:50:57.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_384.cu
--rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_4096.cu
--rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_512.cu
--rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_5120.cu
--rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_6144.cu
--rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_7168.cu
--rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_768.cu
--rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_8192.cu
--rw-r--r--   0 root         (0) root         (0)      925 2023-01-22 08:41:06.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_9216.cu
--rw-r--r--   0 root         (0) root         (0)    18000 2022-12-06 21:18:58.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_cuda_kernel_old.cu
--rw-r--r--   0 root         (0) root         (0)    12721 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_kernels.cuh
--rw-r--r--   0 root         (0) root         (0)     6655 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_kernel_traits.h
--rw-r--r--   0 root         (0) root         (0)     1095 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_1024.cu
--rw-r--r--   0 root         (0) root         (0)     1095 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_1280.cu
--rw-r--r--   0 root         (0) root         (0)     1085 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_1536.cu
--rw-r--r--   0 root         (0) root         (0)     1084 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_2048.cu
--rw-r--r--   0 root         (0) root         (0)     1085 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_256.cu
--rw-r--r--   0 root         (0) root         (0)     1085 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_2560.cu
--rw-r--r--   0 root         (0) root         (0)     1084 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_3072.cu
--rw-r--r--   0 root         (0) root         (0)     1145 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_4096.cu
--rw-r--r--   0 root         (0) root         (0)     1085 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_512.cu
--rw-r--r--   0 root         (0) root         (0)     1145 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_5120.cu
--rw-r--r--   0 root         (0) root         (0)     1084 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_6144.cu
--rw-r--r--   0 root         (0) root         (0)     1084 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_7168.cu
--rw-r--r--   0 root         (0) root         (0)     1085 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_768.cu
--rw-r--r--   0 root         (0) root         (0)     1084 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_8192.cu
--rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_1024.cu
--rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_1280.cu
--rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_1536.cu
--rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_2048.cu
--rw-r--r--   0 root         (0) root         (0)     1032 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_256.cu
--rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_2560.cu
--rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_3072.cu
--rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_4096.cu
--rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_512.cu
--rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_5120.cu
--rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_6144.cu
--rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_7168.cu
--rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_768.cu
--rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_8192.cu
--rw-r--r--   0 root         (0) root         (0)    24916 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_residual_bwd_kernels.cuh
--rw-r--r--   0 root         (0) root         (0)    12530 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_residual_fwd_kernels.cuh
--rw-r--r--   0 root         (0) root         (0)    29989 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/ln_utils.cuh
--rw-r--r--   0 root         (0) root         (0)     1278 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/layer_norm/static_switch.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:47.892298 flash_attn-2.0.0.post1/csrc/rotary/
--rw-r--r--   0 root         (0) root         (0)     1806 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/rotary/rotary.cpp
--rw-r--r--   0 root         (0) root         (0)     1984 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/rotary/rotary_cuda.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:47.897044 flash_attn-2.0.0.post1/csrc/xentropy/
--rw-r--r--   0 root         (0) root         (0)     2290 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/xentropy/interface.cpp
--rw-r--r--   0 root         (0) root         (0)    25783 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/csrc/xentropy/xentropy_kernel.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:47.928243 flash_attn-2.0.0.post1/flash_attn/
--rw-rw-r--   0 root         (0) root         (0)      448 2023-07-17 13:02:20.000000 flash_attn-2.0.0.post1/flash_attn/__init__.py
--rw-rw-r--   0 root         (0) root         (0)    20845 2022-10-31 02:25:05.000000 flash_attn-2.0.0.post1/flash_attn/attention_kernl.py
--rw-r--r--   0 root         (0) root         (0)     5898 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/flash_attn/bert_padding.py
--rw-r--r--   0 root         (0) root         (0)    28027 2023-07-12 12:19:57.000000 flash_attn-2.0.0.post1/flash_attn/fav2_interface.py
--rw-r--r--   0 root         (0) root         (0)     4575 2023-07-17 11:38:20.000000 flash_attn-2.0.0.post1/flash_attn/flash_attention.py
--rw-r--r--   0 root         (0) root         (0)    28021 2023-07-17 12:03:52.000000 flash_attn-2.0.0.post1/flash_attn/flash_attn_interface.py
--rw-r--r--   0 root         (0) root         (0)    38148 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/flash_attn/flash_attn_triton.py
--rw-r--r--   0 root         (0) root         (0)    10593 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/flash_attn/flash_attn_triton_og.py
--rw-r--r--   0 root         (0) root         (0)     8255 2022-11-18 03:30:00.000000 flash_attn-2.0.0.post1/flash_attn/flash_attn_triton_single_query.py
--rw-r--r--   0 root         (0) root         (0)    37797 2023-03-17 09:16:10.000000 flash_attn-2.0.0.post1/flash_attn/flash_attn_triton_tmp.py
--rw-r--r--   0 root         (0) root         (0)    10640 2023-03-12 08:48:14.000000 flash_attn-2.0.0.post1/flash_attn/flash_attn_triton_tmp_og.py
--rw-r--r--   0 root         (0) root         (0)     6819 2022-06-26 00:59:43.000000 flash_attn-2.0.0.post1/flash_attn/flash_blocksparse_attention.py
--rw-r--r--   0 root         (0) root         (0)     7036 2022-06-26 00:59:43.000000 flash_attn-2.0.0.post1/flash_attn/flash_blocksparse_attn_interface.py
--rw-r--r--   0 root         (0) root         (0)     7902 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/flash_attn/fused_softmax.py
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:47.944419 flash_attn-2.0.0.post1/flash_attn/layers/
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/flash_attn/layers/__init__.py
--rw-r--r--   0 root         (0) root         (0)     2039 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/flash_attn/layers/patch_embed.py
--rw-r--r--   0 root         (0) root         (0)    12738 2023-07-17 10:14:25.000000 flash_attn-2.0.0.post1/flash_attn/layers/rotary.py
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:47.950788 flash_attn-2.0.0.post1/flash_attn/losses/
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/flash_attn/losses/__init__.py
--rw-r--r--   0 root         (0) root         (0)     6697 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/flash_attn/losses/cross_entropy.py
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:47.963561 flash_attn-2.0.0.post1/flash_attn/models/
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/flash_attn/models/__init__.py
--rw-r--r--   0 root         (0) root         (0)    26570 2023-04-18 20:33:07.000000 flash_attn-2.0.0.post1/flash_attn/models/bert.py
--rw-r--r--   0 root         (0) root         (0)    38025 2023-06-02 19:10:34.000000 flash_attn-2.0.0.post1/flash_attn/models/gpt.py
--rw-r--r--   0 root         (0) root         (0)     5025 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/flash_attn/models/gpt_neox.py
--rw-r--r--   0 root         (0) root         (0)     4365 2023-04-18 20:33:24.000000 flash_attn-2.0.0.post1/flash_attn/models/gptj.py
--rw-r--r--   0 root         (0) root         (0)     5761 2023-04-19 04:11:30.000000 flash_attn-2.0.0.post1/flash_attn/models/llama.py
--rw-r--r--   0 root         (0) root         (0)     5130 2023-04-18 20:33:17.000000 flash_attn-2.0.0.post1/flash_attn/models/opt.py
--rw-r--r--   0 root         (0) root         (0)    13621 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/flash_attn/models/vit.py
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:47.981227 flash_attn-2.0.0.post1/flash_attn/modules/
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/flash_attn/modules/__init__.py
--rw-r--r--   0 root         (0) root         (0)    16417 2023-07-17 11:13:14.000000 flash_attn-2.0.0.post1/flash_attn/modules/block.py
--rw-r--r--   0 root         (0) root         (0)     8620 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/flash_attn/modules/embedding.py
--rw-r--r--   0 root         (0) root         (0)    32847 2023-07-17 11:37:55.000000 flash_attn-2.0.0.post1/flash_attn/modules/mha.py
--rw-r--r--   0 root         (0) root         (0)     2221 2023-07-02 06:31:30.000000 flash_attn-2.0.0.post1/flash_attn/modules/mlp.py
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:47.992109 flash_attn-2.0.0.post1/flash_attn/ops/
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/flash_attn/ops/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3002 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/flash_attn/ops/activations.py
--rw-r--r--   0 root         (0) root         (0)    26087 2023-04-18 10:32:08.000000 flash_attn-2.0.0.post1/flash_attn/ops/fused_dense.py
--rw-r--r--   0 root         (0) root         (0)    19306 2023-07-04 21:52:07.000000 flash_attn-2.0.0.post1/flash_attn/ops/layer_norm.py
--rw-r--r--   0 root         (0) root         (0)     3672 2023-04-18 22:26:53.000000 flash_attn-2.0.0.post1/flash_attn/ops/rms_norm.py
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:48.002623 flash_attn-2.0.0.post1/flash_attn/utils/
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/flash_attn/utils/__init__.py
--rw-r--r--   0 root         (0) root         (0)     5909 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/flash_attn/utils/benchmark.py
--rw-r--r--   0 root         (0) root         (0)     5545 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/flash_attn/utils/distributed.py
--rw-r--r--   0 root         (0) root         (0)    14105 2023-04-21 18:28:20.000000 flash_attn-2.0.0.post1/flash_attn/utils/generation.py
--rw-r--r--   0 root         (0) root         (0)     1824 2023-04-16 00:48:37.000000 flash_attn-2.0.0.post1/flash_attn/utils/pretrained.py
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-17 13:04:47.941408 flash_attn-2.0.0.post1/flash_attn.egg-info/
--rw-rw-r--   0 root         (0) root         (0)      482 2023-07-17 13:04:36.000000 flash_attn-2.0.0.post1/flash_attn.egg-info/PKG-INFO
--rw-rw-r--   0 root         (0) root         (0)   102362 2023-07-17 13:04:37.000000 flash_attn-2.0.0.post1/flash_attn.egg-info/SOURCES.txt
--rw-rw-r--   0 root         (0) root         (0)        1 2023-07-17 13:04:36.000000 flash_attn-2.0.0.post1/flash_attn.egg-info/dependency_links.txt
--rw-rw-r--   0 root         (0) root         (0)       29 2023-07-17 13:04:36.000000 flash_attn-2.0.0.post1/flash_attn.egg-info/requires.txt
--rw-rw-r--   0 root         (0) root         (0)       29 2023-07-17 13:04:36.000000 flash_attn-2.0.0.post1/flash_attn.egg-info/top_level.txt
--rw-rw-r--   0 root         (0) root         (0)       38 2023-07-17 13:04:47.999437 flash_attn-2.0.0.post1/setup.cfg
--rw-r--r--   0 root         (0) root         (0)     9562 2023-07-17 10:25:17.000000 flash_attn-2.0.0.post1/setup.py
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:18.195256 flash_attn-2.0.1/
+-rw-r--r--   0 root         (0) root         (0)       29 2023-07-20 23:38:22.000000 flash_attn-2.0.1/AUTHORS
+-rw-r--r--   0 root         (0) root         (0)     1558 2022-09-09 19:08:03.000000 flash_attn-2.0.1/LICENSE
+-rw-r--r--   0 root         (0) root         (0)      315 2023-07-20 23:38:22.000000 flash_attn-2.0.1/MANIFEST.in
+-rw-rw-r--   0 root         (0) root         (0)      476 2023-07-24 08:09:18.192462 flash_attn-2.0.1/PKG-INFO
+-rw-r--r--   0 root         (0) root         (0)     9403 2023-07-23 17:32:29.000000 flash_attn-2.0.1/README.md
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.225348 flash_attn-2.0.1/csrc/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.014464 flash_attn-2.0.1/csrc/cutlass/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.342797 flash_attn-2.0.1/csrc/cutlass/cmake/
+-rw-rw-r--   0 root         (0) root         (0)     2023 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/cmake/nop.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:52.637169 flash_attn-2.0.1/csrc/cutlass/examples/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.363413 flash_attn-2.0.1/csrc/cutlass/examples/00_basic_gemm/
+-rw-r--r--   0 root         (0) root         (0)    14698 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/00_basic_gemm/basic_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.380751 flash_attn-2.0.1/csrc/cutlass/examples/01_cutlass_utilities/
+-rw-rw-r--   0 root         (0) root         (0)    13255 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/01_cutlass_utilities/cutlass_utilities.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.398140 flash_attn-2.0.1/csrc/cutlass/examples/02_dump_reg_shmem/
+-rw-rw-r--   0 root         (0) root         (0)     7157 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/02_dump_reg_shmem/dump_reg_shmem.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.464663 flash_attn-2.0.1/csrc/cutlass/examples/03_visualize_layout/
+-rw-rw-r--   0 root         (0) root         (0)     4478 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/03_visualize_layout/options.h
+-rw-rw-r--   0 root         (0) root         (0)     7081 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/03_visualize_layout/register_layout.cu
+-rw-rw-r--   0 root         (0) root         (0)     2691 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/03_visualize_layout/register_layout.h
+-rw-rw-r--   0 root         (0) root         (0)     5819 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/03_visualize_layout/visualize_layout.cpp
+-rw-rw-r--   0 root         (0) root         (0)    11415 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/03_visualize_layout/visualize_layout.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.482326 flash_attn-2.0.1/csrc/cutlass/examples/04_tile_iterator/
+-rw-rw-r--   0 root         (0) root         (0)     8226 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/04_tile_iterator/tile_iterator.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.502408 flash_attn-2.0.1/csrc/cutlass/examples/05_batched_gemm/
+-rw-rw-r--   0 root         (0) root         (0)    15161 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/05_batched_gemm/batched_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.520082 flash_attn-2.0.1/csrc/cutlass/examples/06_splitK_gemm/
+-rw-rw-r--   0 root         (0) root         (0)    17570 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/06_splitK_gemm/splitk_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.537516 flash_attn-2.0.1/csrc/cutlass/examples/07_volta_tensorop_gemm/
+-rw-r--r--   0 root         (0) root         (0)    18280 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/07_volta_tensorop_gemm/volta_tensorop_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.554925 flash_attn-2.0.1/csrc/cutlass/examples/08_turing_tensorop_gemm/
+-rw-r--r--   0 root         (0) root         (0)    18226 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/08_turing_tensorop_gemm/turing_tensorop_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.573483 flash_attn-2.0.1/csrc/cutlass/examples/09_turing_tensorop_conv2dfprop/
+-rw-r--r--   0 root         (0) root         (0)    28124 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/09_turing_tensorop_conv2dfprop/turing_tensorop_conv2dfprop.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.591312 flash_attn-2.0.1/csrc/cutlass/examples/10_planar_complex/
+-rw-rw-r--   0 root         (0) root         (0)    21947 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/10_planar_complex/planar_complex.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.609501 flash_attn-2.0.1/csrc/cutlass/examples/11_planar_complex_array/
+-rw-rw-r--   0 root         (0) root         (0)    23244 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/11_planar_complex_array/planar_complex_array.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.627002 flash_attn-2.0.1/csrc/cutlass/examples/12_gemm_bias_relu/
+-rw-rw-r--   0 root         (0) root         (0)    13151 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/12_gemm_bias_relu/gemm_bias_relu.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.897199 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/
+-rw-rw-r--   0 root         (0) root         (0)    26102 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_conv2d_run.h
+-rw-r--r--   0 root         (0) root         (0)    22877 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_gemm_run.h
+-rw-rw-r--   0 root         (0) root         (0)    28268 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_conv2d_run.h
+-rw-r--r--   0 root         (0) root         (0)    24493 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_gemm_run.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.928382 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/device/
+-rw-r--r--   0 root         (0) root         (0)    15552 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/device/b2b_gemm.h
+-rw-rw-r--   0 root         (0) root         (0)    11520 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/device/b2b_implicit_gemm_convolution.h
+-rw-rw-r--   0 root         (0) root         (0)     8756 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_rf.cu
+-rw-rw-r--   0 root         (0) root         (0)     8759 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_shmem.cu
+-rw-rw-r--   0 root         (0) root         (0)     8712 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_rf.cu
+-rw-rw-r--   0 root         (0) root         (0)     8762 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_shmem.cu
+-rw-rw-r--   0 root         (0) root         (0)     8787 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_rf.cu
+-rw-rw-r--   0 root         (0) root         (0)     8793 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_shmem.cu
+-rw-rw-r--   0 root         (0) root         (0)     8711 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_rf.cu
+-rw-rw-r--   0 root         (0) root         (0)     8775 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_shmem.cu
+-rw-rw-r--   0 root         (0) root         (0)     7269 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_rf.cu
+-rw-rw-r--   0 root         (0) root         (0)     7338 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_shmem.cu
+-rw-rw-r--   0 root         (0) root         (0)     7294 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_rf.cu
+-rw-rw-r--   0 root         (0) root         (0)     7359 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_shmem.cu
+-rw-rw-r--   0 root         (0) root         (0)     7362 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_rf.cu
+-rw-rw-r--   0 root         (0) root         (0)     7430 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_shmem.cu
+-rw-r--r--   0 root         (0) root         (0)     7627 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_rf.cu
+-rw-r--r--   0 root         (0) root         (0)     7634 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_shmem.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.046275 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/
+-rw-r--r--   0 root         (0) root         (0)    16152 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_gemm.h
+-rw-rw-r--   0 root         (0) root         (0)    18151 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_implicit_gemm_convolution.h
+-rw-rw-r--   0 root         (0) root         (0)     3973 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop.h
+-rw-rw-r--   0 root         (0) root         (0)    26762 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm75.h
+-rw-rw-r--   0 root         (0) root         (0)    26775 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm80.h
+-rw-rw-r--   0 root         (0) root         (0)    28422 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm75.h
+-rw-rw-r--   0 root         (0) root         (0)    28073 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm80.h
+-rw-r--r--   0 root         (0) root         (0)    17111 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm.h
+-rw-r--r--   0 root         (0) root         (0)    15658 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm_smem_accumulator.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:52.395211 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/reference/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.067466 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/reference/device/
+-rw-r--r--   0 root         (0) root         (0)    10368 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/reference/device/tensor_scale_bias.h
+-rw-rw-r--   0 root         (0) root         (0)     3577 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/test_run.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.220373 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/
+-rw-rw-r--   0 root         (0) root         (0)    31616 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage.h
+-rw-rw-r--   0 root         (0) root         (0)    31443 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage_smem_accumulator.h
+-rw-r--r--   0 root         (0) root         (0)    21010 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined.h
+-rw-r--r--   0 root         (0) root         (0)    20493 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined_smem_accumulator.h
+-rw-rw-r--   0 root         (0) root         (0)     7983 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base.h
+-rw-rw-r--   0 root         (0) root         (0)     6047 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base_smem_accumulator.h
+-rw-r--r--   0 root         (0) root         (0)    33788 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    33506 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage_smem_accumulator.h
+-rw-r--r--   0 root         (0) root         (0)    21451 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined.h
+-rw-r--r--   0 root         (0) root         (0)    21065 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined_smem_accumulator.h
+-rw-rw-r--   0 root         (0) root         (0)    27144 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma.h
+-rw-rw-r--   0 root         (0) root         (0)    27400 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma_smem_accumulator.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.238458 flash_attn-2.0.1/csrc/cutlass/examples/14_ampere_tf32_tensorop_gemm/
+-rw-rw-r--   0 root         (0) root         (0)    18020 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/14_ampere_tf32_tensorop_gemm/ampere_tf32_tensorop_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.256062 flash_attn-2.0.1/csrc/cutlass/examples/15_ampere_sparse_tensorop_gemm/
+-rw-rw-r--   0 root         (0) root         (0)    15042 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/15_ampere_sparse_tensorop_gemm/ampere_sparse_tensorop_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.273789 flash_attn-2.0.1/csrc/cutlass/examples/16_ampere_tensorop_conv2dfprop/
+-rw-r--r--   0 root         (0) root         (0)    27755 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/16_ampere_tensorop_conv2dfprop/ampere_tensorop_conv2dfprop.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.291238 flash_attn-2.0.1/csrc/cutlass/examples/17_fprop_per_channel_bias/
+-rw-rw-r--   0 root         (0) root         (0)    12580 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/17_fprop_per_channel_bias/fprop_per_channel_bias.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.308725 flash_attn-2.0.1/csrc/cutlass/examples/18_ampere_fp64_tensorop_affine2_gemm/
+-rw-rw-r--   0 root         (0) root         (0)    14007 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/18_ampere_fp64_tensorop_affine2_gemm/ampere_fp64_tensorop_affine2_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.326713 flash_attn-2.0.1/csrc/cutlass/examples/19_tensorop_canonical/
+-rw-rw-r--   0 root         (0) root         (0)    13401 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/19_tensorop_canonical/tensorop_canonical.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.349176 flash_attn-2.0.1/csrc/cutlass/examples/20_simt_canonical/
+-rw-rw-r--   0 root         (0) root         (0)    12556 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/20_simt_canonical/simt_canonical.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.368640 flash_attn-2.0.1/csrc/cutlass/examples/21_quaternion_gemm/
+-rw-rw-r--   0 root         (0) root         (0)    17319 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/21_quaternion_gemm/quaternion_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.385995 flash_attn-2.0.1/csrc/cutlass/examples/22_quaternion_conv/
+-rw-r--r--   0 root         (0) root         (0)    21495 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/22_quaternion_conv/quaternion_conv.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.404487 flash_attn-2.0.1/csrc/cutlass/examples/23_ampere_gemm_operand_reduction_fusion/
+-rw-r--r--   0 root         (0) root         (0)    27530 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/23_ampere_gemm_operand_reduction_fusion/ampere_gemm_operand_reduction_fusion.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.422366 flash_attn-2.0.1/csrc/cutlass/examples/24_gemm_grouped/
+-rw-r--r--   0 root         (0) root         (0)    50967 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/24_gemm_grouped/gemm_grouped.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.452742 flash_attn-2.0.1/csrc/cutlass/examples/25_ampere_fprop_mainloop_fusion/
+-rw-rw-r--   0 root         (0) root         (0)    26547 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_3d_fprop_mainloop_fusion.cu
+-rw-rw-r--   0 root         (0) root         (0)    25628 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_fprop_mainloop_fusion.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.470106 flash_attn-2.0.1/csrc/cutlass/examples/26_ampere_wgrad_mainloop_fusion/
+-rw-rw-r--   0 root         (0) root         (0)    25538 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/26_ampere_wgrad_mainloop_fusion/ampere_wgrad_mainloop_fusion.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.487593 flash_attn-2.0.1/csrc/cutlass/examples/27_ampere_3xtf32_fast_accurate_tensorop_gemm/
+-rw-rw-r--   0 root         (0) root         (0)    30446 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/27_ampere_3xtf32_fast_accurate_tensorop_gemm/27_ampere_3xtf32_fast_accurate_tensorop_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.505271 flash_attn-2.0.1/csrc/cutlass/examples/28_ampere_3xtf32_fast_accurate_tensorop_fprop/
+-rw-rw-r--   0 root         (0) root         (0)    28159 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/28_ampere_3xtf32_fast_accurate_tensorop_fprop/ampere_3xtf32_fast_accurate_tensorop_fprop.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.525884 flash_attn-2.0.1/csrc/cutlass/examples/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm/
+-rw-r--r--   0 root         (0) root         (0)    28403 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.543326 flash_attn-2.0.1/csrc/cutlass/examples/30_wgrad_split_k/
+-rw-rw-r--   0 root         (0) root         (0)    27329 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/30_wgrad_split_k/30_wgrad_split_k.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.560890 flash_attn-2.0.1/csrc/cutlass/examples/31_basic_syrk/
+-rw-r--r--   0 root         (0) root         (0)    15206 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/31_basic_syrk/basic_syrk.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.579306 flash_attn-2.0.1/csrc/cutlass/examples/32_basic_trmm/
+-rw-r--r--   0 root         (0) root         (0)    15907 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/32_basic_trmm/basic_trmm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.596709 flash_attn-2.0.1/csrc/cutlass/examples/33_ampere_3xtf32_tensorop_symm/
+-rw-rw-r--   0 root         (0) root         (0)    31803 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/33_ampere_3xtf32_tensorop_symm/ampere_3xtf32_tensorop_symm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.615405 flash_attn-2.0.1/csrc/cutlass/examples/34_transposed_conv2d/
+-rw-rw-r--   0 root         (0) root         (0)    22378 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/34_transposed_conv2d/34_transposed_conv2d.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.659046 flash_attn-2.0.1/csrc/cutlass/examples/35_gemm_softmax/
+-rw-rw-r--   0 root         (0) root         (0)    23114 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/35_gemm_softmax/gemm_softmax.cu
+-rw-rw-r--   0 root         (0) root         (0)    16723 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/35_gemm_softmax/gemm_with_epilogue_visitor.h
+-rw-r--r--   0 root         (0) root         (0)    18713 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/35_gemm_softmax/gemm_with_softmax.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.677125 flash_attn-2.0.1/csrc/cutlass/examples/36_gather_scatter_fusion/
+-rw-rw-r--   0 root         (0) root         (0)    20795 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/36_gather_scatter_fusion/gather_scatter_fusion.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.721495 flash_attn-2.0.1/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/
+-rw-rw-r--   0 root         (0) root         (0)    31111 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_layernorm.cu
+-rw-rw-r--   0 root         (0) root         (0)    13982 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_epilogue_visitor.h
+-rw-rw-r--   0 root         (0) root         (0)    33905 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_layernorm.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.740388 flash_attn-2.0.1/csrc/cutlass/examples/38_syr2k_grouped/
+-rw-rw-r--   0 root         (0) root         (0)    47455 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/38_syr2k_grouped/syr2k_grouped.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.758015 flash_attn-2.0.1/csrc/cutlass/examples/39_gemm_permute/
+-rw-r--r--   0 root         (0) root         (0)    37896 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/39_gemm_permute/gemm_permute.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.862005 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/
+-rw-rw-r--   0 root         (0) root         (0)    11865 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/debug_utils.h
+-rw-r--r--   0 root         (0) root         (0)     9885 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/default_fmha_grouped.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.904161 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/
+-rw-rw-r--   0 root         (0) root         (0)    22349 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_pipelined.h
+-rw-rw-r--   0 root         (0) root         (0)     9162 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_rescale_output.h
+-rw-rw-r--   0 root         (0) root         (0)     6111 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_thread_apply_logsumexp.h
+-rw-r--r--   0 root         (0) root         (0)    34379 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/fmha_grouped.h
+-rw-rw-r--   0 root         (0) root         (0)     6666 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/fmha_grouped_problem_visitor.h
+-rw-r--r--   0 root         (0) root         (0)    38173 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_fixed_seqlen.cu
+-rw-r--r--   0 root         (0) root         (0)    39997 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_variable_seqlen.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:54.995198 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/
+-rw-rw-r--   0 root         (0) root         (0)     3994 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma.h
+-rw-rw-r--   0 root         (0) root         (0)     6241 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_base.h
+-rw-r--r--   0 root         (0) root         (0)    27198 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    14090 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_pipelined.h
+-rw-rw-r--   0 root         (0) root         (0)     6782 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/find_default_mma.h
+-rw-rw-r--   0 root         (0) root         (0)    13959 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/mma_accum_lambda_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    72983 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/mma_from_smem.h
+-rw-r--r--   0 root         (0) root         (0)    10878 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm_kernel_utils.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.074460 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/
+-rw-rw-r--   0 root         (0) root         (0)    23855 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/epilogue_predicated_tile_iterator.h
+-rw-rw-r--   0 root         (0) root         (0)     3142 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/make_residual_last.h
+-rw-r--r--   0 root         (0) root         (0)    64480 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_access_iterator_residual_last.h
+-rw-rw-r--   0 root         (0) root         (0)    64500 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_iterator_residual_last.h
+-rw-r--r--   0 root         (0) root         (0)     2435 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/transpose_warp_iterator.h
+-rw-r--r--   0 root         (0) root         (0)     9497 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/warp_iterator_from_smem.h
+-rw-r--r--   0 root         (0) root         (0)    48655 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/kernel_forward.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.091812 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/transform/
+-rw-r--r--   0 root         (0) root         (0)     3747 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/transform/tile_smem_loader.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.109261 flash_attn-2.0.1/csrc/cutlass/examples/42_ampere_tensorop_group_conv/
+-rw-rw-r--   0 root         (0) root         (0)    23901 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/42_ampere_tensorop_group_conv/ampere_tensorop_group_conv.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.126713 flash_attn-2.0.1/csrc/cutlass/examples/43_ell_block_sparse_gemm/
+-rw-rw-r--   0 root         (0) root         (0)    23867 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/43_ell_block_sparse_gemm/ell_block_sparse_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.154835 flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:52.578950 flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:52.569342 flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.216363 flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/
+-rw-rw-r--   0 root         (0) root         (0)     6370 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_bias_act_epilogue_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)     4099 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_thread_map_tensor_op_for_fused_bias.h
+-rw-rw-r--   0 root         (0) root         (0)     8285 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/fused_bias_act_epilogue.h
+-rw-rw-r--   0 root         (0) root         (0)    10439 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/output_tile_thread_map_for_fused_bias.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.234398 flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/warp/
+-rw-rw-r--   0 root         (0) root         (0)     6848 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/warp/fused_bias_act_fragment_iterator_tensor_op.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:52.583637 flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.255216 flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/warp/
+-rw-rw-r--   0 root         (0) root         (0)    14747 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/warp/mma_tensor_op_fragment_iterator_without_output_op.h
+-rw-rw-r--   0 root         (0) root         (0)    10231 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/leaky_bias.h
+-rw-rw-r--   0 root         (0) root         (0)     3745 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/utils.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.309595 flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.326942 flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/device/
+-rw-r--r--   0 root         (0) root         (0)    16955 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/device/dual_gemm.h
+-rw-r--r--   0 root         (0) root         (0)    12669 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/dual_gemm.cu
+-rw-rw-r--   0 root         (0) root         (0)     2366 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/dual_gemm_common.h
+-rw-r--r--   0 root         (0) root         (0)    31360 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/dual_gemm_run.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.348761 flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/kernel/
+-rw-r--r--   0 root         (0) root         (0)    18422 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/kernel/dual_gemm.h
+-rw-rw-r--   0 root         (0) root         (0)     3577 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/test_run.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.367777 flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/thread/
+-rw-rw-r--   0 root         (0) root         (0)     5818 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/thread/left_silu_and_mul.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.409696 flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/threadblock/
+-rw-rw-r--   0 root         (0) root         (0)    15613 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_epilogue.h
+-rw-rw-r--   0 root         (0) root         (0)     7920 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_mma_base.h
+-rw-r--r--   0 root         (0) root         (0)    29976 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_mma_multistage.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.428950 flash_attn-2.0.1/csrc/cutlass/examples/46_depthwise_simt_conv2dfprop/
+-rw-r--r--   0 root         (0) root         (0)    24464 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/46_depthwise_simt_conv2dfprop/depthwise_simt_conv2dfprop.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.446475 flash_attn-2.0.1/csrc/cutlass/examples/47_ampere_gemm_universal_streamk/
+-rw-r--r--   0 root         (0) root         (0)    22676 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/47_ampere_gemm_universal_streamk/ampere_gemm_universal_streamk.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.464635 flash_attn-2.0.1/csrc/cutlass/examples/48_hopper_warp_specialized_gemm/
+-rw-r--r--   0 root         (0) root         (0)    16736 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/48_hopper_warp_specialized_gemm/48_hopper_warp_specialized_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.482033 flash_attn-2.0.1/csrc/cutlass/examples/49_hopper_gemm_schedules_with_collective_builder/
+-rw-r--r--   0 root         (0) root         (0)    22631 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/49_hopper_gemm_schedules_with_collective_builder/49_hopper_gemm_schedules_with_collective_builder.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.499634 flash_attn-2.0.1/csrc/cutlass/examples/50_hopper_gemm_with_epilogue_swizzle/
+-rw-r--r--   0 root         (0) root         (0)    18635 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/50_hopper_gemm_with_epilogue_swizzle/50_hopper_gemm_with_epilogue_swizzle.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.516920 flash_attn-2.0.1/csrc/cutlass/examples/60_cutlass_import/
+-rw-rw-r--   0 root         (0) root         (0)     2849 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/60_cutlass_import/main.cpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.534408 flash_attn-2.0.1/csrc/cutlass/examples/common/
+-rw-r--r--   0 root         (0) root         (0)     4449 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/examples/common/helper.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:52.646915 flash_attn-2.0.1/csrc/cutlass/examples/cute/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.554956 flash_attn-2.0.1/csrc/cutlass/examples/cute/tutorial/
+-rw-rw-r--   0 root         (0) root         (0)    14342 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/examples/cute/tutorial/sgemm_nt_1.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:52.688400 flash_attn-2.0.1/csrc/cutlass/include/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.711151 flash_attn-2.0.1/csrc/cutlass/include/cute/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:55.826821 flash_attn-2.0.1/csrc/cutlass/include/cute/algorithm/
+-rw-rw-r--   0 root         (0) root         (0)     2838 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/algorithm/axpby.hpp
+-rw-rw-r--   0 root         (0) root         (0)     2351 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/algorithm/clear.hpp
+-rw-r--r--   0 root         (0) root         (0)     8058 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/algorithm/copy.hpp
+-rw-rw-r--   0 root         (0) root         (0)     2906 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/algorithm/fill.hpp
+-rw-r--r--   0 root         (0) root         (0)     7206 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/algorithm/functional.hpp
+-rw-r--r--   0 root         (0) root         (0)    25632 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/algorithm/gemm.hpp
+-rw-r--r--   0 root         (0) root         (0)     2129 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/algorithm/prefer.hpp
+-rw-r--r--   0 root         (0) root         (0)     3332 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/algorithm/tensor_algorithms.hpp
+-rw-r--r--   0 root         (0) root         (0)    20772 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/algorithm/tuple_algorithms.hpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:56.037907 flash_attn-2.0.1/csrc/cutlass/include/cute/arch/
+-rw-r--r--   0 root         (0) root         (0)     5809 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/arch/cluster_sm90.hpp
+-rw-rw-r--   0 root         (0) root         (0)     2453 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/arch/copy.hpp
+-rw-r--r--   0 root         (0) root         (0)     6785 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/arch/copy_sm75.hpp
+-rw-rw-r--   0 root         (0) root         (0)     4812 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/arch/copy_sm80.hpp
+-rw-rw-r--   0 root         (0) root         (0)     7325 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/arch/copy_sm90.hpp
+-rw-r--r--   0 root         (0) root         (0)     7973 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/arch/copy_sm90_desc.hpp
+-rw-r--r--   0 root         (0) root         (0)    20296 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/arch/copy_sm90_tma.hpp
+-rw-rw-r--   0 root         (0) root         (0)     2393 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/arch/mma.hpp
+-rw-rw-r--   0 root         (0) root         (0)     3160 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/arch/mma_sm61.hpp
+-rw-rw-r--   0 root         (0) root         (0)    12452 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/arch/mma_sm70.hpp
+-rw-rw-r--   0 root         (0) root         (0)     4262 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/arch/mma_sm75.hpp
+-rw-rw-r--   0 root         (0) root         (0)    68248 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/arch/mma_sm80.hpp
+-rw-r--r--   0 root         (0) root         (0)    36696 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/arch/mma_sm90.hpp
+-rw-r--r--   0 root         (0) root         (0)     5323 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/arch/mma_sm90_desc.hpp
+-rw-r--r--   0 root         (0) root         (0)   581439 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/arch/mma_sm90_gmma.hpp
+-rw-r--r--   0 root         (0) root         (0)     5815 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/arch/util.hpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:56.225231 flash_attn-2.0.1/csrc/cutlass/include/cute/atom/
+-rw-r--r--   0 root         (0) root         (0)    23436 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/atom/copy_atom.hpp
+-rw-r--r--   0 root         (0) root         (0)     2950 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/atom/copy_traits.hpp
+-rw-rw-r--   0 root         (0) root         (0)     5087 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/atom/copy_traits_sm75.hpp
+-rw-rw-r--   0 root         (0) root         (0)     3689 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/atom/copy_traits_sm80.hpp
+-rw-rw-r--   0 root         (0) root         (0)     4589 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/atom/copy_traits_sm90.hpp
+-rw-r--r--   0 root         (0) root         (0)    32901 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/atom/copy_traits_sm90_tma.hpp
+-rw-r--r--   0 root         (0) root         (0)    38366 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/atom/mma_atom.hpp
+-rw-r--r--   0 root         (0) root         (0)     2697 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/atom/mma_traits.hpp
+-rw-rw-r--   0 root         (0) root         (0)     2797 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/atom/mma_traits_sm61.hpp
+-rw-rw-r--   0 root         (0) root         (0)     6188 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/atom/mma_traits_sm70.hpp
+-rw-rw-r--   0 root         (0) root         (0)     3327 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/atom/mma_traits_sm75.hpp
+-rw-rw-r--   0 root         (0) root         (0)    14416 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/atom/mma_traits_sm80.hpp
+-rw-rw-r--   0 root         (0) root         (0)     5121 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/atom/mma_traits_sm90.hpp
+-rw-r--r--   0 root         (0) root         (0)   104752 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/atom/mma_traits_sm90_gmma.hpp
+-rw-r--r--   0 root         (0) root         (0)     4255 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/config.hpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:56.329341 flash_attn-2.0.1/csrc/cutlass/include/cute/container/
+-rw-r--r--   0 root         (0) root         (0)     2988 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/container/alignment.hpp
+-rw-r--r--   0 root         (0) root         (0)     5917 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/container/array.hpp
+-rw-r--r--   0 root         (0) root         (0)     6508 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/container/array_aligned.hpp
+-rw-r--r--   0 root         (0) root         (0)    14960 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/container/array_subbyte.hpp
+-rw-r--r--   0 root         (0) root         (0)     5555 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/container/array_view.hpp
+-rw-r--r--   0 root         (0) root         (0)     5485 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/container/bit_field.hpp
+-rw-r--r--   0 root         (0) root         (0)    19389 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/container/tuple.hpp
+-rw-r--r--   0 root         (0) root         (0)     2779 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/container/type_list.hpp
+-rw-r--r--   0 root         (0) root         (0)    24937 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/int_tuple.hpp
+-rw-r--r--   0 root         (0) root         (0)    50290 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/layout.hpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:56.502729 flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/
+-rw-r--r--   0 root         (0) root         (0)    10917 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/arithmetic_tuple.hpp
+-rw-r--r--   0 root         (0) root         (0)     2134 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/bfloat.hpp
+-rw-r--r--   0 root         (0) root         (0)     4516 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/complex.hpp
+-rw-rw-r--   0 root         (0) root         (0)     2033 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/float8.hpp
+-rw-rw-r--   0 root         (0) root         (0)     1997 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/half.hpp
+-rw-r--r--   0 root         (0) root         (0)     4280 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/int.hpp
+-rw-r--r--   0 root         (0) root         (0)     4216 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/integer_sequence.hpp
+-rw-r--r--   0 root         (0) root         (0)     7139 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/integer_subbyte.hpp
+-rw-r--r--   0 root         (0) root         (0)    12839 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/integral_constant.hpp
+-rw-r--r--   0 root         (0) root         (0)     8826 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/math.hpp
+-rw-rw-r--   0 root         (0) root         (0)     2259 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/real.hpp
+-rw-r--r--   0 root         (0) root         (0)     2134 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/tfloat.hpp
+-rw-rw-r--   0 root         (0) root         (0)     7531 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/uint128.hpp
+-rw-r--r--   0 root         (0) root         (0)     7829 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/pointer.hpp
+-rw-r--r--   0 root         (0) root         (0)    13950 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/stride.hpp
+-rw-r--r--   0 root         (0) root         (0)    17168 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/swizzle.hpp
+-rw-r--r--   0 root         (0) root         (0)    35450 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/swizzle_layout.hpp
+-rw-r--r--   0 root         (0) root         (0)     9413 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/swizzle_ptr.hpp
+-rw-r--r--   0 root         (0) root         (0)    25878 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/tensor.hpp
+-rw-rw-r--   0 root         (0) root         (0)     2305 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/tensor_predicate.hpp
+-rw-rw-r--   0 root         (0) root         (0)     2279 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/tile.hpp
+-rw-r--r--   0 root         (0) root         (0)     5052 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/underscore.hpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:56.544663 flash_attn-2.0.1/csrc/cutlass/include/cute/util/
+-rw-r--r--   0 root         (0) root         (0)     4867 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/util/debug.hpp
+-rw-r--r--   0 root         (0) root         (0)     3486 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/util/print.hpp
+-rw-r--r--   0 root         (0) root         (0)     3362 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cute/util/type_traits.hpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:57.109870 flash_attn-2.0.1/csrc/cutlass/include/cutlass/
+-rw-rw-r--   0 root         (0) root         (0)     3793 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/aligned_buffer.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:57.412709 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/
+-rw-r--r--   0 root         (0) root         (0)     3538 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/arch.h
+-rw-r--r--   0 root         (0) root         (0)    12127 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/barrier.h
+-rw-rw-r--   0 root         (0) root         (0)     2691 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/cache_operation.h
+-rw-r--r--   0 root         (0) root         (0)    14313 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/memory.h
+-rw-r--r--   0 root         (0) root         (0)     8511 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/memory_sm75.h
+-rw-rw-r--   0 root         (0) root         (0)    15166 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/memory_sm80.h
+-rw-r--r--   0 root         (0) root         (0)     8072 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/mma.h
+-rw-rw-r--   0 root         (0) root         (0)    11096 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/mma_sm50.h
+-rw-rw-r--   0 root         (0) root         (0)     7040 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/mma_sm60.h
+-rw-rw-r--   0 root         (0) root         (0)     4193 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/mma_sm61.h
+-rw-rw-r--   0 root         (0) root         (0)    16554 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/mma_sm70.h
+-rw-rw-r--   0 root         (0) root         (0)    31682 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/mma_sm75.h
+-rw-rw-r--   0 root         (0) root         (0)    55577 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/mma_sm80.h
+-rw-r--r--   0 root         (0) root         (0)     8254 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/mma_sm90.h
+-rw-rw-r--   0 root         (0) root         (0)    43978 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/mma_sparse_sm80.h
+-rw-rw-r--   0 root         (0) root         (0)     2622 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/reg_reconfig.h
+-rw-rw-r--   0 root         (0) root         (0)     3998 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/simd.h
+-rw-rw-r--   0 root         (0) root         (0)     3656 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/simd_sm60.h
+-rw-rw-r--   0 root         (0) root         (0)     5102 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/simd_sm61.h
+-rw-rw-r--   0 root         (0) root         (0)     8473 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/wmma.h
+-rw-rw-r--   0 root         (0) root         (0)     5286 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/wmma_sm70.h
+-rw-rw-r--   0 root         (0) root         (0)     7746 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/wmma_sm72.h
+-rw-rw-r--   0 root         (0) root         (0)     7616 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/wmma_sm75.h
+-rw-rw-r--   0 root         (0) root         (0)    62709 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/array.h
+-rw-rw-r--   0 root         (0) root         (0)     3662 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/array_planar_complex.h
+-rw-rw-r--   0 root         (0) root         (0)    13128 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/array_subbyte.h
+-rw-r--r--   0 root         (0) root         (0)     6371 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/barrier.h
+-rw-rw-r--   0 root         (0) root         (0)    13371 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/bfloat16.h
+-rw-rw-r--   0 root         (0) root         (0)     6338 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/blas3.h
+-rw-rw-r--   0 root         (0) root         (0)     9372 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/block_striped.h
+-rw-r--r--   0 root         (0) root         (0)     6113 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/cluster_launch.hpp
+-rw-r--r--   0 root         (0) root         (0)    19422 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/complex.h
+-rw-rw-r--   0 root         (0) root         (0)    47943 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/constants.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:57.453244 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/
+-rw-r--r--   0 root         (0) root         (0)    22725 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/conv2d_problem_size.h
+-rw-rw-r--   0 root         (0) root         (0)    16292 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/conv3d_problem_size.h
+-rw-r--r--   0 root         (0) root         (0)     6664 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/convolution.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:57.495099 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/device/
+-rw-rw-r--   0 root         (0) root         (0)     9744 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/device/direct_convolution.h
+-rw-rw-r--   0 root         (0) root         (0)    12078 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/device/implicit_gemm_convolution.h
+-rw-rw-r--   0 root         (0) root         (0)    10044 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/device/implicit_gemm_convolution_fusion.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:57.741436 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/
+-rw-rw-r--   0 root         (0) root         (0)     7671 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d.h
+-rw-rw-r--   0 root         (0) root         (0)    53546 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_dgrad.h
+-rw-rw-r--   0 root         (0) root         (0)    56838 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop.h
+-rw-rw-r--   0 root         (0) root         (0)    11953 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_fusion.h
+-rw-r--r--   0 root         (0) root         (0)     4690 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_broadcast.h
+-rw-r--r--   0 root         (0) root         (0)     4660 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_reduction.h
+-rw-r--r--   0 root         (0) root         (0)    15891 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_group_fprop.h
+-rw-rw-r--   0 root         (0) root         (0)    28745 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad.h
+-rw-rw-r--   0 root         (0) root         (0)    10459 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad_fusion.h
+-rw-rw-r--   0 root         (0) root         (0)     9324 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_dgrad.h
+-rw-rw-r--   0 root         (0) root         (0)    14864 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop.h
+-rw-rw-r--   0 root         (0) root         (0)    11980 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop_fusion.h
+-rw-rw-r--   0 root         (0) root         (0)    14883 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_wgrad.h
+-rw-r--r--   0 root         (0) root         (0)    19294 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_depthwise_fprop.h
+-rw-rw-r--   0 root         (0) root         (0)    18048 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/direct_convolution.h
+-rw-rw-r--   0 root         (0) root         (0)    15430 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution.h
+-rw-rw-r--   0 root         (0) root         (0)    15685 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_fusion.h
+-rw-rw-r--   0 root         (0) root         (0)    17107 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_strided_dgrad.h
+-rw-rw-r--   0 root         (0) root         (0)    16725 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_with_fused_epilogue.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:57.759149 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/thread/
+-rw-rw-r--   0 root         (0) root         (0)     9689 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/thread/depthwise_mma.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:58.332171 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/
+-rw-rw-r--   0 root         (0) root         (0)    15306 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_analytic.h
+-rw-rw-r--   0 root         (0) root         (0)    19735 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_optimized.h
+-rw-rw-r--   0 root         (0) root         (0)    18940 2023-07-17 10:57:19.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_analytic.h
+-rw-r--r--   0 root         (0) root         (0)    26137 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_optimized.h
+-rw-r--r--   0 root         (0) root         (0)    10953 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_analytic.h
+-rw-rw-r--   0 root         (0) root         (0)    11529 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_few_channels.h
+-rw-rw-r--   0 root         (0) root         (0)    11333 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_fixed_channels.h
+-rw-r--r--   0 root         (0) root         (0)    13664 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_optimized.h
+-rw-r--r--   0 root         (0) root         (0)    10627 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_analytic.h
+-rw-rw-r--   0 root         (0) root         (0)     9314 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_few_channels.h
+-rw-rw-r--   0 root         (0) root         (0)     9018 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_fixed_channels.h
+-rw-r--r--   0 root         (0) root         (0)    10387 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_optimized.h
+-rw-rw-r--   0 root         (0) root         (0)    30197 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_params.h
+-rw-rw-r--   0 root         (0) root         (0)    11202 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_tile_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    10350 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_analytic.h
+-rw-r--r--   0 root         (0) root         (0)    11520 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_optimized.h
+-rw-r--r--   0 root         (0) root         (0)     9043 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_analytic.h
+-rw-r--r--   0 root         (0) root         (0)    10832 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_optimized.h
+-rw-rw-r--   0 root         (0) root         (0)     8450 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_analytic.h
+-rw-rw-r--   0 root         (0) root         (0)     9569 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_optimized.h
+-rw-rw-r--   0 root         (0) root         (0)    11020 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_analytic.h
+-rw-rw-r--   0 root         (0) root         (0)    15014 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_optimized.h
+-rw-rw-r--   0 root         (0) root         (0)     9634 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_analytic.h
+-rw-rw-r--   0 root         (0) root         (0)    15132 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_optimized.h
+-rw-rw-r--   0 root         (0) root         (0)     7945 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_analytic.h
+-rw-rw-r--   0 root         (0) root         (0)     8891 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_optimized.h
+-rw-rw-r--   0 root         (0) root         (0)    18249 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_params.h
+-rw-r--r--   0 root         (0) root         (0)     9971 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_analytic.h
+-rw-r--r--   0 root         (0) root         (0)    12024 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_optimized.h
+-rw-r--r--   0 root         (0) root         (0)     8821 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_analytic.h
+-rw-r--r--   0 root         (0) root         (0)    10744 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_optimized.h
+-rw-rw-r--   0 root         (0) root         (0)     8871 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_direct_conv_params.h
+-rw-rw-r--   0 root         (0) root         (0)    10747 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_fixed_stride_dilation.h
+-rw-rw-r--   0 root         (0) root         (0)     9899 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_optimized.h
+-rw-rw-r--   0 root         (0) root         (0)    20899 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_direct_conv_multistage.h
+-rw-rw-r--   0 root         (0) root         (0)     8921 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_filter_tile_access_iterator_direct_conv_optimized.h
+-rw-r--r--   0 root         (0) root         (0)    12744 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_pipelined.h
+-rw-rw-r--   0 root         (0) root         (0)     8097 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_mma_base.h
+-rw-rw-r--   0 root         (0) root         (0)    36697 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_mma_core_with_lane_access_size.h
+-rw-rw-r--   0 root         (0) root         (0)    30106 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_fprop_fusion_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    20086 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    12174 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_pipelined.h
+-rw-rw-r--   0 root         (0) root         (0)    26320 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_wgrad_fusion_multistage.h
+-rw-rw-r--   0 root         (0) root         (0)    16915 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_access_iterator.h
+-rw-rw-r--   0 root         (0) root         (0)    12476 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_iterator.h
+-rw-r--r--   0 root         (0) root         (0)     8050 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/threadblock_swizzle.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:58.379053 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/warp/
+-rw-rw-r--   0 root         (0) root         (0)    12419 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/warp/mma_depthwise_simt.h
+-rw-rw-r--   0 root         (0) root         (0)    30655 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/warp/mma_depthwise_simt_tile_iterator.h
+-rw-rw-r--   0 root         (0) root         (0)     8772 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/warp/scale_bias_relu_transform.h
+-rw-rw-r--   0 root         (0) root         (0)    11827 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/coord.h
+-rw-r--r--   0 root         (0) root         (0)    11077 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/core_io.h
+-rw-r--r--   0 root         (0) root         (0)     8697 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/cutlass.h
+-rw-r--r--   0 root         (0) root         (0)     4216 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/device_kernel.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:58.394498 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:58.450926 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/collective/
+-rw-r--r--   0 root         (0) root         (0)     2610 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/collective/collective_epilogue.hpp
+-rw-r--r--   0 root         (0) root         (0)     7786 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/collective/default_epilogue.hpp
+-rw-r--r--   0 root         (0) root         (0)     8109 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/collective/default_transposed_epilogue.hpp
+-rw-r--r--   0 root         (0) root         (0)    13059 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/collective/epilogue.hpp
+-rw-r--r--   0 root         (0) root         (0)     2134 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/dispatch_policy.hpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:58.734224 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/
+-rw-r--r--   0 root         (0) root         (0)    18909 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/activation.h
+-rw-rw-r--   0 root         (0) root         (0)     4691 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/conversion_op.h
+-rw-r--r--   0 root         (0) root         (0)    11563 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination.h
+-rw-r--r--   0 root         (0) root         (0)     8423 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_elementwise.h
+-rw-r--r--   0 root         (0) root         (0)    13569 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_relu.h
+-rw-r--r--   0 root         (0) root         (0)    23649 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_clamp.h
+-rw-r--r--   0 root         (0) root         (0)     9067 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_dgelu.h
+-rw-r--r--   0 root         (0) root         (0)    15195 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_drelu.h
+-rw-rw-r--   0 root         (0) root         (0)     3669 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_gelu.h
+-rw-r--r--   0 root         (0) root         (0)     8065 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_generic.h
+-rw-rw-r--   0 root         (0) root         (0)     3693 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_hardswish.h
+-rw-r--r--   0 root         (0) root         (0)     8344 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_leaky_relu.h
+-rw-r--r--   0 root         (0) root         (0)     3058 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_params.h
+-rw-rw-r--   0 root         (0) root         (0)     9351 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_planar_complex.h
+-rw-r--r--   0 root         (0) root         (0)    20486 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_relu.h
+-rw-r--r--   0 root         (0) root         (0)    19348 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_relu0.h
+-rw-r--r--   0 root         (0) root         (0)    12033 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_residual_block.h
+-rw-rw-r--   0 root         (0) root         (0)     3688 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_sigmoid.h
+-rw-rw-r--   0 root         (0) root         (0)     3669 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_silu.h
+-rw-r--r--   0 root         (0) root         (0)     8662 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_with_elementwise.h
+-rw-rw-r--   0 root         (0) root         (0)     3416 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/reduction_op.h
+-rw-rw-r--   0 root         (0) root         (0)     2656 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/scale_type.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:59.286563 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/
+-rw-r--r--   0 root         (0) root         (0)     9142 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     9441 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op_blas3.h
+-rw-rw-r--   0 root         (0) root         (0)     3234 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_direct_store.h
+-rw-rw-r--   0 root         (0) root         (0)     7209 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_planar_complex.h
+-rw-rw-r--   0 root         (0) root         (0)    13385 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_simt.h
+-rw-rw-r--   0 root         (0) root         (0)    28290 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)     7129 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op_blas3.h
+-rw-rw-r--   0 root         (0) root         (0)    10846 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_volta_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     5817 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_broadcast.h
+-rw-rw-r--   0 root         (0) root         (0)     5763 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_reduction.h
+-rw-rw-r--   0 root         (0) root         (0)     5947 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_wmma_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)     4409 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_simt.h
+-rw-rw-r--   0 root         (0) root         (0)     7398 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)     7303 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_volta_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)     4098 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_wmma_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)     4678 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/direct_store_epilogue_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    20099 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue.h
+-rw-rw-r--   0 root         (0) root         (0)     8279 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_base.h
+-rw-rw-r--   0 root         (0) root         (0)     7455 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_base_streamk.h
+-rw-rw-r--   0 root         (0) root         (0)    13424 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_depthwise.h
+-rw-rw-r--   0 root         (0) root         (0)    13933 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_direct_store.h
+-rw-rw-r--   0 root         (0) root         (0)     7401 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_gemm_k_reduction.h
+-rw-rw-r--   0 root         (0) root         (0)    14610 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_planar_complex.h
+-rw-rw-r--   0 root         (0) root         (0)     9073 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_smem_accumulator.h
+-rw-rw-r--   0 root         (0) root         (0)    16804 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_visitor_with_softmax.h
+-rw-r--r--   0 root         (0) root         (0)    52430 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_broadcast.h
+-rw-rw-r--   0 root         (0) root         (0)    29199 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_reduction.h
+-rw-rw-r--   0 root         (0) root         (0)    13454 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_visitor.h
+-rw-rw-r--   0 root         (0) root         (0)     7308 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_workspace.h
+-rw-rw-r--   0 root         (0) root         (0)    14359 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/interleaved_epilogue.h
+-rw-rw-r--   0 root         (0) root         (0)     2912 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/output_iterator_parameter.h
+-rw-rw-r--   0 root         (0) root         (0)    19750 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/output_tile_thread_map.h
+-rw-r--r--   0 root         (0) root         (0)    40870 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator.h
+-rw-rw-r--   0 root         (0) root         (0)    18821 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine.h
+-rw-rw-r--   0 root         (0) root         (0)     5636 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine_layout_params.h
+-rw-rw-r--   0 root         (0) root         (0)    21249 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_blas3.h
+-rw-r--r--   0 root         (0) root         (0)    13872 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_direct_conv.h
+-rw-rw-r--   0 root         (0) root         (0)    14496 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_params.h
+-rw-rw-r--   0 root         (0) root         (0)     9146 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_predicates.h
+-rw-r--r--   0 root         (0) root         (0)    15536 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_strided_dgrad.h
+-rw-rw-r--   0 root         (0) root         (0)     7487 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    17756 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_mixed.h
+-rw-rw-r--   0 root         (0) root         (0)     7394 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_pitch_liner.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:59.487288 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/
+-rw-rw-r--   0 root         (0) root         (0)     7055 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_complex_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)     7736 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_gaussian_complex_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)     5880 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_simt.h
+-rw-rw-r--   0 root         (0) root         (0)     9883 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)     8924 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_volta_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)     6045 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_wmma_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)     4864 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/simt_policy.h
+-rw-rw-r--   0 root         (0) root         (0)     5979 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/tensor_op_policy.h
+-rw-rw-r--   0 root         (0) root         (0)    25658 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_simt.h
+-rw-rw-r--   0 root         (0) root         (0)    20290 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)    22922 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op_mixed.h
+-rw-rw-r--   0 root         (0) root         (0)    14258 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_volta_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)     7704 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_wmma_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)     7485 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/volta_tensor_op_policy.h
+-rw-rw-r--   0 root         (0) root         (0)     3916 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/wmma_tensor_op_policy.h
+-rw-rw-r--   0 root         (0) root         (0)    26026 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/fast_math.h
+-rw-r--r--   0 root         (0) root         (0)    35369 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/float8.h
+-rw-rw-r--   0 root         (0) root         (0)     2645 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/floating_point_nvrtc.h
+-rw-r--r--   0 root         (0) root         (0)    12668 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/functional.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:59.515095 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:59.614328 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/collective/
+-rw-r--r--   0 root         (0) root         (0)     3406 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/collective/collective_builder.hpp
+-rw-r--r--   0 root         (0) root         (0)     3055 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/collective/collective_mma.hpp
+-rw-r--r--   0 root         (0) root         (0)    22013 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/collective/sm70_mma_twostage.hpp
+-rw-r--r--   0 root         (0) root         (0)    27329 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/collective/sm80_mma_multistage.hpp
+-rw-r--r--   0 root         (0) root         (0)    23874 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_multistage_gmma_ss.hpp
+-rw-r--r--   0 root         (0) root         (0)    20444 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_ss.hpp
+-rw-r--r--   0 root         (0) root         (0)    20900 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_ss_warpspecialized.hpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:59.891292 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/
+-rw-r--r--   0 root         (0) root         (0)    17028 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/base_grouped.h
+-rw-r--r--   0 root         (0) root         (0)    24413 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/default_gemm_configuration.h
+-rw-r--r--   0 root         (0) root         (0)    27616 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/ell_gemm.h
+-rw-r--r--   0 root         (0) root         (0)    25202 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm.h
+-rw-r--r--   0 root         (0) root         (0)    22367 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_array.h
+-rw-r--r--   0 root         (0) root         (0)    22375 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_batched.h
+-rw-r--r--   0 root         (0) root         (0)    22725 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_complex.h
+-rw-rw-r--   0 root         (0) root         (0)     2591 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_grouped.h
+-rw-r--r--   0 root         (0) root         (0)    13736 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_layernorm_mainloop_fusion.h
+-rw-rw-r--   0 root         (0) root         (0)    17329 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_sparse.h
+-rw-rw-r--   0 root         (0) root         (0)    20450 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_splitk_parallel.h
+-rw-r--r--   0 root         (0) root         (0)    14902 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal.h
+-rw-r--r--   0 root         (0) root         (0)    21594 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_adapter.h
+-rw-r--r--   0 root         (0) root         (0)    13362 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_base.h
+-rw-r--r--   0 root         (0) root         (0)    13968 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_with_broadcast.h
+-rw-r--r--   0 root         (0) root         (0)    14853 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_with_k_reduction.h
+-rw-r--r--   0 root         (0) root         (0)     5690 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemv.h
+-rw-r--r--   0 root         (0) root         (0)    18127 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/rank_2k.h
+-rw-rw-r--   0 root         (0) root         (0)     2747 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/rank_2k_grouped.h
+-rw-r--r--   0 root         (0) root         (0)    16719 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/rank_k.h
+-rwxr-xr-x   0 root         (0) root         (0)    21050 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/symm.h
+-rw-r--r--   0 root         (0) root         (0)    26464 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/trmm.h
+-rw-r--r--   0 root         (0) root         (0)     5207 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/dispatch_policy.hpp
+-rw-r--r--   0 root         (0) root         (0)    15946 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/gemm.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:00.693844 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/
+-rw-rw-r--   0 root         (0) root         (0)    29360 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_ell_gemm.h
+-rw-r--r--   0 root         (0) root         (0)    37758 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm.h
+-rw-rw-r--   0 root         (0) root         (0)    16130 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_complex.h
+-rw-rw-r--   0 root         (0) root         (0)    12385 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped.h
+-rw-rw-r--   0 root         (0) root         (0)     6592 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped_softmax_mainloop_fusion.h
+-rw-rw-r--   0 root         (0) root         (0)     5848 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_layernorm_mainloop_fusion.h
+-rw-rw-r--   0 root         (0) root         (0)    11104 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_planar_complex_universal.h
+-rw-rw-r--   0 root         (0) root         (0)     7983 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_sparse.h
+-rw-rw-r--   0 root         (0) root         (0)     4932 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_splitk_parallel.h
+-rw-r--r--   0 root         (0) root         (0)    11951 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_universal.h
+-rw-r--r--   0 root         (0) root         (0)     8125 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_broadcast.h
+-rw-rw-r--   0 root         (0) root         (0)     6457 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_k_reduction.h
+-rw-r--r--   0 root         (0) root         (0)     8086 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_reduction.h
+-rwxrwxr-x   0 root         (0) root         (0)     5349 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemv.h
+-rw-rw-r--   0 root         (0) root         (0)    11560 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k.h
+-rw-rw-r--   0 root         (0) root         (0)    20509 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_complex.h
+-rw-rw-r--   0 root         (0) root         (0)    12470 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_grouped.h
+-rw-rw-r--   0 root         (0) root         (0)    10620 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_universal.h
+-rw-rw-r--   0 root         (0) root         (0)     9872 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k.h
+-rw-rw-r--   0 root         (0) root         (0)    16990 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k_complex.h
+-rw-rw-r--   0 root         (0) root         (0)     9444 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k_universal.h
+-rwxrwxr-x   0 root         (0) root         (0)    13375 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_symm.h
+-rwxrwxr-x   0 root         (0) root         (0)    21830 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_symm_complex.h
+-rwxrwxr-x   0 root         (0) root         (0)    10315 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_symm_universal.h
+-rw-rw-r--   0 root         (0) root         (0)    10873 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm.h
+-rw-rw-r--   0 root         (0) root         (0)    10730 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm_complex.h
+-rw-rw-r--   0 root         (0) root         (0)    10850 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm_universal.h
+-rw-rw-r--   0 root         (0) root         (0)    28916 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/ell_gemm.h
+-rw-rw-r--   0 root         (0) root         (0)    13357 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm.h
+-rw-rw-r--   0 root         (0) root         (0)     8693 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_array.h
+-rw-rw-r--   0 root         (0) root         (0)     8761 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_batched.h
+-rw-rw-r--   0 root         (0) root         (0)    14687 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped.h
+-rw-rw-r--   0 root         (0) root         (0)     4691 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped_problem_visitor.h
+-rw-rw-r--   0 root         (0) root         (0)    15623 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped_softmax_mainloop_fusion.h
+-rw-r--r--   0 root         (0) root         (0)    27281 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_layernorm_mainloop_fusion.h
+-rwxrwxr-x   0 root         (0) root         (0)     6144 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_params.h
+-rw-rw-r--   0 root         (0) root         (0)     5141 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_pipelined.h
+-rw-r--r--   0 root         (0) root         (0)    22949 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex.h
+-rw-r--r--   0 root         (0) root         (0)    18937 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex_array.h
+-rw-rw-r--   0 root         (0) root         (0)     8142 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_splitk_parallel.h
+-rw-rw-r--   0 root         (0) root         (0)     4291 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_transpose_operands.h
+-rw-r--r--   0 root         (0) root         (0)    23216 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal.h
+-rw-r--r--   0 root         (0) root         (0)     3418 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal.hpp
+-rw-r--r--   0 root         (0) root         (0)    39288 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal_streamk.h
+-rw-r--r--   0 root         (0) root         (0)    47186 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_with_fused_epilogue.h
+-rw-r--r--   0 root         (0) root         (0)    23605 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_with_k_reduction.h
+-rw-r--r--   0 root         (0) root         (0)     8090 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemv.h
+-rwxrwxr-x   0 root         (0) root         (0)     8979 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemv_batched_strided.h
+-rw-r--r--   0 root         (0) root         (0)    16849 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/grouped_problem_visitor.h
+-rw-rw-r--   0 root         (0) root         (0)     7148 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/params_universal_base.h
+-rw-rw-r--   0 root         (0) root         (0)    22938 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped.h
+-rw-rw-r--   0 root         (0) root         (0)    16100 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped_problem_visitor.h
+-rw-rw-r--   0 root         (0) root         (0)     4334 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_transpose_operands.h
+-rw-rw-r--   0 root         (0) root         (0)    24138 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_universal.h
+-rw-rw-r--   0 root         (0) root         (0)    17543 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/rank_k_universal.h
+-rw-r--r--   0 root         (0) root         (0)     9808 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/sm70_gemm.hpp
+-rw-r--r--   0 root         (0) root         (0)    11878 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma.hpp
+-rw-r--r--   0 root         (0) root         (0)    14177 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma_warpspecialized.hpp
+-rw-r--r--   0 root         (0) root         (0)    21143 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma_warpspecialized_persistent.hpp
+-rw-r--r--   0 root         (0) root         (0)     5709 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_tile_scheduler.hpp
+-rw-rw-r--   0 root         (0) root         (0)    13586 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/sparse_gemm.h
+-rwxrwxr-x   0 root         (0) root         (0)    23876 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/symm_universal.h
+-rw-rw-r--   0 root         (0) root         (0)    19513 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/trmm_universal.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:00.750576 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/thread/
+-rw-rw-r--   0 root         (0) root         (0)     3567 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/thread/mma.h
+-rw-rw-r--   0 root         (0) root         (0)    15373 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/thread/mma_sm50.h
+-rw-rw-r--   0 root         (0) root         (0)    29987 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/thread/mma_sm60.h
+-rw-rw-r--   0 root         (0) root         (0)     8142 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/thread/mma_sm61.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:02.311149 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/
+-rw-rw-r--   0 root         (0) root         (0)    31930 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_ell_mma.h
+-rwxrwxr-x   0 root         (0) root         (0)     6979 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_gemv_core.h
+-rw-r--r--   0 root         (0) root         (0)    34241 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma.h
+-rw-rw-r--   0 root         (0) root         (0)     5123 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core.h
+-rw-rw-r--   0 root         (0) root         (0)    57426 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_simt.h
+-rw-rw-r--   0 root         (0) root         (0)    19257 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm70.h
+-rw-rw-r--   0 root         (0) root         (0)    42310 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm75.h
+-rw-rw-r--   0 root         (0) root         (0)   103000 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm80.h
+-rw-rw-r--   0 root         (0) root         (0)    32106 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sparse_sm80.h
+-rw-r--r--   0 root         (0) root         (0)    12645 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_access_size.h
+-rw-rw-r--   0 root         (0) root         (0)     7387 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_reduction.h
+-rw-rw-r--   0 root         (0) root         (0)    20975 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_wmma.h
+-rw-rw-r--   0 root         (0) root         (0)     7998 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_layernorm_mainloop_fusion.h
+-rw-rw-r--   0 root         (0) root         (0)     5110 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_multistage.h
+-rw-rw-r--   0 root         (0) root         (0)     4627 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_pipelined.h
+-rw-rw-r--   0 root         (0) root         (0)     7113 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_softmax_mainloop_fusion.h
+-rw-rw-r--   0 root         (0) root         (0)     6323 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_with_reduction.h
+-rw-rw-r--   0 root         (0) root         (0)     7121 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex.h
+-rw-rw-r--   0 root         (0) root         (0)     4959 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core.h
+-rw-rw-r--   0 root         (0) root         (0)    65201 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core_sm80.h
+-rw-rw-r--   0 root         (0) root         (0)    25495 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_trmm_complex.h
+-rw-rw-r--   0 root         (0) root         (0)     8509 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_sparse_mma.h
+-rw-rw-r--   0 root         (0) root         (0)    19515 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_trmm.h
+-rw-r--r--   0 root         (0) root         (0)    24047 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/ell_mma_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    13836 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/ell_mma_pipelined.h
+-rwxrwxr-x   0 root         (0) root         (0)     4726 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/gemv.h
+-rw-rw-r--   0 root         (0) root         (0)     3652 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/index_remat.h
+-rw-rw-r--   0 root         (0) root         (0)     7823 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_base.h
+-rw-r--r--   0 root         (0) root         (0)    27415 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_blas3_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    32894 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_layernorm_mainloop_fusion_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    28015 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_multistage.h
+-rw-rw-r--   0 root         (0) root         (0)    15995 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_pipelined.h
+-rw-rw-r--   0 root         (0) root         (0)     6901 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_base.h
+-rw-r--r--   0 root         (0) root         (0)    22653 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    14746 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_pipelined.h
+-rw-rw-r--   0 root         (0) root         (0)     9864 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_singlestage.h
+-rw-r--r--   0 root         (0) root         (0)    27061 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_softmax_mainloop_fusion_multistage.h
+-rw-rw-r--   0 root         (0) root         (0)     9210 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_sparse_base.h
+-rw-r--r--   0 root         (0) root         (0)    25333 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_sparse_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    20473 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_with_reduction_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    15007 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle.h
+-rw-r--r--   0 root         (0) root         (0)    26450 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle_streamk.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:02.742828 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/
+-rw-rw-r--   0 root         (0) root         (0)    20553 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_complex_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)     6684 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_sparse_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     5160 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)     9026 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op_sm80.h
+-rw-rw-r--   0 root         (0) root         (0)     4053 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_with_reduction_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)     4685 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_wmma_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)     5725 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/layernorm_scale_bias_transform.h
+-rw-rw-r--   0 root         (0) root         (0)     2619 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma.h
+-rw-r--r--   0 root         (0) root         (0)    37705 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)    23132 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_fast_f32.h
+-rw-rw-r--   0 root         (0) root         (0)    78615 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_tile_iterator_sm80.h
+-rw-rw-r--   0 root         (0) root         (0)    21205 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)    14589 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op_tile_iterator_sm80.h
+-rw-rw-r--   0 root         (0) root         (0)     6144 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_planar_complex.h
+-rw-rw-r--   0 root         (0) root         (0)     8446 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_simt.h
+-rw-rw-r--   0 root         (0) root         (0)     3079 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_simt_policy.h
+-rw-rw-r--   0 root         (0) root         (0)    59793 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_simt_tile_iterator.h
+-rw-rw-r--   0 root         (0) root         (0)    11758 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_sparse_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)    14407 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)    15721 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fast_f32.h
+-rw-rw-r--   0 root         (0) root         (0)    18643 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fragment_iterator.h
+-rw-rw-r--   0 root         (0) root         (0)     2939 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_policy.h
+-rw-rw-r--   0 root         (0) root         (0)     8966 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_sm70.h
+-rw-rw-r--   0 root         (0) root         (0)    11017 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_access_iterator.h
+-rw-rw-r--   0 root         (0) root         (0)   136033 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator.h
+-rw-rw-r--   0 root         (0) root         (0)    99649 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm70.h
+-rw-rw-r--   0 root         (0) root         (0)    75179 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm80.h
+-rw-rw-r--   0 root         (0) root         (0)    13151 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sparse.h
+-rw-rw-r--   0 root         (0) root         (0)    27101 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_wmma.h
+-rw-rw-r--   0 root         (0) root         (0)     7241 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_wmma.h
+-rw-rw-r--   0 root         (0) root         (0)    17303 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_with_reduction_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)    19125 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/scale_bias_tile_iterator.h
+-rw-rw-r--   0 root         (0) root         (0)     4610 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/softmax_scale_bias_transform.h
+-rw-rw-r--   0 root         (0) root         (0)     8728 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/tile_iterator_planar_complex.h
+-rw-rw-r--   0 root         (0) root         (0)    23615 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/half.h
+-rw-rw-r--   0 root         (0) root         (0)     6893 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/integer_subbyte.h
+-rw-r--r--   0 root         (0) root         (0)     2669 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/kernel_hardware_info.hpp
+-rw-rw-r--   0 root         (0) root         (0)     2801 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/kernel_launch.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:02.858923 flash_attn-2.0.1/csrc/cutlass/include/cutlass/layout/
+-rw-rw-r--   0 root         (0) root         (0)     3020 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/layout/layout.h
+-rw-r--r--   0 root         (0) root         (0)    35369 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/layout/matrix.h
+-rw-r--r--   0 root         (0) root         (0)     9133 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/layout/permute.h
+-rw-rw-r--   0 root         (0) root         (0)     4696 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/layout/pitch_linear.h
+-rw-rw-r--   0 root         (0) root         (0)    18295 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/layout/tensor.h
+-rw-rw-r--   0 root         (0) root         (0)    29599 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm70.h
+-rw-rw-r--   0 root         (0) root         (0)    33137 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm75.h
+-rw-rw-r--   0 root         (0) root         (0)    29336 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm80.h
+-rw-rw-r--   0 root         (0) root         (0)     3328 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/layout/vector.h
+-rw-rw-r--   0 root         (0) root         (0)   364115 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/matrix.h
+-rw-rw-r--   0 root         (0) root         (0)     4991 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/matrix_coord.h
+-rw-rw-r--   0 root         (0) root         (0)     2726 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/matrix_shape.h
+-rw-r--r--   0 root         (0) root         (0)    71278 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/numeric_conversion.h
+-rw-rw-r--   0 root         (0) root         (0)     3505 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/numeric_types.h
+-rw-r--r--   0 root         (0) root         (0)    16389 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/pipeline.hpp
+-rw-rw-r--   0 root         (0) root         (0)     5492 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/pitch_linear_coord.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:02.876211 flash_attn-2.0.1/csrc/cutlass/include/cutlass/platform/
+-rw-r--r--   0 root         (0) root         (0)    26097 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/platform/platform.h
+-rw-rw-r--   0 root         (0) root         (0)    15565 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/predicate_vector.h
+-rw-rw-r--   0 root         (0) root         (0)    20900 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/quaternion.h
+-rw-rw-r--   0 root         (0) root         (0)     2369 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/real.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:02.891787 flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:02.946659 flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/device/
+-rw-rw-r--   0 root         (0) root         (0)     6823 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/device/reduce_split_k.h
+-rw-rw-r--   0 root         (0) root         (0)     8152 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce.h
+-rw-rw-r--   0 root         (0) root         (0)    11579 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_contiguous.h
+-rw-rw-r--   0 root         (0) root         (0)    11448 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_strided.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:03.002069 flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/kernel/
+-rw-rw-r--   0 root         (0) root         (0)     8762 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/kernel/reduce_softmax_final.h
+-rw-rw-r--   0 root         (0) root         (0)     7897 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/kernel/reduce_split_k.h
+-rw-r--r--   0 root         (0) root         (0)    20685 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_contiguous.h
+-rw-r--r--   0 root         (0) root         (0)    21662 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_strided.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:03.032257 flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/thread/
+-rw-rw-r--   0 root         (0) root         (0)     7208 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/thread/reduce.h
+-rw-rw-r--   0 root         (0) root         (0)     6790 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/thread/reduction_operators.h
+-rw-rw-r--   0 root         (0) root         (0)     2936 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/threadblock_swizzle.h
+-rw-r--r--   0 root         (0) root         (0)     5929 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/relatively_equal.h
+-rw-r--r--   0 root         (0) root         (0)     4186 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/semaphore.h
+-rw-rw-r--   0 root         (0) root         (0)    17243 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/subbyte_reference.h
+-rw-rw-r--   0 root         (0) root         (0)     8964 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/tensor_coord.h
+-rw-rw-r--   0 root         (0) root         (0)    12207 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/tensor_ref.h
+-rw-rw-r--   0 root         (0) root         (0)    11201 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/tensor_ref_planar_complex.h
+-rw-rw-r--   0 root         (0) root         (0)     9509 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/tensor_view.h
+-rw-rw-r--   0 root         (0) root         (0)    10250 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/tensor_view_planar_complex.h
+-rw-rw-r--   0 root         (0) root         (0)    13017 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/tfloat32.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:03.049882 flash_attn-2.0.1/csrc/cutlass/include/cutlass/thread/
+-rw-rw-r--   0 root         (0) root         (0)     5931 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/thread/matrix.h
+-rw-rw-r--   0 root         (0) root         (0)     2581 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/trace.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:03.065468 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/
+-rw-rw-r--   0 root         (0) root         (0)    33349 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/pitch_linear_thread_map.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:03.095098 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/thread/
+-rw-rw-r--   0 root         (0) root         (0)     3835 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/thread/transpose.h
+-rw-rw-r--   0 root         (0) root         (0)     4309 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/thread/unary_op.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:04.445716 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/
+-rw-rw-r--   0 root         (0) root         (0)     6181 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/ell_iterator.h
+-rw-rw-r--   0 root         (0) root         (0)    44443 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_access_iterator.h
+-rw-rw-r--   0 root         (0) root         (0)    44309 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_iterator.h
+-rw-rw-r--   0 root         (0) root         (0)    12890 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_access_iterator.h
+-rw-rw-r--   0 root         (0) root         (0)    11097 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    70684 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator.h
+-rw-rw-r--   0 root         (0) root         (0)    28232 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_2dthreadtile.h
+-rwxrwxr-x   0 root         (0) root         (0)    10243 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_params.h
+-rw-rw-r--   0 root         (0) root         (0)    31412 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_triangular_matrix.h
+-rw-r--r--   0 root         (0) root         (0)    62672 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator.h
+-rw-rw-r--   0 root         (0) root         (0)    27175 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_2dthreadtile.h
+-rw-rw-r--   0 root         (0) root         (0)    28064 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_triangular_matrix.h
+-rw-rw-r--   0 root         (0) root         (0)    13088 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_vector_access_iterator.h
+-rw-rw-r--   0 root         (0) root         (0)     8232 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_scale_bias_vector_access_iterator.h
+-rw-rw-r--   0 root         (0) root         (0)     2638 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator.h
+-rw-rw-r--   0 root         (0) root         (0)    13283 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear.h
+-rw-rw-r--   0 root         (0) root         (0)    18623 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear_direct_conv.h
+-rw-rw-r--   0 root         (0) root         (0)    27922 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op.h
+-rw-rw-r--   0 root         (0) root         (0)    47789 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op_sm80.h
+-rw-rw-r--   0 root         (0) root         (0)     2616 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    16510 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear.h
+-rw-rw-r--   0 root         (0) root         (0)    15486 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear_2dthreadtile.h
+-rw-rw-r--   0 root         (0) root         (0)    36050 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)    43663 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op_sm70.h
+-rw-rw-r--   0 root         (0) root         (0)     5226 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/vector_iterator.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:04.463154 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/warp/
+-rw-rw-r--   0 root         (0) root         (0)     8828 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/warp/vector_fragment_iterator.h
+-rw-r--r--   0 root         (0) root         (0)     8179 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/uint128.h
+-rw-rw-r--   0 root         (0) root         (0)     4543 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/include/cutlass/wmma_array.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:52.836093 flash_attn-2.0.1/csrc/cutlass/test/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:04.481875 flash_attn-2.0.1/csrc/cutlass/test/unit/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:04.511831 flash_attn-2.0.1/csrc/cutlass/test/unit/common/
+-rw-rw-r--   0 root         (0) root         (0)     4900 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/common/cutlass_unit_test.h
+-rw-rw-r--   0 root         (0) root         (0)     5381 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/common/filter_architecture.cpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:52.851945 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:07.352996 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/
+-rw-rw-r--   0 root         (0) root         (0)    21797 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/cache_testbed_output.h
+-rw-rw-r--   0 root         (0) root         (0)     5344 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)     5443 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    11470 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5239 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     9110 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)     8485 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5243 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5378 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    12054 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_few_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     9603 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_fixed_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5267 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)     5357 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5089 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
+-rw-rw-r--   0 root         (0) root         (0)    13690 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5390 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5191 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)    11136 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)     5291 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     3551 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)     5157 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
+-rwxrwxr-x   0 root         (0) root         (0)     8278 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_qf32nhwc_qf32nhwc_qf32nhwc_simt_f32_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    20555 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    20647 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5155 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)     5239 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    26114 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    26210 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5111 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)     5194 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5738 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5439 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     7363 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)     3984 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_reduction_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    39452 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_problems.h
+-rw-rw-r--   0 root         (0) root         (0)    14471 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     4662 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    26224 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_testbed.h
+-rw-r--r--   0 root         (0) root         (0)    22092 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_testbed_interleaved.h
+-rw-rw-r--   0 root         (0) root         (0)     5179 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)     5358 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5264 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     3615 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     7591 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    10514 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5157 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5772 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    23526 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_with_broadcast_testbed.h
+-rw-r--r--   0 root         (0) root         (0)    21512 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_with_reduction_testbed.h
+-rw-rw-r--   0 root         (0) root         (0)     5135 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5347 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     3736 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)     6560 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5257 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    12276 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv3d_problems.h
+-rw-r--r--   0 root         (0) root         (0)    21643 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv3d_testbed.h
+-rw-rw-r--   0 root         (0) root         (0)     3622 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)     6560 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5256 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    17700 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_direct_conv_testbed.h
+-rw-rw-r--   0 root         (0) root         (0)    18451 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
+-rw-rw-r--   0 root         (0) root         (0)    22194 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_fixed_stride_dilation_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
+-rw-rw-r--   0 root         (0) root         (0)     9383 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
+-rw-r--r--   0 root         (0) root         (0)    16100 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/group_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:07.544355 flash_attn-2.0.1/csrc/cutlass/test/unit/core/
+-rw-rw-r--   0 root         (0) root         (0)     7365 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/core/array.cu
+-rw-rw-r--   0 root         (0) root         (0)     7353 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/core/bfloat16.cu
+-rw-rw-r--   0 root         (0) root         (0)     6981 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/core/complex.cu
+-rw-rw-r--   0 root         (0) root         (0)     4009 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/core/float8.cu
+-rw-rw-r--   0 root         (0) root         (0)    13001 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/core/functional.cu
+-rw-rw-r--   0 root         (0) root         (0)     3553 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/core/half.cu
+-rw-rw-r--   0 root         (0) root         (0)     5295 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/core/matrix.cu
+-rw-rw-r--   0 root         (0) root         (0)     8592 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/core/matrix_coord.cu
+-rw-rw-r--   0 root         (0) root         (0)    10684 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/core/numeric_conversion.cu
+-rw-rw-r--   0 root         (0) root         (0)     8148 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/core/predicate_vector.cu
+-rw-rw-r--   0 root         (0) root         (0)     5777 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/core/quaternion.cu
+-rw-rw-r--   0 root         (0) root         (0)     6746 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/core/tensor_ref.cu
+-rw-rw-r--   0 root         (0) root         (0)     8885 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/core/tensor_view.cu
+-rw-rw-r--   0 root         (0) root         (0)     2050 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/core/test_unit_core.cpp
+-rw-rw-r--   0 root         (0) root         (0)     7088 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/core/tfloat32.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:52.874820 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:07.577123 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/ampere/
+-rw-rw-r--   0 root         (0) root         (0)     3527 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/ampere/cp_async.cu
+-rw-rw-r--   0 root         (0) root         (0)    14320 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/ampere/ldsm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:07.731808 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/
+-rw-rw-r--   0 root         (0) root         (0)     3332 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/bitfield.cpp
+-rw-rw-r--   0 root         (0) root         (0)     4861 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/coalesce.cpp
+-rw-rw-r--   0 root         (0) root         (0)     5620 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/compare.cpp
+-rw-rw-r--   0 root         (0) root         (0)     7178 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/complement.cpp
+-rw-rw-r--   0 root         (0) root         (0)    12569 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/composition.cpp
+-rw-rw-r--   0 root         (0) root         (0)     4856 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/inverse_left.cpp
+-rw-rw-r--   0 root         (0) root         (0)     6702 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/inverse_right.cpp
+-rw-rw-r--   0 root         (0) root         (0)     6734 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/logical_divide.cpp
+-rw-rw-r--   0 root         (0) root         (0)     5914 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/logical_product.cpp
+-rw-rw-r--   0 root         (0) root         (0)     3488 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/mixedbits.cpp
+-rw-rw-r--   0 root         (0) root         (0)     2342 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/transform.cpp
+-rw-rw-r--   0 root         (0) root         (0)    13304 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/tuple.cpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:07.773834 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/hopper/
+-rw-r--r--   0 root         (0) root         (0)    14365 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/hopper/stsm.cu
+-rw-r--r--   0 root         (0) root         (0)    18990 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/hopper/tma_load.cu
+-rw-r--r--   0 root         (0) root         (0)    13875 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/hopper/tma_store.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:07.791252 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/layout/
+-rw-rw-r--   0 root         (0) root         (0)     4544 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/cute/layout/layout_operator.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:52.898169 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:07.836990 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/thread/
+-rw-rw-r--   0 root         (0) root         (0)    15818 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/thread/activation.cu
+-rw-rw-r--   0 root         (0) root         (0)     6534 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/thread/linear_combination.cu
+-rw-rw-r--   0 root         (0) root         (0)     9964 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/thread/linear_combination_planar_complex.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:08.006114 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/
+-rw-rw-r--   0 root         (0) root         (0)    13824 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_planar_complex.cu
+-rw-rw-r--   0 root         (0) root         (0)    27176 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt.cu
+-rw-rw-r--   0 root         (0) root         (0)    12061 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm60.cu
+-rw-rw-r--   0 root         (0) root         (0)    25275 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm61.cu
+-rw-rw-r--   0 root         (0) root         (0)    84612 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_tensor_op.cu
+-rw-rw-r--   0 root         (0) root         (0)    70486 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_volta_tensor_op.cu
+-rw-rw-r--   0 root         (0) root         (0)    25293 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_tensor_op.cu
+-rw-rw-r--   0 root         (0) root         (0)    13012 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_testbed.h
+-rw-rw-r--   0 root         (0) root         (0)     7743 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_wmma_tensor_op_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)    19178 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/output_tile_threadmap.cu
+-rw-rw-r--   0 root         (0) root         (0)    28433 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/predicated_tile_iterator.cu
+-rw-rw-r--   0 root         (0) root         (0)    11038 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/testbed.h
+-rw-rw-r--   0 root         (0) root         (0)    11734 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/testbed_planar_complex.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:08.061305 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/warp/
+-rw-rw-r--   0 root         (0) root         (0)     6783 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_tensor_op.cu
+-rw-rw-r--   0 root         (0) root         (0)     7275 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_volta_tensor_op.cu
+-rw-rw-r--   0 root         (0) root         (0)     6616 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_wmma_tensor_op.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:52.926576 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:12.196450 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/
+-rw-r--r--   0 root         (0) root         (0)    52269 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/default_gemm_configuration.hpp
+-rw-rw-r--   0 root         (0) root         (0)    10189 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    17899 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8933 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_wmma_tensor_op_s32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    10164 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    17984 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8915 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_wmma_tensor_op_s32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    16447 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_bf16n_bf16n_f32t_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    16575 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_bf16t_bf16t_bf16t_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8318 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_cf32n_cf32t_cf32t_tensor_op_tf32_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8317 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_cf32t_cf32n_cf32t_tensor_op_tf32_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     6714 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     6747 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm90.cu
+-rw-rw-r--   0 root         (0) root         (0)     7895 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     7930 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm90.cu
+-rw-rw-r--   0 root         (0) root         (0)     6516 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     6549 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm90.cu
+-rw-rw-r--   0 root         (0) root         (0)     9016 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     9053 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm90.cu
+-rw-rw-r--   0 root         (0) root         (0)     4628 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_direct_store_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     6165 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f16_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     6124 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     9634 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    16357 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    13189 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sparse_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8845 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_volta_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)    13583 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f16_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)    13464 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     9571 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    16239 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     6140 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_wmma_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     9544 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    16417 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    13075 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8775 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_volta_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)    11470 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_wmma_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     6156 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f16_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     6116 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     3528 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)     3539 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     7965 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    16470 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    13273 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sparse_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     3648 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8608 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_volta_tensor_op_f16_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)    13518 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f16_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     3645 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     6096 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32n_wmma_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     7845 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    18135 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    13008 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8505 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_volta_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)    11497 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_wmma_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)    11090 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_singlestage_wmma_tensor_op_f16_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     6156 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f16_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     6116 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)    11066 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_singlestage_wmma_tensor_op_f16_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)    17114 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_broadcast_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     3528 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)     3540 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     7964 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    16457 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    13266 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sparse_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8933 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_volta_tensor_op_f16_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)    13551 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f16_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)    13540 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     6130 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32n_wmma_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     8160 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_singlestage_wmma_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     7847 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    16131 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    13014 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8754 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_volta_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)    11497 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_wmma_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     6147 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f16_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     6107 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)    13518 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f16_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)    13398 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     7845 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    16149 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     6119 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_wmma_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     7827 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    16101 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     9526 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     7898 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_volta_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)    11470 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_wmma_tensor_op_f32_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     3584 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_bf16_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     3473 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    12967 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    12931 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32t_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    12930 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f32t_f32n_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    12895 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f32t_f32t_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8349 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     7300 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm90.cu
+-rw-rw-r--   0 root         (0) root         (0)     8348 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     7291 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm90.cu
+-rw-rw-r--   0 root         (0) root         (0)    10240 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_grouped_scheduler_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    26146 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_grouped_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    11339 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)     7346 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    12397 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     6859 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)     7239 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8121 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    16882 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8407 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_wmma_tensor_op_s32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)     8103 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    17111 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    12637 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sparse_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8388 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_wmma_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    10044 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    17544 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    10020 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    17544 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     9588 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    11288 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     7977 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    16531 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5693 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_wmma_tensor_op_s32_sm72.cu
+-rw-rw-r--   0 root         (0) root         (0)     7959 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    16691 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    12408 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sparse_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     6864 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_wmma_tensor_op_s32_sm72.cu
+-rw-r--r--   0 root         (0) root         (0)     7744 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    16531 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     6675 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_wmma_tensor_op_s32_sm72.cu
+-rw-r--r--   0 root         (0) root         (0)     7752 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    16484 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     6663 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_wmma_tensor_op_s32_sm72.cu
+-rw-rw-r--   0 root         (0) root         (0)     4663 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_serial_tensor_op_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)     4945 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_simt_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)     6616 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)    10581 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    24892 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_testbed_3x.hpp
+-rw-rw-r--   0 root         (0) root         (0)    16950 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_tf32n_tf32n_f32t_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    16902 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_tf32n_tf32t_f32t_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    15131 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_tf32t_tf32n_f32t_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    16855 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_tf32t_tf32t_f32t_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     6854 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_u8t_u8n_s32t_wmma_tensor_op_s32_sm72.cu
+-rw-rw-r--   0 root         (0) root         (0)     6686 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf32n_cf32n_cf32n_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     6755 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     6687 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     4726 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32n_tensor_op_f32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)     4718 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32t_tensor_op_f32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    16715 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_with_broadcast_f16n_f16n_f16n_tensorop_f32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    12841 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_with_reduction_f16n_f16n_f16n_tensorop_f32_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)     4544 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_with_reduction_f16t_f16n_f16n_tensorop_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    13157 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemv.cu
+-rw-rw-r--   0 root         (0) root         (0)     6028 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_ls_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     6031 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_rs_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     6064 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_ls_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     6067 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_rs_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     4909 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/hemm_cf64_cf64_cf64_tensor_op_f64_sm90.cu
+-rw-rw-r--   0 root         (0) root         (0)     6088 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     6037 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     6040 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_rs_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5382 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5406 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_fast_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5402 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/her2k_cf64_cf64_tensor_op_f64_sm90.cu
+-rw-rw-r--   0 root         (0) root         (0)    13055 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/her2k_cf64h_cf64n_tensor_op_f64_grouped_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    13027 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5388 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     6939 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64t_tensor_op_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     7677 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     7725 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_fast_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     3854 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/herk_cf64_cf64_tensor_op_f64_sm90.cu
+-rw-rw-r--   0 root         (0) root         (0)     6396 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/herk_cf64h_cf64n_tensor_op_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    10157 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/multistage_testbed.h
+-rw-rw-r--   0 root         (0) root         (0)    10306 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/multistage_testbed_interleaved.h
+-rw-rw-r--   0 root         (0) root         (0)    11186 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/rank_2k_grouped_scheduler_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    46795 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nn_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    54085 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)     8318 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    46687 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)     8411 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    46578 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tt_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    40533 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_nn_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    47656 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_nt_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    40441 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_tn_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    40354 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_tt_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)     3513 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_f8gemm_tn_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    89517 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_nn_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    89304 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_nt_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    89304 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_tn_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    89091 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_tt_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    69175 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_igemm_nn_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    71438 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_igemm_nt_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    67796 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_igemm_tn_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    70056 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_igemm_tt_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)     7156 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61.cu
+-rw-rw-r--   0 root         (0) root         (0)     6067 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_perf.cu
+-rw-rw-r--   0 root         (0) root         (0)     9063 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_sliced_k.cu
+-rw-rw-r--   0 root         (0) root         (0)    35894 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_nn_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    35813 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_nt_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    35813 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_tn_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    35732 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_tt_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    70872 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nn_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    73136 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)     8870 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    69488 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)     8865 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    71755 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tt_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    33231 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_nn_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    33156 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_nt_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    33156 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_tn_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    33081 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_tt_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)     5238 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm50_gemm_f32_f32_f32_simt.cu
+-rw-rw-r--   0 root         (0) root         (0)     5253 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm50_gemm_f64_f64_f64_simt.cu
+-rw-rw-r--   0 root         (0) root         (0)     5357 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm61_gemm_s8_s8_s32_simt.cu
+-rw-rw-r--   0 root         (0) root         (0)     5479 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f16_f16_f32_tensor_op_f32.cu
+-rw-rw-r--   0 root         (0) root         (0)     5238 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f32_f32_f32_simt.cu
+-rw-rw-r--   0 root         (0) root         (0)     5253 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f64_f64_f64_simt.cu
+-rw-rw-r--   0 root         (0) root         (0)     3875 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f64_f64_f64_tensor_op_f64.cu
+-rw-rw-r--   0 root         (0) root         (0)     3734 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_s8_s8_s32_tensor_op.cu
+-rw-rw-r--   0 root         (0) root         (0)     5387 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_tf32_tf32_f32_tensor_op_f32.cu
+-rw-r--r--   0 root         (0) root         (0)     7436 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32.cu
+-rw-r--r--   0 root         (0) root         (0)     7409 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_tensor_op_f32.cu
+-rw-r--r--   0 root         (0) root         (0)    17391 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op.cu
+-rw-r--r--   0 root         (0) root         (0)    42504 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op.cu
+-rw-r--r--   0 root         (0) root         (0)    22602 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_unspecialized.cu
+-rw-r--r--   0 root         (0) root         (0)    22874 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized.cu
+-rw-r--r--   0 root         (0) root         (0)    42526 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_persistent.cu
+-rw-r--r--   0 root         (0) root         (0)     3810 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f32_f32_f32_tensor_op_f32.cu
+-rw-r--r--   0 root         (0) root         (0)     5976 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32.cu
+-rw-r--r--   0 root         (0) root         (0)     9313 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_tensor_op_s32.cu
+-rw-r--r--   0 root         (0) root         (0)     5986 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32.cu
+-rw-r--r--   0 root         (0) root         (0)     7268 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_tensor_op_f32.cu
+-rw-rw-r--   0 root         (0) root         (0)     5923 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_ls_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5926 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_rs_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5959 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_ls_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5962 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_rs_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     4839 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_cf64_cf64_cf64_tensor_op_f64_sm90.cu
+-rw-rw-r--   0 root         (0) root         (0)     5983 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5932 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5935 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_rs_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    15203 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8623 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_rs_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    15104 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     4777 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f64_f64_tensor_op_f64_sm90.cu
+-rw-rw-r--   0 root         (0) root         (0)     8103 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_ls_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8108 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_rs_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8088 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_ls_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8093 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_rs_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8073 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_ls_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8078 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_rs_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8058 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_ls_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8063 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_rs_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    15071 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_ls_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8551 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_rs_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    14972 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_tf32t_f32t_tensor_op_f32_ls_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5362 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5386 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_fast_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5356 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5380 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_fast_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5379 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64_cf64_tensor_op_f64_sm90.cu
+-rw-rw-r--   0 root         (0) root         (0)    12952 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5368 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     7208 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_grouped_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5362 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     7199 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64n_tensor_op_f64_grouped_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     7190 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64t_tensor_op_f64_grouped_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     4794 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_f32n_f32n_tensor_op_fast_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     4783 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_f32t_f32n_tensor_op_fast_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     4740 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_f64_f64_tensor_op_f64_sm90.cu
+-rw-rw-r--   0 root         (0) root         (0)    19145 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_grouped_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     7991 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    11015 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_grouped_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     7976 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    12342 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_grouped_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     7961 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    12321 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64t_tensor_op_f64_grouped_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     4786 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_tf32n_f32n_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     4775 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_tf32t_f32n_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     4993 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5017 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_fast_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     4987 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5011 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_fast_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     5024 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_cf64_cf64_tensor_op_f64_sm90.cu
+-rw-rw-r--   0 root         (0) root         (0)     4996 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64n_tensor_op_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     3793 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     4990 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    16083 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_f32n_f32t_tensor_op_fast_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    16041 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_f32t_f32t_tensor_op_fast_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     4530 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_f64_f64_tensor_op_f64_sm90.cu
+-rw-rw-r--   0 root         (0) root         (0)     7451 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_f64n_f64t_tensor_op_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     9401 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_f64t_f64n_tensor_op_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    16027 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_tf32n_f32t_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    15985 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_tf32t_f32t_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    20465 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed.h
+-rw-rw-r--   0 root         (0) root         (0)     8264 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_complex.h
+-rw-rw-r--   0 root         (0) root         (0)    20736 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_gemm_with_broadcast.h
+-rw-rw-r--   0 root         (0) root         (0)    19479 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_gemm_with_reduction.h
+-rw-rw-r--   0 root         (0) root         (0)    16502 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_grouped.h
+-rw-rw-r--   0 root         (0) root         (0)    16562 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k.h
+-rw-rw-r--   0 root         (0) root         (0)    17002 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k_scheduler.h
+-rw-rw-r--   0 root         (0) root         (0)    14698 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_grouped_scheduler.h
+-rw-rw-r--   0 root         (0) root         (0)    10262 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_interleaved.h
+-rw-rw-r--   0 root         (0) root         (0)     9481 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_planar_complex.h
+-rw-rw-r--   0 root         (0) root         (0)    20898 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_rank2k_universal.h
+-rw-rw-r--   0 root         (0) root         (0)    15652 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_rank_k_universal.h
+-rw-rw-r--   0 root         (0) root         (0)     8639 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_sanity.h
+-rw-r--r--   0 root         (0) root         (0)    15901 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_sparse.h
+-rw-rw-r--   0 root         (0) root         (0)     6124 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_splitk.h
+-rw-rw-r--   0 root         (0) root         (0)    19993 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_symm_universal.h
+-rw-rw-r--   0 root         (0) root         (0)    20332 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_trmm_universal.h
+-rw-rw-r--   0 root         (0) root         (0)    17443 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_universal.h
+-rw-rw-r--   0 root         (0) root         (0)     2626 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_utils.h
+-rw-rw-r--   0 root         (0) root         (0)     9916 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     9988 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_fast_f32_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     4989 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_cf64_cf64_cf64_tensor_op_f64_sm90.cu
+-rw-rw-r--   0 root         (0) root         (0)     4992 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     9762 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    15614 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8733 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_rs_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    14089 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    14444 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32t_tensor_op_fast_f32_ls_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     4608 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_f64_f64_f64_tensor_op_f64_sm90.cu
+-rw-rw-r--   0 root         (0) root         (0)    12798 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_ls_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    12809 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_rs_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    12764 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64t_f64t_tensor_op_f64_rs_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    12768 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_ls_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    12779 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_rs_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    15504 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_ls_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     8673 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_rs_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    13989 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32n_tensor_op_f32_ls_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    14344 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32t_tensor_op_f32_ls_sm80.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:12.226407 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/kernel/
+-rwxrwxr-x   0 root         (0) root         (0)    46470 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/kernel/batched_gemv.cu
+-rwxrwxr-x   0 root         (0) root         (0)    14362 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/kernel/testbed_gemv.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:12.280677 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/thread/
+-rw-rw-r--   0 root         (0) root         (0)     4847 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/thread/gemm_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)    12503 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/thread/gemm_sm60.cu
+-rw-rw-r--   0 root         (0) root         (0)     3109 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/thread/gemm_sm61.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:12.310707 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/thread/host/
+-rw-rw-r--   0 root         (0) root         (0)     5198 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/thread/host/gemm_sm60_host.cu
+-rw-rw-r--   0 root         (0) root         (0)     7161 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/thread/host/testbed_host.h
+-rw-rw-r--   0 root         (0) root         (0)     7124 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/thread/testbed.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:12.576857 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/
+-rw-rw-r--   0 root         (0) root         (0)    25036 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/batched_gemv.cu
+-rw-rw-r--   0 root         (0) root         (0)     4345 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/epilogue_workspace.cu
+-rw-rw-r--   0 root         (0) root         (0)   135045 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage.cu
+-rw-rw-r--   0 root         (0) root         (0)     4644 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_slicedk.cu
+-rw-rw-r--   0 root         (0) root         (0)    94442 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse.cu
+-rw-rw-r--   0 root         (0) root         (0)    17090 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse_testbed.h
+-rw-rw-r--   0 root         (0) root         (0)    13897 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed.h
+-rw-rw-r--   0 root         (0) root         (0)    14539 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed_slicedk.h
+-rw-rw-r--   0 root         (0) root         (0)    49052 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_simt.cu
+-rw-rw-r--   0 root         (0) root         (0)     8407 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_slicedk.cu
+-rw-rw-r--   0 root         (0) root         (0)    18705 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)    78122 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    21051 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    13771 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed.h
+-rw-rw-r--   0 root         (0) root         (0)    14239 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed_slicedk.h
+-rw-rw-r--   0 root         (0) root         (0)    29772 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)    12395 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)     3502 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_planar_complex_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    12138 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_planar_complex_testbed.h
+-rw-rw-r--   0 root         (0) root         (0)    16308 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)    12502 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm75.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:12.768350 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/
+-rw-rw-r--   0 root         (0) root         (0)    22128 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_complex_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    10916 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_complex_sm90.cu
+-rw-rw-r--   0 root         (0) root         (0)     9873 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_gaussian_complex_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    18220 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_sm50.cu
+-rw-rw-r--   0 root         (0) root         (0)     4920 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_sm60.cu
+-rw-rw-r--   0 root         (0) root         (0)     6291 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_sm61.cu
+-rw-rw-r--   0 root         (0) root         (0)     9297 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_sm70.cu
+-rw-rw-r--   0 root         (0) root         (0)    37942 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_sm75.cu
+-rw-rw-r--   0 root         (0) root         (0)    81659 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)     9089 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_sm90.cu
+-rw-rw-r--   0 root         (0) root         (0)    48928 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_sparse_sm80.cu
+-rw-rw-r--   0 root         (0) root         (0)    49647 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/testbed.h
+-rw-rw-r--   0 root         (0) root         (0)    25780 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/wmma_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     7544 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/wmma_sm72.cu
+-rw-rw-r--   0 root         (0) root         (0)     6487 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/wmma_sm75.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:12.810282 flash_attn-2.0.1/csrc/cutlass/test/unit/layout/
+-rw-rw-r--   0 root         (0) root         (0)     5788 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/layout/matrix.cu
+-rw-rw-r--   0 root         (0) root         (0)     5984 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/layout/tensor.cu
+-rw-rw-r--   0 root         (0) root         (0)     7081 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/layout/tensor_nhwc.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:52.964876 flash_attn-2.0.1/csrc/cutlass/test/unit/nvrtc/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:52.950566 flash_attn-2.0.1/csrc/cutlass/test/unit/nvrtc/cutlass/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:12.834101 flash_attn-2.0.1/csrc/cutlass/test/unit/nvrtc/cutlass/nvrtc/
+-rw-rw-r--   0 root         (0) root         (0)     2096 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/nvrtc/cutlass/nvrtc/environment.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:52.960454 flash_attn-2.0.1/csrc/cutlass/test/unit/nvrtc/kernel/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:12.854750 flash_attn-2.0.1/csrc/cutlass/test/unit/nvrtc/kernel/thread/
+-rw-rw-r--   0 root         (0) root         (0)     2915 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/nvrtc/kernel/thread/testbed_kernel.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:12.883681 flash_attn-2.0.1/csrc/cutlass/test/unit/nvrtc/stdlib/
+-rw-rw-r--   0 root         (0) root         (0)        0 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/nvrtc/stdlib/assert.h
+-rw-rw-r--   0 root         (0) root         (0)     4250 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/nvrtc/stdlib/stdint.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:12.913806 flash_attn-2.0.1/csrc/cutlass/test/unit/nvrtc/thread/
+-rw-rw-r--   0 root         (0) root         (0)     5727 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/nvrtc/thread/gemm_nvrtc.cu
+-rw-rw-r--   0 root         (0) root         (0)    10328 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/nvrtc/thread/testbed.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:12.993965 flash_attn-2.0.1/csrc/cutlass/test/unit/pipeline/
+-rw-r--r--   0 root         (0) root         (0)    15532 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/pipeline/pipeline_async.cu
+-rw-r--r--   0 root         (0) root         (0)    15490 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/pipeline/pipeline_tma_async.cu
+-rw-r--r--   0 root         (0) root         (0)    17098 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/pipeline/pipeline_tma_async_warp_specialized.cu
+-rw-r--r--   0 root         (0) root         (0)    20252 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/pipeline/pipeline_tma_async_warp_specialized_persistent.cu
+-rw-r--r--   0 root         (0) root         (0)     7623 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/pipeline/sequence_barrier.cu
+-rw-rw-r--   0 root         (0) root         (0)     4327 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/pipeline/testbed.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:52.991928 flash_attn-2.0.1/csrc/cutlass/test/unit/reduction/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:13.035011 flash_attn-2.0.1/csrc/cutlass/test/unit/reduction/device/
+-rw-rw-r--   0 root         (0) root         (0)    14684 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/reduction/device/tensor_reduce_contiguous.cu
+-rw-rw-r--   0 root         (0) root         (0)    15609 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/reduction/device/tensor_reduce_strided.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:13.072433 flash_attn-2.0.1/csrc/cutlass/test/unit/reduction/kernel/
+-rw-rw-r--   0 root         (0) root         (0)    11350 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/reduction/kernel/reduce_splitk.cu
+-rw-rw-r--   0 root         (0) root         (0)     2228 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/reduction/kernel/reduce_splitk_testbed.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:13.104550 flash_attn-2.0.1/csrc/cutlass/test/unit/reduction/thread/
+-rw-rw-r--   0 root         (0) root         (0)     3110 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/reduction/thread/reduction_thread.cu
+-rw-rw-r--   0 root         (0) root         (0)     6657 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/reduction/thread/testbed.h
+-rw-rw-r--   0 root         (0) root         (0)     2047 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/test_unit.cpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.002005 flash_attn-2.0.1/csrc/cutlass/test/unit/transform/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:13.137985 flash_attn-2.0.1/csrc/cutlass/test/unit/transform/threadblock/
+-rw-rw-r--   0 root         (0) root         (0)    25527 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/transform/threadblock/predicated_tile_iterator.cu
+-rw-rw-r--   0 root         (0) root         (0)     9501 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/transform/threadblock/regular_tile_iterator_tensor_op.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:13.167496 flash_attn-2.0.1/csrc/cutlass/test/unit/util/
+-rw-rw-r--   0 root         (0) root         (0)     2663 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/util/cutlass_test_levels.cu
+-rw-rw-r--   0 root         (0) root         (0)     7474 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/test/unit/util/tensor_reduce.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.130905 flash_attn-2.0.1/csrc/cutlass/tools/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.104135 flash_attn-2.0.1/csrc/cutlass/tools/library/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.028813 flash_attn-2.0.1/csrc/cutlass/tools/library/include/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.033511 flash_attn-2.0.1/csrc/cutlass/tools/library/include/cutlass/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:13.272801 flash_attn-2.0.1/csrc/cutlass/tools/library/include/cutlass/library/
+-rw-r--r--   0 root         (0) root         (0)     4118 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/include/cutlass/library/arch_mappings.h
+-rw-r--r--   0 root         (0) root         (0)    16013 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/include/cutlass/library/handle.h
+-rw-r--r--   0 root         (0) root         (0)    38761 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/include/cutlass/library/library.h
+-rw-rw-r--   0 root         (0) root         (0)     4070 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/include/cutlass/library/manifest.h
+-rw-r--r--   0 root         (0) root         (0)    17934 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/include/cutlass/library/operation_table.h
+-rw-rw-r--   0 root         (0) root         (0)     2724 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/include/cutlass/library/singleton.h
+-rw-rw-r--   0 root         (0) root         (0)     7904 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/include/cutlass/library/util.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.045042 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.049777 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.054788 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:13.334997 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/
+-rw-r--r--   0 root         (0) root         (0)     2788 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/compiler.h
+-rw-r--r--   0 root         (0) root         (0)     2460 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/cute.cpp
+-rw-r--r--   0 root         (0) root         (0)     6224 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/cutlass.cpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:13.399441 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/
+-rw-r--r--   0 root         (0) root         (0)     2851 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/arch.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:13.442027 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/
+-rw-r--r--   0 root         (0) root         (0)     5897 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/conv_problem_size.h
+-rw-r--r--   0 root         (0) root         (0)     4763 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/convolution.h
+-rw-r--r--   0 root         (0) root         (0)     2650 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/host.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:13.470063 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/
+-rw-r--r--   0 root         (0) root         (0)     6845 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_generic.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:13.626046 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/
+-rw-r--r--   0 root         (0) root         (0)     3003 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/binary_ops.h
+-rw-r--r--   0 root         (0) root         (0)     6103 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/unary_ops.h
+-rw-r--r--   0 root         (0) root         (0)     4698 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_accumulator.h
+-rw-r--r--   0 root         (0) root         (0)     8397 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_binary.h
+-rw-r--r--   0 root         (0) root         (0)     8830 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_column_broadcast.h
+-rw-r--r--   0 root         (0) root         (0)    12999 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_column_reduction.h
+-rw-r--r--   0 root         (0) root         (0)     9454 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_linear_combination.h
+-rw-r--r--   0 root         (0) root         (0)     9085 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_row_broadcast.h
+-rw-r--r--   0 root         (0) root         (0)    11976 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_row_reduction.h
+-rw-r--r--   0 root         (0) root         (0)     6177 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_tensor_input.h
+-rw-r--r--   0 root         (0) root         (0)     8017 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_tensor_output.h
+-rw-r--r--   0 root         (0) root         (0)     7201 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_unary.h
+-rw-r--r--   0 root         (0) root         (0)    16970 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_with_layernorm.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:13.668149 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/
+-rw-r--r--   0 root         (0) root         (0)     3673 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/gemm.h
+-rw-r--r--   0 root         (0) root         (0)    21504 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/gemm_universal_with_visitor.h
+-rw-r--r--   0 root         (0) root         (0)     2328 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/host.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:13.711056 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/
+-rw-r--r--   0 root         (0) root         (0)     2115 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/layout.h
+-rw-r--r--   0 root         (0) root         (0)     4337 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/matrix.h
+-rw-r--r--   0 root         (0) root         (0)     3694 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/tensor.h
+-rw-r--r--   0 root         (0) root         (0)     8565 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/swizzling.h
+-rw-r--r--   0 root         (0) root         (0)     3902 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/tensor_coord.h
+-rw-r--r--   0 root         (0) root         (0)     5563 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/tensor_ref_view.h
+-rw-r--r--   0 root         (0) root         (0)     4855 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/types.h
+-rw-r--r--   0 root         (0) root         (0)      811 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/library.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.095361 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:13.756216 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/
+-rw-r--r--   0 root         (0) root         (0)     2651 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/conv_problems.h
+-rw-r--r--   0 root         (0) root         (0)     2253 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/convolution.h
+-rw-r--r--   0 root         (0) root         (0)     8826 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/host.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:13.785756 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/gemm/
+-rw-r--r--   0 root         (0) root         (0)     2139 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/gemm/gemm.h
+-rw-r--r--   0 root         (0) root         (0)    18930 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/gemm/host.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:13.961772 flash_attn-2.0.1/csrc/cutlass/tools/library/src/
+-rw-r--r--   0 root         (0) root         (0)    22377 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/conv2d_operation.h
+-rw-r--r--   0 root         (0) root         (0)    13851 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/conv3d_operation.h
+-rw-r--r--   0 root         (0) root         (0)    42129 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/gemm_operation.h
+-rw-r--r--   0 root         (0) root         (0)    11614 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/gemm_operation_3x.hpp
+-rw-r--r--   0 root         (0) root         (0)    35777 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/handle.cu
+-rw-r--r--   0 root         (0) root         (0)    12616 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/library_internal.h
+-rw-r--r--   0 root         (0) root         (0)     3782 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/manifest.cpp
+-rw-r--r--   0 root         (0) root         (0)     5468 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/operation_table.cu
+-rw-r--r--   0 root         (0) root         (0)    12873 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/rank_2k_operation.h
+-rw-rw-r--   0 root         (0) root         (0)    11367 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/rank_k_operation.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:14.005226 flash_attn-2.0.1/csrc/cutlass/tools/library/src/reduction/
+-rw-r--r--   0 root         (0) root         (0)     3190 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/reduction/init_reduction_operations.cu
+-rw-r--r--   0 root         (0) root         (0)     6367 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/reduction/reduction_device.cu
+-rw-r--r--   0 root         (0) root         (0)    10270 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/reduction/reduction_operation.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:14.090202 flash_attn-2.0.1/csrc/cutlass/tools/library/src/reference/
+-rw-rw-r--   0 root         (0) root         (0)     6746 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/reference/conv2d.cu
+-rw-rw-r--   0 root         (0) root         (0)     6286 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/reference/conv3d.cu
+-rw-r--r--   0 root         (0) root         (0)    17191 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/reference/conv_reference_operation.h
+-rw-r--r--   0 root         (0) root         (0)     7199 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/reference/gemm.cu
+-rw-r--r--   0 root         (0) root         (0)    14732 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/reference/gemm_reference_operation.h
+-rw-rw-r--   0 root         (0) root         (0)     2857 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/reference/initialize_reference_operations.cu
+-rw-rw-r--   0 root         (0) root         (0)     2669 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/singleton.cu
+-rw-r--r--   0 root         (0) root         (0)    13134 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/symm_operation.h
+-rw-rw-r--   0 root         (0) root         (0)    11698 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/trmm_operation.h
+-rw-r--r--   0 root         (0) root         (0)    43704 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/library/src/util.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.124140 flash_attn-2.0.1/csrc/cutlass/tools/profiler/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:14.633176 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/
+-rw-r--r--   0 root         (0) root         (0)    54128 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/conv2d_operation_profiler.cu
+-rw-r--r--   0 root         (0) root         (0)    18170 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/conv2d_operation_profiler.h
+-rw-r--r--   0 root         (0) root         (0)    48659 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/conv3d_operation_profiler.cu
+-rw-r--r--   0 root         (0) root         (0)    16043 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/conv3d_operation_profiler.h
+-rw-r--r--   0 root         (0) root         (0)    36462 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/cublas_helpers.cu
+-rw-r--r--   0 root         (0) root         (0)    10627 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/cublas_helpers.h
+-rw-r--r--   0 root         (0) root         (0)    17049 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/cudnn_helpers.cpp
+-rw-r--r--   0 root         (0) root         (0)    20433 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/cudnn_helpers.h
+-rw-r--r--   0 root         (0) root         (0)     7233 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/cutlass_profiler.cu
+-rw-rw-r--   0 root         (0) root         (0)     3233 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/cutlass_profiler.h
+-rw-r--r--   0 root         (0) root         (0)     2453 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/debug.h
+-rw-r--r--   0 root         (0) root         (0)    53643 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/device_allocation.cu
+-rw-r--r--   0 root         (0) root         (0)     7217 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/device_allocation.h
+-rw-r--r--   0 root         (0) root         (0)     6841 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/device_context.cu
+-rw-r--r--   0 root         (0) root         (0)     4300 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/device_context.h
+-rw-rw-r--   0 root         (0) root         (0)     8296 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/enumerated_types.cpp
+-rw-rw-r--   0 root         (0) root         (0)     6421 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/enumerated_types.h
+-rw-r--r--   0 root         (0) root         (0)    42366 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/gemm_operation_profiler.cu
+-rw-r--r--   0 root         (0) root         (0)     8544 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/gemm_operation_profiler.h
+-rw-r--r--   0 root         (0) root         (0)     3874 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/gpu_timer.cpp
+-rw-r--r--   0 root         (0) root         (0)     2724 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/gpu_timer.h
+-rw-rw-r--   0 root         (0) root         (0)     2340 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/main.cpp
+-rw-r--r--   0 root         (0) root         (0)    22087 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/operation_profiler.cu
+-rw-r--r--   0 root         (0) root         (0)     7876 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/operation_profiler.h
+-rw-r--r--   0 root         (0) root         (0)    27172 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/options.cu
+-rw-r--r--   0 root         (0) root         (0)     8773 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/options.h
+-rw-rw-r--   0 root         (0) root         (0)    14192 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/performance_report.cpp
+-rw-rw-r--   0 root         (0) root         (0)     4337 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/performance_report.h
+-rw-rw-r--   0 root         (0) root         (0)     2494 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/performance_result.cu
+-rw-rw-r--   0 root         (0) root         (0)     3941 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/performance_result.h
+-rw-rw-r--   0 root         (0) root         (0)    37487 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/problem_space.cpp
+-rw-r--r--   0 root         (0) root         (0)    27747 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/problem_space.h
+-rw-r--r--   0 root         (0) root         (0)    25014 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/rank_2k_operation_profiler.cu
+-rw-rw-r--   0 root         (0) root         (0)     6891 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/rank_2k_operation_profiler.h
+-rw-r--r--   0 root         (0) root         (0)    24253 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/rank_k_operation_profiler.cu
+-rw-rw-r--   0 root         (0) root         (0)     6830 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/rank_k_operation_profiler.h
+-rw-rw-r--   0 root         (0) root         (0)     5452 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/reduction_operation_profiler.h
+-rw-r--r--   0 root         (0) root         (0)    20688 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/sparse_gemm_operation_profiler.cu
+-rw-rw-r--   0 root         (0) root         (0)     6471 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/sparse_gemm_operation_profiler.h
+-rw-r--r--   0 root         (0) root         (0)    26610 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/symm_operation_profiler.cu
+-rw-rw-r--   0 root         (0) root         (0)     6933 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/symm_operation_profiler.h
+-rw-r--r--   0 root         (0) root         (0)    24431 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/trmm_operation_profiler.cu
+-rw-rw-r--   0 root         (0) root         (0)     6599 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/trmm_operation_profiler.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.135542 flash_attn-2.0.1/csrc/cutlass/tools/util/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.140356 flash_attn-2.0.1/csrc/cutlass/tools/util/include/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.145102 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:14.952788 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/
+-rw-rw-r--   0 root         (0) root         (0)     2410 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/GPU_Clock.hpp
+-rw-r--r--   0 root         (0) root         (0)     9774 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/command_line.h
+-rw-rw-r--   0 root         (0) root         (0)    19866 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/cublas_wrappers.hpp
+-rw-rw-r--   0 root         (0) root         (0)     5104 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/debug.h
+-rw-rw-r--   0 root         (0) root         (0)     5953 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/device_dump.h
+-rw-r--r--   0 root         (0) root         (0)    17695 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/device_groupnorm.h
+-rw-rw-r--   0 root         (0) root         (0)    20881 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/device_layernorm.h
+-rw-rw-r--   0 root         (0) root         (0)    10561 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/device_memory.h
+-rw-rw-r--   0 root         (0) root         (0)     5219 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/device_nchw_to_nhwc.h
+-rw-r--r--   0 root         (0) root         (0)    11067 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_padding.h
+-rw-rw-r--   0 root         (0) root         (0)    18653 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_pooling.h
+-rw-rw-r--   0 root         (0) root         (0)     5214 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_to_nchw.h
+-rw-rw-r--   0 root         (0) root         (0)     4007 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/device_utils.h
+-rw-rw-r--   0 root         (0) root         (0)     4597 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/distribution.h
+-rw-rw-r--   0 root         (0) root         (0)     2674 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/exceptions.h
+-rw-r--r--   0 root         (0) root         (0)     3946 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/helper_cuda.hpp
+-rw-rw-r--   0 root         (0) root         (0)     4821 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/host_reorder.h
+-rw-rw-r--   0 root         (0) root         (0)    16745 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/host_tensor.h
+-rw-rw-r--   0 root         (0) root         (0)    20354 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/host_tensor_planar_complex.h
+-rw-rw-r--   0 root         (0) root         (0)     5890 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/host_uncompress.h
+-rw-rw-r--   0 root         (0) root         (0)     1962 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/index_sequence.h
+-rw-rw-r--   0 root         (0) root         (0)     4589 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/packed_stride.hpp
+-rw-r--r--   0 root         (0) root         (0)     9529 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/print_error.hpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:08:53.176106 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:14.985548 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/detail/
+-rw-rw-r--   0 root         (0) root         (0)     4606 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/detail/inner_product.h
+-rw-rw-r--   0 root         (0) root         (0)     3527 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/detail/linear_to_coordinate.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:15.118888 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/
+-rw-rw-r--   0 root         (0) root         (0)    48350 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/convolution.h
+-rw-r--r--   0 root         (0) root         (0)    14296 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm.h
+-rw-r--r--   0 root         (0) root         (0)    10524 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm_complex.h
+-rw-rw-r--   0 root         (0) root         (0)     9652 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm_planar_complex.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:15.161573 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/
+-rw-rw-r--   0 root         (0) root         (0)     5381 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/gemm.h
+-rw-rw-r--   0 root         (0) root         (0)     6198 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_elementwise.h
+-rw-r--r--   0 root         (0) root         (0)     5126 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_foreach.h
+-rw-rw-r--   0 root         (0) root         (0)    11615 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/rank_2k_complex.h
+-rw-rw-r--   0 root         (0) root         (0)     7278 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_compare.h
+-rw-r--r--   0 root         (0) root         (0)    46444 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_fill.h
+-rw-r--r--   0 root         (0) root         (0)     5293 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_foreach.h
+-rw-rw-r--   0 root         (0) root         (0)    15964 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_reduce.h
+-rw-rw-r--   0 root         (0) root         (0)     4589 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_relu.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:15.179303 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/thread/
+-rw-rw-r--   0 root         (0) root         (0)     5872 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/thread/gemm.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:15.471491 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/
+-rw-r--r--   0 root         (0) root         (0)    28439 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/convolution.h
+-rw-rw-r--   0 root         (0) root         (0)     2766 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/error_metrics.h
+-rw-r--r--   0 root         (0) root         (0)    17163 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm.h
+-rw-r--r--   0 root         (0) root         (0)     7097 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm_complex.h
+-rw-rw-r--   0 root         (0) root         (0)     7708 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm_planar_complex.h
+-rw-r--r--   0 root         (0) root         (0)    12983 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gett.hpp
+-rw-rw-r--   0 root         (0) root         (0)     9441 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k.h
+-rw-rw-r--   0 root         (0) root         (0)    11444 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k_complex.h
+-rw-rw-r--   0 root         (0) root         (0)     8148 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_k_complex.h
+-rw-rw-r--   0 root         (0) root         (0)    10509 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/symm.h
+-rw-rw-r--   0 root         (0) root         (0)    12296 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/symm_complex.h
+-rw-r--r--   0 root         (0) root         (0)     8440 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_compare.h
+-rw-rw-r--   0 root         (0) root         (0)     3339 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_compare.hpp
+-rw-rw-r--   0 root         (0) root         (0)     8317 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_copy.h
+-rw-rw-r--   0 root         (0) root         (0)     9027 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_elementwise.h
+-rw-r--r--   0 root         (0) root         (0)    43961 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_fill.h
+-rw-rw-r--   0 root         (0) root         (0)    12875 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_fill.hpp
+-rw-r--r--   0 root         (0) root         (0)     4756 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_foreach.h
+-rw-rw-r--   0 root         (0) root         (0)     2133 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_norm.h
+-rw-rw-r--   0 root         (0) root         (0)     6111 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.h
+-rw-rw-r--   0 root         (0) root         (0)     5987 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.hpp
+-rw-rw-r--   0 root         (0) root         (0)     7670 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/trmm.h
+-rw-rw-r--   0 root         (0) root         (0)     9874 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/trmm_complex.h
+-rw-r--r--   0 root         (0) root         (0)     8285 2023-07-17 10:57:41.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/tensor_view_io.h
+-rw-rw-r--   0 root         (0) root         (0)     8809 2023-07-17 10:57:20.000000 flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/type_traits.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:15.499452 flash_attn-2.0.1/csrc/flash_attn/
+-rw-r--r--   0 root         (0) root         (0)    41827 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/flash_api.cpp
+-rw-r--r--   0 root         (0) root         (0)    33267 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/fmha_api.cpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:16.274015 flash_attn-2.0.1/csrc/flash_attn/src/
+-rw-r--r--   0 root         (0) root         (0)     1664 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/block_info.h
+-rw-r--r--   0 root         (0) root         (0)     4109 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash.h
+-rw-r--r--   0 root         (0) root         (0)      879 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim128_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     1569 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim128_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      361 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim160_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      353 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim160_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      361 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim192_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      353 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim192_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      361 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim224_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      353 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim224_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      361 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim256_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      353 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim256_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      667 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim32_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      651 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim32_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      667 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim64_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     2751 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim64_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      874 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim96_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     1031 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim96_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    85685 2023-07-21 00:39:57.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_kernel.h
+-rw-r--r--   0 root         (0) root         (0)    20375 2023-07-23 22:33:51.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_launch_template.h
+-rw-r--r--   0 root         (0) root         (0)      783 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim128_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     1951 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim128_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      682 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim160_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     1674 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim160_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      682 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim192_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     1647 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim192_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      329 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim224_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      321 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim224_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      329 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim256_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      321 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim256_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      326 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim32_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     1151 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim32_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      777 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim64_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     1463 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim64_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      677 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim96_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     1328 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim96_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    30177 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_kernel.h
+-rw-r--r--   0 root         (0) root         (0)    15208 2023-07-23 22:33:51.000000 flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_launch_template.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:16.366499 flash_attn-2.0.1/csrc/flash_attn/src/fmha/
+-rw-r--r--   0 root         (0) root         (0)    17999 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha/gemm.h
+-rw-r--r--   0 root         (0) root         (0)    22872 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha/gmem_tile.h
+-rw-r--r--   0 root         (0) root         (0)     5997 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha/kernel_traits.h
+-rw-r--r--   0 root         (0) root         (0)     4362 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha/mask.h
+-rw-r--r--   0 root         (0) root         (0)    74010 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha/smem_tile.h
+-rw-r--r--   0 root         (0) root         (0)    25514 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha/softmax.h
+-rw-r--r--   0 root         (0) root         (0)    41059 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha/utils.h
+-rw-r--r--   0 root         (0) root         (0)     7237 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha.h
+-rw-r--r--   0 root         (0) root         (0)     4118 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha_block_dgrad_fp16_kernel_loop.sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    33506 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha_block_dgrad_kernel_1xN_loop.h
+-rw-r--r--   0 root         (0) root         (0)     5292 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha_block_fprop_fp16_kernel.sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    23207 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha_block_fprop_kernel_1xN.h
+-rw-r--r--   0 root         (0) root         (0)     2502 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha_blockmask.h
+-rw-r--r--   0 root         (0) root         (0)      465 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha_bwd_hdim128.cu
+-rw-r--r--   0 root         (0) root         (0)      727 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha_bwd_hdim32.cu
+-rw-r--r--   0 root         (0) root         (0)     1713 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha_bwd_hdim64.cu
+-rw-r--r--   0 root         (0) root         (0)     6453 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha_bwd_launch_template.h
+-rw-r--r--   0 root         (0) root         (0)    37168 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h
+-rw-r--r--   0 root         (0) root         (0)    31042 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha_fprop_kernel_1xN.h
+-rw-r--r--   0 root         (0) root         (0)      445 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha_fwd_hdim128.cu
+-rw-r--r--   0 root         (0) root         (0)      724 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha_fwd_hdim32.cu
+-rw-r--r--   0 root         (0) root         (0)      725 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha_fwd_hdim64.cu
+-rw-r--r--   0 root         (0) root         (0)     4393 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha_fwd_launch_template.h
+-rw-r--r--   0 root         (0) root         (0)     3104 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha_kernel.h
+-rw-r--r--   0 root         (0) root         (0)     4892 2023-07-20 08:13:56.000000 flash_attn-2.0.1/csrc/flash_attn/src/fmha_utils.h
+-rw-r--r--   0 root         (0) root         (0)    18396 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/kernel_traits.h
+-rw-r--r--   0 root         (0) root         (0)     7555 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/kernel_traits_sm90.h
+-rw-r--r--   0 root         (0) root         (0)     5372 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/philox.cuh
+-rw-r--r--   0 root         (0) root         (0)    14205 2023-07-21 01:43:36.000000 flash_attn-2.0.1/csrc/flash_attn/src/softmax.h
+-rw-r--r--   0 root         (0) root         (0)     2598 2023-07-21 00:39:57.000000 flash_attn-2.0.1/csrc/flash_attn/src/static_switch.h
+-rw-r--r--   0 root         (0) root         (0)    16378 2023-07-20 23:38:22.000000 flash_attn-2.0.1/csrc/flash_attn/src/utils.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:16.384757 flash_attn-2.0.1/csrc/flash_gen/
+-rw-r--r--   0 root         (0) root         (0)     7018 2022-11-21 06:35:03.000000 flash_attn-2.0.1/csrc/flash_gen/decoder_masked_multihead_attention.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:16.476585 flash_attn-2.0.1/csrc/ft_attention/
+-rw-r--r--   0 root         (0) root         (0)     8253 2023-04-16 00:48:36.000000 flash_attn-2.0.1/csrc/ft_attention/cuda_bf16_fallbacks.cuh
+-rw-r--r--   0 root         (0) root         (0)      867 2023-04-16 00:48:36.000000 flash_attn-2.0.1/csrc/ft_attention/cuda_bf16_wrapper.h
+-rw-r--r--   0 root         (0) root         (0)     7069 2023-06-06 06:13:59.000000 flash_attn-2.0.1/csrc/ft_attention/decoder_masked_multihead_attention.cu
+-rw-r--r--   0 root         (0) root         (0)     7733 2023-07-22 05:49:11.000000 flash_attn-2.0.1/csrc/ft_attention/decoder_masked_multihead_attention.h
+-rw-r--r--   0 root         (0) root         (0)    57953 2023-07-22 06:00:35.000000 flash_attn-2.0.1/csrc/ft_attention/decoder_masked_multihead_attention_template.hpp
+-rw-r--r--   0 root         (0) root         (0)    64946 2023-07-03 16:25:44.000000 flash_attn-2.0.1/csrc/ft_attention/decoder_masked_multihead_attention_utils.h
+-rw-r--r--   0 root         (0) root         (0)    10432 2023-07-22 06:14:42.000000 flash_attn-2.0.1/csrc/ft_attention/ft_attention.cpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:16.506252 flash_attn-2.0.1/csrc/fused_dense_lib/
+-rw-r--r--   0 root         (0) root         (0)    10179 2023-05-30 21:13:46.000000 flash_attn-2.0.1/csrc/fused_dense_lib/fused_dense.cpp
+-rw-r--r--   0 root         (0) root         (0)    24690 2023-05-30 21:14:57.000000 flash_attn-2.0.1/csrc/fused_dense_lib/fused_dense_cuda.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:16.585489 flash_attn-2.0.1/csrc/fused_softmax/
+-rw-r--r--   0 root         (0) root         (0)     5037 2023-04-16 00:48:36.000000 flash_attn-2.0.1/csrc/fused_softmax/fused_softmax.cpp
+-rw-r--r--   0 root         (0) root         (0)    23616 2023-04-16 00:48:36.000000 flash_attn-2.0.1/csrc/fused_softmax/scaled_masked_softmax.h
+-rw-r--r--   0 root         (0) root         (0)     4209 2023-04-16 00:48:36.000000 flash_attn-2.0.1/csrc/fused_softmax/scaled_masked_softmax_cuda.cu
+-rw-r--r--   0 root         (0) root         (0)    24659 2023-04-16 00:48:36.000000 flash_attn-2.0.1/csrc/fused_softmax/scaled_upper_triang_masked_softmax.h
+-rw-r--r--   0 root         (0) root         (0)     3154 2023-04-16 00:48:36.000000 flash_attn-2.0.1/csrc/fused_softmax/scaled_upper_triang_masked_softmax_cuda.cu
+-rw-r--r--   0 root         (0) root         (0)     1216 2023-04-16 00:48:36.000000 flash_attn-2.0.1/csrc/fused_softmax/type_shim.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:17.477289 flash_attn-2.0.1/csrc/layer_norm/
+-rw-r--r--   0 root         (0) root         (0)     7248 2023-04-16 00:48:36.000000 flash_attn-2.0.1/csrc/layer_norm/ln.h
+-rw-r--r--   0 root         (0) root         (0)    36420 2023-07-23 22:07:05.000000 flash_attn-2.0.1/csrc/layer_norm/ln_api.cpp
+-rw-r--r--   0 root         (0) root         (0)      987 2023-04-16 00:48:36.000000 flash_attn-2.0.1/csrc/layer_norm/ln_bwd_1024.cu
+-rw-r--r--   0 root         (0) root         (0)      987 2023-04-16 00:48:36.000000 flash_attn-2.0.1/csrc/layer_norm/ln_bwd_1280.cu
+-rw-r--r--   0 root         (0) root         (0)      977 2023-04-16 00:48:36.000000 flash_attn-2.0.1/csrc/layer_norm/ln_bwd_1536.cu
+-rw-r--r--   0 root         (0) root         (0)      976 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_bwd_2048.cu
+-rw-r--r--   0 root         (0) root         (0)      977 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_bwd_256.cu
+-rw-r--r--   0 root         (0) root         (0)      977 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_bwd_2560.cu
+-rw-r--r--   0 root         (0) root         (0)      976 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_bwd_3072.cu
+-rw-r--r--   0 root         (0) root         (0)      976 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_bwd_4096.cu
+-rw-r--r--   0 root         (0) root         (0)      977 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_bwd_512.cu
+-rw-r--r--   0 root         (0) root         (0)      976 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_bwd_5120.cu
+-rw-r--r--   0 root         (0) root         (0)      976 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_bwd_6144.cu
+-rw-r--r--   0 root         (0) root         (0)      976 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_bwd_7168.cu
+-rw-r--r--   0 root         (0) root         (0)      977 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_bwd_768.cu
+-rw-r--r--   0 root         (0) root         (0)      976 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_bwd_8192.cu
+-rw-r--r--   0 root         (0) root         (0)    25647 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_bwd_kernels.cuh
+-rw-r--r--   0 root         (0) root         (0)    19944 2023-01-19 07:34:02.000000 flash_attn-2.0.1/csrc/layer_norm/ln_bwd_semi_cuda_kernel_old.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_fwd_1024.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-01-22 09:05:55.000000 flash_attn-2.0.1/csrc/layer_norm/ln_fwd_10240.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-01-22 09:07:15.000000 flash_attn-2.0.1/csrc/layer_norm/ln_fwd_12288.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2022-12-05 08:45:58.000000 flash_attn-2.0.1/csrc/layer_norm/ln_fwd_128.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_fwd_1280.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_fwd_1536.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_fwd_2048.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_fwd_256.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_fwd_2560.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_fwd_3072.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2022-12-05 08:50:57.000000 flash_attn-2.0.1/csrc/layer_norm/ln_fwd_384.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_fwd_4096.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_fwd_512.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_fwd_5120.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_fwd_6144.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_fwd_7168.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_fwd_768.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_fwd_8192.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-01-22 08:41:06.000000 flash_attn-2.0.1/csrc/layer_norm/ln_fwd_9216.cu
+-rw-r--r--   0 root         (0) root         (0)    18000 2022-12-06 21:18:58.000000 flash_attn-2.0.1/csrc/layer_norm/ln_fwd_cuda_kernel_old.cu
+-rw-r--r--   0 root         (0) root         (0)    12721 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_fwd_kernels.cuh
+-rw-r--r--   0 root         (0) root         (0)     6655 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_kernel_traits.h
+-rw-r--r--   0 root         (0) root         (0)     1095 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_1024.cu
+-rw-r--r--   0 root         (0) root         (0)     1095 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_1280.cu
+-rw-r--r--   0 root         (0) root         (0)     1085 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_1536.cu
+-rw-r--r--   0 root         (0) root         (0)     1084 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_2048.cu
+-rw-r--r--   0 root         (0) root         (0)     1085 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_256.cu
+-rw-r--r--   0 root         (0) root         (0)     1085 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_2560.cu
+-rw-r--r--   0 root         (0) root         (0)     1084 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_3072.cu
+-rw-r--r--   0 root         (0) root         (0)     1145 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_4096.cu
+-rw-r--r--   0 root         (0) root         (0)     1085 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_512.cu
+-rw-r--r--   0 root         (0) root         (0)     1145 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_5120.cu
+-rw-r--r--   0 root         (0) root         (0)     1084 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_6144.cu
+-rw-r--r--   0 root         (0) root         (0)     1084 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_7168.cu
+-rw-r--r--   0 root         (0) root         (0)     1085 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_768.cu
+-rw-r--r--   0 root         (0) root         (0)     1084 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_8192.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_1024.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_1280.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_1536.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_2048.cu
+-rw-r--r--   0 root         (0) root         (0)     1032 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_256.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_2560.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_3072.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_4096.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_512.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_5120.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_6144.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_7168.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_768.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_8192.cu
+-rw-r--r--   0 root         (0) root         (0)    24916 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_residual_bwd_kernels.cuh
+-rw-r--r--   0 root         (0) root         (0)    12530 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_parallel_residual_fwd_kernels.cuh
+-rw-r--r--   0 root         (0) root         (0)    29989 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/ln_utils.cuh
+-rw-r--r--   0 root         (0) root         (0)     1278 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/layer_norm/static_switch.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:17.506945 flash_attn-2.0.1/csrc/rotary/
+-rw-r--r--   0 root         (0) root         (0)     1806 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/rotary/rotary.cpp
+-rw-r--r--   0 root         (0) root         (0)     1984 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/rotary/rotary_cuda.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:17.546902 flash_attn-2.0.1/csrc/xentropy/
+-rw-r--r--   0 root         (0) root         (0)     2290 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/xentropy/interface.cpp
+-rw-r--r--   0 root         (0) root         (0)    25783 2023-04-16 00:48:37.000000 flash_attn-2.0.1/csrc/xentropy/xentropy_kernel.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:17.729931 flash_attn-2.0.1/flash_attn/
+-rw-r--r--   0 root         (0) root         (0)      442 2023-07-23 22:33:28.000000 flash_attn-2.0.1/flash_attn/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    20845 2022-10-31 02:25:05.000000 flash_attn-2.0.1/flash_attn/attention_kernl.py
+-rw-r--r--   0 root         (0) root         (0)     5898 2023-04-16 00:48:37.000000 flash_attn-2.0.1/flash_attn/bert_padding.py
+-rw-r--r--   0 root         (0) root         (0)    28027 2023-07-12 12:19:57.000000 flash_attn-2.0.1/flash_attn/fav2_interface.py
+-rw-r--r--   0 root         (0) root         (0)     4722 2023-07-20 08:13:56.000000 flash_attn-2.0.1/flash_attn/flash_attention.py
+-rw-r--r--   0 root         (0) root         (0)    28419 2023-07-21 00:38:09.000000 flash_attn-2.0.1/flash_attn/flash_attn_interface.py
+-rw-r--r--   0 root         (0) root         (0)    38148 2023-04-16 00:48:37.000000 flash_attn-2.0.1/flash_attn/flash_attn_triton.py
+-rw-r--r--   0 root         (0) root         (0)    10593 2023-04-16 00:48:37.000000 flash_attn-2.0.1/flash_attn/flash_attn_triton_og.py
+-rw-r--r--   0 root         (0) root         (0)     8255 2022-11-18 03:30:00.000000 flash_attn-2.0.1/flash_attn/flash_attn_triton_single_query.py
+-rw-r--r--   0 root         (0) root         (0)    37797 2023-03-17 09:16:10.000000 flash_attn-2.0.1/flash_attn/flash_attn_triton_tmp.py
+-rw-r--r--   0 root         (0) root         (0)    10640 2023-03-12 08:48:14.000000 flash_attn-2.0.1/flash_attn/flash_attn_triton_tmp_og.py
+-rw-r--r--   0 root         (0) root         (0)     6819 2022-06-26 00:59:43.000000 flash_attn-2.0.1/flash_attn/flash_blocksparse_attention.py
+-rw-r--r--   0 root         (0) root         (0)     7036 2022-06-26 00:59:43.000000 flash_attn-2.0.1/flash_attn/flash_blocksparse_attn_interface.py
+-rw-r--r--   0 root         (0) root         (0)     7902 2023-04-16 00:48:37.000000 flash_attn-2.0.1/flash_attn/fused_softmax.py
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:17.838932 flash_attn-2.0.1/flash_attn/layers/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-04-16 00:48:37.000000 flash_attn-2.0.1/flash_attn/layers/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     2039 2023-04-16 00:48:37.000000 flash_attn-2.0.1/flash_attn/layers/patch_embed.py
+-rw-r--r--   0 root         (0) root         (0)    15657 2023-07-22 04:55:20.000000 flash_attn-2.0.1/flash_attn/layers/rotary.py
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:17.868510 flash_attn-2.0.1/flash_attn/losses/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-04-16 00:48:37.000000 flash_attn-2.0.1/flash_attn/losses/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6697 2023-04-16 00:48:37.000000 flash_attn-2.0.1/flash_attn/losses/cross_entropy.py
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:17.984907 flash_attn-2.0.1/flash_attn/models/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-04-16 00:48:37.000000 flash_attn-2.0.1/flash_attn/models/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    26979 2023-07-23 17:32:29.000000 flash_attn-2.0.1/flash_attn/models/bert.py
+-rw-r--r--   0 root         (0) root         (0)     5940 2023-07-23 17:32:29.000000 flash_attn-2.0.1/flash_attn/models/falcon.py
+-rw-r--r--   0 root         (0) root         (0)    40471 2023-07-23 17:32:29.000000 flash_attn-2.0.1/flash_attn/models/gpt.py
+-rw-r--r--   0 root         (0) root         (0)     5025 2023-04-16 00:48:37.000000 flash_attn-2.0.1/flash_attn/models/gpt_neox.py
+-rw-r--r--   0 root         (0) root         (0)     4365 2023-04-18 20:33:24.000000 flash_attn-2.0.1/flash_attn/models/gptj.py
+-rw-r--r--   0 root         (0) root         (0)     5761 2023-04-19 04:11:30.000000 flash_attn-2.0.1/flash_attn/models/llama.py
+-rw-r--r--   0 root         (0) root         (0)     5130 2023-04-18 20:33:17.000000 flash_attn-2.0.1/flash_attn/models/opt.py
+-rw-r--r--   0 root         (0) root         (0)    13621 2023-04-16 00:48:37.000000 flash_attn-2.0.1/flash_attn/models/vit.py
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:18.053817 flash_attn-2.0.1/flash_attn/modules/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-04-16 00:48:37.000000 flash_attn-2.0.1/flash_attn/modules/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    16615 2023-07-23 06:44:58.000000 flash_attn-2.0.1/flash_attn/modules/block.py
+-rw-r--r--   0 root         (0) root         (0)     8620 2023-04-16 00:48:37.000000 flash_attn-2.0.1/flash_attn/modules/embedding.py
+-rw-r--r--   0 root         (0) root         (0)    37920 2023-07-23 06:44:27.000000 flash_attn-2.0.1/flash_attn/modules/mha.py
+-rw-r--r--   0 root         (0) root         (0)     3596 2023-07-23 00:03:03.000000 flash_attn-2.0.1/flash_attn/modules/mlp.py
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:18.119789 flash_attn-2.0.1/flash_attn/ops/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-04-16 00:48:37.000000 flash_attn-2.0.1/flash_attn/ops/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3002 2023-04-16 00:48:37.000000 flash_attn-2.0.1/flash_attn/ops/activations.py
+-rw-r--r--   0 root         (0) root         (0)    26087 2023-07-23 00:03:01.000000 flash_attn-2.0.1/flash_attn/ops/fused_dense.py
+-rw-r--r--   0 root         (0) root         (0)    19306 2023-07-04 21:52:07.000000 flash_attn-2.0.1/flash_attn/ops/layer_norm.py
+-rw-r--r--   0 root         (0) root         (0)     3672 2023-04-18 22:26:53.000000 flash_attn-2.0.1/flash_attn/ops/rms_norm.py
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:18.186232 flash_attn-2.0.1/flash_attn/utils/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-04-16 00:48:37.000000 flash_attn-2.0.1/flash_attn/utils/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5909 2023-04-16 00:48:37.000000 flash_attn-2.0.1/flash_attn/utils/benchmark.py
+-rw-r--r--   0 root         (0) root         (0)     5545 2023-04-16 00:48:37.000000 flash_attn-2.0.1/flash_attn/utils/distributed.py
+-rw-r--r--   0 root         (0) root         (0)    14105 2023-04-21 18:28:20.000000 flash_attn-2.0.1/flash_attn/utils/generation.py
+-rw-r--r--   0 root         (0) root         (0)     1824 2023-04-16 00:48:37.000000 flash_attn-2.0.1/flash_attn/utils/pretrained.py
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-07-24 08:09:17.797240 flash_attn-2.0.1/flash_attn.egg-info/
+-rw-rw-r--   0 root         (0) root         (0)      476 2023-07-24 08:08:44.000000 flash_attn-2.0.1/flash_attn.egg-info/PKG-INFO
+-rw-rw-r--   0 root         (0) root         (0)   103444 2023-07-24 08:08:52.000000 flash_attn-2.0.1/flash_attn.egg-info/SOURCES.txt
+-rw-rw-r--   0 root         (0) root         (0)        1 2023-07-24 08:08:44.000000 flash_attn-2.0.1/flash_attn.egg-info/dependency_links.txt
+-rw-rw-r--   0 root         (0) root         (0)       29 2023-07-24 08:08:44.000000 flash_attn-2.0.1/flash_attn.egg-info/requires.txt
+-rw-rw-r--   0 root         (0) root         (0)       29 2023-07-24 08:08:44.000000 flash_attn-2.0.1/flash_attn.egg-info/top_level.txt
+-rw-rw-r--   0 root         (0) root         (0)       38 2023-07-24 08:09:18.196462 flash_attn-2.0.1/setup.cfg
+-rw-r--r--   0 root         (0) root         (0)     9562 2023-07-23 22:33:51.000000 flash_attn-2.0.1/setup.py
```

### Comparing `flash_attn-2.0.0.post1/LICENSE` & `flash_attn-2.0.1/LICENSE`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/README.md` & `flash_attn-2.0.1/README.md`

 * *Files 6% similar despite different names*

```diff
@@ -33,63 +33,75 @@
 - PyTorch 1.12 and above.
 
 We recommend the
 [Pytorch](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch)
 container from Nvidia, which has all the required tools to install FlashAttention.
 
 To install:
-- Make sure that PyTorch is installed.
-- Make sure that `packaging` and `ninja` are installed (e.g., with `pip install -U
-packaging ninja`). Without `ninja` compiling can take a long time. With `ninja`
-compiling takes 3-5 minutes on a 64-core machine.
-- Then:
+1. Make sure that PyTorch is installed.
+2. Make sure that `packaging` is installed (`pip install packaging`)
+3. Make sure that `ninja` is installed and that it works correctly (e.g. `ninja
+--version` then `echo $?` should return exit code 0). If not (sometimes `ninja
+--version` then `echo $?` returns a nonzero exit code), uninstall then reinstall
+`ninja` (`pip uninstall -y ninja && pip install ninja`). Without `ninja`,
+compiling can take a very long time (2h) since it does not use multiple CPU
+cores. With `ninja` compiling takes 3-5 minutes on a 64-core machine.
+4. Then:
 ```sh
 pip install flash-attn --no-build-isolation
 ```
-
 Alternatively you can compile from source:
-```
+```sh
 python setup.py install
 ```
 
+If your machine has less than 96GB of RAM and lots of CPU cores, `ninja` might
+run too many parallel compilation jobs that could exhaust the amount of RAM. To
+limit the number of parallel compilation jobs, you can set the environment
+variable `MAX_JOBS`:
+```sh
+MAX_JOBS=4 pip install flash-attn --no-build-isolation
+```
+
 Interface: `src/flash_attention_interface.py`
 
 FlashAttention-2 currently supports:
 1. Ampere, Ada, or Hopper GPUs (e.g., A100, RTX 3090, RTX 4090, H100). Support for Turing
    GPUs (T4, RTX 2080) is coming soon, please use FlashAttention 1.x for Turing
    GPUs for now.
 2. Datatype fp16 and bf16 (bf16 requires Ampere, Ada, or Hopper GPUs).
 3. All head dimensions up to 256. Head dim > 192 backward requires A100/A800 or H100/H800.
 
 
 ## How to use FlashAttention
 
 The main functions implement scaled dot product attention (softmax(Q @ K^T *
 softmax_scale) @ V):
-```
+```python
 from flash_attn import flash_attn_qkvpacked_func, flash_attn_func
 ```
 
-```
+```python
 flash_attn_qkvpacked_func(qkv, dropout_p=0.0, softmax_scale=None, causal=False):
 """dropout_p should be set to 0.0 during evaluation
 If Q, K, V are already stacked into 1 tensor, this function will be faster than
 calling flash_attn_func on Q, K, V since the backward pass avoids explicit concatenation
 of the gradients of Q, K, V.
 Arguments:
     qkv: (batch_size, seqlen, 3, nheads, headdim)
     dropout_p: float. Dropout probability.
     softmax_scale: float. The scaling of QK^T before applying softmax.
         Default to 1 / sqrt(headdim).
     causal: bool. Whether to apply causal attention mask (e.g., for auto-regressive modeling).
 Return:
     out: (batch_size, seqlen, nheads, headdim).
+"""
 ```
 
-```
+```python
 flash_attn_func(q, k, v, dropout_p=0.0, softmax_scale=None, causal=False):
 """dropout_p should be set to 0.0 during evaluation
 Supports multi-query and grouped-query attention (MQA/GQA) by passing in KV with fewer heads
 than Q. Note that the number of heads in KV must be divisible by the number of heads in Q.
 For example, if Q has 6 heads and K, V have 2 heads, head 0, 1, 2 of Q will attention to head
 0 of K, V, and head 3, 4, 5 of Q will attention to head 1 of K, V.
 
@@ -99,32 +111,33 @@
     v: (batch_size, seqlen, nheads_k, headdim)
     dropout_p: float. Dropout probability.
     softmax_scale: float. The scaling of QK^T before applying softmax.
         Default to 1 / sqrt(headdim).
     causal: bool. Whether to apply causal attention mask (e.g., for auto-regressive modeling).
 Return:
     out: (batch_size, seqlen, nheads, headdim).
+"""
 ```
 
 To see how these functions are used in a multi-head attention layer (which
 includes QKV projection, output projection), see the MHA [implementation](https://github.com/Dao-AILab/flash-attention/blob/main/flash_attn/modules/mha.py).
 
 ## Upgrading from FlashAttention (1.x) to FlashAttention-2
 
 These functions have been renamed:
 - `flash_attn_unpadded_func` -> `flash_attn_varlen_func`
 - `flash_attn_unpadded_qkvpacked_func` -> `flash_attn_varlen_qkvpacked_func`
 - `flash_attn_unpadded_kvpacked_func` -> `flash_attn_varlen_kvpacked_func`
 
 If the inputs have the same sequence lengths in the same batch, it is simpler
 and faster to use these functions:
-```
+```python
 flash_attn_qkvpacked_func(qkv, dropout_p, softmax_scale=None, causal=False)
 ```
-```
+```python
 flash_attn_func(q, k, v, dropout_p=0.0, softmax_scale=None, causal=False)
 ```
 
 ## Performance
 
 We present expected speedup (combined forward + backward pass) and memory savings from using FlashAttention against PyTorch standard attention, depending on sequence length, on different GPUs (speedup depends on memory bandwidth - we see more speedup on slower GPU memory).
 
@@ -190,23 +203,23 @@
 We test that FlashAttention produces the same output and gradient as a reference
 implementation, up to some numerical tolerance. In particular, we check that the
 maximum numerical error of FlashAttention is at most twice the numerical error
 of a baseline implementation in Pytorch (for different head dimensions, input
 dtype, sequence length, causal / non-causal).
 
 To run the tests:
-```
+```sh
 pytest -q -s tests/test_flash_attn.py
 ```
 ## When you encounter issues
 
-This new release of FlashAttention-2 have been tested on several GPT-style
+This new release of FlashAttention-2 has been tested on several GPT-style
 models, mostly on A100 GPUs.
 
-If you encounter any of bugs, please open a respective GitHub Issue!
+If you encounter bugs, please open a GitHub Issue!
 
 ## Citation
 If you use this codebase, or otherwise found our work valuable, please cite:
 ```
 @inproceedings{dao2022flashattention,
   title={Flash{A}ttention: Fast and Memory-Efficient Exact Attention with {IO}-Awareness},
   author={Dao, Tri and Fu, Daniel Y. and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
```

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/cmake/nop.cu` & `flash_attn-2.0.1/csrc/cutlass/cmake/nop.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/00_basic_gemm/basic_gemm.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/00_basic_gemm/basic_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/01_cutlass_utilities/cutlass_utilities.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/01_cutlass_utilities/cutlass_utilities.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/02_dump_reg_shmem/dump_reg_shmem.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/02_dump_reg_shmem/dump_reg_shmem.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/03_visualize_layout/options.h` & `flash_attn-2.0.1/csrc/cutlass/examples/03_visualize_layout/options.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/03_visualize_layout/register_layout.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/03_visualize_layout/register_layout.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/03_visualize_layout/register_layout.h` & `flash_attn-2.0.1/csrc/cutlass/examples/03_visualize_layout/register_layout.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/03_visualize_layout/visualize_layout.cpp` & `flash_attn-2.0.1/csrc/cutlass/examples/03_visualize_layout/visualize_layout.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/03_visualize_layout/visualize_layout.h` & `flash_attn-2.0.1/csrc/cutlass/examples/03_visualize_layout/visualize_layout.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/04_tile_iterator/tile_iterator.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/04_tile_iterator/tile_iterator.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/05_batched_gemm/batched_gemm.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/05_batched_gemm/batched_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/06_splitK_gemm/splitk_gemm.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/06_splitK_gemm/splitk_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/07_volta_tensorop_gemm/volta_tensorop_gemm.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/07_volta_tensorop_gemm/volta_tensorop_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/08_turing_tensorop_gemm/turing_tensorop_gemm.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/08_turing_tensorop_gemm/turing_tensorop_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/09_turing_tensorop_conv2dfprop/turing_tensorop_conv2dfprop.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/09_turing_tensorop_conv2dfprop/turing_tensorop_conv2dfprop.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/10_planar_complex/planar_complex.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/10_planar_complex/planar_complex.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/11_planar_complex_array/planar_complex_array.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/11_planar_complex_array/planar_complex_array.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/12_gemm_bias_relu/gemm_bias_relu.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/12_gemm_bias_relu/gemm_bias_relu.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_conv2d_run.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_conv2d_run.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_gemm_run.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_gemm_run.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_conv2d_run.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_conv2d_run.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_gemm_run.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_gemm_run.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/device/b2b_gemm.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/device/b2b_gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/device/b2b_implicit_gemm_convolution.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/device/b2b_implicit_gemm_convolution.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_rf.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_rf.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_shmem.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_shmem.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_rf.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_rf.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_shmem.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_shmem.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_rf.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_rf.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_shmem.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_shmem.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_rf.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_rf.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_shmem.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_shmem.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_rf.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_rf.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_shmem.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_shmem.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_rf.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_rf.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_shmem.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_shmem.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_rf.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_rf.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_shmem.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_shmem.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_rf.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_rf.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_shmem.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_shmem.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_gemm.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_implicit_gemm_convolution.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_implicit_gemm_convolution.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm75.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm75.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm80.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm75.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm75.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm80.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm_smem_accumulator.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm_smem_accumulator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/reference/device/tensor_scale_bias.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/reference/device/tensor_scale_bias.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/test_run.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/test_run.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage_smem_accumulator.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage_smem_accumulator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined_smem_accumulator.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined_smem_accumulator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base_smem_accumulator.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base_smem_accumulator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage_smem_accumulator.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage_smem_accumulator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined_smem_accumulator.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined_smem_accumulator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma_smem_accumulator.h` & `flash_attn-2.0.1/csrc/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma_smem_accumulator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/14_ampere_tf32_tensorop_gemm/ampere_tf32_tensorop_gemm.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/14_ampere_tf32_tensorop_gemm/ampere_tf32_tensorop_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/15_ampere_sparse_tensorop_gemm/ampere_sparse_tensorop_gemm.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/15_ampere_sparse_tensorop_gemm/ampere_sparse_tensorop_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/16_ampere_tensorop_conv2dfprop/ampere_tensorop_conv2dfprop.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/16_ampere_tensorop_conv2dfprop/ampere_tensorop_conv2dfprop.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/17_fprop_per_channel_bias/fprop_per_channel_bias.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/17_fprop_per_channel_bias/fprop_per_channel_bias.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/18_ampere_fp64_tensorop_affine2_gemm/ampere_fp64_tensorop_affine2_gemm.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/18_ampere_fp64_tensorop_affine2_gemm/ampere_fp64_tensorop_affine2_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/19_tensorop_canonical/tensorop_canonical.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/19_tensorop_canonical/tensorop_canonical.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/20_simt_canonical/simt_canonical.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/20_simt_canonical/simt_canonical.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/21_quaternion_gemm/quaternion_gemm.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/21_quaternion_gemm/quaternion_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/22_quaternion_conv/quaternion_conv.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/22_quaternion_conv/quaternion_conv.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/23_ampere_gemm_operand_reduction_fusion/ampere_gemm_operand_reduction_fusion.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/23_ampere_gemm_operand_reduction_fusion/ampere_gemm_operand_reduction_fusion.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/24_gemm_grouped/gemm_grouped.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/24_gemm_grouped/gemm_grouped.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_3d_fprop_mainloop_fusion.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_3d_fprop_mainloop_fusion.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_fprop_mainloop_fusion.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_fprop_mainloop_fusion.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/26_ampere_wgrad_mainloop_fusion/ampere_wgrad_mainloop_fusion.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/26_ampere_wgrad_mainloop_fusion/ampere_wgrad_mainloop_fusion.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/27_ampere_3xtf32_fast_accurate_tensorop_gemm/27_ampere_3xtf32_fast_accurate_tensorop_gemm.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/27_ampere_3xtf32_fast_accurate_tensorop_gemm/27_ampere_3xtf32_fast_accurate_tensorop_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/28_ampere_3xtf32_fast_accurate_tensorop_fprop/ampere_3xtf32_fast_accurate_tensorop_fprop.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/28_ampere_3xtf32_fast_accurate_tensorop_fprop/ampere_3xtf32_fast_accurate_tensorop_fprop.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/30_wgrad_split_k/30_wgrad_split_k.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/30_wgrad_split_k/30_wgrad_split_k.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/31_basic_syrk/basic_syrk.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/31_basic_syrk/basic_syrk.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/32_basic_trmm/basic_trmm.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/32_basic_trmm/basic_trmm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/33_ampere_3xtf32_tensorop_symm/ampere_3xtf32_tensorop_symm.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/33_ampere_3xtf32_tensorop_symm/ampere_3xtf32_tensorop_symm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/34_transposed_conv2d/34_transposed_conv2d.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/34_transposed_conv2d/34_transposed_conv2d.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/35_gemm_softmax/gemm_softmax.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/35_gemm_softmax/gemm_softmax.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/35_gemm_softmax/gemm_with_epilogue_visitor.h` & `flash_attn-2.0.1/csrc/cutlass/examples/35_gemm_softmax/gemm_with_epilogue_visitor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/35_gemm_softmax/gemm_with_softmax.h` & `flash_attn-2.0.1/csrc/cutlass/examples/35_gemm_softmax/gemm_with_softmax.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/36_gather_scatter_fusion/gather_scatter_fusion.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/36_gather_scatter_fusion/gather_scatter_fusion.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_layernorm.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_layernorm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_epilogue_visitor.h` & `flash_attn-2.0.1/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_epilogue_visitor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_layernorm.h` & `flash_attn-2.0.1/csrc/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_layernorm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/38_syr2k_grouped/syr2k_grouped.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/38_syr2k_grouped/syr2k_grouped.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/39_gemm_permute/gemm_permute.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/39_gemm_permute/gemm_permute.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/debug_utils.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/debug_utils.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/default_fmha_grouped.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/default_fmha_grouped.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_pipelined.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_rescale_output.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_rescale_output.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_thread_apply_logsumexp.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_thread_apply_logsumexp.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/fmha_grouped.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/fmha_grouped.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/fmha_grouped_problem_visitor.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/fmha_grouped_problem_visitor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_fixed_seqlen.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_fixed_seqlen.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_variable_seqlen.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_variable_seqlen.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_base.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_base.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_multistage.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_pipelined.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/find_default_mma.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/find_default_mma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/mma_accum_lambda_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/mma_accum_lambda_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/mma_from_smem.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm/mma_from_smem.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm_kernel_utils.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/gemm_kernel_utils.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/epilogue_predicated_tile_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/epilogue_predicated_tile_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/make_residual_last.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/make_residual_last.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_access_iterator_residual_last.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_access_iterator_residual_last.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_iterator_residual_last.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_iterator_residual_last.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/transpose_warp_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/transpose_warp_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/warp_iterator_from_smem.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/iterators/warp_iterator_from_smem.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/kernel_forward.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/kernel_forward.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/41_fused_multi_head_attention/transform/tile_smem_loader.h` & `flash_attn-2.0.1/csrc/cutlass/examples/41_fused_multi_head_attention/transform/tile_smem_loader.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/42_ampere_tensorop_group_conv/ampere_tensorop_group_conv.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/42_ampere_tensorop_group_conv/ampere_tensorop_group_conv.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/43_ell_block_sparse_gemm/ell_block_sparse_gemm.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/43_ell_block_sparse_gemm/ell_block_sparse_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_bias_act_epilogue_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_bias_act_epilogue_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_thread_map_tensor_op_for_fused_bias.h` & `flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_thread_map_tensor_op_for_fused_bias.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/fused_bias_act_epilogue.h` & `flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/fused_bias_act_epilogue.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/output_tile_thread_map_for_fused_bias.h` & `flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/output_tile_thread_map_for_fused_bias.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/warp/fused_bias_act_fragment_iterator_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/warp/fused_bias_act_fragment_iterator_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/warp/mma_tensor_op_fragment_iterator_without_output_op.h` & `flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/warp/mma_tensor_op_fragment_iterator_without_output_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/leaky_bias.h` & `flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/leaky_bias.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/utils.h` & `flash_attn-2.0.1/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/utils.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/device/dual_gemm.h` & `flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/device/dual_gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/dual_gemm.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/dual_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/dual_gemm_common.h` & `flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/dual_gemm_common.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/dual_gemm_run.h` & `flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/dual_gemm_run.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/kernel/dual_gemm.h` & `flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/kernel/dual_gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/test_run.h` & `flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/test_run.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/thread/left_silu_and_mul.h` & `flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/thread/left_silu_and_mul.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_epilogue.h` & `flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_epilogue.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_mma_base.h` & `flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_mma_base.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_mma_multistage.h` & `flash_attn-2.0.1/csrc/cutlass/examples/45_dual_gemm/threadblock/dual_mma_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/46_depthwise_simt_conv2dfprop/depthwise_simt_conv2dfprop.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/46_depthwise_simt_conv2dfprop/depthwise_simt_conv2dfprop.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/47_ampere_gemm_universal_streamk/ampere_gemm_universal_streamk.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/47_ampere_gemm_universal_streamk/ampere_gemm_universal_streamk.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/48_hopper_warp_specialized_gemm/48_hopper_warp_specialized_gemm.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/48_hopper_warp_specialized_gemm/48_hopper_warp_specialized_gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/49_hopper_gemm_schedules_with_collective_builder/49_hopper_gemm_schedules_with_collective_builder.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/49_hopper_gemm_schedules_with_collective_builder/49_hopper_gemm_schedules_with_collective_builder.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/50_hopper_gemm_with_epilogue_swizzle/50_hopper_gemm_with_epilogue_swizzle.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/50_hopper_gemm_with_epilogue_swizzle/50_hopper_gemm_with_epilogue_swizzle.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/60_cutlass_import/main.cpp` & `flash_attn-2.0.1/csrc/cutlass/examples/60_cutlass_import/main.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/common/helper.h` & `flash_attn-2.0.1/csrc/cutlass/examples/common/helper.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/examples/cute/tutorial/sgemm_nt_1.cu` & `flash_attn-2.0.1/csrc/cutlass/examples/cute/tutorial/sgemm_nt_1.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/algorithm/axpby.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/algorithm/axpby.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/algorithm/clear.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/algorithm/clear.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/algorithm/copy.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/algorithm/copy.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/algorithm/fill.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/algorithm/fill.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/algorithm/functional.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/algorithm/functional.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/algorithm/gemm.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/algorithm/gemm.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/algorithm/prefer.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/algorithm/prefer.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/algorithm/tensor_algorithms.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/algorithm/tensor_algorithms.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/algorithm/tuple_algorithms.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/algorithm/tuple_algorithms.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/cluster_sm90.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/arch/cluster_sm90.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/copy.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/arch/copy.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/copy_sm75.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/arch/copy_sm75.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/copy_sm80.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/arch/copy_sm80.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/copy_sm90.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/arch/copy_sm90.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/copy_sm90_desc.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/arch/copy_sm90_desc.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/copy_sm90_tma.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/arch/copy_sm90_tma.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/mma.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/arch/mma.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/mma_sm61.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/arch/mma_sm61.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/mma_sm70.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/arch/mma_sm70.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/mma_sm75.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/arch/mma_sm75.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/mma_sm80.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/arch/mma_sm80.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/mma_sm90.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/arch/mma_sm90.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/mma_sm90_desc.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/arch/mma_sm90_desc.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/mma_sm90_gmma.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/arch/mma_sm90_gmma.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/arch/util.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/arch/util.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/copy_atom.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/atom/copy_atom.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/copy_traits.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/atom/copy_traits.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/copy_traits_sm75.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/atom/copy_traits_sm75.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/copy_traits_sm80.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/atom/copy_traits_sm80.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/copy_traits_sm90.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/atom/copy_traits_sm90.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/copy_traits_sm90_tma.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/atom/copy_traits_sm90_tma.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/mma_atom.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/atom/mma_atom.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/mma_traits.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/atom/mma_traits.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/mma_traits_sm61.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/atom/mma_traits_sm61.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/mma_traits_sm70.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/atom/mma_traits_sm70.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/mma_traits_sm75.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/atom/mma_traits_sm75.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/mma_traits_sm80.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/atom/mma_traits_sm80.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/mma_traits_sm90.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/atom/mma_traits_sm90.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/atom/mma_traits_sm90_gmma.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/atom/mma_traits_sm90_gmma.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/config.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/config.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/container/alignment.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/container/alignment.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/container/array.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/container/array.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/container/array_aligned.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/container/array_aligned.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/container/array_subbyte.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/container/array_subbyte.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/container/array_view.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/container/array_view.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/container/bit_field.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/container/bit_field.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/container/tuple.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/container/tuple.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/container/type_list.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/container/type_list.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/int_tuple.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/int_tuple.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/layout.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/layout.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/arithmetic_tuple.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/arithmetic_tuple.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/bfloat.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/bfloat.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/complex.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/complex.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/float8.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/float8.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/half.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/half.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/int.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/int.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/integer_sequence.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/integer_sequence.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/integer_subbyte.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/integer_subbyte.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/integral_constant.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/integral_constant.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/math.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/math.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/real.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/real.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/tfloat.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/tfloat.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/numeric/uint128.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/numeric/uint128.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/pointer.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/pointer.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/stride.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/stride.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/swizzle.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/swizzle.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/swizzle_layout.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/swizzle_layout.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/swizzle_ptr.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/swizzle_ptr.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/tensor.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/tensor.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/tensor_predicate.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/tensor_predicate.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/tile.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/tile.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/underscore.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/underscore.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/util/debug.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/util/debug.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/util/print.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/util/print.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cute/util/type_traits.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cute/util/type_traits.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/aligned_buffer.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/aligned_buffer.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/arch.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/arch.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/barrier.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/barrier.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/cache_operation.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/cache_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/memory.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/memory.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/memory_sm75.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/memory_sm75.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/memory_sm80.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/memory_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/mma.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/mma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/mma_sm50.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/mma_sm50.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/mma_sm60.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/mma_sm60.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/mma_sm61.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/mma_sm61.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/mma_sm70.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/mma_sm70.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/mma_sm75.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/mma_sm75.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/mma_sm80.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/mma_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/mma_sm90.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/mma_sm90.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/mma_sparse_sm80.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/mma_sparse_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/reg_reconfig.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/reg_reconfig.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/simd.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/simd.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/simd_sm60.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/simd_sm60.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/simd_sm61.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/simd_sm61.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/wmma.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/wmma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/wmma_sm70.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/wmma_sm70.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/wmma_sm72.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/wmma_sm72.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/arch/wmma_sm75.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/arch/wmma_sm75.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/array.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/array.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/array_planar_complex.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/array_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/array_subbyte.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/array_subbyte.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/barrier.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/barrier.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/bfloat16.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/bfloat16.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/blas3.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/blas3.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/block_striped.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/block_striped.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/cluster_launch.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/cluster_launch.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/complex.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/constants.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/constants.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/conv2d_problem_size.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/conv2d_problem_size.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/conv3d_problem_size.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/conv3d_problem_size.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/convolution.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/convolution.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/device/direct_convolution.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/device/direct_convolution.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/device/implicit_gemm_convolution.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/device/implicit_gemm_convolution.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/device/implicit_gemm_convolution_fusion.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/device/implicit_gemm_convolution_fusion.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_dgrad.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_dgrad.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_fusion.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_fusion.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_broadcast.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_broadcast.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_reduction.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_reduction.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_group_fprop.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_group_fprop.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad_fusion.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad_fusion.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_dgrad.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_dgrad.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop_fusion.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop_fusion.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_wgrad.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_conv3d_wgrad.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/default_depthwise_fprop.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/default_depthwise_fprop.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/direct_convolution.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/direct_convolution.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_fusion.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_fusion.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_strided_dgrad.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_strided_dgrad.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_with_fused_epilogue.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_with_fused_epilogue.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/thread/depthwise_mma.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/thread/depthwise_mma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_analytic.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_optimized.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_analytic.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_optimized.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_analytic.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_few_channels.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_few_channels.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_fixed_channels.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_fixed_channels.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_optimized.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_analytic.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_few_channels.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_few_channels.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_fixed_channels.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_fixed_channels.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_optimized.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_params.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_params.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_tile_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_tile_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_analytic.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_optimized.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_analytic.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_optimized.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_analytic.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_optimized.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_analytic.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_optimized.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_analytic.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_optimized.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_analytic.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_optimized.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_params.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_params.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_analytic.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_optimized.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_analytic.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_analytic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_optimized.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_direct_conv_params.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_direct_conv_params.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_fixed_stride_dilation.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_fixed_stride_dilation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_optimized.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_direct_conv_multistage.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_direct_conv_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_filter_tile_access_iterator_direct_conv_optimized.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_filter_tile_access_iterator_direct_conv_optimized.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_pipelined.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_mma_base.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_mma_base.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_mma_core_with_lane_access_size.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/depthwise_mma_core_with_lane_access_size.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_fprop_fusion_multistage.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_fprop_fusion_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_multistage.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_pipelined.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_wgrad_fusion_multistage.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/implicit_gemm_wgrad_fusion_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_access_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_access_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/threadblock/threadblock_swizzle.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/threadblock/threadblock_swizzle.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/warp/mma_depthwise_simt.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/warp/mma_depthwise_simt.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/warp/mma_depthwise_simt_tile_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/warp/mma_depthwise_simt_tile_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/conv/warp/scale_bias_relu_transform.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/conv/warp/scale_bias_relu_transform.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/coord.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/coord.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/core_io.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/core_io.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/cutlass.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/cutlass.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/device_kernel.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/device_kernel.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/collective/collective_epilogue.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/collective/collective_epilogue.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/collective/default_epilogue.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/collective/default_epilogue.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/collective/default_transposed_epilogue.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/collective/default_transposed_epilogue.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/collective/epilogue.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/collective/epilogue.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/dispatch_policy.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/dispatch_policy.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/activation.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/activation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/conversion_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/conversion_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_elementwise.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_elementwise.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_relu.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_relu.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_clamp.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_clamp.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_dgelu.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_dgelu.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_drelu.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_drelu.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_gelu.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_gelu.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_generic.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_generic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_hardswish.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_hardswish.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_leaky_relu.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_leaky_relu.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_params.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_params.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_planar_complex.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_relu.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_relu.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_relu0.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_relu0.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_residual_block.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_residual_block.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_sigmoid.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_sigmoid.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_silu.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_silu.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_with_elementwise.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/linear_combination_with_elementwise.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/reduction_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/reduction_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/thread/scale_type.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/thread/scale_type.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op_blas3.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op_blas3.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_direct_store.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_direct_store.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_planar_complex.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_simt.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_simt.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op_blas3.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op_blas3.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_volta_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_volta_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_broadcast.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_broadcast.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_reduction.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_reduction.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_wmma_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_wmma_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_simt.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_simt.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_volta_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_volta_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_wmma_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_wmma_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/direct_store_epilogue_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/direct_store_epilogue_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_base.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_base.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_base_streamk.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_base_streamk.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_depthwise.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_depthwise.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_direct_store.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_direct_store.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_gemm_k_reduction.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_gemm_k_reduction.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_planar_complex.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_smem_accumulator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_smem_accumulator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_visitor_with_softmax.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_visitor_with_softmax.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_broadcast.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_broadcast.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_reduction.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_reduction.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_visitor.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_visitor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_workspace.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/epilogue_workspace.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/interleaved_epilogue.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/interleaved_epilogue.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/output_iterator_parameter.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/output_iterator_parameter.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/output_tile_thread_map.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/output_tile_thread_map.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine_layout_params.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine_layout_params.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_blas3.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_blas3.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_direct_conv.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_direct_conv.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_params.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_params.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_predicates.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_predicates.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_strided_dgrad.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_strided_dgrad.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_mixed.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_mixed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_pitch_liner.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_pitch_liner.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_complex_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_complex_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_gaussian_complex_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_gaussian_complex_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_simt.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_simt.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_volta_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_volta_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_wmma_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/fragment_iterator_wmma_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/simt_policy.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/simt_policy.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/tensor_op_policy.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/tensor_op_policy.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_simt.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_simt.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op_mixed.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op_mixed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_volta_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_volta_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_wmma_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/tile_iterator_wmma_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/volta_tensor_op_policy.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/volta_tensor_op_policy.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/epilogue/warp/wmma_tensor_op_policy.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/epilogue/warp/wmma_tensor_op_policy.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/fast_math.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/fast_math.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/float8.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/float8.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/floating_point_nvrtc.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/floating_point_nvrtc.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/functional.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/functional.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/collective/collective_builder.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/collective/collective_builder.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/collective/collective_mma.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/collective/collective_mma.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/collective/sm70_mma_twostage.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/collective/sm70_mma_twostage.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/collective/sm80_mma_multistage.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/collective/sm80_mma_multistage.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_multistage_gmma_ss.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_multistage_gmma_ss.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_ss.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_ss.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_ss_warpspecialized.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/collective/sm90_mma_tma_gmma_ss_warpspecialized.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/base_grouped.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/base_grouped.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/default_gemm_configuration.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/default_gemm_configuration.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/ell_gemm.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/ell_gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_array.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_array.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_batched.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_batched.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_complex.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_grouped.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_grouped.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_layernorm_mainloop_fusion.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_layernorm_mainloop_fusion.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_sparse.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_sparse.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_splitk_parallel.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_splitk_parallel.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_adapter.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_adapter.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_base.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_base.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_with_broadcast.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_universal_with_broadcast.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemm_with_k_reduction.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemm_with_k_reduction.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/gemv.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/gemv.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/rank_2k.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/rank_2k.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/rank_2k_grouped.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/rank_2k_grouped.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/rank_k.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/rank_k.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/symm.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/symm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/device/trmm.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/device/trmm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/dispatch_policy.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/dispatch_policy.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/gemm.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_ell_gemm.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_ell_gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_complex.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped_softmax_mainloop_fusion.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped_softmax_mainloop_fusion.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_layernorm_mainloop_fusion.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_layernorm_mainloop_fusion.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_planar_complex_universal.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_planar_complex_universal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_sparse.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_sparse.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_splitk_parallel.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_splitk_parallel.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_universal.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_universal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_broadcast.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_broadcast.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_k_reduction.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_k_reduction.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_reduction.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemm_with_reduction.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemv.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_gemv.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_complex.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_grouped.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_grouped.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_universal.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_2k_universal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k_complex.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k_universal.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_rank_k_universal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_symm.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_symm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_symm_complex.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_symm_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_symm_universal.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_symm_universal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm_complex.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm_universal.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/default_trmm_universal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/ell_gemm.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/ell_gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_array.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_array.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_batched.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_batched.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped_problem_visitor.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped_problem_visitor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped_softmax_mainloop_fusion.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_grouped_softmax_mainloop_fusion.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_layernorm_mainloop_fusion.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_layernorm_mainloop_fusion.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_params.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_params.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_pipelined.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex_array.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex_array.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_splitk_parallel.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_splitk_parallel.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_transpose_operands.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_transpose_operands.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal_streamk.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_universal_streamk.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_with_fused_epilogue.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_with_fused_epilogue.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_with_k_reduction.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemm_with_k_reduction.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemv.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemv.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/gemv_batched_strided.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/gemv_batched_strided.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/grouped_problem_visitor.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/grouped_problem_visitor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/params_universal_base.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/params_universal_base.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped_problem_visitor.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped_problem_visitor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_transpose_operands.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_transpose_operands.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_universal.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/rank_2k_universal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/rank_k_universal.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/rank_k_universal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm70_gemm.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/sm70_gemm.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma_warpspecialized.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma_warpspecialized.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma_warpspecialized_persistent.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_gemm_tma_warpspecialized_persistent.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_tile_scheduler.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/sm90_tile_scheduler.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/sparse_gemm.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/sparse_gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/symm_universal.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/symm_universal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/kernel/trmm_universal.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/kernel/trmm_universal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/thread/mma.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/thread/mma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/thread/mma_sm50.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/thread/mma_sm50.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/thread/mma_sm60.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/thread/mma_sm60.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/thread/mma_sm61.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/thread/mma_sm61.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_ell_mma.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_ell_mma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_gemv_core.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_gemv_core.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_simt.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_simt.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm70.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm70.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm75.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm75.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm80.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sparse_sm80.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sparse_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_access_size.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_access_size.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_reduction.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_reduction.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_wmma.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_core_wmma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_layernorm_mainloop_fusion.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_layernorm_mainloop_fusion.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_multistage.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_pipelined.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_softmax_mainloop_fusion.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_softmax_mainloop_fusion.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_with_reduction.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_mma_with_reduction.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core_sm80.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_trmm_complex.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_multistage_trmm_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_sparse_mma.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_sparse_mma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/default_trmm.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/default_trmm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/ell_mma_multistage.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/ell_mma_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/ell_mma_pipelined.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/ell_mma_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/gemv.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/gemv.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/index_remat.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/index_remat.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_base.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_base.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_blas3_multistage.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_blas3_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_layernorm_mainloop_fusion_multistage.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_layernorm_mainloop_fusion_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_multistage.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_pipelined.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_base.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_base.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_multistage.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_pipelined.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_pipelined.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_singlestage.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_singlestage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_softmax_mainloop_fusion_multistage.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_softmax_mainloop_fusion_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_sparse_base.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_sparse_base.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_sparse_multistage.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_sparse_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_with_reduction_multistage.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/mma_with_reduction_multistage.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle_streamk.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle_streamk.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_complex_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_complex_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_sparse_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_sparse_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op_sm80.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_with_reduction_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_with_reduction_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_wmma_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/default_mma_wmma_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/layernorm_scale_bias_transform.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/layernorm_scale_bias_transform.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_fast_f32.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_fast_f32.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_tile_iterator_sm80.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_tile_iterator_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op_tile_iterator_sm80.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op_tile_iterator_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_planar_complex.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_simt.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_simt.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_simt_policy.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_simt_policy.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_simt_tile_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_simt_tile_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_sparse_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_sparse_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fast_f32.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fast_f32.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fragment_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fragment_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_policy.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_policy.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_sm70.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_sm70.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_access_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_access_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm70.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm70.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm80.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sparse.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sparse.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_wmma.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_wmma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_wmma.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_tensor_op_wmma.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/mma_with_reduction_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/mma_with_reduction_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/scale_bias_tile_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/scale_bias_tile_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/softmax_scale_bias_transform.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/softmax_scale_bias_transform.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/gemm/warp/tile_iterator_planar_complex.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/gemm/warp/tile_iterator_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/half.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/half.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/integer_subbyte.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/integer_subbyte.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/kernel_hardware_info.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/kernel_hardware_info.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/kernel_launch.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/kernel_launch.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/layout/layout.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/layout/layout.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/layout/matrix.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/layout/matrix.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/layout/permute.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/layout/permute.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/layout/pitch_linear.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/layout/pitch_linear.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/layout/tensor.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/layout/tensor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm70.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm70.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm75.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm75.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm80.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/layout/vector.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/layout/vector.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/matrix.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/matrix.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/matrix_coord.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/matrix_coord.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/matrix_shape.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/matrix_shape.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/numeric_conversion.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/numeric_conversion.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/numeric_types.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/numeric_types.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/pipeline.hpp` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/pipeline.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/pitch_linear_coord.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/pitch_linear_coord.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/platform/platform.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/platform/platform.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/predicate_vector.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/predicate_vector.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/quaternion.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/quaternion.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/real.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/real.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/device/reduce_split_k.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/device/reduce_split_k.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_contiguous.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_contiguous.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_strided.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_strided.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/kernel/reduce_softmax_final.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/kernel/reduce_softmax_final.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/kernel/reduce_split_k.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/kernel/reduce_split_k.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_contiguous.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_contiguous.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_strided.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_strided.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/thread/reduce.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/thread/reduce.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/thread/reduction_operators.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/thread/reduction_operators.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/reduction/threadblock_swizzle.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/reduction/threadblock_swizzle.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/relatively_equal.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/relatively_equal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/semaphore.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/semaphore.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/subbyte_reference.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/subbyte_reference.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/tensor_coord.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/tensor_coord.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/tensor_ref.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/tensor_ref.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/tensor_ref_planar_complex.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/tensor_ref_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/tensor_view.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/tensor_view.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/tensor_view_planar_complex.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/tensor_view_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/tfloat32.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/tfloat32.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/thread/matrix.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/thread/matrix.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/trace.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/trace.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/pitch_linear_thread_map.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/pitch_linear_thread_map.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/thread/transpose.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/thread/transpose.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/thread/unary_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/thread/unary_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/ell_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/ell_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_access_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_access_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_access_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_access_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_2dthreadtile.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_2dthreadtile.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_params.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_params.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_triangular_matrix.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_triangular_matrix.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_2dthreadtile.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_2dthreadtile.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_triangular_matrix.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_triangular_matrix.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_vector_access_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/predicated_vector_access_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_scale_bias_vector_access_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_scale_bias_vector_access_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear_direct_conv.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear_direct_conv.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op_sm80.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op_sm80.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear_2dthreadtile.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear_2dthreadtile.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op_sm70.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op_sm70.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/threadblock/vector_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/threadblock/vector_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/transform/warp/vector_fragment_iterator.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/transform/warp/vector_fragment_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/uint128.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/uint128.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/include/cutlass/wmma_array.h` & `flash_attn-2.0.1/csrc/cutlass/include/cutlass/wmma_array.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/common/cutlass_unit_test.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/common/cutlass_unit_test.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/common/filter_architecture.cpp` & `flash_attn-2.0.1/csrc/cutlass/test/unit/common/filter_architecture.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/cache_testbed_output.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/cache_testbed_output.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_few_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_few_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_fixed_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_fixed_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_qf32nhwc_qf32nhwc_qf32nhwc_simt_f32_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_qf32nhwc_qf32nhwc_qf32nhwc_simt_f32_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_reduction_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_fprop_with_reduction_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_problems.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_problems.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_testbed.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_testbed_interleaved.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_testbed_interleaved.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_with_broadcast_testbed.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_with_broadcast_testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv2d_with_reduction_testbed.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv2d_with_reduction_testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv3d_problems.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv3d_problems.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv3d_testbed.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv3d_testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_direct_conv_testbed.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_direct_conv_testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_fixed_stride_dilation_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_fixed_stride_dilation_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/conv/device/group_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/conv/device/group_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/array.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/core/array.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/bfloat16.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/core/bfloat16.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/complex.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/core/complex.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/float8.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/core/float8.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/functional.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/core/functional.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/half.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/core/half.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/matrix.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/core/matrix.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/matrix_coord.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/core/matrix_coord.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/numeric_conversion.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/core/numeric_conversion.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/predicate_vector.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/core/predicate_vector.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/quaternion.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/core/quaternion.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/tensor_ref.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/core/tensor_ref.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/tensor_view.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/core/tensor_view.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/test_unit_core.cpp` & `flash_attn-2.0.1/csrc/cutlass/test/unit/core/test_unit_core.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/core/tfloat32.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/core/tfloat32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/ampere/cp_async.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/cute/ampere/cp_async.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/ampere/ldsm.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/cute/ampere/ldsm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/bitfield.cpp` & `flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/bitfield.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/coalesce.cpp` & `flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/coalesce.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/compare.cpp` & `flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/compare.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/complement.cpp` & `flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/complement.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/composition.cpp` & `flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/composition.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/inverse_left.cpp` & `flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/inverse_left.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/inverse_right.cpp` & `flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/inverse_right.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/logical_divide.cpp` & `flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/logical_divide.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/logical_product.cpp` & `flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/logical_product.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/mixedbits.cpp` & `flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/mixedbits.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/transform.cpp` & `flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/transform.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/core/tuple.cpp` & `flash_attn-2.0.1/csrc/cutlass/test/unit/cute/core/tuple.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/hopper/stsm.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/cute/hopper/stsm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/hopper/tma_load.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/cute/hopper/tma_load.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/hopper/tma_store.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/cute/hopper/tma_store.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/cute/layout/layout_operator.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/cute/layout/layout_operator.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/thread/activation.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/thread/activation.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/thread/linear_combination.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/thread/linear_combination.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/thread/linear_combination_planar_complex.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/thread/linear_combination_planar_complex.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_planar_complex.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_planar_complex.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm60.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm60.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm61.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm61.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_tensor_op.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_tensor_op.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_volta_tensor_op.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_volta_tensor_op.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_tensor_op.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_tensor_op.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_testbed.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_wmma_tensor_op_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/epilogue_wmma_tensor_op_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/output_tile_threadmap.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/output_tile_threadmap.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/predicated_tile_iterator.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/predicated_tile_iterator.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/testbed.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/threadblock/testbed_planar_complex.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/threadblock/testbed_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_tensor_op.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_tensor_op.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_volta_tensor_op.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_volta_tensor_op.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_wmma_tensor_op.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/epilogue/warp/fragment_iterator_wmma_tensor_op.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/default_gemm_configuration.hpp` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/default_gemm_configuration.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_wmma_tensor_op_s32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_wmma_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_wmma_tensor_op_s32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_wmma_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_bf16n_bf16n_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_bf16n_bf16n_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_bf16t_bf16t_bf16t_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_bf16t_bf16t_bf16t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf32n_cf32t_cf32t_tensor_op_tf32_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_cf32n_cf32t_cf32t_tensor_op_tf32_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf32t_cf32n_cf32t_tensor_op_tf32_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_cf32t_cf32n_cf32t_tensor_op_tf32_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm90.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm90.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm90.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm90.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_direct_store_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_direct_store_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f16_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_volta_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_volta_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f16_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_volta_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_volta_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f16_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sparse_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_volta_tensor_op_f16_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_volta_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f16_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32n_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_volta_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_volta_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_singlestage_wmma_tensor_op_f16_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_singlestage_wmma_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f16_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_singlestage_wmma_tensor_op_f16_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_singlestage_wmma_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_broadcast_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_broadcast_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sparse_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_volta_tensor_op_f16_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_volta_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f16_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32n_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_singlestage_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_singlestage_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_volta_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_volta_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f16_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f16_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f16_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_volta_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_volta_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_wmma_tensor_op_f32_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_bf16_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_bf16_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32t_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f32n_f32t_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32t_f32n_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f32t_f32n_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f32t_f32t_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f32t_f32t_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm90.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm90.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_grouped_scheduler_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_grouped_scheduler_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_grouped_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_grouped_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_wmma_tensor_op_s32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_wmma_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sparse_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_wmma_tensor_op_s32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_wmma_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_wmma_tensor_op_s32_sm72.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_wmma_tensor_op_s32_sm72.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sparse_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_wmma_tensor_op_s32_sm72.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_wmma_tensor_op_s32_sm72.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_wmma_tensor_op_s32_sm72.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_wmma_tensor_op_s32_sm72.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_wmma_tensor_op_s32_sm72.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_wmma_tensor_op_s32_sm72.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_serial_tensor_op_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_serial_tensor_op_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_simt_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_simt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_testbed_3x.hpp` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_testbed_3x.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_tf32n_tf32n_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_tf32n_tf32n_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_tf32n_tf32t_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_tf32n_tf32t_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_tf32t_tf32n_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_tf32t_tf32n_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_tf32t_tf32t_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_tf32t_tf32t_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_u8t_u8n_s32t_wmma_tensor_op_s32_sm72.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_u8t_u8n_s32t_wmma_tensor_op_s32_sm72.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf32n_cf32n_cf32n_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf32n_cf32n_cf32n_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32n_tensor_op_f32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32n_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32t_tensor_op_f32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32t_tensor_op_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_with_broadcast_f16n_f16n_f16n_tensorop_f32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_with_broadcast_f16n_f16n_f16n_tensorop_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_with_reduction_f16n_f16n_f16n_tensorop_f32_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_with_reduction_f16n_f16n_f16n_tensorop_f32_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemm_with_reduction_f16t_f16n_f16n_tensorop_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemm_with_reduction_f16t_f16n_f16n_tensorop_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/gemv.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/gemv.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_ls_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_rs_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_ls_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_rs_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf64_cf64_cf64_tensor_op_f64_sm90.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/hemm_cf64_cf64_cf64_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_rs_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_rs_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf64_cf64_tensor_op_f64_sm90.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/her2k_cf64_cf64_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf64h_cf64n_tensor_op_f64_grouped_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/her2k_cf64h_cf64n_tensor_op_f64_grouped_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64t_tensor_op_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/her2k_cf64n_cf64t_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/herk_cf64_cf64_tensor_op_f64_sm90.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/herk_cf64_cf64_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/herk_cf64h_cf64n_tensor_op_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/herk_cf64h_cf64n_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/multistage_testbed.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/multistage_testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/multistage_testbed_interleaved.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/multistage_testbed_interleaved.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/rank_2k_grouped_scheduler_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/rank_2k_grouped_scheduler_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nn_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tt_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_cgemm_tt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_nn_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_nn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_nt_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_nt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_tn_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_tn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_tt_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_dgemm_tt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_f8gemm_tn_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_f8gemm_tn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_nn_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_nn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_nt_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_nt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_tn_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_tn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_tt_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_hgemm_tt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_igemm_nn_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_igemm_nn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_igemm_nt_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_igemm_nt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_igemm_tn_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_igemm_tn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_igemm_tt_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_igemm_tt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_perf.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_perf.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_sliced_k.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_sliced_k.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_nn_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_nn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_nt_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_nt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_tn_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_tn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_tt_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_qgemm_tt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nn_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tt_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_sgemm_tt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_nn_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_nn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_nt_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_nt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_tn_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_tn_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_tt_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/simt_zgemm_tt_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm50_gemm_f32_f32_f32_simt.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm50_gemm_f32_f32_f32_simt.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm50_gemm_f64_f64_f64_simt.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm50_gemm_f64_f64_f64_simt.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm61_gemm_s8_s8_s32_simt.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm61_gemm_s8_s8_s32_simt.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f16_f16_f32_tensor_op_f32.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f16_f16_f32_tensor_op_f32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f32_f32_f32_simt.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f32_f32_f32_simt.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f64_f64_f64_simt.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f64_f64_f64_simt.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f64_f64_f64_tensor_op_f64.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_f64_f64_f64_tensor_op_f64.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_s8_s8_s32_tensor_op.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_s8_s8_s32_tensor_op.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_tf32_tf32_f32_tensor_op_f32.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm80_gemm_tf32_tf32_f32_tensor_op_f32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_tensor_op_f32.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_tensor_op_f32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_unspecialized.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_unspecialized.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_persistent.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_persistent.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f32_f32_f32_tensor_op_f32.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_f32_f32_f32_tensor_op_f32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_tensor_op_s32.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_tensor_op_s32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_tensor_op_f32.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_tensor_op_f32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_ls_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_rs_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_ls_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_rs_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_cf64_cf64_cf64_tensor_op_f64_sm90.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_cf64_cf64_cf64_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_rs_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_rs_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_rs_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f64_f64_tensor_op_f64_sm90.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f64_f64_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_ls_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_rs_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_ls_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_rs_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_ls_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_rs_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_ls_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_rs_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_ls_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_rs_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/symm_tf32t_f32t_tensor_op_f32_ls_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/symm_tf32t_f32t_tensor_op_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64_cf64_tensor_op_f64_sm90.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64_cf64_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_grouped_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_grouped_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64n_tensor_op_f64_grouped_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64n_tensor_op_f64_grouped_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64t_tensor_op_f64_grouped_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64t_tensor_op_f64_grouped_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f32n_f32n_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_f32n_f32n_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f32t_f32n_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_f32t_f32n_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64_f64_tensor_op_f64_sm90.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_f64_f64_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_grouped_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_grouped_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_grouped_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_grouped_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_grouped_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_grouped_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64t_tensor_op_f64_grouped_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_f64t_f64t_tensor_op_f64_grouped_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_tf32n_f32n_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_tf32n_f32n_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syr2k_tf32t_f32n_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syr2k_tf32t_f32n_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf64_cf64_tensor_op_f64_sm90.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_cf64_cf64_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64n_tensor_op_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64n_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_f32n_f32t_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_f32n_f32t_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_f32t_f32t_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_f32t_f32t_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_f64_f64_tensor_op_f64_sm90.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_f64_f64_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_f64n_f64t_tensor_op_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_f64n_f64t_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_f64t_f64n_tensor_op_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_f64t_f64n_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_tf32n_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_tf32n_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/syrk_tf32t_f32t_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/syrk_tf32t_f32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_complex.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_gemm_with_broadcast.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_gemm_with_broadcast.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_gemm_with_reduction.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_gemm_with_reduction.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_grouped.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_grouped.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k_scheduler.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k_scheduler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_grouped_scheduler.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_grouped_scheduler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_interleaved.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_interleaved.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_planar_complex.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_rank2k_universal.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_rank2k_universal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_rank_k_universal.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_rank_k_universal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_sanity.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_sanity.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_sparse.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_sparse.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_splitk.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_splitk.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_symm_universal.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_symm_universal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_trmm_universal.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_trmm_universal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_universal.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_universal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/testbed_utils.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/testbed_utils.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_fast_f32_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_fast_f32_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_cf64_cf64_cf64_tensor_op_f64_sm90.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_cf64_cf64_cf64_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_rs_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32t_tensor_op_fast_f32_ls_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32t_tensor_op_fast_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64_f64_f64_tensor_op_f64_sm90.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_f64_f64_f64_tensor_op_f64_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_ls_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_rs_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64t_f64t_tensor_op_f64_rs_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_f64n_f64t_f64t_tensor_op_f64_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_ls_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_rs_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_ls_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_rs_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_rs_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32n_tensor_op_f32_ls_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32n_tensor_op_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32t_tensor_op_f32_ls_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32t_tensor_op_f32_ls_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/kernel/batched_gemv.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/kernel/batched_gemv.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/kernel/testbed_gemv.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/kernel/testbed_gemv.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/thread/gemm_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/thread/gemm_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/thread/gemm_sm60.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/thread/gemm_sm60.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/thread/gemm_sm61.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/thread/gemm_sm61.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/thread/host/gemm_sm60_host.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/thread/host/gemm_sm60_host.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/thread/host/testbed_host.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/thread/host/testbed_host.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/thread/testbed.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/thread/testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/batched_gemv.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/batched_gemv.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/epilogue_workspace.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/epilogue_workspace.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_slicedk.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_slicedk.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse_testbed.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse_testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed_slicedk.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed_slicedk.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_simt.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_simt.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_slicedk.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_slicedk.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed_slicedk.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed_slicedk.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_planar_complex_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_planar_complex_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_planar_complex_testbed.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_planar_complex_testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_complex_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_complex_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_complex_sm90.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_complex_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_gaussian_complex_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_gaussian_complex_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm50.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_sm50.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm60.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_sm60.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm61.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_sm61.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sm90.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_sm90.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/gemm_sparse_sm80.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/gemm_sparse_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/testbed.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/wmma_sm70.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/wmma_sm70.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/wmma_sm72.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/wmma_sm72.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/gemm/warp/wmma_sm75.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/gemm/warp/wmma_sm75.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/layout/matrix.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/layout/matrix.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/layout/tensor.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/layout/tensor.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/layout/tensor_nhwc.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/layout/tensor_nhwc.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/nvrtc/cutlass/nvrtc/environment.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/nvrtc/cutlass/nvrtc/environment.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/nvrtc/kernel/thread/testbed_kernel.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/nvrtc/kernel/thread/testbed_kernel.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/nvrtc/stdlib/stdint.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/nvrtc/stdlib/stdint.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/nvrtc/thread/gemm_nvrtc.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/nvrtc/thread/gemm_nvrtc.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/nvrtc/thread/testbed.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/nvrtc/thread/testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/pipeline/pipeline_async.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/pipeline/pipeline_async.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/pipeline/pipeline_tma_async.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/pipeline/pipeline_tma_async.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/pipeline/pipeline_tma_async_warp_specialized.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/pipeline/pipeline_tma_async_warp_specialized.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/pipeline/pipeline_tma_async_warp_specialized_persistent.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/pipeline/pipeline_tma_async_warp_specialized_persistent.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/pipeline/sequence_barrier.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/pipeline/sequence_barrier.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/pipeline/testbed.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/pipeline/testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/reduction/device/tensor_reduce_contiguous.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/reduction/device/tensor_reduce_contiguous.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/reduction/device/tensor_reduce_strided.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/reduction/device/tensor_reduce_strided.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/reduction/kernel/reduce_splitk.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/reduction/kernel/reduce_splitk.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/reduction/kernel/reduce_splitk_testbed.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/reduction/kernel/reduce_splitk_testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/reduction/thread/reduction_thread.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/reduction/thread/reduction_thread.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/reduction/thread/testbed.h` & `flash_attn-2.0.1/csrc/cutlass/test/unit/reduction/thread/testbed.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/test_unit.cpp` & `flash_attn-2.0.1/csrc/cutlass/test/unit/test_unit.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/transform/threadblock/predicated_tile_iterator.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/transform/threadblock/predicated_tile_iterator.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/transform/threadblock/regular_tile_iterator_tensor_op.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/transform/threadblock/regular_tile_iterator_tensor_op.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/util/cutlass_test_levels.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/util/cutlass_test_levels.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/test/unit/util/tensor_reduce.cu` & `flash_attn-2.0.1/csrc/cutlass/test/unit/util/tensor_reduce.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/include/cutlass/library/arch_mappings.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/include/cutlass/library/arch_mappings.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/include/cutlass/library/handle.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/include/cutlass/library/handle.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/include/cutlass/library/library.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/include/cutlass/library/library.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/include/cutlass/library/manifest.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/include/cutlass/library/manifest.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/include/cutlass/library/operation_table.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/include/cutlass/library/operation_table.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/include/cutlass/library/singleton.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/include/cutlass/library/singleton.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/include/cutlass/library/util.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/include/cutlass/library/util.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/compiler.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/compiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/cute.cpp` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/cute.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/cutlass.cpp` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/cutlass.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/arch.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/arch.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/conv_problem_size.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/conv_problem_size.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/convolution.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/convolution.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/host.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/host.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_generic.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_generic.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/binary_ops.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/binary_ops.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/unary_ops.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/unary_ops.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_accumulator.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_accumulator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_binary.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_binary.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_column_broadcast.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_column_broadcast.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_column_reduction.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_column_reduction.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_linear_combination.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_linear_combination.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_row_broadcast.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_row_broadcast.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_row_reduction.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_row_reduction.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_tensor_input.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_tensor_input.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_tensor_output.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_tensor_output.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_unary.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_unary.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_with_layernorm.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_with_layernorm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/gemm.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/gemm_universal_with_visitor.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/gemm_universal_with_visitor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/host.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/host.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/layout.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/layout.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/matrix.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/matrix.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/tensor.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/tensor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/swizzling.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/swizzling.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/tensor_coord.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/tensor_coord.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/tensor_ref_view.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/tensor_ref_view.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/types.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/include/types.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/library.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/library.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/conv_problems.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/conv_problems.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/convolution.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/convolution.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/host.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/host.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/gemm/gemm.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/gemm/gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/gemm/host.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/scripts/pycutlass/src/cpp/test/gemm/host.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/conv2d_operation.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/conv2d_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/conv3d_operation.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/conv3d_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/gemm_operation.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/gemm_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/gemm_operation_3x.hpp` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/gemm_operation_3x.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/handle.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/handle.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/library_internal.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/library_internal.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/manifest.cpp` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/manifest.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/operation_table.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/operation_table.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/rank_2k_operation.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/rank_2k_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/rank_k_operation.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/rank_k_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/reduction/init_reduction_operations.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/reduction/init_reduction_operations.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/reduction/reduction_device.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/reduction/reduction_device.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/reduction/reduction_operation.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/reduction/reduction_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/reference/conv2d.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/reference/conv2d.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/reference/conv3d.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/reference/conv3d.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/reference/conv_reference_operation.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/reference/conv_reference_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/reference/gemm.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/reference/gemm.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/reference/gemm_reference_operation.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/reference/gemm_reference_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/reference/initialize_reference_operations.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/reference/initialize_reference_operations.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/singleton.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/singleton.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/symm_operation.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/symm_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/trmm_operation.h` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/trmm_operation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/library/src/util.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/library/src/util.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/conv2d_operation_profiler.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/conv2d_operation_profiler.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/conv2d_operation_profiler.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/conv2d_operation_profiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/conv3d_operation_profiler.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/conv3d_operation_profiler.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/conv3d_operation_profiler.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/conv3d_operation_profiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/cublas_helpers.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/cublas_helpers.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/cublas_helpers.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/cublas_helpers.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/cudnn_helpers.cpp` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/cudnn_helpers.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/cudnn_helpers.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/cudnn_helpers.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/cutlass_profiler.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/cutlass_profiler.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/cutlass_profiler.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/cutlass_profiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/debug.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/debug.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/device_allocation.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/device_allocation.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/device_allocation.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/device_allocation.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/device_context.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/device_context.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/device_context.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/device_context.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/enumerated_types.cpp` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/enumerated_types.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/enumerated_types.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/enumerated_types.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/gemm_operation_profiler.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/gemm_operation_profiler.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/gemm_operation_profiler.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/gemm_operation_profiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/gpu_timer.cpp` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/gpu_timer.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/gpu_timer.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/gpu_timer.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/main.cpp` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/main.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/operation_profiler.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/operation_profiler.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/operation_profiler.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/operation_profiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/options.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/options.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/options.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/options.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/performance_report.cpp` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/performance_report.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/performance_report.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/performance_report.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/performance_result.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/performance_result.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/performance_result.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/performance_result.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/problem_space.cpp` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/problem_space.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/problem_space.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/problem_space.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/rank_2k_operation_profiler.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/rank_2k_operation_profiler.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/rank_2k_operation_profiler.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/rank_2k_operation_profiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/rank_k_operation_profiler.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/rank_k_operation_profiler.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/rank_k_operation_profiler.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/rank_k_operation_profiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/reduction_operation_profiler.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/reduction_operation_profiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/sparse_gemm_operation_profiler.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/sparse_gemm_operation_profiler.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/sparse_gemm_operation_profiler.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/sparse_gemm_operation_profiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/symm_operation_profiler.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/symm_operation_profiler.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/symm_operation_profiler.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/symm_operation_profiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/trmm_operation_profiler.cu` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/trmm_operation_profiler.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/profiler/src/trmm_operation_profiler.h` & `flash_attn-2.0.1/csrc/cutlass/tools/profiler/src/trmm_operation_profiler.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/GPU_Clock.hpp` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/GPU_Clock.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/command_line.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/command_line.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/cublas_wrappers.hpp` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/cublas_wrappers.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/debug.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/debug.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/device_dump.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/device_dump.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/device_groupnorm.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/device_groupnorm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/device_layernorm.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/device_layernorm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/device_memory.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/device_memory.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/device_nchw_to_nhwc.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/device_nchw_to_nhwc.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_padding.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_padding.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_pooling.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_pooling.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_to_nchw.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/device_nhwc_to_nchw.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/device_utils.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/device_utils.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/distribution.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/distribution.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/exceptions.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/exceptions.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/helper_cuda.hpp` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/helper_cuda.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/host_reorder.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/host_reorder.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/host_tensor.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/host_tensor.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/host_tensor_planar_complex.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/host_tensor_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/host_uncompress.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/host_uncompress.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/index_sequence.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/index_sequence.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/packed_stride.hpp` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/packed_stride.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/print_error.hpp` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/print_error.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/detail/inner_product.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/detail/inner_product.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/detail/linear_to_coordinate.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/detail/linear_to_coordinate.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/convolution.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/convolution.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm_complex.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm_planar_complex.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/gemm_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/gemm.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_elementwise.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_elementwise.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_foreach.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_foreach.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/rank_2k_complex.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/rank_2k_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_compare.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_compare.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_fill.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_fill.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_foreach.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_foreach.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_reduce.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_reduce.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_relu.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/tensor_relu.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/thread/gemm.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/device/thread/gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/convolution.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/convolution.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/error_metrics.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/error_metrics.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm_complex.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm_planar_complex.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gemm_planar_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gett.hpp` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/gett.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k_complex.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_k_complex.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/rank_k_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/symm.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/symm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/symm_complex.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/symm_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_compare.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_compare.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_compare.hpp` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_compare.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_copy.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_copy.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_elementwise.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_elementwise.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_fill.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_fill.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_fill.hpp` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_fill.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_foreach.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_foreach.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_norm.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_norm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.hpp` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.hpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/trmm.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/trmm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/trmm_complex.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/reference/host/trmm_complex.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/tensor_view_io.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/tensor_view_io.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/cutlass/tools/util/include/cutlass/util/type_traits.h` & `flash_attn-2.0.1/csrc/cutlass/tools/util/include/cutlass/util/type_traits.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/flash_api.cpp` & `flash_attn-2.0.1/csrc/flash_attn/flash_api.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/block_info.h` & `flash_attn-2.0.1/csrc/flash_attn/src/block_info.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash.h` & `flash_attn-2.0.1/csrc/flash_attn/src/flash.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim128_bf16_sm80.cu` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim128_bf16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim128_fp16_sm80.cu` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim128_fp16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim32_bf16_sm80.cu` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim32_bf16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim32_fp16_sm80.cu` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim32_fp16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim64_bf16_sm80.cu` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim64_bf16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim64_fp16_sm80.cu` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim64_fp16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim96_bf16_sm80.cu` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim96_bf16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_hdim96_fp16_sm80.cu` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_hdim96_fp16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_kernel.h` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_kernel.h`

 * *Files 0% similar despite different names*

```diff
@@ -137,15 +137,15 @@
     const index_t row_offset_dpsum = (bidb * params.h + bidh) * params.seqlen_q_rounded + m_block * kBlockM;
 
     Tensor gdO = make_tensor(make_gmem_ptr(reinterpret_cast<Element *>(params.do_ptr) + row_offset_do),
                              Shape<Int<kBlockM>, Int<kHeadDim>>{},
                              make_stride(params.do_row_stride, _1{}));
     Tensor gO = make_tensor(make_gmem_ptr(reinterpret_cast<Element *>(params.o_ptr) + row_offset_o),
                             Shape<Int<kBlockM>, Int<kHeadDim>>{},
-                            make_stride(params.do_row_stride, _1{}));
+                            make_stride(params.o_row_stride, _1{}));
     Tensor gdQaccum = make_tensor(make_gmem_ptr(reinterpret_cast<ElementAccum *>(params.dq_accum_ptr) + row_offset_dq_accum),
                                   Shape<Int<kBlockM>, Int<kHeadDim>>{}, Stride<Int<kHeadDim>, _1>{});
     Tensor dP_sum = make_tensor(make_gmem_ptr(reinterpret_cast<ElementAccum *>(params.dsoftmax_sum) + row_offset_dpsum),
                                 Shape<Int<kBlockM>>{}, Stride<_1>{});
 
     auto gmem_thr_copy_dO = typename Kernel_traits::GmemTiledCopydO{}.get_thread_slice(tidx);
     // TODO: careful, we're zeroing out dQaccum with type float4, but when
@@ -470,15 +470,15 @@
                             Shape<Int<kBlockN>, Int<kHeadDim>>{},
                             make_stride(params.v_row_stride, _1{}));
     Tensor gdO = make_tensor(make_gmem_ptr(reinterpret_cast<Element *>(params.do_ptr) + row_offset_do),
                              Shape<Int<kBlockM>, Int<kHeadDim>>{},
                              make_stride(params.do_row_stride, _1{}));
     Tensor gO = make_tensor(make_gmem_ptr(reinterpret_cast<Element *>(params.o_ptr) + row_offset_o),
                             Shape<Int<kBlockM>, Int<kHeadDim>>{},
-                            make_stride(params.do_row_stride, _1{}));
+                            make_stride(params.o_row_stride, _1{}));
     Tensor gdQ = make_tensor(make_gmem_ptr(reinterpret_cast<Element *>(params.dq_ptr) + row_offset_dq),
                              Shape<Int<kBlockM>, Int<kHeadDim>>{},
                              make_stride(params.dq_row_stride, _1{}));
     Tensor gdQaccum = make_tensor(make_gmem_ptr(reinterpret_cast<ElementAccum *>(params.dq_accum_ptr) + row_offset_dq_accum),
                                   Shape<Int<kBlockM>, Int<kHeadDim>>{},
                                   Stride<Int<kHeadDim>, _1>{});
     Tensor gLSE = make_tensor(make_gmem_ptr(reinterpret_cast<ElementAccum *>(params.softmax_lse_ptr) + row_offset_lse),
@@ -1094,15 +1094,15 @@
     const index_t row_offset_k = binfo.k_offset(params.k_batch_stride, params.k_row_stride, bidb)
         + (n_block_max - 1) * kBlockN * params.k_row_stride + (bidh / params.h_h_k_ratio) * params.k_head_stride;
     const index_t row_offset_v = binfo.k_offset(params.v_batch_stride, params.v_row_stride, bidb)
         + (n_block_max - 1) * kBlockN * params.v_row_stride + (bidh / params.h_h_k_ratio) * params.v_head_stride;
     const index_t row_offset_do = binfo.q_offset(params.do_batch_stride, params.do_row_stride, bidb)
         + m_block * kBlockM * params.do_row_stride + bidh * params.do_head_stride;
     const index_t row_offset_o = binfo.q_offset(params.o_batch_stride, params.o_row_stride, bidb)
-        + m_block * kBlockM * params.do_row_stride + bidh * params.o_head_stride;
+        + m_block * kBlockM * params.o_row_stride + bidh * params.o_head_stride;
     // We'll advance gdKaccum and gdVaccum before the first write.
     const index_t row_offset_dkv_accum = ((bidb * params.h_k + (bidh / params.h_h_k_ratio)) * params.seqlen_k_rounded
                                           + n_block_max * kBlockN) * params.d_rounded;
     const index_t row_offset_lse = (bidb * params.h + bidh) * params.seqlen_q + m_block * kBlockM;
 
     // We assume that params.d == kHeadDim for now
     Tensor gQ = make_tensor(make_gmem_ptr(reinterpret_cast<Element *>(params.q_ptr) + row_offset_q),
@@ -1115,15 +1115,15 @@
                             Shape<Int<kBlockN>, Int<kHeadDim>>{},
                             make_stride(params.v_row_stride, _1{}));
     Tensor gdO = make_tensor(make_gmem_ptr(reinterpret_cast<Element *>(params.do_ptr) + row_offset_do),
                              Shape<Int<kBlockM>, Int<kHeadDim>>{},
                              make_stride(params.do_row_stride, _1{}));
     Tensor gO = make_tensor(make_gmem_ptr(reinterpret_cast<Element *>(params.o_ptr) + row_offset_o),
                             Shape<Int<kBlockM>, Int<kHeadDim>>{},
-                            make_stride(params.do_row_stride, _1{}));
+                            make_stride(params.o_row_stride, _1{}));
     Tensor gdKaccum = make_tensor(make_gmem_ptr(reinterpret_cast<ElementAccum *>(params.dk_accum_ptr) + row_offset_dkv_accum),
                                   Shape<Int<kBlockN>, Int<kHeadDim>>{},
                                   Stride<Int<kHeadDim>, _1>{});
     Tensor gdVaccum = make_tensor(make_gmem_ptr(reinterpret_cast<ElementAccum *>(params.dv_accum_ptr) + row_offset_dkv_accum),
                                   Shape<Int<kBlockN>, Int<kHeadDim>>{},
                                   Stride<Int<kHeadDim>, _1>{});
     Tensor gLSE = make_tensor(make_gmem_ptr(reinterpret_cast<ElementAccum *>(params.softmax_lse_ptr) + row_offset_lse),
```

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_bwd_launch_template.h` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_bwd_launch_template.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim128_bf16_sm80.cu` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim128_bf16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim128_fp16_sm80.cu` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim128_fp16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim160_bf16_sm80.cu` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim160_bf16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim160_fp16_sm80.cu` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim160_fp16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim192_bf16_sm80.cu` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim192_bf16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim192_fp16_sm80.cu` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim192_fp16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim32_fp16_sm80.cu` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim32_fp16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim64_bf16_sm80.cu` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim64_bf16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim64_fp16_sm80.cu` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim64_fp16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim96_bf16_sm80.cu` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim96_bf16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_hdim96_fp16_sm80.cu` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_hdim96_fp16_sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_kernel.h` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_kernel.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/flash_fwd_launch_template.h` & `flash_attn-2.0.1/csrc/flash_attn/src/flash_fwd_launch_template.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/kernel_traits.h` & `flash_attn-2.0.1/csrc/flash_attn/src/kernel_traits.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/kernel_traits_sm90.h` & `flash_attn-2.0.1/csrc/flash_attn/src/kernel_traits_sm90.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/philox.cuh` & `flash_attn-2.0.1/csrc/flash_attn/src/philox.cuh`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/softmax.h` & `flash_attn-2.0.1/csrc/flash_attn/src/softmax.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/static_switch.h` & `flash_attn-2.0.1/csrc/flash_attn/src/static_switch.h`

 * *Files 12% similar despite different names*

```diff
@@ -1,65 +1,66 @@
-// Inspired by https://github.com/NVIDIA/DALI/blob/main/include/dali/core/static_switch.h
+// Inspired by
+// https://github.com/NVIDIA/DALI/blob/main/include/dali/core/static_switch.h
 // and https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/Dispatch.h
 
 #pragma once
 
 /// @param COND       - a boolean expression to switch by
 /// @param CONST_NAME - a name given for the constexpr bool variable.
 /// @param ...       - code to execute for true and false
 ///
 /// Usage:
 /// ```
 /// BOOL_SWITCH(flag, BoolConst, [&] {
 ///     some_function<BoolConst>(...);
 /// });
 /// ```
-#define BOOL_SWITCH(COND, CONST_NAME, ...)                                           \
-    [&] {                                                                            \
-        if (COND) {                                                                  \
-            constexpr bool CONST_NAME = true;                                        \
-            return __VA_ARGS__();                                                    \
-        } else {                                                                     \
-            constexpr bool CONST_NAME = false;                                       \
-            return __VA_ARGS__();                                                    \
-        }                                                                            \
-    }()
+#define BOOL_SWITCH(COND, CONST_NAME, ...)      \
+  [&] {                                         \
+    if (COND) {                                 \
+      constexpr static bool CONST_NAME = true;  \
+      return __VA_ARGS__();                     \
+    } else {                                    \
+      constexpr static bool CONST_NAME = false; \
+      return __VA_ARGS__();                     \
+    }                                           \
+  }()
 
-#define FP16_SWITCH(COND, ...)                     \
-    [&] {                                          \
-        if (COND) {                                \
-            using elem_type = cutlass::half_t;     \
-            return __VA_ARGS__();                  \
-        } else {                                   \
-            using elem_type = cutlass::bfloat16_t; \
-            return __VA_ARGS__();                  \
-        }                                          \
-    }()
+#define FP16_SWITCH(COND, ...)               \
+  [&] {                                      \
+    if (COND) {                              \
+      using elem_type = cutlass::half_t;     \
+      return __VA_ARGS__();                  \
+    } else {                                 \
+      using elem_type = cutlass::bfloat16_t; \
+      return __VA_ARGS__();                  \
+    }                                        \
+  }()
 
-#define FWD_HEADDIM_SWITCH(HEADDIM, ...)  \
-    [&] {                                 \
-        if (HEADDIM <= 32) {              \
-            constexpr int kHeadDim = 32;  \
-            return __VA_ARGS__();         \
-        } else if (HEADDIM <= 64) {       \
-            constexpr int kHeadDim = 64;  \
-            return __VA_ARGS__();         \
-        } else if (HEADDIM <= 96) {       \
-            constexpr int kHeadDim = 96;  \
-            return __VA_ARGS__();         \
-        } else if (HEADDIM <= 128) {      \
-            constexpr int kHeadDim = 128; \
-            return __VA_ARGS__();         \
-        } else if (HEADDIM <= 160) {      \
-            constexpr int kHeadDim = 160; \
-            return __VA_ARGS__();         \
-        } else if (HEADDIM <= 192) {      \
-            constexpr int kHeadDim = 192; \
-            return __VA_ARGS__();         \
-        } else if (HEADDIM <= 224) {      \
-            constexpr int kHeadDim = 224; \
-            return __VA_ARGS__();         \
-        } else if (HEADDIM <= 256) {      \
-            constexpr int kHeadDim = 256; \
-            return __VA_ARGS__();         \
-        }                                 \
-    }()
+#define FWD_HEADDIM_SWITCH(HEADDIM, ...)   \
+  [&] {                                    \
+    if (HEADDIM <= 32) {                   \
+      constexpr static int kHeadDim = 32;  \
+      return __VA_ARGS__();                \
+    } else if (HEADDIM <= 64) {            \
+      constexpr static int kHeadDim = 64;  \
+      return __VA_ARGS__();                \
+    } else if (HEADDIM <= 96) {            \
+      constexpr static int kHeadDim = 96;  \
+      return __VA_ARGS__();                \
+    } else if (HEADDIM <= 128) {           \
+      constexpr static int kHeadDim = 128; \
+      return __VA_ARGS__();                \
+    } else if (HEADDIM <= 160) {           \
+      constexpr static int kHeadDim = 160; \
+      return __VA_ARGS__();                \
+    } else if (HEADDIM <= 192) {           \
+      constexpr static int kHeadDim = 192; \
+      return __VA_ARGS__();                \
+    } else if (HEADDIM <= 224) {           \
+      constexpr static int kHeadDim = 224; \
+      return __VA_ARGS__();                \
+    } else if (HEADDIM <= 256) {           \
+      constexpr static int kHeadDim = 256; \
+      return __VA_ARGS__();                \
+    }                                      \
+  }()
```

### Comparing `flash_attn-2.0.0.post1/csrc/flash_attn/src/utils.h` & `flash_attn-2.0.1/csrc/flash_attn/src/utils.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/flash_gen/decoder_masked_multihead_attention.cu` & `flash_attn-2.0.1/csrc/flash_gen/decoder_masked_multihead_attention.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/ft_attention/cuda_bf16_fallbacks.cuh` & `flash_attn-2.0.1/csrc/ft_attention/cuda_bf16_fallbacks.cuh`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/ft_attention/cuda_bf16_wrapper.h` & `flash_attn-2.0.1/csrc/ft_attention/cuda_bf16_wrapper.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/ft_attention/decoder_masked_multihead_attention.cu` & `flash_attn-2.0.1/csrc/ft_attention/decoder_masked_multihead_attention.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/ft_attention/decoder_masked_multihead_attention.h` & `flash_attn-2.0.1/csrc/ft_attention/decoder_masked_multihead_attention.h`

 * *Files 3% similar despite different names*

```diff
@@ -65,24 +65,28 @@
     T* k_cache = nullptr;
     // The cache for the Vs. The size must be at least B x L x D.
     T* v_cache = nullptr;
     // The indirections to use for cache when beam sampling.
     const int* cache_indir = nullptr;
 
     // Stride to handle the case when KQV is a single buffer
-    int stride = 0;
+    int stride_q = 0;
+    int stride_k = 0;
+    int stride_v = 0;
 
     // The batch size.
     int batch_size = 0;
     // The beam width
     int beam_width = 0;
     // The sequence length.
     int memory_max_len = 0;
     // The number of heads (H).
     int num_heads = 0;
+    int num_heads_kv = 0;
+    int num_heads_q_kv_ratio = 0;
     // The hidden dimension per head (Dh).
     int hidden_size_per_head = 0;
     // The per-head latent space reserved for rotary embeddings.
     int  rotary_embedding_dim = 0;
     bool neox_rotary_style    = false;
     float rotary_base = 0.0f;
     // The maximum length of input sentences.
```

### Comparing `flash_attn-2.0.0.post1/csrc/ft_attention/decoder_masked_multihead_attention_template.hpp` & `flash_attn-2.0.1/csrc/ft_attention/decoder_masked_multihead_attention_template.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -939,29 +939,33 @@
     // The beam idx
     const int beami = bi % params.beam_width;
     // The "beam-aware" batch idx
     const int bbi = bi / params.beam_width;
     // The head.
     // const int hi = blockIdx.x;
     const int hi = params.nnz_head_idx == nullptr ? blockIdx.x : params.nnz_head_idx[blockIdx.x];
+    const int hi_kv = hi / params.num_heads_q_kv_ratio;
     // Combine the batch and the head indices.
     const int bhi = bi * params.num_heads + hi;
+    const int bhi_kv = bi * params.num_heads_kv + hi_kv;
     // Combine the "beam-aware" batch idx and the head indices.
-    const int bbhi = bbi * params.beam_width * params.num_heads + hi;
+    const int bbhi = bbi * params.beam_width * params.num_heads_kv + hi_kv;
     // The thread in the block.
     const int tidx = threadIdx.x;
 
     const bool handle_kv = !DO_CROSS_ATTENTION || (DO_CROSS_ATTENTION && params.timestep == 0);
 
     // While doing the product Q*K^T for the different keys we track the max.
     float qk_max = -FLT_MAX;
 
     float qk = 0.0F;
 
-    int qkv_base_offset = (params.stride == 0) ? bhi * Dh : bi * params.stride + hi * Dh;
+    int q_base_offset = (params.stride_q == 0) ? bhi * Dh : bi * params.stride_q + hi * Dh;
+    int k_base_offset = (params.stride_k == 0) ? bhi_kv * Dh : bi * params.stride_k + hi_kv * Dh;
+    int v_base_offset = (params.stride_v == 0) ? bhi_kv * Dh : bi * params.stride_v + hi_kv * Dh;
 
     const size_t bi_seq_len_offset = bi * params.memory_max_len;
 
     // int tlength = (DO_CROSS_ATTENTION)? params.memory_length_per_sample[bi] - 1 : params.timestep;
     int       tlength      = (DO_CROSS_ATTENTION) ? params.memory_length_per_sample[bi] - 1 :
                              (params.length_per_sample == nullptr) ?
                                                     params.timestep :
@@ -969,84 +973,86 @@
     const int first_step   = max(0, tlength + 1 - params.memory_max_len);
     const int tlength_circ = tlength % params.memory_max_len;
 
     // First QK_VECS_PER_WARP load Q and K + the bias values for the current timestep.
     const bool is_masked = tidx >= QK_VECS_PER_WARP;
 
     // The offset in the Q and K buffer also accounts for the batch.
-    int qk_offset = qkv_base_offset + tidx * QK_VEC_SIZE;
+    int q_offset = q_base_offset + tidx * QK_VEC_SIZE;
+    int k_offset = k_base_offset + tidx * QK_VEC_SIZE;
     // The offset in the bias buffer.
-    int qk_bias_offset = hi * Dh + tidx * QK_VEC_SIZE;
+    int q_bias_offset = hi * Dh + tidx * QK_VEC_SIZE;
+    int k_bias_offset = hi_kv * Dh + tidx * QK_VEC_SIZE;
 
     const bool do_ia3      = handle_kv && params.ia3_tasks != nullptr;
     const int  ia3_task_id = do_ia3 ? params.ia3_tasks[bbi] : 0;
 
     // Trigger the loads from the Q and K buffers.
     Qk_vec q;
     zero(q);
     if (!is_masked && (Dh == Dh_MAX || tidx * QK_VEC_SIZE < Dh)) {
         if (params.int8_mode == 2) {
             using Packed_Int8_t  = typename packed_type<int8_t, num_elems<Qk_vec>::value>::type;
             using Packed_Float_t = typename packed_type<float, num_elems<Qk_vec>::value>::type;
             const auto q_scaling = params.qkv_scale_out[0];
             const auto q_quant =
-                *reinterpret_cast<const Packed_Int8_t*>(&reinterpret_cast<const int8_t*>(params.q)[qk_offset]);
+                *reinterpret_cast<const Packed_Int8_t*>(&reinterpret_cast<const int8_t*>(params.q)[q_offset]);
 
             convert_from_float(q, mul<Packed_Float_t, float>(q_scaling, float_from_int8(q_quant)));
         }
         else {
-            q = *reinterpret_cast<const Qk_vec*>(&params.q[qk_offset]);
+            q = *reinterpret_cast<const Qk_vec*>(&params.q[q_offset]);
         }
     }
 
     Qk_vec k;
     zero(k);
     if (DO_CROSS_ATTENTION) {
         // The 16B chunk written by the thread.
         int co = tidx / QK_VECS_IN_16B;
         // The position of the thread in that 16B chunk.
         int ci = tidx % QK_VECS_IN_16B * QK_VEC_SIZE;
 
         // Two chunks are separated by L * x elements. A thread write QK_VEC_SIZE elements.
-        int offset = bhi * params.memory_max_len * Dh + co * params.memory_max_len * QK_ELTS_IN_16B +
+        int offset = bhi_kv * params.memory_max_len * Dh + co * params.memory_max_len * QK_ELTS_IN_16B +
                      // params.timestep*QK_ELTS_IN_16B +
                      tlength * QK_ELTS_IN_16B + ci;
         k = !is_masked && (Dh == Dh_MAX || tidx * QK_VEC_SIZE < Dh) ?
                 *reinterpret_cast<const Qk_vec*>(&params.k_cache[offset]) :
                 k;
     }
     else {
         if (!is_masked && (Dh == Dh_MAX || tidx * QK_VEC_SIZE < Dh)) {
             if (params.int8_mode == 2) {
                 using Packed_Int8_t  = typename packed_type<int8_t, num_elems<Qk_vec>::value>::type;
                 using Packed_Float_t = typename packed_type<float, num_elems<Qk_vec>::value>::type;
                 const auto k_scaling = params.qkv_scale_out[1];
                 const auto k_quant =
-                    *reinterpret_cast<const Packed_Int8_t*>(&reinterpret_cast<const int8_t*>(params.k)[qk_offset]);
+                    *reinterpret_cast<const Packed_Int8_t*>(&reinterpret_cast<const int8_t*>(params.k)[k_offset]);
 
                 convert_from_float(k, mul<Packed_Float_t, float>(k_scaling, float_from_int8(k_quant)));
             }
             else {
-                k = *reinterpret_cast<const Qk_vec*>(&params.k[qk_offset]);
+                k = *reinterpret_cast<const Qk_vec*>(&params.k[k_offset]);
             }
         }
     }
 
     // Trigger the loads from the Q and K bias buffers.
     Qk_vec q_bias;
     zero(q_bias);
     q_bias = (!is_masked && Dh == Dh_MAX || tidx * QK_VEC_SIZE < Dh) && params.q_bias != nullptr ?
-                 *reinterpret_cast<const Qk_vec*>(&params.q_bias[qk_bias_offset]) :
+                 *reinterpret_cast<const Qk_vec*>(&params.q_bias[q_bias_offset]) :
                  q_bias;
 
     Qk_vec k_bias;
     zero(k_bias);
     if (handle_kv) {
         k_bias = !is_masked && (Dh == Dh_MAX || tidx * QK_VEC_SIZE < Dh) && params.k_bias != nullptr ?
-                     *reinterpret_cast<const Qk_vec*>(&params.k_bias[qk_bias_offset]) :
+                     *reinterpret_cast<const Qk_vec*>(&params.k_bias[k_bias_offset]) :
                      k_bias;
     }
 
     // Computes the Q/K values with bias.
     q = add(q, q_bias);
     if (handle_kv) {
         k = add(k, k_bias);
@@ -1168,19 +1174,19 @@
 
         // The 16B chunk written by the thread.
         int co = tidx / QK_VECS_IN_16B;
         // The position of the thread in that 16B chunk.
         int ci = tidx % QK_VECS_IN_16B * QK_VEC_SIZE;
 
         // Two chunks are separated by L * x elements. A thread write QK_VEC_SIZE elements.
-        int offset = bhi * params.memory_max_len * Dh + co * params.memory_max_len * QK_ELTS_IN_16B +
+        int offset = bhi_kv * params.memory_max_len * Dh + co * params.memory_max_len * QK_ELTS_IN_16B +
                      // params.timestep*QK_ELTS_IN_16B +
                      tlength_circ * QK_ELTS_IN_16B + ci;
 
-        if (handle_kv) {
+        if (handle_kv && hi % params.num_heads_q_kv_ratio == 0) {
             // Trigger the stores to global memory.
             if (Dh == Dh_MAX || co < Dh / QK_ELTS_IN_16B) {
                 *reinterpret_cast<Qk_vec*>(&params.k_cache[offset]) = k;
             }
         }
 
         // Compute \sum_i Q[i] * K^T[i] for the current timestep.
@@ -1259,15 +1265,15 @@
 
     // The number of timesteps loaded per iteration.
     constexpr int K_PER_ITER = THREADS_PER_BLOCK / THREADS_PER_KEY;
     // The number of keys per warp.
     constexpr int K_PER_WARP = WARP_SIZE / THREADS_PER_KEY;
 
     // The base pointer for the key in the cache buffer.
-    T* k_cache = &params.k_cache[bhi * params.memory_max_len * Dh + ki];
+    T* k_cache = &params.k_cache[bhi_kv * params.memory_max_len * Dh + ki];
     // Base pointer for the beam's batch, before offsetting with indirection buffer
     T* k_cache_batch = &params.k_cache[bbhi * params.memory_max_len * Dh + ki];
 
     // Pick a number of keys to make sure all the threads of a warp enter (due to shfl_sync).
     // int ti_end = div_up(params.timestep, K_PER_WARP) * K_PER_WARP;
     int ti_end = div_up(tlength - first_step, K_PER_WARP) * K_PER_WARP + first_step;
 
@@ -1423,15 +1429,15 @@
 
     // The value computed by this thread.
     int vo = tidx / THREADS_PER_VALUE;
     // The hidden dimensions computed by this particular thread.
     int vi = tidx % THREADS_PER_VALUE * V_VEC_SIZE;
 
     // The base pointer for the value in the cache buffer.
-    T* v_cache = &params.v_cache[bhi * params.memory_max_len * Dh + vi];
+    T* v_cache = &params.v_cache[bhi_kv * params.memory_max_len * Dh + vi];
     // Base pointer for the beam's batch, before offsetting with indirection buffer
     T* v_cache_batch = &params.v_cache[bbhi * params.memory_max_len * Dh + vi];
 
     // The number of values processed per iteration of the loop.
     constexpr int V_PER_ITER = THREADS_PER_BLOCK / THREADS_PER_VALUE;
 
     // One group of threads computes the product(s) for the current timestep.
@@ -1439,15 +1445,15 @@
     zero(v_bias);
     // if( vo == params.timestep % V_PER_ITER ) {
     if (Dh == Dh_MAX || vi < Dh) {
         if (handle_kv) {
             if (vo == tlength % V_PER_ITER) {
                 // Trigger the loads from the V bias buffer.
                 if (params.v_bias != nullptr) {
-                    v_bias = *reinterpret_cast<const V_vec*>(&params.v_bias[hi * Dh + vi]);
+                    v_bias = *reinterpret_cast<const V_vec*>(&params.v_bias[hi_kv * Dh + vi]);
                 }
                 if (DO_CROSS_ATTENTION) {
                     *reinterpret_cast<V_vec*>(&bias_smem[vi]) = v_bias;
                 }
             }
         }
     }
@@ -1506,15 +1512,15 @@
 
         V_vec v;
         if (DO_CROSS_ATTENTION) {
             v = *reinterpret_cast<const V_vec*>(&v_cache[tlength * Dh]);
         }
         else {
             // Trigger the loads from the V buffer.
-            const auto v_offset = qkv_base_offset + vi;
+            const auto v_offset = v_base_offset + vi;
             if (params.int8_mode == 2) {
                 using Packed_Int8_t  = typename packed_type<int8_t, num_elems<V_vec>::value>::type;
                 using Packed_Float_t = typename packed_type<float, num_elems<V_vec>::value>::type;
                 const auto v_scaling = params.qkv_scale_out[2];
                 const auto v_quant =
                     *reinterpret_cast<const Packed_Int8_t*>(&reinterpret_cast<const int8_t*>(params.v)[v_offset]);
 
@@ -1535,16 +1541,18 @@
                 v = mul<V_vec, V_vec, V_vec>(
                     v,
                     *reinterpret_cast<const V_vec*>(
                         &params.ia3_value_weights[(ia3_task_id * params.num_heads + hi) * Dh + vi]));
             }
 
             // Store the values with bias back to global memory in the cache for V.
-            //*reinterpret_cast<V_vec*>(&v_cache[params.timestep*Dh]) = v;
-            *reinterpret_cast<V_vec*>(&v_cache[tlength_circ * Dh]) = v;
+            if (hi % params.num_heads_q_kv_ratio == 0) {
+                //*reinterpret_cast<V_vec*>(&v_cache[params.timestep*Dh]) = v;
+                *reinterpret_cast<V_vec*>(&v_cache[tlength_circ * Dh]) = v;
+            }
         }
 
         // Initialize the output value with the current timestep.
 #if defined(MMHA_USE_FP32_ACUM_FOR_LOGITS)
         // out = fma(logits_smem[params.timestep], cast_to_float(v), out);
         out = fma(logits_smem[tlength - first_step], cast_to_float(v), out);
 #else
```

### Comparing `flash_attn-2.0.0.post1/csrc/ft_attention/decoder_masked_multihead_attention_utils.h` & `flash_attn-2.0.1/csrc/ft_attention/decoder_masked_multihead_attention_utils.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/ft_attention/ft_attention.cpp` & `flash_attn-2.0.1/csrc/ft_attention/ft_attention.cpp`

 * *Files 6% similar despite different names*

```diff
@@ -46,21 +46,24 @@
     using Type = __nv_bfloat16;
 };
 
 template <typename T>
 void set_params(Masked_multihead_attention_params<T> &params,
                 const size_t batch_size,
                 const size_t nheads,
+                const size_t nheads_kv,
                 const size_t memory_max_seqlen,
                 const size_t headdim,
                 const int timestep,
                 const int rotary_embedding_dim,
                 const float rotary_base,
                 const bool neox_rotary_style,
-                const int qkv_batch_stride,
+                const int q_batch_stride,
+                const int k_batch_stride,
+                const int v_batch_stride,
                 const int nnz_heads,
                 T *q_ptr,
                 T *k_ptr,
                 T *v_ptr,
                 T *k_cache_ptr,
                 T *v_cache_ptr,
                 int *length_per_sample,
@@ -76,19 +79,23 @@
     params.q_bias = nullptr;
     params.k_bias = nullptr;
     params.v_bias = nullptr;
     params.k_cache = k_cache_ptr;
     params.v_cache = v_cache_ptr;
     params.out = out_ptr;
     params.cache_indir = nullptr;
-    params.stride = qkv_batch_stride;
+    params.stride_q = q_batch_stride;
+    params.stride_k = k_batch_stride;
+    params.stride_v = v_batch_stride;
     params.batch_size = batch_size;
     params.beam_width = 1;
     params.memory_max_len = memory_max_seqlen;
     params.num_heads = nheads;
+    params.num_heads_kv = nheads_kv;
+    params.num_heads_q_kv_ratio = nheads / nheads_kv;
     params.nnz_heads = nnz_heads;
     params.hidden_size_per_head = headdim;
     params.rotary_embedding_dim = rotary_embedding_dim;
     params.rotary_base = rotary_base;
     params.neox_rotary_style = neox_rotary_style;
     params.timestep = timestep;
     params.inv_sqrt_dh = 1.f / sqrt(float(headdim));
@@ -120,31 +127,31 @@
                                      c10::optional<const torch::Tensor> nnz_head_idx_,
                                      const int timestep,
                                      int rotary_embedding_dim = 0,
                                      const float rotary_base = 10000.0f,
                                      const bool neox_rotary_style=true) {
     CHECK_DEVICE(q); CHECK_DEVICE(k); CHECK_DEVICE(v); CHECK_DEVICE(k_cache); CHECK_DEVICE(v_cache);
     int batch_size = v_cache.size(0);
-    int nheads = v_cache.size(1);
+    int nheads = q.size(1);
+    int nheads_kv = v_cache.size(1);
     int memory_max_seqlen = v_cache.size(2);
     int headdim = v_cache.size(3);
     auto input_type = q.scalar_type();
     TORCH_CHECK(input_type == at::ScalarType::Float || input_type == at::ScalarType::Half || input_type == at::ScalarType::BFloat16);
 
     CHECK_SHAPE(q, batch_size, nheads, headdim);
-    CHECK_SHAPE(k, batch_size, nheads, headdim);
-    CHECK_SHAPE(v, batch_size, nheads, headdim);
-    CHECK_SHAPE(v_cache, batch_size, nheads, memory_max_seqlen, headdim);
+    CHECK_SHAPE(k, batch_size, nheads_kv, headdim);
+    CHECK_SHAPE(v, batch_size, nheads_kv, headdim);
+    CHECK_SHAPE(v_cache, batch_size, nheads_kv, memory_max_seqlen, headdim);
     // k_cache shape: [B, H, Dh/x, L, x] where x=8 for fp16 and x=4 for fp32
     int packsize = k_cache.dtype() == torch::kFloat32 ? 4 : 8;
-    CHECK_SHAPE(k_cache, batch_size, nheads, headdim / packsize, memory_max_seqlen, packsize);
+    CHECK_SHAPE(k_cache, batch_size, nheads_kv, headdim / packsize, memory_max_seqlen, packsize);
     TORCH_CHECK(q.stride(2) == 1 && q.stride(1) == headdim);
     TORCH_CHECK(k.stride(2) == 1 && k.stride(1) == headdim);
     TORCH_CHECK(v.stride(2) == 1 && v.stride(1) == headdim);
-    TORCH_CHECK(q.stride(0) == k.stride(0) && q.stride(0) == v.stride(0));
     CHECK_CONTIGUOUS(v_cache); CHECK_CONTIGUOUS(k_cache);
 
     TORCH_CHECK(q.scalar_type() == input_type);
     TORCH_CHECK(k.scalar_type() == input_type);
     TORCH_CHECK(v.scalar_type() == input_type);
     TORCH_CHECK(k_cache.scalar_type() == input_type);
     TORCH_CHECK(v_cache.scalar_type() == input_type);
@@ -187,16 +194,17 @@
     at::cuda::CUDAGuard device_guard{(char)q.get_device()};
 
     torch::Tensor out = torch::empty_like(q);
 
     DISPATCH_FLOAT_AND_HALF_AND_BF16(q.scalar_type(), "single_query_attention", [&] {
         using DataType = typename SATypeConverter<scalar_t>::Type;
         Masked_multihead_attention_params<DataType> params;
-        set_params(params, batch_size, nheads, memory_max_seqlen, headdim, timestep,
-                   rotary_embedding_dim, rotary_base, neox_rotary_style, q.stride(0),
+        set_params(params, batch_size, nheads, nheads_kv, memory_max_seqlen, headdim, timestep,
+                   rotary_embedding_dim, rotary_base, neox_rotary_style,
+                   q.stride(0), k.stride(0), v.stride(0),
                    nnz_head_idx_.has_value() ? nnz_head_idx_.value().size(0) : 0,
                    reinterpret_cast<DataType*>(q.data_ptr()),
                    reinterpret_cast<DataType*>(k.data_ptr()),
                    reinterpret_cast<DataType*>(v.data_ptr()),
                    reinterpret_cast<DataType*>(k_cache.data_ptr()),
                    reinterpret_cast<DataType*>(v_cache.data_ptr()),
                    length_per_sample_.has_value()
```

### Comparing `flash_attn-2.0.0.post1/csrc/fused_dense_lib/fused_dense.cpp` & `flash_attn-2.0.1/csrc/fused_dense_lib/fused_dense.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/fused_dense_lib/fused_dense_cuda.cu` & `flash_attn-2.0.1/csrc/fused_dense_lib/fused_dense_cuda.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/fused_softmax/fused_softmax.cpp` & `flash_attn-2.0.1/csrc/fused_softmax/fused_softmax.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/fused_softmax/scaled_masked_softmax.h` & `flash_attn-2.0.1/csrc/fused_softmax/scaled_masked_softmax.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/fused_softmax/scaled_masked_softmax_cuda.cu` & `flash_attn-2.0.1/csrc/fused_softmax/scaled_masked_softmax_cuda.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/fused_softmax/scaled_upper_triang_masked_softmax.h` & `flash_attn-2.0.1/csrc/fused_softmax/scaled_upper_triang_masked_softmax.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/fused_softmax/scaled_upper_triang_masked_softmax_cuda.cu` & `flash_attn-2.0.1/csrc/fused_softmax/scaled_upper_triang_masked_softmax_cuda.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/fused_softmax/type_shim.h` & `flash_attn-2.0.1/csrc/fused_softmax/type_shim.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln.h` & `flash_attn-2.0.1/csrc/layer_norm/ln.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_api.cpp` & `flash_attn-2.0.1/csrc/layer_norm/ln_api.cpp`

 * *Files 0% similar despite different names*

```diff
@@ -128,15 +128,15 @@
     auto mtype = torch::kUInt8;
 
     TORCH_CHECK(x0.is_cuda());
     TORCH_CHECK(gamma.is_cuda());
 
     TORCH_CHECK(x0.is_contiguous());
     // c10::IntArrayRef does not own the storage, so we need to construct a vector.
-    // Otherwise just constructing IntArrayRef({blah}) will cause unintialized memory because
+    // Otherwise just constructing IntArrayRef({blah}) will cause uninitialized memory because
     // blah is then deallocated.
     std::vector<int64_t> sizes_vec {!x0_subset_.has_value() ? x0.size(0) : x0_subset_.value().size(0), x0.size(1)};
     auto sizes = c10::IntArrayRef(sizes_vec);
     TORCH_CHECK(x0.dim() == 2);
     TORCH_CHECK(sizes.size() == 2);
 
     const int rows = sizes[0];
@@ -225,19 +225,14 @@
         gen_, at::cuda::detail::getDefaultCUDAGenerator());
 
     auto round_multiple = [](int x, int m) { return (x + m - 1) / m * m; };
     const int multiple = hidden_size <= 1536 ? 256 : (hidden_size <= 3072 ? 512 : 1024);
     // Request the kernel launcher.
     auto launcher = get_fwd_launcher(wtype, itype, rtype, otype, ctype, round_multiple(hidden_size, multiple));
 
-    // Query the kernel-specific launch parameters.
-    launcher(launch_params, true);
-
-    at::Tensor workspace, barrier;
-
     // Set the kernel runtime parameters.
     layer_norm::FwdParams &params = launch_params.params;
     params.rows = rows;
     params.cols = cols;
     params.x0 = x0.data_ptr();
     params.x = save_x ? x.data_ptr() : nullptr;
     params.dmask = dropout_p > 0.f ? dmask.data_ptr() : nullptr;
@@ -248,14 +243,19 @@
     params.z = z.data_ptr();
     params.epsilon = epsilon;
     params.dropout_scale = 1.f / (1.f - dropout_p);
     params.inverse_cols = 1.f / float(params.cols);
     params.rowscale_const = rowscale_const;
     params.is_rms_norm = is_rms_norm;
 
+    // Query the kernel-specific launch parameters.
+    launcher(launch_params, true);
+
+    at::Tensor workspace, barrier;
+
     if (dropout_p > 0.f) {
         // number of times random will be generated per thread, to offset philox counter in thc random
         // state
         int64_t counter_offset = launch_params.elts_per_thread;
 
         // See Note [Acquire lock when using random generators]
         {
@@ -327,15 +327,15 @@
     auto cols = sizes[1];
     TORCH_CHECK(dz.dim() == 2);
     TORCH_CHECK(dz.size(1) == cols);
     auto hidden_size = gamma.numel();
     TORCH_CHECK(hidden_size == cols);
 
     // c10::IntArrayRef does not own the storage, so we need to construct a vector.
-    // Otherwise just constructing IntArrayRef({blah}) will cause unintialized memory because
+    // Otherwise just constructing IntArrayRef({blah}) will cause uninitialized memory because
     // blah is then deallocated.
     std::vector<int64_t> x0_sizes_vec {!x0_subset_.has_value() ? rows : x0_numrows, cols};
     auto x0_sizes = c10::IntArrayRef(x0_sizes_vec);
 
     if (dx_.has_value()) {
         auto dx = dx_.value();
         TORCH_CHECK(dx.dtype() == rtype);
@@ -590,19 +590,14 @@
         gen_, at::cuda::detail::getDefaultCUDAGenerator());
 
     auto round_multiple = [](int x, int m) { return (x + m - 1) / m * m; };
     const int multiple = hidden_size <= 1536 ? 256 : (hidden_size <= 3072 ? 512 : 1024);
     // Request the kernel launcher.
     auto launcher = get_parallel_fwd_launcher(wtype, itype, rtype, otype, ctype, round_multiple(hidden_size, multiple));
 
-    // Query the kernel-specific launch parameters.
-    launcher(launch_params, true);
-
-    at::Tensor workspace, barrier;
-
     // Set the kernel runtime parameters.
     layer_norm::FwdParams &params = launch_params.params;
     params.rows = rows;
     params.cols = cols;
     params.x0 = x0.data_ptr();
     params.x1 = x1_.has_value() ? x1_.value().data_ptr() : nullptr;
     params.x = save_x ? x.data_ptr() : nullptr;
@@ -617,14 +612,19 @@
     params.z = z0.data_ptr();
     params.z1 = gamma1_.has_value() ? z1.data_ptr() : nullptr;
     params.epsilon = epsilon;
     params.dropout_scale = 1.f / (1.f - dropout_p);
     params.inverse_cols = 1.f / float(params.cols);
     params.is_rms_norm = is_rms_norm;
 
+    // Query the kernel-specific launch parameters.
+    launcher(launch_params, true);
+
+    at::Tensor workspace, barrier;
+
     if (dropout_p > 0.f) {
         // number of times random will be generated per thread, to offset philox counter in thc random
         // state
         int64_t counter_offset = 2 * launch_params.elts_per_thread;
 
         // See Note [Acquire lock when using random generators]
         {
```

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_1024.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_bwd_1024.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_1280.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_bwd_1280.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_1536.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_bwd_1536.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_2048.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_bwd_2048.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_256.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_bwd_256.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_2560.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_bwd_2560.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_3072.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_bwd_3072.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_4096.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_bwd_4096.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_512.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_bwd_512.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_5120.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_bwd_5120.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_6144.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_bwd_6144.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_7168.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_bwd_7168.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_768.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_bwd_768.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_8192.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_bwd_8192.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_kernels.cuh` & `flash_attn-2.0.1/csrc/layer_norm/ln_bwd_kernels.cuh`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_bwd_semi_cuda_kernel_old.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_bwd_semi_cuda_kernel_old.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_1024.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_fwd_1024.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_10240.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_fwd_10240.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_12288.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_fwd_12288.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_128.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_fwd_128.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_1280.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_fwd_1280.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_1536.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_fwd_1536.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_2048.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_fwd_2048.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_256.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_fwd_256.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_2560.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_fwd_2560.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_3072.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_fwd_3072.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_384.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_fwd_384.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_4096.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_fwd_4096.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_512.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_fwd_512.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_5120.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_fwd_5120.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_6144.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_fwd_6144.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_7168.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_fwd_7168.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_768.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_fwd_768.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_8192.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_fwd_8192.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_9216.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_fwd_9216.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_cuda_kernel_old.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_fwd_cuda_kernel_old.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_fwd_kernels.cuh` & `flash_attn-2.0.1/csrc/layer_norm/ln_fwd_kernels.cuh`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_kernel_traits.h` & `flash_attn-2.0.1/csrc/layer_norm/ln_kernel_traits.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_1024.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_1024.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_1280.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_1280.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_1536.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_1536.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_2048.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_2048.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_256.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_256.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_2560.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_2560.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_3072.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_3072.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_4096.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_4096.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_512.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_512.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_5120.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_5120.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_6144.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_6144.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_7168.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_7168.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_768.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_768.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_bwd_8192.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_bwd_8192.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_1024.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_1024.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_1280.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_1280.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_1536.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_1536.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_2048.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_2048.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_256.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_256.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_2560.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_2560.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_3072.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_3072.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_4096.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_4096.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_512.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_512.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_5120.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_5120.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_6144.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_6144.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_7168.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_7168.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_768.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_768.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_fwd_8192.cu` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_fwd_8192.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_residual_bwd_kernels.cuh` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_residual_bwd_kernels.cuh`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_parallel_residual_fwd_kernels.cuh` & `flash_attn-2.0.1/csrc/layer_norm/ln_parallel_residual_fwd_kernels.cuh`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/ln_utils.cuh` & `flash_attn-2.0.1/csrc/layer_norm/ln_utils.cuh`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/layer_norm/static_switch.h` & `flash_attn-2.0.1/csrc/layer_norm/static_switch.h`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/rotary/rotary.cpp` & `flash_attn-2.0.1/csrc/rotary/rotary.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/rotary/rotary_cuda.cu` & `flash_attn-2.0.1/csrc/rotary/rotary_cuda.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/xentropy/interface.cpp` & `flash_attn-2.0.1/csrc/xentropy/interface.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/csrc/xentropy/xentropy_kernel.cu` & `flash_attn-2.0.1/csrc/xentropy/xentropy_kernel.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/attention_kernl.py` & `flash_attn-2.0.1/flash_attn/attention_kernl.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/bert_padding.py` & `flash_attn-2.0.1/flash_attn/bert_padding.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/fav2_interface.py` & `flash_attn-2.0.1/flash_attn/fav2_interface.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/flash_attention.py` & `flash_attn-2.0.1/flash_attn/flash_attention.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 import math
 import torch
 import torch.nn as nn
 
 from einops import rearrange
 
-from flash_attn import flash_attn_qkvpacked_func, flash_attn_varlen_qkvpacked_func
+from flash_attn.flash_attn_interface import flash_attn_unpadded_qkvpacked_func
 from flash_attn.bert_padding import unpad_input, pad_input
 
 
 class FlashAttention(nn.Module):
     """Implement the scaled dot product attention with softmax.
     Arguments
     ---------
@@ -20,53 +20,54 @@
     """
     def __init__(self, softmax_scale=None, attention_dropout=0.0):
         super().__init__()
         self.softmax_scale = softmax_scale
         self.dropout_p = attention_dropout
 
     def forward(self, qkv, key_padding_mask=None, causal=False, cu_seqlens=None,
-                max_s=None):
+                max_s=None, need_weights=False):
         """Implements the multihead softmax attention.
         Arguments
         ---------
             qkv: The tensor containing the query, key, and value. (B, S, 3, H, D) if key_padding_mask is None
                 if unpadded: (nnz, 3, h, d)
             key_padding_mask: a bool tensor of shape (B, S)
         """
+        assert not need_weights
         assert qkv.dtype in [torch.float16, torch.bfloat16]
         assert qkv.is_cuda
 
         if cu_seqlens is None:
             batch_size = qkv.shape[0]
             seqlen = qkv.shape[1]
             if key_padding_mask is None:
                 qkv = rearrange(qkv, 'b s ... -> (b s) ...')
                 max_s = seqlen
                 cu_seqlens = torch.arange(0, (batch_size + 1) * seqlen, step=seqlen, dtype=torch.int32,
                                         device=qkv.device)
-                output = flash_attn_varlen_qkvpacked_func(
+                output = flash_attn_unpadded_qkvpacked_func(
                     qkv, cu_seqlens, max_s, self.dropout_p if self.training else 0.0,
                     softmax_scale=self.softmax_scale, causal=causal
                 )
                 output = rearrange(output, '(b s) ... -> b s ...', b=batch_size)
             else:
                 nheads = qkv.shape[-2]
                 x = rearrange(qkv, 'b s three h d -> b s (three h d)')
                 x_unpad, indices, cu_seqlens, max_s = unpad_input(x, key_padding_mask)
                 x_unpad = rearrange(x_unpad, 'nnz (three h d) -> nnz three h d', three=3, h=nheads)
-                output_unpad = flash_attn_varlen_qkvpacked_func(
+                output_unpad = flash_attn_unpadded_qkvpacked_func(
                     x_unpad, cu_seqlens, max_s, self.dropout_p if self.training else 0.0,
                     softmax_scale=self.softmax_scale, causal=causal
                 )
                 output = rearrange(pad_input(rearrange(output_unpad, 'nnz h d -> nnz (h d)'),
                                             indices, batch_size, seqlen),
                                 'b s (h d) -> b s h d', h=nheads)
         else:
             assert max_s is not None
-            output = flash_attn_varlen_qkvpacked_func(
+            output = flash_attn_unpadded_qkvpacked_func(
                 qkv, cu_seqlens, max_s, self.dropout_p if self.training else 0.0,
                 softmax_scale=self.softmax_scale, causal=causal
             )
 
         return output, None
 
 
@@ -79,22 +80,22 @@
         super().__init__()
         self.embed_dim = embed_dim
         self.causal = causal
 
         self.num_heads = num_heads
         assert self.embed_dim % num_heads == 0, "self.kdim must be divisible by num_heads"
         self.head_dim = self.embed_dim // num_heads
-        assert self.head_dim <= 256, "Only support head_dim <= 258"
+        assert self.head_dim % 8 == 0 and self.head_dim <= 128, "Only support head_dim <= 128 and divisible by 8"
 
         self.Wqkv = nn.Linear(embed_dim, 3 * embed_dim, bias=bias, **factory_kwargs)
         self.inner_attn = FlashAttention(attention_dropout=attention_dropout)
         self.out_proj = nn.Linear(embed_dim, embed_dim, bias=bias, **factory_kwargs)
 
-    def forward(self, x, key_padding_mask=None):
+    def forward(self, x, key_padding_mask=None, need_weights=False):
         """x: (batch, seqlen, hidden_dim) (where hidden_dim = num heads * head dim)
         key_padding_mask: bool tensor of shape (batch, seqlen)
         """
         qkv = self.Wqkv(x)
         qkv = rearrange(qkv, 'b s (three h d) -> b s three h d', three=3, h=self.num_heads)
         context, attn_weights = self.inner_attn(qkv, key_padding_mask=key_padding_mask,
-                                                causal=self.causal)
+                                                need_weights=need_weights, causal=self.causal)
         return self.out_proj(rearrange(context, 'b s h d -> b s (h d)')), attn_weights
```

### Comparing `flash_attn-2.0.0.post1/flash_attn/flash_attn_interface.py` & `flash_attn-2.0.1/flash_attn/flash_attn_interface.py`

 * *Files 2% similar despite different names*

```diff
@@ -33,54 +33,52 @@
     elif head_dim <= 224:
         return (128, 64) if (is_sm80 or is_sm90) else (64, 64)
     elif head_dim <= 256:
         return (128, 64) if is_sm80 else (64, 64)
 
 
 def _flash_attn_forward(q, k, v, dropout_p, softmax_scale, causal, return_softmax):
-    if q.stride(-1) != 1:
-        q = q.contiguous()
-    if k.stride(-1) != 1:
-        k = k.contiguous()
-    if v.stride(-1) != 1:
-        v = v.contiguous()
+    maybe_contiguous = lambda x: x.contiguous() if x.stride(-1) != 1 else x
+    q, k, v = [maybe_contiguous(x) for x in (q, k, v)]
     out, q, k, v, out_padded, softmax_lse, S_dmask = flash_attn_cuda.fwd(
         q, k, v, None, dropout_p, softmax_scale, causal, return_softmax, None
     )
     return out, q, k, v, out_padded, softmax_lse, S_dmask
 
 
 def _flash_attn_varlen_forward(q, k, v, cu_seqlens_q, cu_seqlens_k, max_seqlen_q, max_seqlen_k,
                                dropout_p, softmax_scale, causal, return_softmax):
-    if q.stride(-1) != 1:
-        q = q.contiguous()
-    if k.stride(-1) != 1:
-        k = k.contiguous()
-    if v.stride(-1) != 1:
-        v = v.contiguous()
+    maybe_contiguous = lambda x: x.contiguous() if x.stride(-1) != 1 else x
+    q, k, v = [maybe_contiguous(x) for x in (q, k, v)]
     out, q, k, v, out_padded, softmax_lse, S_dmask = flash_attn_cuda.varlen_fwd(
         q, k, v, None, cu_seqlens_q, cu_seqlens_k, max_seqlen_q, max_seqlen_k, dropout_p,
         softmax_scale, False, causal, return_softmax, None
     )
     # if out.isnan().any() or softmax_lse.isnan().any():
     #     breakpoint()
     return out, q, k, v, out_padded, softmax_lse, S_dmask
 
 
 def _flash_attn_backward(dout, q, k, v, out, softmax_lse, dq, dk, dv,
                          dropout_p, softmax_scale, causal):
+    maybe_contiguous = lambda x: x.contiguous() if x.stride(-1) != 1 else x
+    # dq, dk, dv are allocated by us so they should already be contiguous
+    dout, q, k, v, out = [maybe_contiguous(x) for x in (dout, q, k, v, out)]
     dq, dk, dv, softmax_d, = flash_attn_cuda.bwd(
         dout, q, k, v, out, softmax_lse, dq, dk, dv, dropout_p, softmax_scale, causal, None
     )
     return dq, dk, dv, softmax_d
 
 
 def _flash_attn_varlen_backward(dout, q, k, v, out, softmax_lse, dq, dk, dv,
                                 cu_seqlens_q, cu_seqlens_k, max_seqlen_q, max_seqlen_k,
                                 dropout_p, softmax_scale, causal):
+    maybe_contiguous = lambda x: x.contiguous() if x.stride(-1) != 1 else x
+    # dq, dk, dv are allocated by us so they should already be contiguous
+    dout, q, k, v, out = [maybe_contiguous(x) for x in (dout, q, k, v, out)]
     dq, dk, dv, softmax_d, = flash_attn_cuda.varlen_bwd(
         dout, q, k, v, out, softmax_lse, dq, dk, dv, cu_seqlens_q, cu_seqlens_k,
         max_seqlen_q, max_seqlen_k, dropout_p, softmax_scale, False, causal, None
     )
     # if dk.isnan().any() or dk.isnan().any() or dv.isnan().any() or softmax_d.isnan().any():
     #     breakpoint()
     return dq, dk, dv, softmax_d
```

### Comparing `flash_attn-2.0.0.post1/flash_attn/flash_attn_triton.py` & `flash_attn-2.0.1/flash_attn/flash_attn_triton.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/flash_attn_triton_og.py` & `flash_attn-2.0.1/flash_attn/flash_attn_triton_og.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/flash_attn_triton_single_query.py` & `flash_attn-2.0.1/flash_attn/flash_attn_triton_single_query.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/flash_attn_triton_tmp.py` & `flash_attn-2.0.1/flash_attn/flash_attn_triton_tmp.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/flash_attn_triton_tmp_og.py` & `flash_attn-2.0.1/flash_attn/flash_attn_triton_tmp_og.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/flash_blocksparse_attention.py` & `flash_attn-2.0.1/flash_attn/flash_blocksparse_attention.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/flash_blocksparse_attn_interface.py` & `flash_attn-2.0.1/flash_attn/flash_blocksparse_attn_interface.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/fused_softmax.py` & `flash_attn-2.0.1/flash_attn/fused_softmax.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/layers/patch_embed.py` & `flash_attn-2.0.1/flash_attn/layers/patch_embed.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/layers/rotary.py` & `flash_attn-2.0.1/flash_attn/layers/rotary.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Copyright (c) 2023, Tri Dao.
 
-from typing import Tuple
+from typing import Tuple, Optional
 import math
 
 import torch
 
 from einops import rearrange, repeat
 
 import rotary_emb
@@ -147,14 +147,59 @@
                                 rearrange(sin_k[:seqlen], 's d -> s 1 d'), dk1, dk2, True)
         return dqkv, None, None, None, None, None
 
 
 apply_rotary_emb_qkv_ = ApplyRotaryEmbQKV_.apply
 
 
+class ApplyRotaryEmbKV_(torch.autograd.Function):
+
+    @staticmethod
+    def forward(ctx, kv, cos, sin, interleaved=False):
+        """
+            kv: (batch_size, seqlen, 2, nheads, headdim)
+            cos, sin: (seqlen, rotary_dim / 2)
+            interleaved: if True, rotate pairs of even and odd dimensions (GPT-J style) instead of
+                1st half and 2nd half (GPT-NeoX style).
+        rotary_dim must be <= headdim
+        Apply rotary embedding *inplace* to the first rotary_dim of k.
+        """
+        batch, seqlen, two, nheads, headdim = kv.shape
+        assert two == 2
+        rotary_seqlen, rotary_dim = cos.shape
+        rotary_dim *= 2
+        assert rotary_dim <= headdim
+        assert seqlen <= rotary_seqlen
+        k_ro = kv[:, :, 0, :, :rotary_dim]
+        k1, k2 = k_ro.chunk(2, dim=-1) if not interleaved else (k_ro[..., ::2], k_ro[..., 1::2])
+        rotary_emb.apply_rotary(k1, k2, rearrange(cos[:seqlen], 's d -> s 1 d'),
+                                rearrange(sin[:seqlen], 's d -> s 1 d'), k1, k2,
+                                False)  # conj=False since this is the forward pass
+        ctx.save_for_backward(cos, sin)
+        ctx.interleaved = interleaved
+        return kv
+
+    @staticmethod
+    def backward(ctx, dkv):
+        cos, sin = ctx.saved_tensors
+        _, seqlen, _, _, headdim = dkv.shape
+        rotary_dim = cos.shape[-1]
+        rotary_dim *= 2
+        dk_ro = dkv[:, :, 0, :, :rotary_dim]
+        dk1, dk2 = (dk_ro.chunk(2, dim=-1) if not ctx.interleaved
+                    else (dk_ro[..., ::2], dk_ro[..., 1::2]))
+        rotary_emb.apply_rotary(dk1, dk2, rearrange(cos[:seqlen], 's d -> s 1 d'),
+                                rearrange(sin[:seqlen], 's d -> s 1 d'), dk1, dk2,
+                                True)  # conj=True since this is the backward pass
+        return dkv, None, None, None
+
+
+apply_rotary_emb_kv_ = ApplyRotaryEmbKV_.apply
+
+
 class RotaryEmbedding(torch.nn.Module):
     """
     The rotary position embeddings from RoFormer_ (Su et. al).
     A crucial insight from the method is that the query and keys are
     transformed by rotation matrices which depend on the relative positions.
 
     Other implementations are available in the Rotary Transformer repo_ and in
@@ -187,20 +232,20 @@
         """
         super().__init__()
         self.dim = dim
         self.base = float(base)
         self.pos_idx_in_fp32 = pos_idx_in_fp32
         # Generate and save the inverse frequency buffer (non trainable)
         inv_freq = self._compute_inv_freq(device)
-        self.register_buffer("inv_freq", inv_freq)
+        self.register_buffer("inv_freq", inv_freq, persistent=False)
         self.interleaved = interleaved
         self.scale_base = scale_base
         scale = ((torch.arange(0, dim, 2, device=device, dtype=torch.float32) + 0.4 * dim)
                  / (1.4 * dim) if scale_base is not None else None)
-        self.register_buffer("scale", scale)
+        self.register_buffer("scale", scale, persistent=False)
 
         self._seq_len_cached = 0
         self._cos_cached = None
         self._sin_cached = None
         self._cos_k_cached = None
         self._sin_k_cached = None
 
@@ -245,25 +290,47 @@
                 scale = self.scale.to(device=power.device) ** rearrange(power, 's -> s 1')
                 # We want the multiplication by scale to happen in fp32
                 self._cos_cached = (torch.cos(freqs) * scale).to(dtype)
                 self._sin_cached = (torch.sin(freqs) * scale).to(dtype)
                 self._cos_k_cached = (torch.cos(freqs) / scale).to(dtype)
                 self._sin_k_cached = (torch.sin(freqs) / scale).to(dtype)
 
-    def forward(self, qkv: torch.Tensor, seqlen_offset: int = 0) -> Tuple[torch.Tensor, torch.Tensor]:
+    def forward(self, qkv: torch.Tensor, kv: Optional[torch.Tensor] = None,
+                seqlen_offset: int = 0) -> Tuple[torch.Tensor, torch.Tensor]:
         """
-        qkv: (batch, seqlen, 3, nheads, headdim)
+        qkv: (batch, seqlen, 3, nheads, headdim) if kv is none,
+             else it's just q of shape (batch, seqlen, nheads, headdim)
+        kv: (batch, seqlen, 2, nheads, headdim)
         seqlen_offset: can be used in generation where the qkv being passed in is only the last
         token in the batch.
         """
-        self._update_cos_sin_cache(qkv.shape[1] + seqlen_offset, device=qkv.device, dtype=qkv.dtype)
-        if self.scale is None:
-            return apply_rotary_emb_qkv_(
-                qkv, self._cos_cached[seqlen_offset:], self._sin_cached[seqlen_offset:],
-                None, None, self.interleaved
-            )
+        seqlen = qkv.shape[1]
+        self._update_cos_sin_cache(seqlen + seqlen_offset, device=qkv.device, dtype=qkv.dtype)
+        if kv is None:
+            if self.scale is None:
+                return apply_rotary_emb_qkv_(
+                    qkv, self._cos_cached[seqlen_offset:], self._sin_cached[seqlen_offset:],
+                    None, None, self.interleaved
+                )
+            else:
+                return apply_rotary_emb_qkv_(
+                    qkv, self._cos_cached[seqlen_offset:], self._sin_cached[seqlen_offset:],
+                    self._cos_k_cached[seqlen_offset:], self._sin_k_cached[seqlen_offset:],
+                    self.interleaved
+                )
         else:
-            return apply_rotary_emb_qkv_(
-                qkv, self._cos_cached[seqlen_offset:], self._sin_cached[seqlen_offset:],
-                self._cos_k_cached[seqlen_offset:], self._sin_k_cached[seqlen_offset:],
-                self.interleaved
+            q = qkv
+            q = apply_rotary_emb_func(
+                q, self._cos_cached[seqlen_offset:], self._sin_cached[seqlen_offset:],
+                self.interleaved, True
             )
+            if self.scale is None:
+                kv = apply_rotary_emb_kv_(
+                    kv, self._cos_cached[seqlen_offset:], self._sin_cached[seqlen_offset:],
+                    self.interleaved
+                )
+            else:
+                kv = apply_rotary_emb_kv_(
+                    kv, self._cos_k_cached[seqlen_offset:], self._sin_k_cached[seqlen_offset:],
+                    self.interleaved
+                )
+            return q, kv
```

### Comparing `flash_attn-2.0.0.post1/flash_attn/losses/cross_entropy.py` & `flash_attn-2.0.1/flash_attn/losses/cross_entropy.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/models/bert.py` & `flash_attn-2.0.1/flash_attn/models/bert.py`

 * *Files 2% similar despite different names*

```diff
@@ -48,18 +48,24 @@
 
 logger = logging.getLogger(__name__)
 
 
 def create_mixer_cls(config, cross_attn=False, return_residual=False):
     use_flash_attn = getattr(config, 'use_flash_attn', False)
     fused_bias_fc = getattr(config, 'fused_bias_fc', False)
+    rotary_kwargs = {}
+    if config.position_embedding_type == "rotary":
+        rotary_kwargs["rotary_emb_dim"] = getattr(config, "rotary_emb_dim", config.hidden_size)
+        rotary_kwargs["rotary_emb_base"] = getattr(config, "rotary_emb_base", 10000.0)
+        rotary_kwargs["rotary_emb_scale_base"] = getattr(config, "rotary_emb_scale_base", None)
+        rotary_kwargs["rotary_emb_interleaved"] = getattr(config, "rotary_emb_interleaved", False)
     mixer_cls = partial(MHA, num_heads=config.num_attention_heads, cross_attn=cross_attn,
                         dropout=config.attention_probs_dropout_prob, causal=False,
                         fused_bias_fc=fused_bias_fc, use_flash_attn=use_flash_attn,
-                        return_residual=return_residual)
+                        return_residual=return_residual, **rotary_kwargs)
     return mixer_cls
 
 
 def create_mlp_cls(config, layer_idx=None, return_residual=False):
     inner_dim = config.intermediate_size
     fused_mlp = getattr(config, 'fused_mlp', False)
     if fused_mlp:
@@ -294,15 +300,14 @@
         self.pad_vocab_size_multiple = getattr(config, 'pad_vocab_size_multiple', 1)
         if config.vocab_size % self.pad_vocab_size_multiple != 0:
             config.vocab_size += (self.pad_vocab_size_multiple
                                   - (config.vocab_size % self.pad_vocab_size_multiple))
         self.fused_dropout_add_ln = getattr(config, 'fused_dropout_add_ln', False)
         if self.fused_dropout_add_ln and layer_norm is None:
             raise ImportError('dropout_add_layer_norm is not installed')
-        assert config.position_embedding_type == 'absolute'
         assert config.hidden_act in ['gelu', 'gelu_new', 'gelu_fast']
 
         self.embeddings = BertEmbeddings(config.hidden_size, config.vocab_size,
                                          config.max_position_embeddings, config.type_vocab_size,
                                          padding_idx=config.pad_token_id)
         self.emb_drop = nn.Dropout(config.hidden_dropout_prob)
         self.emb_ln = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)
```

### Comparing `flash_attn-2.0.0.post1/flash_attn/models/gpt.py` & `flash_attn-2.0.1/flash_attn/models/gpt.py`

 * *Files 3% similar despite different names*

```diff
@@ -14,23 +14,24 @@
 
 from transformers import GPT2Config
 
 from einops import rearrange
 
 from flash_attn.ops.activations import sqrelu_fwd
 from flash_attn.modules.mha import MHA, ParallelMHA
-from flash_attn.modules.mlp import Mlp, GatedMlp, FusedMLP, ParallelFusedMLP
+from flash_attn.modules.mlp import Mlp, GatedMlp, ParallelMLP, FusedMLP, ParallelFusedMLP
 from flash_attn.modules.block import Block, ParallelBlock
 from flash_attn.modules.embedding import GPT2Embeddings, ParallelGPT2Embeddings
 from flash_attn.utils.distributed import sync_shared_params, all_gather_raw
 from flash_attn.utils.pretrained import state_dict_from_pretrained
 from flash_attn.utils.generation import GenerationMixin
 from flash_attn.models.opt import remap_state_dict_hf_opt
 from flash_attn.models.gptj import remap_state_dict_hf_gptj
 from flash_attn.models.gpt_neox import remap_state_dict_hf_gpt_neox
+from flash_attn.models.falcon import remap_state_dict_hf_falcon
 
 try:
     from flash_attn.ops.fused_dense import ColumnParallelLinear
 except ImportError:
     ColumnParallelLinear = None
 
 try:
@@ -84,15 +85,17 @@
         assert process_group is None, 'TensorParallel MHA requires fused_bias_fc'
     mha_cls = MHA if process_group is None else ParallelMHA
     serial_kwargs = ({'fused_bias_fc': fused_bias_fc, 'dwconv': dwconv}
                      if process_group is None else {})
     parallel_kwargs = ({'process_group': process_group,
                         'sequence_parallel': getattr(config, 'sequence_parallel', True)}
                        if process_group is not None else {})
+    num_heads_kv = getattr(config, "n_head_kv", None)
     mixer_cls = partial(mha_cls, num_heads=config.num_attention_heads,
+                        num_heads_kv=num_heads_kv,
                         qkv_proj_bias=qkv_proj_bias, out_proj_bias=out_proj_bias,
                         dropout=config.attn_pdrop,
                         softmax_scale=softmax_scale, causal=True, layer_idx=layer_idx,
                         rotary_emb_dim=rotary_emb_dim, rotary_emb_base=rotary_emb_base,
                         rotary_emb_scale_base=rotary_emb_scale_base,
                         rotary_emb_interleaved=rotary_emb_interleaved,
                         use_flash_attn=use_flash_attn,
@@ -108,18 +111,16 @@
     if fused_mlp:
         assert config.activation_function in ['gelu_new', 'gelu_fast', 'gelu_approx', 'relu', 'sqrelu']
     fused_dense_sqrelu_dense = getattr(config, 'fused_dense_sqrelu_dense', False)
     if fused_dense_sqrelu_dense:
         assert config.activation_function == 'sqrelu', ('fused_dense_sqrelu_dense only '
                                                'supports approximate activation_function sqrelu')
     assert not (fused_dense_sqrelu_dense and fused_mlp)
-    if process_group is not None:
-        assert fused_mlp, 'Tensor Parallel is only implemented for FusedMLP'
     if not fused_mlp and not fused_dense_sqrelu_dense:
-        assert config.activation_function in ['gelu_new', 'gelu_fast', 'gelu_approx', 'relu',
+        assert config.activation_function in ['gelu', 'gelu_new', 'gelu_fast', 'gelu_approx', 'relu',
                                               'sqrelu', 'glu', 'swiglu', 'geglu']
         if config.activation_function in ['glu', 'swiglu', 'geglu']:
             activation = (F.sigmoid if config.activation_function == 'glu'
                           else (F.silu if config.activation_function == 'swiglu'
                                 else F.gelu))
             mlp_cls = partial(GatedMlp, hidden_features=config.n_inner, activation=activation,
                               bias1=mlp_fc1_bias, bias2=mlp_fc2_bias, **factory_kwargs)
@@ -128,16 +129,21 @@
                 activation = partial(F.relu, inplace=True)
             elif config.activation_function == 'sqrelu':
                 activation = sqrelu_fwd
             else:
                 approximate = ('tanh' if config.activation_function
                             in ['gelu_new', 'gelu_fast', 'gelu_approx'] else 'none')
                 activation=partial(F.gelu, approximate=approximate)
-            mlp_cls = partial(Mlp, hidden_features=config.n_inner, activation=activation,
-                              bias1=mlp_fc1_bias, bias2=mlp_fc2_bias, **factory_kwargs)
+            mlp_cls = Mlp if process_group is None else ParallelMLP
+            parallel_kwargs = ({'process_group': process_group,
+                                'sequence_parallel': getattr(config, 'sequence_parallel', True)}
+                               if process_group is not None else {})
+            mlp_cls = partial(mlp_cls, hidden_features=config.n_inner, activation=activation,
+                              bias1=mlp_fc1_bias, bias2=mlp_fc2_bias,
+                              **parallel_kwargs, **factory_kwargs)
     else:
         mlp_checkpoint_lvl = getattr(config, 'mlp_checkpoint_lvl', 0)
         # mlp_checkpoint_lvl could be a list, which contains the checkpoint_lvl for each layer
         if isinstance(mlp_checkpoint_lvl, Sequence):
             assert layer_idx is not None
             mlp_checkpoint_lvl = mlp_checkpoint_lvl[layer_idx]
         if fused_mlp:
@@ -230,17 +236,18 @@
         )
         if model_name.startswith('gpt2'):
             state_dict = remap_state_dict_hf_gpt2(state_dict, config)
         elif model_name.startswith('facebook/opt'):
             state_dict = remap_state_dict_hf_opt(state_dict, config)
         elif model_name.startswith('EleutherAI/gpt-j-'):
             state_dict = remap_state_dict_hf_gptj(state_dict, config)
-            strict = False  # We have rotary_emb.inf_freq buffers not in the GPT-J checkpoint
         elif model_name.startswith('EleutherAI/gpt-neox-'):
             state_dict = remap_state_dict_hf_gpt_neox(state_dict, config)
+        elif model_name.startswith('tiiuae/falcon-'):
+            state_dict = remap_state_dict_hf_falcon(state_dict, config)
         else:
             raise NotImplementedError(f'Model {model_name} not supported')
         if world_size > 1:
             state_dict = shard_state_dict_tp(state_dict, config, world_size, rank)
         load_return = model.load_state_dict(state_dict, strict=strict)
         logger.info(load_return)
         return model
@@ -497,45 +504,62 @@
     vocab_size = (math.ceil(config.vocab_size / pad_vocab_size_multiple) * pad_vocab_size_multiple)
     assert vocab_size % world_size == 0
     assert config.hidden_size % world_size == 0
     inner_dim = config.n_inner if config.n_inner is not None else 4 * config.hidden_size
     assert inner_dim % world_size == 0
 
     def shard_first_dim(state_dict, key):
-        x = state_dict[key]
-        dim = x.shape[0] // world_size
-        state_dict[key] = x[rank * dim:(rank + 1) * dim]
+        if key in state_dict:
+            x = state_dict[key]
+            dim = x.shape[0] // world_size
+            state_dict[key] = x[rank * dim:(rank + 1) * dim]
 
     def shard_last_dim(state_dict, key):
-        x = state_dict[key]
-        dim = x.shape[-1] // world_size
-        state_dict[key] = x[..., rank * dim:(rank + 1) * dim]
+        if key in state_dict:
+            x = state_dict[key]
+            dim = x.shape[-1] // world_size
+            state_dict[key] = x[..., rank * dim:(rank + 1) * dim]
 
     def shard_qkv_headdim(state_dict, key):
-        x = rearrange(state_dict[key], '(three d) ... -> three d ...', three=3)
-        dim = x.shape[1] // world_size
-        state_dict[key] = rearrange(x[:, rank * dim:(rank + 1) * dim],
-                                    'three d ... -> (three d) ...')
+        if key in state_dict:
+            n_head = config.n_head
+            n_head_kv = getattr(config, 'n_head_kv', n_head)
+            assert n_head % world_size == 0 and n_head_kv % world_size == 0
+            if n_head_kv == n_head:
+                x = rearrange(state_dict[key], '(three d) ... -> three d ...', three=3)
+                dim = x.shape[1] // world_size
+                state_dict[key] = rearrange(x[:, rank * dim:(rank + 1) * dim],
+                                            'three d ... -> (three d) ...')
+            else:
+                n_head_per_rank = n_head // world_size
+                n_head_kv_per_rank = n_head_kv // world_size
+                x = rearrange(state_dict[key], '(nheadqkv headdim) ... -> nheadqkv headdim ...',
+                              nheadqkv=n_head + 2 * n_head_kv)
+                state_dict[key] = rearrange(torch.cat([
+                    x[rank * n_head_per_rank:(rank + 1) * n_head_per_rank],
+                    x[n_head + rank * n_head_kv_per_rank:n_head + (rank + 1) * n_head_kv_per_rank],
+                    x[n_head + n_head_kv + rank * n_head_kv_per_rank:n_head + n_head_kv + (rank + 1) * n_head_kv_per_rank],
+                ], dim=0), "nheadqkv headdim ... -> (nheadqkv headdim) ...")
 
     shard_first_dim(state_dict, 'transformer.embeddings.word_embeddings.weight')
     if 'lm_head.weight' in state_dict:
         shard_first_dim(state_dict, 'lm_head.weight')
     if 'transformer.embeddings.position_embeddings.weight' in state_dict:
         shard_last_dim(state_dict, 'transformer.embeddings.position_embeddings.weight')
     for i in range(config.num_hidden_layers):
         shard_qkv_headdim(state_dict, f'transformer.layers.{i}.mixer.Wqkv.weight')
         shard_qkv_headdim(state_dict, f'transformer.layers.{i}.mixer.Wqkv.bias')
         shard_last_dim(state_dict, f'transformer.layers.{i}.mixer.out_proj.weight')
         if rank != 0:
-            state_dict.pop(f'transformer.layers.{i}.mixer.out_proj.bias')
+            state_dict.pop(f'transformer.layers.{i}.mixer.out_proj.bias', None)
         shard_first_dim(state_dict, f'transformer.layers.{i}.mlp.fc1.weight')
         shard_first_dim(state_dict, f'transformer.layers.{i}.mlp.fc1.bias')
         shard_last_dim(state_dict, f'transformer.layers.{i}.mlp.fc2.weight')
         if rank != 0:
-            state_dict.pop(f'transformer.layers.{i}.mlp.fc2.bias')
+            state_dict.pop(f'transformer.layers.{i}.mlp.fc2.bias', None)
     return state_dict
 
 
 def combine_state_dicts_tp(state_dicts, config):
     """Convert the state_dict of a standard GPT model to the state_dict of a GPT model
     with tensor parallel.
     """
@@ -555,17 +579,31 @@
         state_dict[key] = torch.cat([s[key] for s in state_dicts], dim=dim)
 
     def combine_dim(state_dicts, state_dict, key, dim=-1):
         if key in state_dict:
             state_dict[key] = torch.cat([s[key] for s in state_dicts], dim=dim)
 
     def combine_qkv_headdim(state_dicts, state_dict, key):
+        n_head = config.n_head
+        n_head_kv = getattr(config, 'n_head_kv', n_head)
+        assert n_head % world_size == 0 and n_head_kv % world_size == 0
+        n_head_per_rank = n_head // world_size
+        n_head_kv_per_rank = n_head_kv // world_size
         if key in state_dict:
-            xs = [rearrange(s[key], '(three d) ... -> three d ...', three=3) for s in state_dicts]
-            state_dict[key] = rearrange(torch.cat(xs, dim=1), 'three d ... -> (three d) ...')
+            if n_head_kv == n_head:
+                xs = [rearrange(s[key], '(three d) ... -> three d ...', three=3) for s in state_dicts]
+                state_dict[key] = rearrange(torch.cat(xs, dim=1), 'three d ... -> (three d) ...')
+            else:
+                xs = [rearrange(s[key], '(nheadqkv headdim) ... -> nheadqkv headdim ...',
+                                nheadqkv=n_head + 2 * n_head_kv) for s in state_dicts]
+                state_dict[key] = rearrange(torch.cat([
+                    torch.cat([x[:n_head_per_rank] for x in xs], dim=0),
+                    torch.cat([x[n_head_per_rank:n_head_per_rank + n_head_kv_per_rank] for x in xs], dim=0),
+                    torch.cat([x[-n_head_kv_per_rank:] for x in xs], dim=0),
+                ], dim=0), "nheadqkv headdim ... -> (nheadqkv headdim) ...")
 
     def combine_gated_mlp(state_dicts, state_dict, key):
         if key in state_dict:
             xs = [rearrange(s[key], '(two d) ... -> two d ...', two=2) for s in state_dicts]
             state_dict[key] = rearrange(torch.cat(xs, dim=1), 'two d ... -> (two d) ...')
 
     state_dict = state_dicts[0].copy()  # don't modify state_dict[0] inplace
```

### Comparing `flash_attn-2.0.0.post1/flash_attn/models/gpt_neox.py` & `flash_attn-2.0.1/flash_attn/models/gpt_neox.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/models/gptj.py` & `flash_attn-2.0.1/flash_attn/models/gptj.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/models/llama.py` & `flash_attn-2.0.1/flash_attn/models/llama.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/models/opt.py` & `flash_attn-2.0.1/flash_attn/models/opt.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/models/vit.py` & `flash_attn-2.0.1/flash_attn/models/vit.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/modules/block.py` & `flash_attn-2.0.1/flash_attn/modules/block.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 from functools import partial
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from torch import Tensor
 
-# from torchvision.ops import StochasticDepth
+from torchvision.ops import StochasticDepth
 
 from flash_attn.modules.mha import MHA
 from flash_attn.modules.mlp import Mlp
 
 try:
     from flash_attn.ops.layer_norm import dropout_add_layer_norm
 except ImportError:
@@ -66,20 +66,20 @@
             assert self.prenorm, 'residual_in_fp32 is only compatible with prenorm=True'
         if mixer_cls is None:
             mixer_cls = partial(MHA, num_heads=dim // 64)
         if mlp_cls is None:
             mlp_cls = partial(Mlp, hidden_features=4 * dim)
         self.mixer = mixer_cls(dim)
         self.dropout1 = dropout_cls(resid_dropout1)
-        # self.drop_path1 = StochasticDepth(drop_path1, mode='row')
+        self.drop_path1 = StochasticDepth(drop_path1, mode='row')
         self.norm1 = norm_cls(dim)
         self.mlp = mlp_cls(dim)
         if not isinstance(self.mlp, nn.Identity):
             self.dropout2 = dropout_cls(resid_dropout2)
-            # self.drop_path2 = StochasticDepth(drop_path2, mode='row')
+            self.drop_path2 = StochasticDepth(drop_path2, mode='row')
             self.norm2 = norm_cls(dim)
 
         if self.fused_dropout_add_ln:
             assert dropout_add_layer_norm is not None, 'dropout_layer_norm is not installed'
             assert dropout_add_rms_norm is not None, 'dropout_layer_norm is not installed'
             assert (isinstance(self.norm1, (nn.LayerNorm, RMSNorm))
                     and isinstance(self.dropout1, nn.Dropout))
@@ -125,22 +125,21 @@
             if not self.fused_dropout_add_ln:
                 dropped = self.drop_path1(self.dropout1(hidden_states))
                 residual = (dropped + residual) if residual is not None else dropped
                 hidden_states = self.norm1(residual.to(dtype=self.norm1.weight.dtype))
                 if self.residual_in_fp32:
                     residual = residual.to(torch.float32)
             else:
-                rowscale1 = None
-                # if self.drop_path1.p == 0 or not self.training:
-                #     rowscale1 = None
-                # else:
-                #     rowscale1 = self.drop_path1(torch.ones(
-                #         hidden_states.shape[:-1], device=hidden_states.device,
-                #         dtype=hidden_states.dtype)
-                #     )
+                if self.drop_path1.p == 0 or not self.training:
+                    rowscale1 = None
+                else:
+                    rowscale1 = self.drop_path1(torch.ones(
+                        hidden_states.shape[:-1], device=hidden_states.device,
+                        dtype=hidden_states.dtype)
+                    )
                 hidden_states, residual = fused_add_norm_fn(
                     hidden_states, residual, self.norm1.weight, self.norm1.bias,
                     self.dropout1.p if self.training else 0.0, self.norm1.eps,
                     rowscale=rowscale1, prenorm=True, residual_in_fp32=self.residual_in_fp32
                 )
             if mixer_kwargs is None:
                 mixer_kwargs = {}
@@ -153,22 +152,21 @@
                 if not self.fused_dropout_add_ln:
                     dropped = self.drop_path2(self.dropout2(hidden_states))
                     residual = (dropped + residual) if residual is not None else dropped
                     hidden_states = self.norm2(residual.to(dtype=self.norm2.weight.dtype))
                     if self.residual_in_fp32:
                         residual = residual.to(torch.float32)
                 else:
-                    # if self.drop_path2.p == 0 or not self.training:
-                    #     rowscale2 = None
-                    # else:
-                    #     rowscale2 = self.drop_path2(torch.ones(
-                    #         hidden_states.shape[:-1], device=hidden_states.device,
-                    #         dtype=hidden_states.dtype)
-                    #     )
-                    rowscale2 = None
+                    if self.drop_path2.p == 0 or not self.training:
+                        rowscale2 = None
+                    else:
+                        rowscale2 = self.drop_path2(torch.ones(
+                            hidden_states.shape[:-1], device=hidden_states.device,
+                            dtype=hidden_states.dtype)
+                        )
                     hidden_states, residual = fused_add_norm_fn(
                         hidden_states, residual, self.norm2.weight, self.norm2.bias,
                         self.dropout2.p if self.training else 0.0, self.norm2.eps,
                         rowscale=rowscale2, prenorm=True, residual_in_fp32=self.residual_in_fp32
                     )
                 hidden_states = self.mlp(hidden_states)
             return hidden_states, residual
@@ -274,23 +272,28 @@
         if mark_shared_params:
             for p in self.norm1.parameters():
                 p._shared_params = True
             if hasattr(self, 'norm2'):
                 for p in self.norm2.parameters():
                     p._shared_params = True
 
+    def allocate_inference_cache(self, batch_size, max_seqlen, dtype=None, **kwargs):
+        return self.mixer.allocate_inference_cache(batch_size, max_seqlen, dtype=dtype, **kwargs)
+
     def forward(self, hidden_states1: Tensor, hidden_states2: Optional[Tensor] = None,
                 residual: Optional[Tensor] = None, mixer_kwargs=None):
         r"""Pass the input through the encoder layer.
 
         Args:
             hidden_states1: the output of the previous attention (mixer) or embedding layer.
             hidden_states2: the output of the previous MLP layer (if None, will use hidden_states1).
             residual.
         """
+        # TODO: Ideally we should only do the allgather / allreduce once for
+        # the Linear to MLP & Attention
         fused_add_norm_fn = (dropout_add_rms_norm_parallel_residual
                              if isinstance(self.norm1, RMSNorm)
                              else dropout_add_layer_norm_parallel_residual)
         if not self.fused_dropout_add_ln:
             dropped1 = self.dropout1(hidden_states1)
             # For the very 1st block, we only want 1 dropout, not two different dropouts
             if hidden_states2 is not None:
```

### Comparing `flash_attn-2.0.0.post1/flash_attn/modules/embedding.py` & `flash_attn-2.0.1/flash_attn/modules/embedding.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/modules/mha.py` & `flash_attn-2.0.1/flash_attn/modules/mha.py`

 * *Files 12% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 import math
 from functools import partial
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from einops import rearrange
+from einops import rearrange, repeat
 
 try:
     from flash_attn import flash_attn_varlen_qkvpacked_func, flash_attn_varlen_kvpacked_func
     from flash_attn import flash_attn_qkvpacked_func, flash_attn_kvpacked_func
 except ImportError:
     flash_attn_varlen_qkvpacked_func, flash_attn_varlen_kvpacked_func = None, None
     flash_attn_qkvpacked_func, flash_attn_kvpacked_func = None, None
@@ -207,23 +207,25 @@
         self.drop = nn.Dropout(attention_dropout)
 
     def forward(self, q, kv, causal=None, key_padding_mask=None):
         """Implements the multihead softmax attention.
         Arguments
         ---------
             q: The tensor containing the query. (B, Sq, H, D)
-            kv: The tensor containing the key and value. (B, Sk, 2, H, D)
+            kv: The tensor containing the key and value. (B, Sk, 2, H_k, D)
             causal: if passed, will override self.causal
             key_padding_mask: boolean mask to apply to the attention weights. True means to keep,
                 False means to mask out. (B, Sk)
         """
         batch_size, seqlen_q = q.shape[0], q.shape[1]
         causal = self.causal if causal is None else causal
         seqlen_k = kv.shape[1]
-        assert kv.shape[0] == batch_size and kv.shape[3] == q.shape[2] and kv.shape[4] == q.shape[3]
+        assert kv.shape[0] == batch_size and kv.shape[4] == q.shape[3]
+        if kv.shape[3] != q.shape[2]:  # MQA/GQA
+            kv = repeat(kv, "... hkv d -> ... (hkv g) d", g=q.shape[2] // kv.shape[3])
         k, v = kv.unbind(dim=2)
         softmax_scale = self.softmax_scale or 1.0 / math.sqrt(q.shape[-1])
         scores = torch.einsum('bthd,bshd->bhts', q, k * softmax_scale)
         if key_padding_mask is not None:
             padding_mask = torch.full((batch_size, seqlen_k), -10000.0, dtype=scores.dtype,
                                       device=scores.device)
             padding_mask.masked_fill_(key_padding_mask, 0.0)
@@ -300,25 +302,60 @@
             )
             v_cache[batch_start:batch_end, :, :sequence_end, :] = rearrange(
                 kv[:, :, 1], 'b s h d -> b h s d'
             )
         return kv
 
 
+def _apply_rotary_single_query_attention(qkv, inference_params, layer_idx, rotary_emb_dim,
+                                         rotary_emb_base, kv=None, rotary_emb_interleaved=False):
+    """
+    qkv: (batch_size, 1, 3, nheads, head_dim) if kv is None else it's just
+            q of shape (batch_size, 1, nheads, head_dim)
+    kv: (batch_size, 1, 2, nheads_kv, head_dim)
+    """
+    assert inference_params.fused_ft_kernel
+    assert ft_attention is not None
+    if kv is None:
+        q, k, v = rearrange(qkv, 'b 1 three h d -> b three h d').unbind(dim=1)
+    else:
+        q = rearrange(qkv, 'b 1 h d -> b h d')
+        k, v = rearrange(kv, 'b 1 two h d -> b two h d').unbind(dim=1)
+    batch_start = inference_params.batch_size_offset
+    batch_end = batch_start + q.shape[0]
+    k_cache, v_cache = inference_params.key_value_memory_dict[layer_idx]
+    lengths_per_sample = (inference_params.lengths_per_sample[batch_start:batch_end]
+                            if inference_params.lengths_per_sample is not None else None)
+    context = ft_attention.single_query_attention(
+        q, k, v,
+        k_cache[batch_start:batch_end],
+        v_cache[batch_start:batch_end],
+        lengths_per_sample,
+        None,  # rotary_cos_
+        None,  # rotary_sin_
+        None,  # nnz_head_idx
+        inference_params.sequence_len_offset,
+        rotary_emb_dim, rotary_emb_base,
+        not rotary_emb_interleaved  # neox_rotary_style
+    )
+    return rearrange(context, 'b h d -> b 1 h d')
+
+
 class MHA(nn.Module):
     """Multi-head self-attention and cross-attention
     """
 
-    def __init__(self, embed_dim, num_heads, cross_attn=False,
+    def __init__(self, embed_dim, num_heads, num_heads_kv=None, cross_attn=False,
                  qkv_proj_bias=True, out_proj_bias=True,
                  dropout=0.0, softmax_scale=None, causal=False, layer_idx=None, dwconv=False,
                  rotary_emb_dim=0, rotary_emb_base=10000.0, rotary_emb_scale_base=None,
                  rotary_emb_interleaved=False, fused_bias_fc=False, use_flash_attn=False,
                  return_residual=False, checkpointing=False, device=None, dtype=None) -> None:
         """
+            num_heads_kv: can be used to toggle MQA / GQA. If None, use num_heads.
             return_residual: whether to return the input x along with the output. This is for
                 performance reason: for post-norm architecture, returning the input allows us
                 to fuse the backward of nn.Linear with the residual connection.
         """
         factory_kwargs = {'device': device, 'dtype': dtype}
         super().__init__()
         self.embed_dim = embed_dim
@@ -328,83 +365,91 @@
         self.dwconv = dwconv
         self.rotary_emb_dim = rotary_emb_dim
         self.use_flash_attn = use_flash_attn
         self.return_residual = return_residual
         self.checkpointing = checkpointing
 
         self.num_heads = num_heads
-        assert self.embed_dim % num_heads == 0, "self.kdim must be divisible by num_heads"
+        self.num_heads_kv = num_heads_kv if num_heads_kv is not None else num_heads
+        assert self.num_heads % self.num_heads_kv == 0, "num_heads must be divisible by num_heads_kv"
+        assert self.embed_dim % num_heads == 0, "embed_dim must be divisible by num_heads"
         self.head_dim = self.embed_dim // num_heads
+        qkv_dim = self.head_dim * (self.num_heads + 2 * self.num_heads_kv)
+        kv_dim = 2 * self.head_dim * self.num_heads_kv
 
         if self.rotary_emb_dim > 0:
             assert not cross_attn, 'MHA with rotary embedding does not support cross-attention yet'
             assert RotaryEmbedding is not None, 'rotary_emb is not installed'
             self.rotary_emb = RotaryEmbedding(self.rotary_emb_dim, base=rotary_emb_base,
                                               scale_base=rotary_emb_scale_base,
                                               interleaved=rotary_emb_interleaved, device=device)
 
         if fused_bias_fc and FusedDense is None:
             raise ImportError('fused_dense is not installed')
         linear_cls = nn.Linear if not fused_bias_fc else FusedDense
         linear_resid_cls = (LinearResidual if not fused_bias_fc
                             else partial(FusedDense, return_residual=True))
+        wqkv_cls = linear_cls if not self.return_residual else linear_resid_cls
         inner_attn_cls = FlashSelfAttention if use_flash_attn else SelfAttention
         inner_cross_attn_cls = FlashCrossAttention if use_flash_attn else CrossAttention
         if not self.cross_attn:
-            if not self.return_residual:
-                self.Wqkv = linear_cls(embed_dim, 3 * embed_dim, bias=qkv_proj_bias,
-                                       **factory_kwargs)
-            else:
-                self.Wqkv = linear_resid_cls(embed_dim, 3 * embed_dim, bias=qkv_proj_bias,
-                                             **factory_kwargs)
-            if self.dwconv:
-                self.dwconv_qkv = nn.Conv1d(3 * embed_dim, 3 * embed_dim, kernel_size=3, padding=2,
-                                            groups=3 * embed_dim)
+            self.Wqkv = wqkv_cls(embed_dim, qkv_dim, bias=qkv_proj_bias, **factory_kwargs)
         else:
             self.Wq = linear_cls(embed_dim, embed_dim, bias=qkv_proj_bias, **factory_kwargs)
-            if not self.return_residual:
-                self.Wkv = linear_cls(embed_dim, 2 * embed_dim, bias=qkv_proj_bias,
-                                      **factory_kwargs)
+            self.Wkv = wqkv_cls(embed_dim, kv_dim, bias=qkv_proj_bias, **factory_kwargs)
+        if self.dwconv:
+            if self.num_heads_kv == self.num_heads:
+                self.dwconv_qkv = nn.Conv1d(qkv_dim, qkv_dim, kernel_size=3, padding=2,
+                                            groups=qkv_dim)
             else:
-                self.Wkv = linear_resid_cls(embed_dim, 2 * embed_dim, bias=qkv_proj_bias,
-                                            **factory_kwargs)
-            if self.dwconv:
                 self.dwconv_q = nn.Conv1d(embed_dim, embed_dim, kernel_size=3, padding=2,
                                           groups=embed_dim)
-                self.dwconv_kv = nn.Conv1d(2 * embed_dim, 2 * embed_dim, kernel_size=3, padding=2,
-                                          groups=2 * embed_dim)
+                self.dwconv_kv = nn.Conv1d(kv_dim, kv_dim, kernel_size=3, padding=2,
+                                           groups=kv_dim)
         self.inner_attn = inner_attn_cls(causal=causal, softmax_scale=softmax_scale,
                                          attention_dropout=dropout)
         self.inner_cross_attn = inner_cross_attn_cls(causal=causal, softmax_scale=softmax_scale,
                                                      attention_dropout=dropout)
         self.out_proj = linear_cls(embed_dim, embed_dim, bias=out_proj_bias, **factory_kwargs)
 
     def allocate_inference_cache(self, batch_size, max_seqlen, dtype=None, fused_ft_kernel=True):
         dtype = self.out_proj.weight.dtype if dtype is None else dtype
         device = self.out_proj.weight.device
         if not fused_ft_kernel:
-            return torch.empty(batch_size, max_seqlen, 2, self.num_heads, self.head_dim,
+            return torch.empty(batch_size, max_seqlen, 2, self.num_heads_kv, self.head_dim,
                                dtype=dtype, device=device)
         else:
             assert dtype in [torch.float16, torch.bfloat16, torch.float32]
             packsize = 4 if dtype == torch.float32 else 8
             assert self.head_dim % packsize == 0
-            k_cache = torch.empty(batch_size, self.num_heads, self.head_dim // packsize, max_seqlen,
-                                  packsize, dtype=dtype, device=device)
-            v_cache = torch.empty(batch_size, self.num_heads, max_seqlen, self.head_dim,
+            k_cache = torch.empty(batch_size, self.num_heads_kv, self.head_dim // packsize,
+                                  max_seqlen, packsize, dtype=dtype, device=device)
+            v_cache = torch.empty(batch_size, self.num_heads_kv, max_seqlen, self.head_dim,
                                   dtype=dtype, device=device)
             return k_cache, v_cache
 
     def _update_kv_cache(self, kv, inference_params):
         """kv: (batch_size, seqlen, 2, nheads, head_dim) or (batch_size, 1, 2, nheads, head_dim)
         """
         assert not self.dwconv, 'Generation does not support dwconv yet'
         assert self.layer_idx is not None, 'Generation requires layer_idx in the constructor'
         return _update_kv_cache(kv, inference_params, self.layer_idx)
 
+    def _apply_rotary_single_query_attention(self, qkv, inference_params, kv=None):
+        """
+        qkv: (batch_size, 1, 3, nheads, head_dim) if kv is None else it's just
+              q of shape (batch_size, 1, nheads, head_dim)
+        kv: (batch_size, 1, 2, nheads_kv, head_dim)
+        """
+        rotary_emb_base = self.rotary_emb.base if self.rotary_emb_dim > 0 else 0
+        return _apply_rotary_single_query_attention(
+            qkv, inference_params, self.layer_idx, self.rotary_emb_dim, rotary_emb_base, kv=kv,
+            rotary_emb_interleaved=self.rotary_emb.interleaved if self.rotary_emb_dim > 0 else False,
+        )
+
     def forward(self, x, x_kv=None, key_padding_mask=None, cu_seqlens=None, max_seqlen=None,
                 mixer_subset=None, inference_params=None, **kwargs):
         """
         Arguments:
             x: (batch, seqlen, hidden_dim) (where hidden_dim = num heads * head dim) if
                 cu_seqlens is None and max_seqlen is None, else (total, hidden_dim) where total
                 is the is the sum of the sequence lengths in the batch.
@@ -434,190 +479,233 @@
         if inference_params is not None:
             assert key_padding_mask is None
             assert cu_seqlens is None and max_seqlen is None
             assert not self.dwconv
 
         kwargs = ({'cu_seqlens': cu_seqlens, 'max_seqlen': max_seqlen, **kwargs}
                   if self.use_flash_attn else {'key_padding_mask': key_padding_mask, **kwargs})
-        if not self.cross_attn:
+        seqlen_offset = 0 if inference_params is None else inference_params.sequence_len_offset
+        if not self.cross_attn and self.num_heads_kv == self.num_heads:
             assert x_kv is None and mixer_subset is None
             if not self.return_residual:
                 qkv = self.Wqkv(x)
             else:
                 qkv, x = self.Wqkv(x)
             if self.dwconv:
                 qkv = rearrange(self.dwconv_qkv(rearrange(qkv, 'b s d -> b d s'))[..., :-2],
                                 'b d s -> b s d').contiguous()
             qkv = rearrange(qkv, '... (three h d) -> ... three h d', three=3, d=self.head_dim)
-            if inference_params is None:
+            if (inference_params is None or inference_params.sequence_len_offset == 0
+                or not inference_params.fused_ft_kernel):
                 if self.rotary_emb_dim > 0:
-                    qkv = self.rotary_emb(qkv)
-                if not self.checkpointing:
-                    context = self.inner_attn(qkv, **kwargs)
+                    qkv = self.rotary_emb(qkv, seqlen_offset=seqlen_offset)
+                if inference_params is None:
+                    if not self.checkpointing:
+                        context = self.inner_attn(qkv, **kwargs)
+                    else:
+                        context = torch.utils.checkpoint.checkpoint(self.inner_attn, qkv,
+                                                                    **kwargs)
                 else:
-                    context = torch.utils.checkpoint.checkpoint(self.inner_attn, qkv, **kwargs)
-            else:
-                if (not inference_params.fused_ft_kernel) or inference_params.sequence_len_offset == 0:
-                    if self.rotary_emb_dim > 0:
-                        qkv = self.rotary_emb(qkv, seqlen_offset=inference_params.sequence_len_offset)
                     q = qkv[:, :, 0]
                     kv = self._update_kv_cache(qkv[:, :, 1:], inference_params)
                     # If we're processing the prompt, causal=None (use self.causal).
                     # If we're decoding, then causal=False.
                     causal = None if inference_params.sequence_len_offset == 0 else False
                     context = self.inner_cross_attn(q, kv, causal=causal)
-                else:
-                    assert inference_params.fused_ft_kernel
-                    assert ft_attention is not None
-                    batch_start = inference_params.batch_size_offset
-                    batch_end = batch_start + qkv.shape[0]
-                    k_cache, v_cache = inference_params.key_value_memory_dict[self.layer_idx]
-                    lengths_per_sample = (inference_params.lengths_per_sample[batch_start:batch_end]
-                                          if inference_params.lengths_per_sample is not None else None)
-                    rotary_emb_base = self.rotary_emb.base if self.rotary_emb_dim > 0 else 0
-                    context = ft_attention.single_query_attention(
-                        *rearrange(qkv, 'b 1 three h d -> b three h d').unbind(dim=1),
-                        k_cache[batch_start:batch_end],
-                        v_cache[batch_start:batch_end],
-                        lengths_per_sample,
-                        None,  # rotary_cos_
-                        None,  # rotary_sin_
-                        None,  # nnz_head_idx
-                        inference_params.sequence_len_offset,
-                        self.rotary_emb_dim, rotary_emb_base,
-                        # neox_rotary_style
-                        (not self.rotary_emb.interleaved) if self.rotary_emb_dim > 0 else True
-                    )
-                    context = rearrange(context, 'b h d -> b 1 h d')
+            else:
+                context = self._apply_rotary_single_query_attention(qkv, inference_params)
         else:
-            if not self.return_residual:
-                q = self.Wq(x if mixer_subset is None else x[:, mixer_subset])
-                kv = self.Wkv(x_kv if x_kv is not None else x)
+            if self.cross_attn:
+                if not self.return_residual:
+                    q = self.Wq(x if mixer_subset is None else x[:, mixer_subset])
+                    kv = self.Wkv(x_kv if x_kv is not None else x)
+                else:
+                    if x_kv is not None:
+                        kv, x_kv = self.Wkv(x_kv)
+                    else:
+                        kv, x = self.Wkv(x)
+                    q = self.Wq(x if mixer_subset is None else x[:, mixer_subset])
             else:
-                if x_kv is not None:
-                    kv, x_kv = self.Wkv(x_kv)
+                assert self.num_heads_kv != self.num_heads
+                if not self.return_residual:
+                    qkv = self.Wqkv(x)
                 else:
-                    kv, x = self.Wkv(x)
-                q = self.Wq(x if mixer_subset is None else x[:, mixer_subset])
+                    qkv, x = self.Wqkv(x)
+                q = qkv[..., :self.num_heads * self.head_dim]
+                kv = qkv[..., self.num_heads * self.head_dim:]
             q = rearrange(q, '... (h d) -> ... h d', d=self.head_dim)
-            kv = rearrange(kv, '... (two h d) -> ... two h d', two=2, d=self.head_dim)
+            kv = rearrange(kv, '... (two hkv d) -> ... two hkv d', two=2, d=self.head_dim)
             if self.dwconv:
                 q = rearrange(self.dwconv_q(rearrange(q, 'b s d -> b d s'))[..., :-2],
                               'b d s -> b s d').contiguous()
                 kv = rearrange(self.dwconv_kv(rearrange(kv, 'b s d -> b d s'))[..., :-2],
                                'b d s -> b s d').contiguous()
-            if inference_params is None:
-                if not self.checkpointing:
-                    context = self.inner_cross_attn(q, kv, **kwargs)
+            if (inference_params is None or inference_params.sequence_len_offset == 0
+                or not inference_params.fused_ft_kernel):
+                if self.rotary_emb_dim > 0:
+                    q, kv = self.rotary_emb(q, kv, seqlen_offset=seqlen_offset)
+                if inference_params is None:
+                    if not self.checkpointing:
+                        context = self.inner_cross_attn(q, kv, **kwargs)
+                    else:
+                        context = torch.utils.checkpoint.checkpoint(self.inner_cross_attn, q, kv,
+                                                                    **kwargs)
                 else:
-                    context = torch.utils.checkpoint.checkpoint(self.inner_cross_attn, q, kv, **kwargs)
+                    kv = self._update_kv_cache(kv, inference_params)
+                    # If we're processing the prompt, causal=None (use self.causal).
+                    # If we're decoding, then causal=False.
+                    causal = None if inference_params.sequence_len_offset == 0 else False
+                    context = self.inner_cross_attn(q, kv, causal=causal)
             else:
-                kv = self._update_kv_cache(kv)
-                context = self.inner_cross_attn(q, kv, causal=False)
+                context = self._apply_rotary_single_query_attention(q, inference_params, kv=kv)
         out = self.out_proj(rearrange(context, '... h d -> ... (h d)'))
         return out if not self.return_residual else (out, x)
 
 
 class ParallelMHA(nn.Module):
     """Multi-head self-attention and cross-attention
     """
 
-    def __init__(self, embed_dim, num_heads, process_group, qkv_proj_bias=True, out_proj_bias=True,
+    def __init__(self, embed_dim, num_heads, process_group, num_heads_kv=None,
+                 qkv_proj_bias=True, out_proj_bias=True,
                  dropout=0.0, softmax_scale=None, causal=False, layer_idx=None,
                  rotary_emb_dim=0, rotary_emb_base=10000.0, rotary_emb_scale_base=None,
                  rotary_emb_interleaved=False, use_flash_attn=False, checkpointing=False,
                  sequence_parallel=True, device=None, dtype=None) -> None:
         factory_kwargs = {'device': device, 'dtype': dtype}
         super().__init__()
         self.embed_dim = embed_dim
         self.causal = causal
         self.layer_idx = layer_idx
         self.rotary_emb_dim = rotary_emb_dim
         self.use_flash_attn = use_flash_attn
         self.checkpointing = checkpointing
+        self.process_group = process_group
+        self.world_size = process_group.size() if process_group is not None else 1
 
         self.num_heads = num_heads
-        assert self.embed_dim % num_heads == 0, "self.kdim must be divisible by num_heads"
+        self.num_heads_kv = num_heads_kv if num_heads_kv is not None else num_heads
+        self.num_heads_per_rank = num_heads // self.world_size
+        self.num_heads_kv_per_rank = self.num_heads_kv // self.world_size
+        assert self.num_heads % self.num_heads_kv == 0, "num_heads must be divisible by num_heads_kv"
+        assert self.embed_dim % num_heads == 0, "embed_dim must be divisible by num_heads"
+        assert self.num_heads_kv % self.world_size == 0, "num_heads_kv must be divisible by world_size"
         self.head_dim = self.embed_dim // num_heads
+        qkv_dim = self.head_dim * (self.num_heads + 2 * self.num_heads_kv)
+        kv_dim = 2 * self.head_dim * self.num_heads_kv
 
         if self.rotary_emb_dim > 0:
             assert RotaryEmbedding is not None, 'rotary_emb is not installed'
             self.rotary_emb = RotaryEmbedding(self.rotary_emb_dim, base=rotary_emb_base,
                                               scale_base=rotary_emb_scale_base,
                                               interleaved=rotary_emb_interleaved, device=device)
 
         if ColumnParallelLinear is None or RowParallelLinear is None:
             raise ImportError('fused_dense is not installed')
-        self.Wqkv = ColumnParallelLinear(embed_dim, 3 * embed_dim, process_group,
+        self.Wqkv = ColumnParallelLinear(embed_dim, qkv_dim, process_group,
                                          bias=qkv_proj_bias,
                                          sequence_parallel=sequence_parallel, **factory_kwargs)
         inner_attn_cls = FlashSelfAttention if use_flash_attn else SelfAttention
         inner_cross_attn_cls = FlashCrossAttention if use_flash_attn else CrossAttention
         self.inner_attn = inner_attn_cls(causal=causal, softmax_scale=softmax_scale,
                                          attention_dropout=dropout)
         self.inner_cross_attn = inner_cross_attn_cls(causal=causal, softmax_scale=softmax_scale,
                                                      attention_dropout=dropout)
         self.out_proj = RowParallelLinear(embed_dim, embed_dim, process_group,
                                           bias=out_proj_bias,
                                           sequence_parallel=sequence_parallel, **factory_kwargs)
 
+    def allocate_inference_cache(self, batch_size, max_seqlen, dtype=None, fused_ft_kernel=True):
+        dtype = self.out_proj.weight.dtype if dtype is None else dtype
+        device = self.out_proj.weight.device
+        if not fused_ft_kernel:
+            return torch.empty(batch_size, max_seqlen, 2, self.num_heads_kv_per_rank,
+                               self.head_dim, dtype=dtype, device=device)
+        else:
+            assert dtype in [torch.float16, torch.bfloat16, torch.float32]
+            packsize = 4 if dtype == torch.float32 else 8
+            assert self.head_dim % packsize == 0
+            k_cache = torch.empty(batch_size, self.num_heads_kv_per_rank,
+                                  self.head_dim // packsize,
+                                  max_seqlen, packsize, dtype=dtype, device=device)
+            v_cache = torch.empty(batch_size, self.num_heads_kv_per_rank, max_seqlen,
+                                  self.head_dim, dtype=dtype, device=device)
+            return k_cache, v_cache
+
+    def _update_kv_cache(self, kv, inference_params):
+        """kv: (batch_size, seqlen, 2, nheads, head_dim) or (batch_size, 1, 2, nheads, head_dim)
+        """
+        assert self.layer_idx is not None, 'Generation requires layer_idx in the constructor'
+        return _update_kv_cache(kv, inference_params, self.layer_idx)
+
+    def _apply_rotary_single_query_attention(self, qkv, inference_params, kv=None):
+        """
+        qkv: (batch_size, 1, 3, nheads, head_dim) if kv is None else it's just
+              q of shape (batch_size, 1, nheads, head_dim)
+        kv: (batch_size, 1, 2, nheads_kv, head_dim)
+        """
+        rotary_emb_base = self.rotary_emb.base if self.rotary_emb_dim > 0 else 0
+        return _apply_rotary_single_query_attention(
+            qkv, inference_params, self.layer_idx, self.rotary_emb_dim, rotary_emb_base, kv=kv,
+            rotary_emb_interleaved=self.rotary_emb.interleaved if self.rotary_emb_dim > 0 else False,
+        )
+
     def forward(self, x, seqlen=None, inference_params=None, **kwargs):
         """
         Arguments:
             x: (batch, seqlen, hidden_dim) (where hidden_dim = num heads * head dim) if seqlen=None.
                 If seqlen is not None, x is (batch * seqlen, hidden_dim). This is so that when we
                 split x during sequence parallel, we split the batch * seqlen dimension
                 (in case batch is small).
         """
         qkv = self.Wqkv(x)
-        if seqlen is None:
+        if seqlen is not None:
+            qkv = rearrange(qkv, "(b s) ... -> b s ...", s=seqlen)
+        seqlen_offset = 0 if inference_params is None else inference_params.sequence_len_offset
+        if self.num_heads_kv == self.num_heads:
             qkv = rearrange(qkv, 'b s (three h d) -> b s three h d', three=3, d=self.head_dim)
-        else:
-            qkv = rearrange(qkv, '(b s) (three h d) -> b s three h d', s=seqlen, three=3,
-                            d=self.head_dim)
-        if inference_params is None:
-            if self.rotary_emb_dim > 0:
-                qkv = self.rotary_emb(qkv)
-            if not self.checkpointing:
-                context = self.inner_attn(qkv, **kwargs)
+            if (inference_params is None or inference_params.sequence_len_offset == 0
+                or not inference_params.fused_ft_kernel):
+                if self.rotary_emb_dim > 0:
+                    qkv = self.rotary_emb(qkv, seqlen_offset=seqlen_offset)
+                if inference_params is None:
+                    if not self.checkpointing:
+                        context = self.inner_attn(qkv, **kwargs)
+                    else:
+                        context = torch.utils.checkpoint.checkpoint(self.inner_attn, qkv, **kwargs)
+                else:
+                    q = qkv[:, :, 0]
+                    kv = _update_kv_cache(qkv[:, :, 1:], inference_params, self.layer_idx)
+                    # If we're processing the prompt, causal=None (use self.causal).
+                    # If we're decoding, then causal=False.
+                    causal = None if inference_params.sequence_len_offset == 0 else False
+                    context = self.inner_cross_attn(q, kv, causal=causal)
             else:
-                context = torch.utils.checkpoint.checkpoint(self.inner_attn, qkv, **kwargs)
+                context = self._apply_rotary_single_query_attention(qkv, inference_params)
         else:
-            if (not inference_params.fused_ft_kernel) or inference_params.sequence_len_offset == 0:
+            q = rearrange(qkv[..., :self.num_heads_per_rank * self.head_dim],
+                          "... (h d) -> ... h d", d=self.head_dim)
+            kv = rearrange(qkv[..., self.num_heads_per_rank * self.head_dim:],
+                           "... (two hkv d) -> ... two hkv d", two=2, d=self.head_dim)
+            if (inference_params is None or inference_params.sequence_len_offset == 0
+                or not inference_params.fused_ft_kernel):
                 if self.rotary_emb_dim > 0:
-                    qkv = self.rotary_emb(qkv, seqlen_offset=inference_params.sequence_len_offset)
-                q = qkv[:, :, 0]
-                assert self.layer_idx is not None, 'Generation requires layer_idx in the constructor'
-                kv = _update_kv_cache(qkv[:, :, 1:], inference_params, self.layer_idx)
-                # If we're processing the prompt, causal=None (use self.causal).
-                # If we're decoding, then causal=False.
-                causal = None if inference_params.sequence_len_offset == 0 else False
-                context = self.inner_cross_attn(q, kv, causal=causal)
+                    q, kv = self.rotary_emb(q, kv, seqlen_offset=seqlen_offset)
+                if inference_params is None:
+                    if not self.checkpointing:
+                        context = self.inner_cross_attn(q, kv, **kwargs)
+                    else:
+                        context = torch.utils.checkpoint.checkpoint(self.inner_cross_attn, q, kv,
+                                                                    **kwargs)
+                else:
+                    kv = self._update_kv_cache(kv, inference_params)
+                    # If we're processing the prompt, causal=None (use self.causal).
+                    # If we're decoding, then causal=False.
+                    causal = None if inference_params.sequence_len_offset == 0 else False
+                    context = self.inner_cross_attn(q, kv, causal=causal)
             else:
-                assert inference_params.fused_ft_kernel
-                assert ft_attention is not None
-                batch_start = inference_params.batch_size_offset
-                batch_end = batch_start + qkv.shape[0]
-                k_cache, v_cache = inference_params.key_value_memory_dict[self.layer_idx]
-                lengths_per_sample = (inference_params.lengths_per_sample[batch_start:batch_end]
-                                      if inference_params.lengths_per_sample is not None else None)
-                rotary_emb_base = self.rotary_emb.base if self.rotary_emb_dim > 0 else 0
-                context = ft_attention.single_query_attention(
-                    *rearrange(qkv, 'b 1 three h d -> b three h d').unbind(dim=1),
-                    k_cache[batch_start:batch_end],
-                    v_cache[batch_start:batch_end],
-                    lengths_per_sample,
-                    None,  # rotary_cos_
-                    None,  # rotary_sin_
-                    None,  # nnz_head_idx
-                    inference_params.sequence_len_offset,
-                    self.rotary_emb_dim, rotary_emb_base,
-                    # neox_rotary_style
-                    (not self.rotary_emb.interleaved) if self.rotary_emb_dim > 0 else True
-                )
-                context = rearrange(context, 'b h d -> b 1 h d')
-        if seqlen is None:
-            context = rearrange(context, 'b s h d -> b s (h d)')
-        else:
-            context = rearrange(context, 'b s h d -> (b s) (h d)')
+                context = self._apply_rotary_single_query_attention(q, inference_params, kv=kv)
+        context = rearrange(context, 'b s h d -> b s (h d)')
+        if seqlen is not None:
+            context = rearrange(context, 'b s d -> (b s) d')
         out = self.out_proj(context)
         return out
```

### Comparing `flash_attn-2.0.0.post1/flash_attn/modules/mlp.py` & `flash_attn-2.0.1/flash_attn/modules/mlp.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,12 +1,18 @@
 # Copyright (c) 2022, Tri Dao.
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
+from torch.distributed import ProcessGroup
+
+try:
+    from flash_attn.ops.fused_dense import ColumnParallelLinear, RowParallelLinear
+except ImportError:
+    ColumnParallelLinear, RowParallelLinear = None, None
 
 try:
     from flash_attn.ops.fused_dense import FusedMLP, ParallelFusedMLP
 except ImportError:
     FusedMLP, ParallelFusedMLP = None, None
 
 
@@ -26,14 +32,38 @@
     def forward(self, x):
         y = self.fc1(x)
         y = self.activation(y)
         y = self.fc2(y)
         return y if not self.return_residual else (y, x)
 
 
+class ParallelMLP(nn.Module):
+
+    def __init__(self, in_features, hidden_features=None, out_features=None, activation=F.gelu,
+                 process_group: ProcessGroup = None, sequence_parallel=True,
+                 bias1=True, bias2=True, device=None, dtype=None):
+        factory_kwargs = {'device': device, 'dtype': dtype}
+        super().__init__()
+        assert ColumnParallelLinear is not None, "Need to install fused_dense"
+        assert RowParallelLinear is not None, "Need to install fused_dense"
+        out_features = out_features or in_features
+        hidden_features = hidden_features or in_features * 4
+        self.fc1 = ColumnParallelLinear(in_features, hidden_features, process_group, bias=bias1,
+                                        sequence_parallel=sequence_parallel, **factory_kwargs)
+        self.activation = activation
+        self.fc2 = RowParallelLinear(hidden_features, out_features, process_group, bias=bias2,
+                                     sequence_parallel=sequence_parallel, **factory_kwargs)
+
+    def forward(self, x):
+        y = self.fc1(x)
+        y = self.activation(y)
+        y = self.fc2(y)
+        return y
+
+
 class GatedMlp(nn.Module):
 
     def __init__(self, in_features, hidden_features=None, out_features=None, activation=F.sigmoid,
                  bias1=True, bias2=True, multiple_of=256, return_residual=False,
                  device=None, dtype=None):
         factory_kwargs = {'device': device, 'dtype': dtype}
         super().__init__()
```

### Comparing `flash_attn-2.0.0.post1/flash_attn/ops/activations.py` & `flash_attn-2.0.1/flash_attn/ops/activations.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/ops/fused_dense.py` & `flash_attn-2.0.1/flash_attn/ops/fused_dense.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/ops/layer_norm.py` & `flash_attn-2.0.1/flash_attn/ops/layer_norm.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/ops/rms_norm.py` & `flash_attn-2.0.1/flash_attn/ops/rms_norm.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/utils/benchmark.py` & `flash_attn-2.0.1/flash_attn/utils/benchmark.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/utils/distributed.py` & `flash_attn-2.0.1/flash_attn/utils/distributed.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/utils/generation.py` & `flash_attn-2.0.1/flash_attn/utils/generation.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn/utils/pretrained.py` & `flash_attn-2.0.1/flash_attn/utils/pretrained.py`

 * *Files identical despite different names*

### Comparing `flash_attn-2.0.0.post1/flash_attn.egg-info/SOURCES.txt` & `flash_attn-2.0.1/flash_attn.egg-info/SOURCES.txt`

 * *Files 2% similar despite different names*

```diff
@@ -1362,14 +1362,15 @@
 csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_foreach.h
 csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_norm.h
 csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.h
 csrc/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.hpp
 csrc/cutlass/tools/util/include/cutlass/util/reference/host/trmm.h
 csrc/cutlass/tools/util/include/cutlass/util/reference/host/trmm_complex.h
 csrc/flash_attn/flash_api.cpp
+csrc/flash_attn/fmha_api.cpp
 csrc/flash_attn/src/block_info.h
 csrc/flash_attn/src/flash.h
 csrc/flash_attn/src/flash_bwd_hdim128_bf16_sm80.cu
 csrc/flash_attn/src/flash_bwd_hdim128_fp16_sm80.cu
 csrc/flash_attn/src/flash_bwd_hdim160_bf16_sm80.cu
 csrc/flash_attn/src/flash_bwd_hdim160_fp16_sm80.cu
 csrc/flash_attn/src/flash_bwd_hdim192_bf16_sm80.cu
@@ -1400,20 +1401,45 @@
 csrc/flash_attn/src/flash_fwd_hdim32_fp16_sm80.cu
 csrc/flash_attn/src/flash_fwd_hdim64_bf16_sm80.cu
 csrc/flash_attn/src/flash_fwd_hdim64_fp16_sm80.cu
 csrc/flash_attn/src/flash_fwd_hdim96_bf16_sm80.cu
 csrc/flash_attn/src/flash_fwd_hdim96_fp16_sm80.cu
 csrc/flash_attn/src/flash_fwd_kernel.h
 csrc/flash_attn/src/flash_fwd_launch_template.h
+csrc/flash_attn/src/fmha.h
+csrc/flash_attn/src/fmha_block_dgrad_fp16_kernel_loop.sm80.cu
+csrc/flash_attn/src/fmha_block_dgrad_kernel_1xN_loop.h
+csrc/flash_attn/src/fmha_block_fprop_fp16_kernel.sm80.cu
+csrc/flash_attn/src/fmha_block_fprop_kernel_1xN.h
+csrc/flash_attn/src/fmha_blockmask.h
+csrc/flash_attn/src/fmha_bwd_hdim128.cu
+csrc/flash_attn/src/fmha_bwd_hdim32.cu
+csrc/flash_attn/src/fmha_bwd_hdim64.cu
+csrc/flash_attn/src/fmha_bwd_launch_template.h
+csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h
+csrc/flash_attn/src/fmha_fprop_kernel_1xN.h
+csrc/flash_attn/src/fmha_fwd_hdim128.cu
+csrc/flash_attn/src/fmha_fwd_hdim32.cu
+csrc/flash_attn/src/fmha_fwd_hdim64.cu
+csrc/flash_attn/src/fmha_fwd_launch_template.h
+csrc/flash_attn/src/fmha_kernel.h
+csrc/flash_attn/src/fmha_utils.h
 csrc/flash_attn/src/kernel_traits.h
 csrc/flash_attn/src/kernel_traits_sm90.h
 csrc/flash_attn/src/philox.cuh
 csrc/flash_attn/src/softmax.h
 csrc/flash_attn/src/static_switch.h
 csrc/flash_attn/src/utils.h
+csrc/flash_attn/src/fmha/gemm.h
+csrc/flash_attn/src/fmha/gmem_tile.h
+csrc/flash_attn/src/fmha/kernel_traits.h
+csrc/flash_attn/src/fmha/mask.h
+csrc/flash_attn/src/fmha/smem_tile.h
+csrc/flash_attn/src/fmha/softmax.h
+csrc/flash_attn/src/fmha/utils.h
 csrc/flash_gen/decoder_masked_multihead_attention.cu
 csrc/ft_attention/cuda_bf16_fallbacks.cuh
 csrc/ft_attention/cuda_bf16_wrapper.h
 csrc/ft_attention/decoder_masked_multihead_attention.cu
 csrc/ft_attention/decoder_masked_multihead_attention.h
 csrc/ft_attention/decoder_masked_multihead_attention_template.hpp
 csrc/ft_attention/decoder_masked_multihead_attention_utils.h
@@ -1524,14 +1550,15 @@
 flash_attn/layers/__init__.py
 flash_attn/layers/patch_embed.py
 flash_attn/layers/rotary.py
 flash_attn/losses/__init__.py
 flash_attn/losses/cross_entropy.py
 flash_attn/models/__init__.py
 flash_attn/models/bert.py
+flash_attn/models/falcon.py
 flash_attn/models/gpt.py
 flash_attn/models/gpt_neox.py
 flash_attn/models/gptj.py
 flash_attn/models/llama.py
 flash_attn/models/opt.py
 flash_attn/models/vit.py
 flash_attn/modules/__init__.py
```

### Comparing `flash_attn-2.0.0.post1/setup.py` & `flash_attn-2.0.1/setup.py`

 * *Files identical despite different names*

