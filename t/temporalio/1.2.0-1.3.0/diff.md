# Comparing `tmp/temporalio-1.2.0.tar.gz` & `tmp/temporalio-1.3.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "temporalio-1.2.0.tar", max compression
+gzip compressed data, was "temporalio-1.3.0.tar", max compression
```

## Comparing `temporalio-1.2.0.tar` & `temporalio-1.3.0.tar`

### file list

```diff
@@ -1,484 +1,487 @@
--rw-r--r--   0        0        0     1108 2023-05-01 12:07:40.748777 temporalio-1.2.0/LICENSE
--rw-r--r--   0        0        0    66076 2023-05-01 12:07:40.748777 temporalio-1.2.0/README.md
--rw-r--r--   0        0        0      899 2023-05-01 12:07:40.748777 temporalio-1.2.0/build.py
--rw-r--r--   0        0        0     6369 2023-05-01 12:07:40.748777 temporalio-1.2.0/pyproject.toml
--rw-r--r--   0        0        0      423 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/__init__.py
--rw-r--r--   0        0        0    14172 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/activity.py
--rw-r--r--   0        0        0       36 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/__init__.py
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/batch/__init__.py
--rw-r--r--   0        0        0      336 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/batch/v1/__init__.py
--rw-r--r--   0        0        0     5919 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/batch/v1/message_pb2.py
--rw-r--r--   0        0        0     7644 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/batch/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/cluster/__init__.py
--rw-r--r--   0        0        0      286 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/cluster/v1/__init__.py
--rw-r--r--   0        0        0     5853 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/cluster/v1/message_pb2.py
--rw-r--r--   0        0        0    11757 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/cluster/v1/message_pb2.pyi
--rw-r--r--   0        0        0      158 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/cluster/v1/message_pb2_grpc.py
--rw-r--r--   0        0        0     1185 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/cluster/v1/message_pb2_grpc.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/command/__init__.py
--rw-r--r--   0        0        0     1476 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/command/v1/__init__.py
--rw-r--r--   0        0        0    25839 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/command/v1/message_pb2.py
--rw-r--r--   0        0        0    44096 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/command/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/common/__init__.py
--rw-r--r--   0        0        0      604 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/common/v1/__init__.py
--rw-r--r--   0        0        0     1540 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/common/v1/grpc_status_pb2.py
--rw-r--r--   0        0        0     1462 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/common/v1/grpc_status_pb2.pyi
--rw-r--r--   0        0        0    13347 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/common/v1/message_pb2.py
--rw-r--r--   0        0        0    16350 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/common/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/dependencies/__init__.py
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/dependencies/gogoproto/__init__.py
--rw-r--r--   0        0        0    22341 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/dependencies/gogoproto/gogo_pb2.py
--rw-r--r--   0        0        0    15976 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/dependencies/gogoproto/gogo_pb2.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/__init__.py
--rw-r--r--   0        0        0     1917 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/__init__.py
--rw-r--r--   0        0        0     2619 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/batch_operation_pb2.py
--rw-r--r--   0        0        0     3777 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/batch_operation_pb2.pyi
--rw-r--r--   0        0        0     3050 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/command_type_pb2.py
--rw-r--r--   0        0        0     4307 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/command_type_pb2.pyi
--rw-r--r--   0        0        0     2980 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/common_pb2.py
--rw-r--r--   0        0        0     4571 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/common_pb2.pyi
--rw-r--r--   0        0        0     6323 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/event_type_pb2.py
--rw-r--r--   0        0        0    19994 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/event_type_pb2.pyi
--rw-r--r--   0        0        0     9630 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/failed_cause_pb2.py
--rw-r--r--   0        0        0    18937 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/failed_cause_pb2.pyi
--rw-r--r--   0        0        0     2747 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/namespace_pb2.py
--rw-r--r--   0        0        0     4174 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/namespace_pb2.pyi
--rw-r--r--   0        0        0     2353 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/query_pb2.py
--rw-r--r--   0        0        0     3983 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/query_pb2.pyi
--rw-r--r--   0        0        0     1699 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/reset_pb2.py
--rw-r--r--   0        0        0     2543 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/reset_pb2.pyi
--rw-r--r--   0        0        0     2149 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/schedule_pb2.py
--rw-r--r--   0        0        0     5644 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/enums/v1/schedule_pb2.pyi
--rw-r--r--   0        0        0     2151 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/enums/v1/task_queue_pb2.py
--rw-r--r--   0        0        0     4744 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/enums/v1/task_queue_pb2.pyi
--rw-r--r--   0        0        0     2140 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/enums/v1/update_pb2.py
--rw-r--r--   0        0        0     4852 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/enums/v1/update_pb2.pyi
--rw-r--r--   0        0        0     7735 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/enums/v1/workflow_pb2.py
--rw-r--r--   0        0        0    15052 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/enums/v1/workflow_pb2.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/errordetails/__init__.py
--rw-r--r--   0        0        0      974 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/errordetails/v1/__init__.py
--rw-r--r--   0        0        0    12041 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/errordetails/v1/message_pb2.py
--rw-r--r--   0        0        0    10149 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/errordetails/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/failure/__init__.py
--rw-r--r--   0        0        0      530 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/failure/v1/__init__.py
--rw-r--r--   0        0        0     9303 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/failure/v1/message_pb2.py
--rw-r--r--   0        0        0    16245 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/failure/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/filter/__init__.py
--rw-r--r--   0        0        0      236 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/filter/v1/__init__.py
--rw-r--r--   0        0        0     4569 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/filter/v1/message_pb2.py
--rw-r--r--   0        0        0     4131 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/filter/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/history/__init__.py
--rw-r--r--   0        0        0     4622 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/history/v1/__init__.py
--rw-r--r--   0        0        0    73415 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/history/v1/message_pb2.py
--rw-r--r--   0        0        0   149420 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/history/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/interaction/__init__.py
--rw-r--r--   0        0        0      129 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/interaction/v1/__init__.py
--rw-r--r--   0        0        0     4385 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/interaction/v1/message_pb2.py
--rw-r--r--   0        0        0     7155 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/interaction/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/namespace/__init__.py
--rw-r--r--   0        0        0      300 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/namespace/v1/__init__.py
--rw-r--r--   0        0        0    10762 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/namespace/v1/message_pb2.py
--rw-r--r--   0        0        0    12925 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/namespace/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/operatorservice/__init__.py
--rw-r--r--   0        0        0     1423 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/operatorservice/v1/__init__.py
--rw-r--r--   0        0        0    17665 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/operatorservice/v1/request_response_pb2.py
--rw-r--r--   0        0        0    15710 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/operatorservice/v1/request_response_pb2.pyi
--rw-r--r--   0        0        0      158 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/operatorservice/v1/request_response_pb2_grpc.py
--rw-r--r--   0        0        0     1185 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/operatorservice/v1/request_response_pb2_grpc.pyi
--rw-r--r--   0        0        0     2899 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/operatorservice/v1/service_pb2.py
--rw-r--r--   0        0        0     1274 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/operatorservice/v1/service_pb2.pyi
--rw-r--r--   0        0        0    17632 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/operatorservice/v1/service_pb2_grpc.py
--rw-r--r--   0        0        0     8793 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/operatorservice/v1/service_pb2_grpc.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/protocol/__init__.py
--rw-r--r--   0        0        0       63 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/protocol/v1/__init__.py
--rw-r--r--   0        0        0     2034 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/protocol/v1/message_pb2.py
--rw-r--r--   0        0        0     3657 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/protocol/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/query/__init__.py
--rw-r--r--   0        0        0      159 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/query/v1/__init__.py
--rw-r--r--   0        0        0     3696 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/query/v1/message_pb2.py
--rw-r--r--   0        0        0     5000 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/query/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/replication/__init__.py
--rw-r--r--   0        0        0      214 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/replication/v1/__init__.py
--rw-r--r--   0        0        0     4122 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/replication/v1/message_pb2.py
--rw-r--r--   0        0        0     4288 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/replication/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/schedule/__init__.py
--rw-r--r--   0        0        0      732 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/schedule/v1/__init__.py
--rw-r--r--   0        0        0    18729 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/schedule/v1/message_pb2.py
--rw-r--r--   0        0        0    38470 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/schedule/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/sdk/__init__.py
--rw-r--r--   0        0        0      122 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/sdk/v1/__init__.py
--rw-r--r--   0        0        0     1979 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/sdk/v1/task_complete_metadata_pb2.py
--rw-r--r--   0        0        0     4074 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/sdk/v1/task_complete_metadata_pb2.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/taskqueue/__init__.py
--rw-r--r--   0        0        0      422 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/taskqueue/v1/__init__.py
--rw-r--r--   0        0        0     8133 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/taskqueue/v1/message_pb2.py
--rw-r--r--   0        0        0    10314 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/taskqueue/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/testservice/__init__.py
--rw-r--r--   0        0        0      814 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/testservice/v1/__init__.py
--rw-r--r--   0        0        0     7303 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/testservice/v1/request_response_pb2.py
--rw-r--r--   0        0        0     4609 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/testservice/v1/request_response_pb2.pyi
--rw-r--r--   0        0        0      158 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/testservice/v1/request_response_pb2_grpc.py
--rw-r--r--   0        0        0     1185 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/testservice/v1/request_response_pb2_grpc.pyi
--rw-r--r--   0        0        0     2532 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/testservice/v1/service_pb2.py
--rw-r--r--   0        0        0     1274 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/testservice/v1/service_pb2.pyi
--rw-r--r--   0        0        0    14985 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/testservice/v1/service_pb2_grpc.py
--rw-r--r--   0        0        0     9065 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/testservice/v1/service_pb2_grpc.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/update/__init__.py
--rw-r--r--   0        0        0      308 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/update/v1/__init__.py
--rw-r--r--   0        0        0     7265 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/update/v1/message_pb2.py
--rw-r--r--   0        0        0    11510 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/update/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/version/__init__.py
--rw-r--r--   0        0        0      123 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/version/v1/__init__.py
--rw-r--r--   0        0        0     4064 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/version/v1/message_pb2.py
--rw-r--r--   0        0        0     5233 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/version/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflow/__init__.py
--rw-r--r--   0        0        0      476 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflow/v1/__init__.py
--rw-r--r--   0        0        0    15395 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflow/v1/message_pb2.py
--rw-r--r--   0        0        0    24729 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflow/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflowservice/__init__.py
--rw-r--r--   0        0        0     8749 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflowservice/v1/__init__.py
--rw-r--r--   0        0        0   128676 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflowservice/v1/request_response_pb2.py
--rw-r--r--   0        0        0   195808 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflowservice/v1/request_response_pb2.pyi
--rw-r--r--   0        0        0      158 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflowservice/v1/request_response_pb2_grpc.py
--rw-r--r--   0        0        0     1185 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflowservice/v1/request_response_pb2_grpc.pyi
--rw-r--r--   0        0        0    12060 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflowservice/v1/service_pb2.py
--rw-r--r--   0        0        0     1274 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflowservice/v1/service_pb2.pyi
--rw-r--r--   0        0        0   133717 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflowservice/v1/service_pb2_grpc.py
--rw-r--r--   0        0        0    65016 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflowservice/v1/service_pb2_grpc.pyi
--rw-r--r--   0        0        0    75582 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/Cargo.lock
--rw-r--r--   0        0        0      834 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/Cargo.toml
--rw-r--r--   0        0        0      122 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/__init__.py
--rw-r--r--   0        0        0     3601 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/client.py
--rw-r--r--   0        0        0      144 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/__init__.py
--rw-r--r--   0        0        0      336 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/activity_result/__init__.py
--rw-r--r--   0        0        0     6517 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/activity_result/activity_result_pb2.py
--rw-r--r--   0        0        0     9319 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/activity_result/activity_result_pb2.pyi
--rw-r--r--   0        0        0      171 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/activity_task/__init__.py
--rw-r--r--   0        0        0     5900 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/activity_task/activity_task_pb2.py
--rw-r--r--   0        0        0    11710 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/activity_task/activity_task_pb2.pyi
--rw-r--r--   0        0        0     1435 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/bridge/__init__.py
--rw-r--r--   0        0        0    33694 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/bridge/bridge_pb2.py
--rw-r--r--   0        0        0    35620 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/bridge/bridge_pb2.pyi
--rw-r--r--   0        0        0      407 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/child_workflow/__init__.py
--rw-r--r--   0        0        0     6028 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/child_workflow/child_workflow_pb2.py
--rw-r--r--   0        0        0     9065 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/child_workflow/child_workflow_pb2.pyi
--rw-r--r--   0        0        0      102 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/common/__init__.py
--rw-r--r--   0        0        0     1808 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/common/common_pb2.py
--rw-r--r--   0        0        0     1438 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/common/common_pb2.pyi
--rw-r--r--   0        0        0     4340 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/core_interface_pb2.py
--rw-r--r--   0        0        0     2437 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/core_interface_pb2.pyi
--rw-r--r--   0        0        0      158 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/core_interface_pb2_grpc.py
--rw-r--r--   0        0        0       76 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/core_interface_pb2_grpc.pyi
--rw-r--r--   0        0        0      145 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/external_data/__init__.py
--rw-r--r--   0        0        0     2882 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/external_data/external_data_pb2.py
--rw-r--r--   0        0        0     4346 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/external_data/external_data_pb2.pyi
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/health/__init__.py
--rw-r--r--   0        0        0      132 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/health/v1/__init__.py
--rw-r--r--   0        0        0     3055 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/health/v1/health_pb2.py
--rw-r--r--   0        0        0     2546 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/health/v1/health_pb2.pyi
--rw-r--r--   0        0        0     1138 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/workflow_activation/__init__.py
--rw-r--r--   0        0        0    22930 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/workflow_activation/workflow_activation_pb2.py
--rw-r--r--   0        0        0    42958 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/workflow_activation/workflow_activation_pb2.pyi
--rw-r--r--   0        0        0     1318 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/workflow_commands/__init__.py
--rw-r--r--   0        0        0    34647 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/workflow_commands/workflow_commands_pb2.py
--rw-r--r--   0        0        0    59232 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/workflow_commands/workflow_commands_pb2.pyi
--rw-r--r--   0        0        0      165 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/workflow_completion/__init__.py
--rw-r--r--   0        0        0     3971 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/workflow_completion/workflow_completion_pb2.py
--rw-r--r--   0        0        0     4425 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/workflow_completion/workflow_completion_pb2.pyi
--rw-r--r--   0        0        0     1961 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/runtime.py
--rw-r--r--   0        0        0      198 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/.buildkite/docker/Dockerfile
--rwxr-xr-x   0        0        0       45 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/.buildkite/docker/build.sh
--rw-r--r--   0        0        0      616 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose-ci.yaml
--rw-r--r--   0        0        0      963 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose-telem.yaml
--rw-r--r--   0        0        0      839 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose.yaml
--rw-r--r--   0        0        0     1600 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/.buildkite/pipeline.yml
--rw-r--r--   0        0        0      523 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/.cargo/config.toml
--rw-r--r--   0        0        0       39 2023-05-01 12:07:41.304783 temporalio-1.2.0/temporalio/bridge/sdk-core/.git
--rw-r--r--   0        0        0      695 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/.github/workflows/heavy.yml
--rw-r--r--   0        0        0      278 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/.gitignore
--rw-r--r--   0        0        0     7864 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/ARCHITECTURE.md
--rw-r--r--   0        0        0       36 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/CODEOWNERS
--rw-r--r--   0        0        0      100 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/Cargo.toml
--rw-r--r--   0        0        0     1127 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/LICENSE.txt
--rw-r--r--   0        0        0     4911 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/README.md
--rw-r--r--   0        0        0      555 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/arch_docs/diagrams/README.md
--rw-r--r--   0        0        0     1029 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/arch_docs/diagrams/sticky_queues.puml
--rw-r--r--   0        0        0   112308 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/arch_docs/diagrams/workflow_internals.svg
--rw-r--r--   0        0        0     3212 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/arch_docs/sticky_queues.md
--rw-r--r--   0        0        0      982 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/client/Cargo.toml
--rw-r--r--   0        0        0     1127 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/client/LICENSE.txt
--rw-r--r--   0        0        0    53761 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/client/src/lib.rs
--rw-r--r--   0        0        0     6081 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/client/src/metrics.rs
--rw-r--r--   0        0        0    32570 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/client/src/raw.rs
--rw-r--r--   0        0        0    25022 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/client/src/retry.rs
--rw-r--r--   0        0        0     6852 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/client/src/workflow_handle/mod.rs
--rw-r--r--   0        0        0     3569 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/Cargo.toml
--rw-r--r--   0        0        0     1127 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/LICENSE.txt
--rw-r--r--   0        0        0     2426 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/benches/workflow_replay.rs
--rw-r--r--   0        0        0      836 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/abstractions/take_cell.rs
--rw-r--r--   0        0        0    12182 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/abstractions.rs
--rw-r--r--   0        0        0    39245 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/activity_tasks.rs
--rw-r--r--   0        0        0     8003 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/child_workflows.rs
--rw-r--r--   0        0        0    10823 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/determinism.rs
--rw-r--r--   0        0        0    39633 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/local_activities.rs
--rw-r--r--   0        0        0     3130 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/mod.rs
--rw-r--r--   0        0        0    30792 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/queries.rs
--rw-r--r--   0        0        0     2452 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/replay_flag.rs
--rw-r--r--   0        0        0     9544 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/workers.rs
--rw-r--r--   0        0        0     4233 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/workflow_cancels.rs
--rw-r--r--   0        0        0    94977 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/workflow_tasks.rs
--rw-r--r--   0        0        0    21721 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/ephemeral_server/mod.rs
--rw-r--r--   0        0        0     8574 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/internal_flags.rs
--rw-r--r--   0        0        0    10566 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/lib.rs
--rw-r--r--   0        0        0     1852 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/pollers/mod.rs
--rw-r--r--   0        0        0     9552 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/pollers/poll_buffer.rs
--rw-r--r--   0        0        0    15879 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/protosext/mod.rs
--rw-r--r--   0        0        0     7392 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/replay/mod.rs
--rw-r--r--   0        0        0     6553 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/retry_logic.rs
--rw-r--r--   0        0        0     6400 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/telemetry/log_export.rs
--rw-r--r--   0        0        0    16399 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/telemetry/metrics.rs
--rw-r--r--   0        0        0    16464 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/telemetry/mod.rs
--rw-r--r--   0        0        0     3055 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/telemetry/prometheus_server.rs
--rw-r--r--   0        0        0    32518 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/test_help/mod.rs
--rw-r--r--   0        0        0    22866 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/activities/activity_heartbeat_manager.rs
--rw-r--r--   0        0        0     3324 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/activities/activity_task_poller_stream.rs
--rw-r--r--   0        0        0    49177 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/activities/local_activities.rs
--rw-r--r--   0        0        0    28757 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/activities.rs
--rw-r--r--   0        0        0     4017 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/client/mocks.rs
--rw-r--r--   0        0        0    13150 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/client.rs
--rw-r--r--   0        0        0    25181 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/mod.rs
--rw-r--r--   0        0        0     1203 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/bridge.rs
--rw-r--r--   0        0        0     3770 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/driven_workflow.rs
--rw-r--r--   0        0        0    73489 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/history_update.rs
--rw-r--r--   0        0        0    34072 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/activity_state_machine.rs
--rw-r--r--   0        0        0    10483 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/cancel_external_state_machine.rs
--rw-r--r--   0        0        0     5365 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/cancel_workflow_state_machine.rs
--rw-r--r--   0        0        0    36281 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/child_workflow_state_machine.rs
--rw-r--r--   0        0        0     4187 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/complete_workflow_state_machine.rs
--rw-r--r--   0        0        0     5137 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/continue_as_new_workflow_state_machine.rs
--rw-r--r--   0        0        0     3903 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/fail_workflow_state_machine.rs
--rw-r--r--   0        0        0    62534 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/local_activity_state_machine.rs
--rw-r--r--   0        0        0    11457 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/mod.rs
--rw-r--r--   0        0        0     5524 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/modify_workflow_properties_state_machine.rs
--rw-r--r--   0        0        0    31795 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/patch_state_machine.rs
--rw-r--r--   0        0        0    15993 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/signal_external_state_machine.rs
--rw-r--r--   0        0        0    14721 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/timer_state_machine.rs
--rw-r--r--   0        0        0     7813 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/transition_coverage.rs
--rw-r--r--   0        0        0    14499 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/upsert_search_attributes_state_machine.rs
--rw-r--r--   0        0        0     3069 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_machines/local_acts.rs
--rw-r--r--   0        0        0    59636 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_machines.rs
--rw-r--r--   0        0        0     8693 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_task_state_machine.rs
--rw-r--r--   0        0        0     7766 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/managed_run/managed_wf_test.rs
--rw-r--r--   0        0        0    55315 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/managed_run.rs
--rw-r--r--   0        0        0    53007 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/mod.rs
--rw-r--r--   0        0        0     4561 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/run_cache.rs
--rw-r--r--   0        0        0     5425 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/wft_extraction.rs
--rw-r--r--   0        0        0     3213 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/wft_poller.rs
--rw-r--r--   0        0        0     4024 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/workflow_stream/saved_wf_inputs.rs
--rw-r--r--   0        0        0      509 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/workflow_stream/tonic_status_serde.rs
--rw-r--r--   0        0        0    29983 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/workflow_stream.rs
--rw-r--r--   0        0        0      885 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/Cargo.toml
--rw-r--r--   0        0        0     1127 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/LICENSE.txt
--rw-r--r--   0        0        0     2912 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/src/errors.rs
--rw-r--r--   0        0        0     6826 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/src/lib.rs
--rw-r--r--   0        0        0     5542 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/src/telemetry.rs
--rw-r--r--   0        0        0     8185 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/src/worker.rs
--rw-r--r--   0        0        0     7987 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/etc/deps.svg
--rw-r--r--   0        0        0       51 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/etc/dynamic-config.yaml
--rw-r--r--   0        0        0      574 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/etc/otel-collector-config.yaml
--rw-r--r--   0        0        0      173 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/etc/prometheus.yaml
--rwxr-xr-x   0        0        0      204 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/etc/regen-depgraph.sh
--rw-r--r--   0        0        0      574 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/Cargo.toml
--rw-r--r--   0        0        0     1127 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/LICENSE.txt
--rw-r--r--   0        0        0      126 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/README.md
--rw-r--r--   0        0        0      609 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/Cargo.toml
--rw-r--r--   0        0        0     1127 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/LICENSE.txt
--rw-r--r--   0        0        0    26246 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/src/lib.rs
--rw-r--r--   0        0        0      191 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/progress.rs
--rw-r--r--   0        0        0      299 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/dupe_transitions_fail.rs
--rw-r--r--   0        0        0      387 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/dupe_transitions_fail.stderr
--rw-r--r--   0        0        0      892 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/dynamic_dest_pass.rs
--rw-r--r--   0        0        0      202 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/forgot_name_fail.rs
--rw-r--r--   0        0        0      331 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/forgot_name_fail.stderr
--rw-r--r--   0        0        0      686 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/handler_arg_pass.rs
--rw-r--r--   0        0        0      619 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/handler_pass.rs
--rw-r--r--   0        0        0      862 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/medium_complex_pass.rs
--rw-r--r--   0        0        0      584 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/no_handle_conversions_require_into_fail.rs
--rw-r--r--   0        0        0      562 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/no_handle_conversions_require_into_fail.stderr
--rw-r--r--   0        0        0      649 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/simple_pass.rs
--rw-r--r--   0        0        0      307 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/struct_event_variant_fail.rs
--rw-r--r--   0        0        0      161 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/struct_event_variant_fail.stderr
--rw-r--r--   0        0        0      184 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/tuple_more_item_event_variant_fail.rs
--rw-r--r--   0        0        0      189 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/tuple_more_item_event_variant_fail.stderr
--rw-r--r--   0        0        0      176 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/tuple_zero_item_event_variant_fail.rs
--rw-r--r--   0        0        0      181 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/tuple_zero_item_event_variant_fail.stderr
--rw-r--r--   0        0        0      366 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_trait/Cargo.toml
--rw-r--r--   0        0        0     1127 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_trait/LICENSE.txt
--rw-r--r--   0        0        0     6524 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_trait/src/lib.rs
--rw-r--r--   0        0        0      103 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/src/lib.rs
--rw-r--r--   0        0        0     1206 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/histories/ends_empty_wft_complete.bin
--rw-r--r--   0        0        0     1853 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/histories/evict_while_la_running_no_interference-16_history.bin
--rw-r--r--   0        0        0     3277 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/histories/evict_while_la_running_no_interference-23_history.bin
--rw-r--r--   0        0        0     2532 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/histories/evict_while_la_running_no_interference-85_history.bin
--rw-r--r--   0        0        0      924 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/histories/fail_wf_task.bin
--rw-r--r--   0        0        0     1701 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/histories/old_change_marker_format.bin
--rw-r--r--   0        0        0      711 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/histories/timer_workflow_history.bin
--rwxr-xr-x   0        0        0      213 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/integ-with-otel.sh
--rw-r--r--   0        0        0       55 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/.buildkite/Dockerfile
--rw-r--r--   0        0        0      336 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/.buildkite/docker-compose.yml
--rw-r--r--   0        0        0      223 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/.buildkite/pipeline.yml
--rw-r--r--   0        0        0      234 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/.github/CODEOWNERS
--rw-r--r--   0        0        0      227 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/.github/PULL_REQUEST_TEMPLATE.md
--rw-r--r--   0        0        0      587 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/.github/workflows/publish-docs.yml
--rw-r--r--   0        0        0     1097 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/.github/workflows/trigger-api-go-update.yml
--rw-r--r--   0        0        0       21 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/.gitignore
--rw-r--r--   0        0        0     1108 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/LICENSE
--rw-r--r--   0        0        0     2970 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/Makefile
--rw-r--r--   0        0        0      151 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/README.md
--rw-r--r--   0        0        0     1225 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/api-linter.yaml
--rw-r--r--   0        0        0      241 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/buf.yaml
--rw-r--r--   0        0        0       80 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/build/go.mod
--rw-r--r--   0        0        0      478 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/build/go.sum
--rw-r--r--   0        0        0     1350 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/build/tools.go
--rw-r--r--   0        0        0     4974 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/dependencies/gogoproto/gogo.proto
--rw-r--r--   0        0        0      216 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/go.mod
--rw-r--r--   0        0        0     3791 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/batch/v1/message.proto
--rw-r--r--   0        0        0    12498 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/command/v1/message.proto
--rw-r--r--   0        0        0     5835 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/common/v1/message.proto
--rw-r--r--   0        0        0     1916 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/batch_operation.proto
--rw-r--r--   0        0        0     2465 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/command_type.proto
--rw-r--r--   0        0        0     2062 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/common.proto
--rw-r--r--   0        0        0     9826 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/event_type.proto
--rw-r--r--   0        0        0     7183 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/failed_cause.proto
--rw-r--r--   0        0        0     1944 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/namespace.proto
--rw-r--r--   0        0        0     2098 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/query.proto
--rw-r--r--   0        0        0     1821 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/reset.proto
--rw-r--r--   0        0        0     3212 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/schedule.proto
--rw-r--r--   0        0        0     2619 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/task_queue.proto
--rw-r--r--   0        0        0     2961 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/update.proto
--rw-r--r--   0        0        0     5083 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/workflow.proto
--rw-r--r--   0        0        0     3815 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/errordetails/v1/message.proto
--rw-r--r--   0        0        0     4728 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/failure/v1/message.proto
--rw-r--r--   0        0        0     2068 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/filter/v1/message.proto
--rw-r--r--   0        0        0    41215 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/history/v1/message.proto
--rw-r--r--   0        0        0     4024 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/namespace/v1/message.proto
--rw-r--r--   0        0        0     4347 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/operatorservice/v1/request_response.proto
--rw-r--r--   0        0        0     4034 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/operatorservice/v1/service.proto
--rw-r--r--   0        0        0     2427 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/protocol/v1/message.proto
--rw-r--r--   0        0        0     2587 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/query/v1/message.proto
--rw-r--r--   0        0        0     2212 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/replication/v1/message.proto
--rw-r--r--   0        0        0    17214 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/schedule/v1/message.proto
--rw-r--r--   0        0        0     3142 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/sdk/v1/task_complete_metadata.proto
--rw-r--r--   0        0        0     3714 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/taskqueue/v1/message.proto
--rw-r--r--   0        0        0     3985 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/update/v1/message.proto
--rw-r--r--   0        0        0     2367 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/version/v1/message.proto
--rw-r--r--   0        0        0     7039 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflow/v1/message.proto
--rw-r--r--   0        0        0    55999 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflowservice/v1/request_response.proto
--rw-r--r--   0        0        0    23413 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflowservice/v1/service.proto
--rw-r--r--   0        0        0     2416 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/grpc/health/v1/health.proto
--rw-r--r--   0        0        0     2716 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/activity_result/activity_result.proto
--rw-r--r--   0        0        0     3066 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/activity_task/activity_task.proto
--rw-r--r--   0        0        0     2322 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/child_workflow/child_workflow.proto
--rw-r--r--   0        0        0      516 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/common/common.proto
--rw-r--r--   0        0        0     1313 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/core_interface.proto
--rw-r--r--   0        0        0     1726 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/external_data/external_data.proto
--rw-r--r--   0        0        0    12378 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_activation/workflow_activation.proto
--rw-r--r--   0        0        0    14553 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_commands/workflow_commands.proto
--rw-r--r--   0        0        0     1230 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_completion/workflow_completion.proto
--rw-r--r--   0        0        0     2854 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/Makefile
--rw-r--r--   0        0        0     1120 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/api-linter.yaml
--rw-r--r--   0        0        0      137 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/buf.yaml
--rw-r--r--   0        0        0     4974 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/dependencies/gogoproto/gogo.proto
--rw-r--r--   0        0        0     2178 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/temporal/api/testservice/v1/request_response.proto
--rw-r--r--   0        0        0     4494 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/temporal/api/testservice/v1/service.proto
--rw-r--r--   0        0        0       27 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/rustfmt.toml
--rw-r--r--   0        0        0     1231 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/Cargo.toml
--rw-r--r--   0        0        0     1127 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/LICENSE.txt
--rw-r--r--   0        0        0     8019 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/activity_context.rs
--rw-r--r--   0        0        0      979 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/app_data.rs
--rw-r--r--   0        0        0     1789 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/interceptors.rs
--rw-r--r--   0        0        0    31037 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/lib.rs
--rw-r--r--   0        0        0      523 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/payload_converter.rs
--rw-r--r--   0        0        0    11961 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/workflow_context/options.rs
--rw-r--r--   0        0        0    24000 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/workflow_context.rs
--rw-r--r--   0        0        0    23056 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/workflow_future.rs
--rw-r--r--   0        0        0      861 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/Cargo.toml
--rw-r--r--   0        0        0     1127 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/LICENSE.txt
--rw-r--r--   0        0        0     5362 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/build.rs
--rw-r--r--   0        0        0      334 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/src/constants.rs
--rw-r--r--   0        0        0    20979 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/src/history_builder.rs
--rw-r--r--   0        0        0     9296 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/src/history_info.rs
--rw-r--r--   0        0        0    89510 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/src/lib.rs
--rw-r--r--   0        0        0     1289 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/src/task_token.rs
--rw-r--r--   0        0        0      422 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/src/utilities.rs
--rw-r--r--   0        0        0      779 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/test-utils/Cargo.toml
--rw-r--r--   0        0        0    50608 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/test-utils/src/canned_histories.rs
--rw-r--r--   0        0        0     1091 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/test-utils/src/histfetch.rs
--rw-r--r--   0        0        0    25400 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/test-utils/src/lib.rs
--rw-r--r--   0        0        0     1617 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/test-utils/src/wf_input_saver.rs
--rw-r--r--   0        0        0     1148 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/test-utils/src/workflows.rs
--rw-r--r--   0        0        0     4751 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/fuzzy_workflow.rs
--rw-r--r--   0        0        0     8767 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/heavy_tests.rs
--rw-r--r--   0        0        0      118 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/activity_functions.rs
--rw-r--r--   0        0        0     1353 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/client_tests.rs
--rw-r--r--   0        0        0     5118 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/ephemeral_server_tests.rs
--rw-r--r--   0        0        0     8263 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/heartbeat_tests.rs
--rw-r--r--   0        0        0     9785 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/metrics_tests.rs
--rw-r--r--   0        0        0     3333 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/polling_tests.rs
--rw-r--r--   0        0        0    11544 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/queries_tests.rs
--rw-r--r--   0        0        0     5117 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/visibility_tests.rs
--rw-r--r--   0        0        0    34711 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/activities.rs
--rw-r--r--   0        0        0     1996 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/appdata_propagation.rs
--rw-r--r--   0        0        0     1717 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/cancel_external.rs
--rw-r--r--   0        0        0     1629 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/cancel_wf.rs
--rw-r--r--   0        0        0     4091 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/child_workflows.rs
--rw-r--r--   0        0        0     1986 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/continue_as_new.rs
--rw-r--r--   0        0        0     1628 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/determinism.rs
--rw-r--r--   0        0        0    24856 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/local_activities.rs
--rw-r--r--   0        0        0     1616 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/modify_wf_properties.rs
--rw-r--r--   0        0        0     4337 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/patches.rs
--rw-r--r--   0        0        0     9832 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/replay.rs
--rw-r--r--   0        0        0     3038 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/resets.rs
--rw-r--r--   0        0        0     5449 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/signals.rs
--rw-r--r--   0        0        0     2947 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/stickyness.rs
--rw-r--r--   0        0        0     3906 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/timers.rs
--rw-r--r--   0        0        0     2614 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/upsert_search_attrs.rs
--rw-r--r--   0        0        0    20756 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests.rs
--rw-r--r--   0        0        0     3365 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/main.rs
--rw-r--r--   0        0        0     3998 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/runner.rs
--rw-r--r--   0        0        0      850 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/wf_input_replay.rs
--rw-r--r--   0        0        0    17680 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/src/client.rs
--rw-r--r--   0        0        0     2502 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/src/lib.rs
--rw-r--r--   0        0        0     6008 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/src/runtime.rs
--rw-r--r--   0        0        0     5570 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/src/testing.rs
--rw-r--r--   0        0        0    11057 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/src/worker.rs
--rw-r--r--   0        0        0     2392 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/testing.py
--rw-r--r--   0        0        0    12926 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/worker.py
--rw-r--r--   0        0        0   174661 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/client.py
--rw-r--r--   0        0        0     8897 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/common.py
--rw-r--r--   0        0        0       57 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/contrib/__init__.py
--rw-r--r--   0        0        0    24052 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/contrib/opentelemetry.py
--rw-r--r--   0        0        0    52438 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/converter.py
--rw-r--r--   0        0        0     9418 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/exceptions.py
--rw-r--r--   0        0        0        0 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/py.typed
--rw-r--r--   0        0        0     6510 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/runtime.py
--rw-r--r--   0        0        0    28842 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/service.py
--rw-r--r--   0        0        0      207 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/testing/__init__.py
--rw-r--r--   0        0        0     6588 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/testing/_activity.py
--rw-r--r--   0        0        0    23598 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/testing/_workflow.py
--rw-r--r--   0        0        0     4313 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/types.py
--rw-r--r--   0        0        0     1832 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/worker/__init__.py
--rw-r--r--   0        0        0    37852 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/worker/_activity.py
--rw-r--r--   0        0        0    12027 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/worker/_interceptor.py
--rw-r--r--   0        0        0    12986 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/worker/_replayer.py
--rw-r--r--   0        0        0    30426 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/worker/_worker.py
--rw-r--r--   0        0        0    14858 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/worker/_workflow.py
--rw-r--r--   0        0        0    76745 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/worker/_workflow_instance.py
--rw-r--r--   0        0        0     2481 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/worker/workflow_sandbox/__init__.py
--rw-r--r--   0        0        0    17707 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/worker/workflow_sandbox/_importer.py
--rw-r--r--   0        0        0     1817 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/worker/workflow_sandbox/_in_sandbox.py
--rw-r--r--   0        0        0    40240 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/worker/workflow_sandbox/_restrictions.py
--rw-r--r--   0        0        0     6734 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/worker/workflow_sandbox/_runner.py
--rw-r--r--   0        0        0   133562 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/workflow.py
--rw-r--r--   0        0        0    76549 1970-01-01 00:00:00.000000 temporalio-1.2.0/setup.py
--rw-r--r--   0        0        0    67406 1970-01-01 00:00:00.000000 temporalio-1.2.0/PKG-INFO
+-rw-r--r--   0        0        0     1108 2023-07-24 14:45:48.530592 temporalio-1.3.0/LICENSE
+-rw-r--r--   0        0        0    67024 2023-07-24 14:45:48.530592 temporalio-1.3.0/README.md
+-rw-r--r--   0        0        0      899 2023-07-24 14:45:48.530592 temporalio-1.3.0/build.py
+-rw-r--r--   0        0        0     6203 2023-07-24 14:45:48.534592 temporalio-1.3.0/pyproject.toml
+-rw-r--r--   0        0        0      423 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/__init__.py
+-rw-r--r--   0        0        0    16134 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/activity.py
+-rw-r--r--   0        0        0       36 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/__init__.py
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/batch/__init__.py
+-rw-r--r--   0        0        0      388 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/batch/v1/__init__.py
+-rw-r--r--   0        0        0     6858 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/batch/v1/message_pb2.py
+-rw-r--r--   0        0        0     9012 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/batch/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/cluster/__init__.py
+-rw-r--r--   0        0        0      286 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/cluster/v1/__init__.py
+-rw-r--r--   0        0        0     5853 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/cluster/v1/message_pb2.py
+-rw-r--r--   0        0        0    11757 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/cluster/v1/message_pb2.pyi
+-rw-r--r--   0        0        0      158 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/cluster/v1/message_pb2_grpc.py
+-rw-r--r--   0        0        0     1185 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/cluster/v1/message_pb2_grpc.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/command/__init__.py
+-rw-r--r--   0        0        0     1476 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/command/v1/__init__.py
+-rw-r--r--   0        0        0    26000 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/command/v1/message_pb2.py
+-rw-r--r--   0        0        0    45400 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/command/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/common/__init__.py
+-rw-r--r--   0        0        0      604 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/common/v1/__init__.py
+-rw-r--r--   0        0        0     1540 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/common/v1/grpc_status_pb2.py
+-rw-r--r--   0        0        0     1462 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/common/v1/grpc_status_pb2.pyi
+-rw-r--r--   0        0        0    13442 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/common/v1/message_pb2.py
+-rw-r--r--   0        0        0    17368 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/common/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/dependencies/__init__.py
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/dependencies/gogoproto/__init__.py
+-rw-r--r--   0        0        0    22341 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/dependencies/gogoproto/gogo_pb2.py
+-rw-r--r--   0        0        0    15976 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/dependencies/gogoproto/gogo_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/enums/__init__.py
+-rw-r--r--   0        0        0     1987 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/enums/v1/__init__.py
+-rw-r--r--   0        0        0     2704 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/enums/v1/batch_operation_pb2.py
+-rw-r--r--   0        0        0     3906 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/enums/v1/batch_operation_pb2.pyi
+-rw-r--r--   0        0        0     3050 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/enums/v1/command_type_pb2.py
+-rw-r--r--   0        0        0     4307 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/enums/v1/command_type_pb2.pyi
+-rw-r--r--   0        0        0     2980 2023-07-24 14:45:48.534592 temporalio-1.3.0/temporalio/api/enums/v1/common_pb2.py
+-rw-r--r--   0        0        0     4571 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/enums/v1/common_pb2.pyi
+-rw-r--r--   0        0        0     6323 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/enums/v1/event_type_pb2.py
+-rw-r--r--   0        0        0    19994 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/enums/v1/event_type_pb2.pyi
+-rw-r--r--   0        0        0     9727 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/enums/v1/failed_cause_pb2.py
+-rw-r--r--   0        0        0    19148 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/enums/v1/failed_cause_pb2.pyi
+-rw-r--r--   0        0        0     2747 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/enums/v1/namespace_pb2.py
+-rw-r--r--   0        0        0     4174 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/enums/v1/namespace_pb2.pyi
+-rw-r--r--   0        0        0     2353 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/enums/v1/query_pb2.py
+-rw-r--r--   0        0        0     3983 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/enums/v1/query_pb2.pyi
+-rw-r--r--   0        0        0     2141 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/enums/v1/reset_pb2.py
+-rw-r--r--   0        0        0     3823 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/enums/v1/reset_pb2.pyi
+-rw-r--r--   0        0        0     2149 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/enums/v1/schedule_pb2.py
+-rw-r--r--   0        0        0     5644 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/enums/v1/schedule_pb2.pyi
+-rw-r--r--   0        0        0     2849 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/enums/v1/task_queue_pb2.py
+-rw-r--r--   0        0        0     7514 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/enums/v1/task_queue_pb2.pyi
+-rw-r--r--   0        0        0     2140 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/enums/v1/update_pb2.py
+-rw-r--r--   0        0        0     4852 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/enums/v1/update_pb2.pyi
+-rw-r--r--   0        0        0     7735 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/enums/v1/workflow_pb2.py
+-rw-r--r--   0        0        0    15052 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/enums/v1/workflow_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/errordetails/__init__.py
+-rw-r--r--   0        0        0     1034 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/errordetails/v1/__init__.py
+-rw-r--r--   0        0        0    12726 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/errordetails/v1/message_pb2.py
+-rw-r--r--   0        0        0    10736 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/errordetails/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/failure/__init__.py
+-rw-r--r--   0        0        0      530 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/failure/v1/__init__.py
+-rw-r--r--   0        0        0     9303 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/failure/v1/message_pb2.py
+-rw-r--r--   0        0        0    16245 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/failure/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/filter/__init__.py
+-rw-r--r--   0        0        0      236 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/filter/v1/__init__.py
+-rw-r--r--   0        0        0     4569 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/filter/v1/message_pb2.py
+-rw-r--r--   0        0        0     4131 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/filter/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/history/__init__.py
+-rw-r--r--   0        0        0     4622 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/history/v1/__init__.py
+-rw-r--r--   0        0        0    74145 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/history/v1/message_pb2.py
+-rw-r--r--   0        0        0   153866 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/history/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/interaction/__init__.py
+-rw-r--r--   0        0        0      129 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/interaction/v1/__init__.py
+-rw-r--r--   0        0        0     4385 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/interaction/v1/message_pb2.py
+-rw-r--r--   0        0        0     7155 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/interaction/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/namespace/__init__.py
+-rw-r--r--   0        0        0      300 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/namespace/v1/__init__.py
+-rw-r--r--   0        0        0    10762 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/namespace/v1/message_pb2.py
+-rw-r--r--   0        0        0    12925 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/namespace/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/operatorservice/__init__.py
+-rw-r--r--   0        0        0     1423 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/operatorservice/v1/__init__.py
+-rw-r--r--   0        0        0    17665 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/operatorservice/v1/request_response_pb2.py
+-rw-r--r--   0        0        0    15710 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/operatorservice/v1/request_response_pb2.pyi
+-rw-r--r--   0        0        0      158 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/operatorservice/v1/request_response_pb2_grpc.py
+-rw-r--r--   0        0        0     1185 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/operatorservice/v1/request_response_pb2_grpc.pyi
+-rw-r--r--   0        0        0     2899 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/operatorservice/v1/service_pb2.py
+-rw-r--r--   0        0        0     1274 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/operatorservice/v1/service_pb2.pyi
+-rw-r--r--   0        0        0    17632 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/operatorservice/v1/service_pb2_grpc.py
+-rw-r--r--   0        0        0     8793 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/operatorservice/v1/service_pb2_grpc.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/protocol/__init__.py
+-rw-r--r--   0        0        0       63 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/protocol/v1/__init__.py
+-rw-r--r--   0        0        0     2034 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/protocol/v1/message_pb2.py
+-rw-r--r--   0        0        0     3657 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/protocol/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/query/__init__.py
+-rw-r--r--   0        0        0      159 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/query/v1/__init__.py
+-rw-r--r--   0        0        0     3696 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/query/v1/message_pb2.py
+-rw-r--r--   0        0        0     5000 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/query/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/replication/__init__.py
+-rw-r--r--   0        0        0      214 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/replication/v1/__init__.py
+-rw-r--r--   0        0        0     4122 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/replication/v1/message_pb2.py
+-rw-r--r--   0        0        0     4288 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/replication/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/schedule/__init__.py
+-rw-r--r--   0        0        0      732 2023-07-24 14:45:48.538592 temporalio-1.3.0/temporalio/api/schedule/v1/__init__.py
+-rw-r--r--   0        0        0    18729 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/schedule/v1/message_pb2.py
+-rw-r--r--   0        0        0    38470 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/schedule/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/sdk/__init__.py
+-rw-r--r--   0        0        0      122 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/sdk/v1/__init__.py
+-rw-r--r--   0        0        0     1979 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/sdk/v1/task_complete_metadata_pb2.py
+-rw-r--r--   0        0        0     4074 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/sdk/v1/task_complete_metadata_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/taskqueue/__init__.py
+-rw-r--r--   0        0        0      530 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/taskqueue/v1/__init__.py
+-rw-r--r--   0        0        0     9588 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/taskqueue/v1/message_pb2.py
+-rw-r--r--   0        0        0    12733 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/taskqueue/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/testservice/__init__.py
+-rw-r--r--   0        0        0      814 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/testservice/v1/__init__.py
+-rw-r--r--   0        0        0     7303 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/testservice/v1/request_response_pb2.py
+-rw-r--r--   0        0        0     4609 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/testservice/v1/request_response_pb2.pyi
+-rw-r--r--   0        0        0      158 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/testservice/v1/request_response_pb2_grpc.py
+-rw-r--r--   0        0        0     1185 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/testservice/v1/request_response_pb2_grpc.pyi
+-rw-r--r--   0        0        0     2532 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/testservice/v1/service_pb2.py
+-rw-r--r--   0        0        0     1274 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/testservice/v1/service_pb2.pyi
+-rw-r--r--   0        0        0    14985 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/testservice/v1/service_pb2_grpc.py
+-rw-r--r--   0        0        0     9065 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/testservice/v1/service_pb2_grpc.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/update/__init__.py
+-rw-r--r--   0        0        0      308 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/update/v1/__init__.py
+-rw-r--r--   0        0        0     7265 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/update/v1/message_pb2.py
+-rw-r--r--   0        0        0    11510 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/update/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/version/__init__.py
+-rw-r--r--   0        0        0      123 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/version/v1/__init__.py
+-rw-r--r--   0        0        0     4064 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/version/v1/message_pb2.py
+-rw-r--r--   0        0        0     5233 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/version/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/workflow/__init__.py
+-rw-r--r--   0        0        0      476 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/workflow/v1/__init__.py
+-rw-r--r--   0        0        0    15395 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/workflow/v1/message_pb2.py
+-rw-r--r--   0        0        0    25031 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/workflow/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/workflowservice/__init__.py
+-rw-r--r--   0        0        0     8907 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/workflowservice/v1/__init__.py
+-rw-r--r--   0        0        0   129221 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/workflowservice/v1/request_response_pb2.py
+-rw-r--r--   0        0        0   199703 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/workflowservice/v1/request_response_pb2.pyi
+-rw-r--r--   0        0        0      158 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/workflowservice/v1/request_response_pb2_grpc.py
+-rw-r--r--   0        0        0     1185 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/workflowservice/v1/request_response_pb2_grpc.pyi
+-rw-r--r--   0        0        0    12252 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/workflowservice/v1/service_pb2.py
+-rw-r--r--   0        0        0     1274 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/workflowservice/v1/service_pb2.pyi
+-rw-r--r--   0        0        0   137205 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/workflowservice/v1/service_pb2_grpc.py
+-rw-r--r--   0        0        0    68338 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/api/workflowservice/v1/service_pb2_grpc.pyi
+-rw-r--r--   0        0        0    77258 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/bridge/Cargo.lock
+-rw-r--r--   0        0        0      867 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/bridge/Cargo.toml
+-rw-r--r--   0        0        0      122 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/bridge/__init__.py
+-rw-r--r--   0        0        0     3601 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/bridge/client.py
+-rw-r--r--   0        0        0      144 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/bridge/proto/__init__.py
+-rw-r--r--   0        0        0      336 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/bridge/proto/activity_result/__init__.py
+-rw-r--r--   0        0        0     6517 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/bridge/proto/activity_result/activity_result_pb2.py
+-rw-r--r--   0        0        0     9319 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/bridge/proto/activity_result/activity_result_pb2.pyi
+-rw-r--r--   0        0        0      171 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/bridge/proto/activity_task/__init__.py
+-rw-r--r--   0        0        0     5900 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/bridge/proto/activity_task/activity_task_pb2.py
+-rw-r--r--   0        0        0    11710 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/bridge/proto/activity_task/activity_task_pb2.pyi
+-rw-r--r--   0        0        0     1435 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/bridge/proto/bridge/__init__.py
+-rw-r--r--   0        0        0    33694 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/bridge/proto/bridge/bridge_pb2.py
+-rw-r--r--   0        0        0    35620 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/bridge/proto/bridge/bridge_pb2.pyi
+-rw-r--r--   0        0        0      407 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/bridge/proto/child_workflow/__init__.py
+-rw-r--r--   0        0        0     6028 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/bridge/proto/child_workflow/child_workflow_pb2.py
+-rw-r--r--   0        0        0     9065 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/bridge/proto/child_workflow/child_workflow_pb2.pyi
+-rw-r--r--   0        0        0      144 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/bridge/proto/common/__init__.py
+-rw-r--r--   0        0        0     2270 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/bridge/proto/common/common_pb2.py
+-rw-r--r--   0        0        0     3473 2023-07-24 14:45:48.542592 temporalio-1.3.0/temporalio/bridge/proto/common/common_pb2.pyi
+-rw-r--r--   0        0        0     4340 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/proto/core_interface_pb2.py
+-rw-r--r--   0        0        0     2437 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/proto/core_interface_pb2.pyi
+-rw-r--r--   0        0        0      158 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/proto/core_interface_pb2_grpc.py
+-rw-r--r--   0        0        0       76 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/proto/core_interface_pb2_grpc.pyi
+-rw-r--r--   0        0        0      145 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/proto/external_data/__init__.py
+-rw-r--r--   0        0        0     2882 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/proto/external_data/external_data_pb2.py
+-rw-r--r--   0        0        0     4346 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/proto/external_data/external_data_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/proto/health/__init__.py
+-rw-r--r--   0        0        0      132 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/proto/health/v1/__init__.py
+-rw-r--r--   0        0        0     3055 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/proto/health/v1/health_pb2.py
+-rw-r--r--   0        0        0     2546 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/proto/health/v1/health_pb2.pyi
+-rw-r--r--   0        0        0     1138 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/proto/workflow_activation/__init__.py
+-rw-r--r--   0        0        0    23037 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/proto/workflow_activation/workflow_activation_pb2.py
+-rw-r--r--   0        0        0    43548 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/proto/workflow_activation/workflow_activation_pb2.pyi
+-rw-r--r--   0        0        0     1318 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/proto/workflow_commands/__init__.py
+-rw-r--r--   0        0        0    34894 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/proto/workflow_commands/workflow_commands_pb2.py
+-rw-r--r--   0        0        0    60441 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/proto/workflow_commands/workflow_commands_pb2.pyi
+-rw-r--r--   0        0        0      165 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/proto/workflow_completion/__init__.py
+-rw-r--r--   0        0        0     3971 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/proto/workflow_completion/workflow_completion_pb2.py
+-rw-r--r--   0        0        0     4425 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/proto/workflow_completion/workflow_completion_pb2.pyi
+-rw-r--r--   0        0        0     1961 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/runtime.py
+-rw-r--r--   0        0        0      198 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/.buildkite/docker/Dockerfile
+-rwxr-xr-x   0        0        0       45 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/.buildkite/docker/build.sh
+-rw-r--r--   0        0        0      616 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose-ci.yaml
+-rw-r--r--   0        0        0      963 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose-telem.yaml
+-rw-r--r--   0        0        0      839 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose.yaml
+-rw-r--r--   0        0        0     1600 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/.buildkite/pipeline.yml
+-rw-r--r--   0        0        0      523 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/.cargo/config.toml
+-rw-r--r--   0        0        0       39 2023-07-24 14:45:49.118605 temporalio-1.3.0/temporalio/bridge/sdk-core/.git
+-rw-r--r--   0        0        0      706 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/.github/workflows/heavy.yml
+-rw-r--r--   0        0        0      559 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/.github/workflows/semgrep.yml
+-rw-r--r--   0        0        0      278 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/.gitignore
+-rw-r--r--   0        0        0     7864 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/ARCHITECTURE.md
+-rw-r--r--   0        0        0       36 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/CODEOWNERS
+-rw-r--r--   0        0        0      100 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/Cargo.toml
+-rw-r--r--   0        0        0     1127 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/LICENSE.txt
+-rw-r--r--   0        0        0     4991 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/README.md
+-rw-r--r--   0        0        0      555 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/arch_docs/diagrams/README.md
+-rw-r--r--   0        0        0     1029 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/arch_docs/diagrams/sticky_queues.puml
+-rw-r--r--   0        0        0   112308 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/arch_docs/diagrams/workflow_internals.svg
+-rw-r--r--   0        0        0     3212 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/arch_docs/sticky_queues.md
+-rwxr-xr-x   0        0        0      109 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/cargo-tokio-console.sh
+-rw-r--r--   0        0        0      982 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/client/Cargo.toml
+-rw-r--r--   0        0        0     1127 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/client/LICENSE.txt
+-rw-r--r--   0        0        0    52478 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/client/src/lib.rs
+-rw-r--r--   0        0        0     6081 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/client/src/metrics.rs
+-rw-r--r--   0        0        0    32868 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/client/src/raw.rs
+-rw-r--r--   0        0        0    24605 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/client/src/retry.rs
+-rw-r--r--   0        0        0     6852 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/client/src/workflow_handle/mod.rs
+-rw-r--r--   0        0        0     3902 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/Cargo.toml
+-rw-r--r--   0        0        0     1127 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/LICENSE.txt
+-rw-r--r--   0        0        0     2426 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/benches/workflow_replay.rs
+-rw-r--r--   0        0        0      836 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/abstractions/take_cell.rs
+-rw-r--r--   0        0        0     9733 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/abstractions.rs
+-rw-r--r--   0        0        0    39595 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/core_tests/activity_tasks.rs
+-rw-r--r--   0        0        0     8003 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/core_tests/child_workflows.rs
+-rw-r--r--   0        0        0    10823 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/core_tests/determinism.rs
+-rw-r--r--   0        0        0    43030 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/core_tests/local_activities.rs
+-rw-r--r--   0        0        0     3127 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/core_tests/mod.rs
+-rw-r--r--   0        0        0    30792 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/core_tests/queries.rs
+-rw-r--r--   0        0        0     2452 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/core_tests/replay_flag.rs
+-rw-r--r--   0        0        0     9518 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/core_tests/workers.rs
+-rw-r--r--   0        0        0     4233 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/core_tests/workflow_cancels.rs
+-rw-r--r--   0        0        0   102684 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/core_tests/workflow_tasks.rs
+-rw-r--r--   0        0        0    21721 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/ephemeral_server/mod.rs
+-rw-r--r--   0        0        0     8574 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/internal_flags.rs
+-rw-r--r--   0        0        0    10493 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/lib.rs
+-rw-r--r--   0        0        0     2515 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/pollers/mod.rs
+-rw-r--r--   0        0        0    12106 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/pollers/poll_buffer.rs
+-rw-r--r--   0        0        0    15789 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/protosext/mod.rs
+-rw-r--r--   0        0        0     7389 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/replay/mod.rs
+-rw-r--r--   0        0        0     6553 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/retry_logic.rs
+-rw-r--r--   0        0        0     6400 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/telemetry/log_export.rs
+-rw-r--r--   0        0        0    16737 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/telemetry/metrics.rs
+-rw-r--r--   0        0        0    16564 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/telemetry/mod.rs
+-rw-r--r--   0        0        0     3055 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/telemetry/prometheus_server.rs
+-rw-r--r--   0        0        0    32249 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/test_help/mod.rs
+-rw-r--r--   0        0        0    22866 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/activities/activity_heartbeat_manager.rs
+-rw-r--r--   0        0        0     2467 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/activities/activity_task_poller_stream.rs
+-rw-r--r--   0        0        0    53683 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/activities/local_activities.rs
+-rw-r--r--   0        0        0    29859 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/activities.rs
+-rw-r--r--   0        0        0     4003 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/client/mocks.rs
+-rw-r--r--   0        0        0    13707 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/client.rs
+-rw-r--r--   0        0        0    26800 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/mod.rs
+-rw-r--r--   0        0        0     1203 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/bridge.rs
+-rw-r--r--   0        0        0     3616 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/driven_workflow.rs
+-rw-r--r--   0        0        0    73489 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/history_update.rs
+-rw-r--r--   0        0        0    34269 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/activity_state_machine.rs
+-rw-r--r--   0        0        0    10483 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/cancel_external_state_machine.rs
+-rw-r--r--   0        0        0     5365 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/cancel_workflow_state_machine.rs
+-rw-r--r--   0        0        0    36484 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/child_workflow_state_machine.rs
+-rw-r--r--   0        0        0     4187 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/complete_workflow_state_machine.rs
+-rw-r--r--   0        0        0     5253 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/continue_as_new_workflow_state_machine.rs
+-rw-r--r--   0        0        0     3903 2023-07-24 14:45:49.738619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/fail_workflow_state_machine.rs
+-rw-r--r--   0        0        0    62534 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/local_activity_state_machine.rs
+-rw-r--r--   0        0        0    11457 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/mod.rs
+-rw-r--r--   0        0        0     5524 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/modify_workflow_properties_state_machine.rs
+-rw-r--r--   0        0        0    31795 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/patch_state_machine.rs
+-rw-r--r--   0        0        0    15993 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/signal_external_state_machine.rs
+-rw-r--r--   0        0        0    14721 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/timer_state_machine.rs
+-rw-r--r--   0        0        0     7813 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/transition_coverage.rs
+-rw-r--r--   0        0        0    14499 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/upsert_search_attributes_state_machine.rs
+-rw-r--r--   0        0        0     3069 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_machines/local_acts.rs
+-rw-r--r--   0        0        0    62037 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_machines.rs
+-rw-r--r--   0        0        0     8693 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_task_state_machine.rs
+-rw-r--r--   0        0        0     7824 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/managed_run/managed_wf_test.rs
+-rw-r--r--   0        0        0    55841 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/managed_run.rs
+-rw-r--r--   0        0        0    52471 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/mod.rs
+-rw-r--r--   0        0        0     4729 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/run_cache.rs
+-rw-r--r--   0        0        0     5437 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/wft_extraction.rs
+-rw-r--r--   0        0        0     4212 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/wft_poller.rs
+-rw-r--r--   0        0        0     4024 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/workflow_stream/saved_wf_inputs.rs
+-rw-r--r--   0        0        0      509 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/workflow_stream/tonic_status_serde.rs
+-rw-r--r--   0        0        0    30026 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/workflow_stream.rs
+-rw-r--r--   0        0        0      885 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/core-api/Cargo.toml
+-rw-r--r--   0        0        0     1127 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/core-api/LICENSE.txt
+-rw-r--r--   0        0        0     2912 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/core-api/src/errors.rs
+-rw-r--r--   0        0        0     6826 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/core-api/src/lib.rs
+-rw-r--r--   0        0        0     5542 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/core-api/src/telemetry.rs
+-rw-r--r--   0        0        0     9634 2023-07-24 14:45:49.734619 temporalio-1.3.0/temporalio/bridge/sdk-core/core-api/src/worker.rs
+-rw-r--r--   0        0        0     7987 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/etc/deps.svg
+-rw-r--r--   0        0        0       51 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/etc/dynamic-config.yaml
+-rw-r--r--   0        0        0      574 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/etc/otel-collector-config.yaml
+-rw-r--r--   0        0        0      173 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/etc/prometheus.yaml
+-rwxr-xr-x   0        0        0      204 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/etc/regen-depgraph.sh
+-rw-r--r--   0        0        0      574 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/Cargo.toml
+-rw-r--r--   0        0        0     1127 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/LICENSE.txt
+-rw-r--r--   0        0        0      126 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/README.md
+-rw-r--r--   0        0        0      609 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/Cargo.toml
+-rw-r--r--   0        0        0     1127 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/LICENSE.txt
+-rw-r--r--   0        0        0    26246 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/src/lib.rs
+-rw-r--r--   0        0        0      191 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/progress.rs
+-rw-r--r--   0        0        0      299 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/dupe_transitions_fail.rs
+-rw-r--r--   0        0        0      387 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/dupe_transitions_fail.stderr
+-rw-r--r--   0        0        0      892 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/dynamic_dest_pass.rs
+-rw-r--r--   0        0        0      202 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/forgot_name_fail.rs
+-rw-r--r--   0        0        0      331 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/forgot_name_fail.stderr
+-rw-r--r--   0        0        0      686 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/handler_arg_pass.rs
+-rw-r--r--   0        0        0      619 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/handler_pass.rs
+-rw-r--r--   0        0        0      862 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/medium_complex_pass.rs
+-rw-r--r--   0        0        0      584 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/no_handle_conversions_require_into_fail.rs
+-rw-r--r--   0        0        0      562 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/no_handle_conversions_require_into_fail.stderr
+-rw-r--r--   0        0        0      649 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/simple_pass.rs
+-rw-r--r--   0        0        0      307 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/struct_event_variant_fail.rs
+-rw-r--r--   0        0        0      161 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/struct_event_variant_fail.stderr
+-rw-r--r--   0        0        0      184 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/tuple_more_item_event_variant_fail.rs
+-rw-r--r--   0        0        0      189 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/tuple_more_item_event_variant_fail.stderr
+-rw-r--r--   0        0        0      176 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/tuple_zero_item_event_variant_fail.rs
+-rw-r--r--   0        0        0      181 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/tuple_zero_item_event_variant_fail.stderr
+-rw-r--r--   0        0        0      366 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_trait/Cargo.toml
+-rw-r--r--   0        0        0     1127 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_trait/LICENSE.txt
+-rw-r--r--   0        0        0     6524 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_trait/src/lib.rs
+-rw-r--r--   0        0        0      103 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/src/lib.rs
+-rw-r--r--   0        0        0     1206 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/histories/ends_empty_wft_complete.bin
+-rw-r--r--   0        0        0     1853 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/histories/evict_while_la_running_no_interference-16_history.bin
+-rw-r--r--   0        0        0     3277 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/histories/evict_while_la_running_no_interference-23_history.bin
+-rw-r--r--   0        0        0     2532 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/histories/evict_while_la_running_no_interference-85_history.bin
+-rw-r--r--   0        0        0      924 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/histories/fail_wf_task.bin
+-rw-r--r--   0        0        0     1701 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/histories/old_change_marker_format.bin
+-rw-r--r--   0        0        0      711 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/histories/timer_workflow_history.bin
+-rwxr-xr-x   0        0        0      213 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/integ-with-otel.sh
+-rw-r--r--   0        0        0       55 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/.buildkite/Dockerfile
+-rw-r--r--   0        0        0      336 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/.buildkite/docker-compose.yml
+-rw-r--r--   0        0        0      223 2023-07-24 14:45:49.742619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/.buildkite/pipeline.yml
+-rw-r--r--   0        0        0      234 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/.github/CODEOWNERS
+-rw-r--r--   0        0        0      227 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/.github/PULL_REQUEST_TEMPLATE.md
+-rw-r--r--   0        0        0      587 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/.github/workflows/publish-docs.yml
+-rw-r--r--   0        0        0     1097 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/.github/workflows/trigger-api-go-update.yml
+-rw-r--r--   0        0        0       21 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/.gitignore
+-rw-r--r--   0        0        0     1108 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/LICENSE
+-rw-r--r--   0        0        0     2983 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/Makefile
+-rw-r--r--   0        0        0      151 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/README.md
+-rw-r--r--   0        0        0     1225 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/api-linter.yaml
+-rw-r--r--   0        0        0      101 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/buf.yaml
+-rw-r--r--   0        0        0       80 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/build/go.mod
+-rw-r--r--   0        0        0      478 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/build/go.sum
+-rw-r--r--   0        0        0     1350 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/build/tools.go
+-rw-r--r--   0        0        0     4974 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/dependencies/gogoproto/gogo.proto
+-rw-r--r--   0        0        0      216 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/go.mod
+-rw-r--r--   0        0        0     4263 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/batch/v1/message.proto
+-rw-r--r--   0        0        0    13229 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/command/v1/message.proto
+-rw-r--r--   0        0        0     6478 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/common/v1/message.proto
+-rw-r--r--   0        0        0     1950 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/batch_operation.proto
+-rw-r--r--   0        0        0     2465 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/command_type.proto
+-rw-r--r--   0        0        0     2062 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/common.proto
+-rw-r--r--   0        0        0     9826 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/event_type.proto
+-rw-r--r--   0        0        0     7255 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/failed_cause.proto
+-rw-r--r--   0        0        0     1944 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/namespace.proto
+-rw-r--r--   0        0        0     2098 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/query.proto
+-rw-r--r--   0        0        0     2209 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/reset.proto
+-rw-r--r--   0        0        0     3212 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/schedule.proto
+-rw-r--r--   0        0        0     3715 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/task_queue.proto
+-rw-r--r--   0        0        0     2961 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/update.proto
+-rw-r--r--   0        0        0     5083 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/workflow.proto
+-rw-r--r--   0        0        0     3957 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/errordetails/v1/message.proto
+-rw-r--r--   0        0        0     4728 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/failure/v1/message.proto
+-rw-r--r--   0        0        0     2068 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/filter/v1/message.proto
+-rw-r--r--   0        0        0    43050 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/history/v1/message.proto
+-rw-r--r--   0        0        0     4024 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/namespace/v1/message.proto
+-rw-r--r--   0        0        0     4347 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/operatorservice/v1/request_response.proto
+-rw-r--r--   0        0        0     4034 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/operatorservice/v1/service.proto
+-rw-r--r--   0        0        0     2427 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/protocol/v1/message.proto
+-rw-r--r--   0        0        0     2587 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/query/v1/message.proto
+-rw-r--r--   0        0        0     2212 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/replication/v1/message.proto
+-rw-r--r--   0        0        0    17214 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/schedule/v1/message.proto
+-rw-r--r--   0        0        0     3142 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/sdk/v1/task_complete_metadata.proto
+-rw-r--r--   0        0        0     4468 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/taskqueue/v1/message.proto
+-rw-r--r--   0        0        0     3985 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/update/v1/message.proto
+-rw-r--r--   0        0        0     2367 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/version/v1/message.proto
+-rw-r--r--   0        0        0     7330 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflow/v1/message.proto
+-rw-r--r--   0        0        0    58484 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflowservice/v1/request_response.proto
+-rw-r--r--   0        0        0    24927 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflowservice/v1/service.proto
+-rw-r--r--   0        0        0     2069 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/google/rpc/status.proto
+-rw-r--r--   0        0        0     2416 2023-07-24 14:45:49.746619 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/grpc/health/v1/health.proto
+-rw-r--r--   0        0        0     2716 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/activity_result/activity_result.proto
+-rw-r--r--   0        0        0     3066 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/activity_task/activity_task.proto
+-rw-r--r--   0        0        0     2322 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/child_workflow/child_workflow.proto
+-rw-r--r--   0        0        0     1260 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/common/common.proto
+-rw-r--r--   0        0        0     1313 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/core_interface.proto
+-rw-r--r--   0        0        0     1726 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/external_data/external_data.proto
+-rw-r--r--   0        0        0    12592 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_activation/workflow_activation.proto
+-rw-r--r--   0        0        0    15000 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_commands/workflow_commands.proto
+-rw-r--r--   0        0        0     1230 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_completion/workflow_completion.proto
+-rw-r--r--   0        0        0     2854 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/Makefile
+-rw-r--r--   0        0        0     1120 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/api-linter.yaml
+-rw-r--r--   0        0        0      137 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/buf.yaml
+-rw-r--r--   0        0        0     4974 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/dependencies/gogoproto/gogo.proto
+-rw-r--r--   0        0        0     2178 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/temporal/api/testservice/v1/request_response.proto
+-rw-r--r--   0        0        0     4494 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/temporal/api/testservice/v1/service.proto
+-rw-r--r--   0        0        0       27 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/rustfmt.toml
+-rw-r--r--   0        0        0     1231 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/sdk/Cargo.toml
+-rw-r--r--   0        0        0     1127 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/sdk/LICENSE.txt
+-rw-r--r--   0        0        0     8019 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/sdk/src/activity_context.rs
+-rw-r--r--   0        0        0      979 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/sdk/src/app_data.rs
+-rw-r--r--   0        0        0     1789 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/sdk/src/interceptors.rs
+-rw-r--r--   0        0        0    31822 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/sdk/src/lib.rs
+-rw-r--r--   0        0        0      523 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/sdk/src/payload_converter.rs
+-rw-r--r--   0        0        0    11961 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/sdk/src/workflow_context/options.rs
+-rw-r--r--   0        0        0    24000 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/sdk/src/workflow_context.rs
+-rw-r--r--   0        0        0    23161 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/sdk/src/workflow_future.rs
+-rw-r--r--   0        0        0      861 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/sdk-core-protos/Cargo.toml
+-rw-r--r--   0        0        0     1127 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/sdk-core-protos/LICENSE.txt
+-rw-r--r--   0        0        0     5362 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/sdk-core-protos/build.rs
+-rw-r--r--   0        0        0      334 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/sdk-core-protos/src/constants.rs
+-rw-r--r--   0        0        0    21091 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/sdk-core-protos/src/history_builder.rs
+-rw-r--r--   0        0        0     9341 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/sdk-core-protos/src/history_info.rs
+-rw-r--r--   0        0        0    89624 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/sdk-core-protos/src/lib.rs
+-rw-r--r--   0        0        0     1289 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/sdk-core-protos/src/task_token.rs
+-rw-r--r--   0        0        0      422 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/sdk-core-protos/src/utilities.rs
+-rw-r--r--   0        0        0      812 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/test-utils/Cargo.toml
+-rw-r--r--   0        0        0    50608 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/test-utils/src/canned_histories.rs
+-rw-r--r--   0        0        0     1091 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/test-utils/src/histfetch.rs
+-rw-r--r--   0        0        0    25979 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/test-utils/src/lib.rs
+-rw-r--r--   0        0        0     1617 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/test-utils/src/wf_input_saver.rs
+-rw-r--r--   0        0        0     1148 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/test-utils/src/workflows.rs
+-rw-r--r--   0        0        0     4751 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/fuzzy_workflow.rs
+-rw-r--r--   0        0        0     8767 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/heavy_tests.rs
+-rw-r--r--   0        0        0      118 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/activity_functions.rs
+-rw-r--r--   0        0        0     1353 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/client_tests.rs
+-rw-r--r--   0        0        0     5118 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/ephemeral_server_tests.rs
+-rw-r--r--   0        0        0     8263 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/heartbeat_tests.rs
+-rw-r--r--   0        0        0    14658 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/metrics_tests.rs
+-rw-r--r--   0        0        0     3333 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/polling_tests.rs
+-rw-r--r--   0        0        0    11544 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/queries_tests.rs
+-rw-r--r--   0        0        0     5117 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/visibility_tests.rs
+-rw-r--r--   0        0        0    35127 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/activities.rs
+-rw-r--r--   0        0        0     1996 2023-07-24 14:45:49.754620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/appdata_propagation.rs
+-rw-r--r--   0        0        0     1717 2023-07-24 14:45:49.754620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/cancel_external.rs
+-rw-r--r--   0        0        0     1629 2023-07-24 14:45:49.754620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/cancel_wf.rs
+-rw-r--r--   0        0        0     4097 2023-07-24 14:45:49.754620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/child_workflows.rs
+-rw-r--r--   0        0        0     1986 2023-07-24 14:45:49.754620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/continue_as_new.rs
+-rw-r--r--   0        0        0     1628 2023-07-24 14:45:49.754620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/determinism.rs
+-rw-r--r--   0        0        0    24856 2023-07-24 14:45:49.754620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/local_activities.rs
+-rw-r--r--   0        0        0     1616 2023-07-24 14:45:49.754620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/modify_wf_properties.rs
+-rw-r--r--   0        0        0     4337 2023-07-24 14:45:49.754620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/patches.rs
+-rw-r--r--   0        0        0     9832 2023-07-24 14:45:49.754620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/replay.rs
+-rw-r--r--   0        0        0     3038 2023-07-24 14:45:49.754620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/resets.rs
+-rw-r--r--   0        0        0     5449 2023-07-24 14:45:49.754620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/signals.rs
+-rw-r--r--   0        0        0     3059 2023-07-24 14:45:49.754620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/stickyness.rs
+-rw-r--r--   0        0        0     3906 2023-07-24 14:45:49.754620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/timers.rs
+-rw-r--r--   0        0        0     2614 2023-07-24 14:45:49.754620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/upsert_search_attrs.rs
+-rw-r--r--   0        0        0    20820 2023-07-24 14:45:49.750620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests.rs
+-rw-r--r--   0        0        0     3365 2023-07-24 14:45:49.754620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/main.rs
+-rw-r--r--   0        0        0     3998 2023-07-24 14:45:49.754620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/runner.rs
+-rw-r--r--   0        0        0      850 2023-07-24 14:45:49.754620 temporalio-1.3.0/temporalio/bridge/sdk-core/tests/wf_input_replay.rs
+-rw-r--r--   0        0        0    17830 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/src/client.rs
+-rw-r--r--   0        0        0     2497 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/src/lib.rs
+-rw-r--r--   0        0        0     6008 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/src/runtime.rs
+-rw-r--r--   0        0        0     5587 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/src/testing.rs
+-rw-r--r--   0        0        0    11153 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/src/worker.rs
+-rw-r--r--   0        0        0     2384 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/testing.py
+-rw-r--r--   0        0        0    12958 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/bridge/worker.py
+-rw-r--r--   0        0        0   191349 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/client.py
+-rw-r--r--   0        0        0     9994 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/common.py
+-rw-r--r--   0        0        0       57 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/contrib/__init__.py
+-rw-r--r--   0        0        0    24052 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/contrib/opentelemetry.py
+-rw-r--r--   0        0        0    54402 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/converter.py
+-rw-r--r--   0        0        0    10434 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/exceptions.py
+-rw-r--r--   0        0        0        0 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/py.typed
+-rw-r--r--   0        0        0     6510 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/runtime.py
+-rw-r--r--   0        0        0    29061 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/service.py
+-rw-r--r--   0        0        0      207 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/testing/__init__.py
+-rw-r--r--   0        0        0     7002 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/testing/_activity.py
+-rw-r--r--   0        0        0    23564 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/testing/_workflow.py
+-rw-r--r--   0        0        0     4313 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/types.py
+-rw-r--r--   0        0        0     1832 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/worker/__init__.py
+-rw-r--r--   0        0        0    39187 2023-07-24 14:45:48.546592 temporalio-1.3.0/temporalio/worker/_activity.py
+-rw-r--r--   0        0        0    12226 2023-07-24 14:45:48.550592 temporalio-1.3.0/temporalio/worker/_interceptor.py
+-rw-r--r--   0        0        0    13031 2023-07-24 14:45:48.550592 temporalio-1.3.0/temporalio/worker/_replayer.py
+-rw-r--r--   0        0        0    31164 2023-07-24 14:45:48.550592 temporalio-1.3.0/temporalio/worker/_worker.py
+-rw-r--r--   0        0        0    15186 2023-07-24 14:45:48.550592 temporalio-1.3.0/temporalio/worker/_workflow.py
+-rw-r--r--   0        0        0    82747 2023-07-24 14:45:48.550592 temporalio-1.3.0/temporalio/worker/_workflow_instance.py
+-rw-r--r--   0        0        0     2481 2023-07-24 14:45:48.550592 temporalio-1.3.0/temporalio/worker/workflow_sandbox/__init__.py
+-rw-r--r--   0        0        0    17707 2023-07-24 14:45:48.550592 temporalio-1.3.0/temporalio/worker/workflow_sandbox/_importer.py
+-rw-r--r--   0        0        0     1817 2023-07-24 14:45:48.550592 temporalio-1.3.0/temporalio/worker/workflow_sandbox/_in_sandbox.py
+-rw-r--r--   0        0        0    40240 2023-07-24 14:45:48.550592 temporalio-1.3.0/temporalio/worker/workflow_sandbox/_restrictions.py
+-rw-r--r--   0        0        0     6734 2023-07-24 14:45:48.550592 temporalio-1.3.0/temporalio/worker/workflow_sandbox/_runner.py
+-rw-r--r--   0        0        0   144761 2023-07-24 14:45:48.550592 temporalio-1.3.0/temporalio/workflow.py
+-rw-r--r--   0        0        0    77564 1970-01-01 00:00:00.000000 temporalio-1.3.0/setup.py
+-rw-r--r--   0        0        0    68354 1970-01-01 00:00:00.000000 temporalio-1.3.0/PKG-INFO
```

### Comparing `temporalio-1.2.0/LICENSE` & `temporalio-1.3.0/LICENSE`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/README.md` & `temporalio-1.3.0/README.md`

 * *Files 2% similar despite different names*

```diff
@@ -29,14 +29,17 @@
 
 **Custom `asyncio` Event Loop**
 
 The workflow implementation basically turns `async def` functions into workflows backed by a distributed, fault-tolerant
 event loop. This means task management, sleep, cancellation, etc have all been developed to seamlessly integrate with
 `asyncio` concepts.
 
+See the [blog post](https://temporal.io/blog/durable-distributed-asyncio-event-loop) introducing the Python SDK for an
+informal introduction to the features and their implementation.
+
 ---
 
 <!-- START doctoc generated TOC please keep comment here to allow auto update -->
 <!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
 **Contents**
 
 - [Quick Start](#quick-start)
@@ -302,16 +305,16 @@
   * [UUID](https://docs.python.org/3/library/uuid.html)
 
 This notably doesn't include any `date`, `time`, or `datetime` objects as they may not work across SDKs.
 
 Users are strongly encouraged to use a single `dataclass` for parameter and return types so fields with defaults can be
 easily added without breaking compatibility.
 
-Classes with generics may not have the generics properly resolved. The current implementation, similar to Pydantic, does
-not have generic type resolution. Users should use concrete types.
+Classes with generics may not have the generics properly resolved. The current implementation does not have generic
+type resolution. Users should use concrete types.
 
 ##### Custom Type Data Conversion
 
 For converting from JSON, the workflow/activity type hint is taken into account to convert to the proper type. Care has
 been taken to support all common typings including `Optional`, `Union`, all forms of iterables and mappings, `NewType`,
 etc in addition to the regular JSON values mentioned before.
 
@@ -492,15 +495,15 @@
         self._greeting_info_update.set()
 
     @workflow.signal
     async def complete_with_greeting(self) -> None:
         self._complete.set()
 
     @workflow.query
-    async def current_greeting(self) -> str:
+    def current_greeting(self) -> str:
         return self._current_greeting
 
 ```
 
 This assumes there's an activity in `my_activities.py` like:
 
 ```python
@@ -535,35 +538,40 @@
   `self._greeting_info` parameter is not a `GreetingInfo`
 
 Here are the decorators that can be applied:
 
 * `@workflow.defn` - Defines a workflow class
   * Must be defined on the class given to the worker (ignored if present on a base class)
   * Can have a `name` param to customize the workflow name, otherwise it defaults to the unqualified class name
+  * Can have `dynamic=True` which means all otherwise unhandled workflows fall through to this. If present, cannot have
+    `name` argument, and run method must accept a single parameter of `Sequence[temporalio.common.RawValue]` type. The
+    payload of the raw value can be converted via `workflow.payload_converter().from_payload`.
 * `@workflow.run` - Defines the primary workflow run method
   * Must be defined on the same class as `@workflow.defn`, not a base class (but can _also_ be defined on the same
     method of a base class)
   * Exactly one method name must have this decorator, no more or less
   * Must be defined on an `async def` method
   * The method's arguments are the workflow's arguments
   * The first parameter must be `self`, followed by positional arguments. Best practice is to only take a single
     argument that is an object/dataclass of fields that can be added to as needed.
 * `@workflow.signal` - Defines a method as a signal
   * Can be defined on an `async` or non-`async` function at any hierarchy depth, but if decorated method is overridden,
     the override must also be decorated
   * The method's arguments are the signal's arguments
   * Can have a `name` param to customize the signal name, otherwise it defaults to the unqualified method name
   * Can have `dynamic=True` which means all otherwise unhandled signals fall through to this. If present, cannot have
-    `name` argument, and method parameters must be `self`, a string signal name, and a `*args` varargs param.
+    `name` argument, and method parameters must be `self`, a string signal name, and a
+    `Sequence[temporalio.common.RawValue]`.
   * Non-dynamic method can only have positional arguments. Best practice is to only take a single argument that is an
     object/dataclass of fields that can be added to as needed.
   * Return value is ignored
 * `@workflow.query` - Defines a method as a query
   * All the same constraints as `@workflow.signal` but should return a value
-  * Temporal queries should never mutate anything in the workflow
+  * Should not be `async`
+  * Temporal queries should never mutate anything in the workflow or call any calls that would mutate the workflow
 
 #### Running
 
 To start a locally-defined workflow from a client, you can simply reference its method like so:
 
 ```python
 from temporalio.client import Client
@@ -1047,14 +1055,18 @@
 * Long running activities should regularly heartbeat and handle cancellation
 * Activities can only have positional arguments. Best practice is to only take a single argument that is an
   object/dataclass of fields that can be added to as needed.
 * Activities can be defined on methods instead of top-level functions. This allows the instance to carry state that an
   activity may need (e.g. a DB connection). The instance method should be what is registered with the worker.
 * Activities can also be defined on callable classes (i.e. classes with `__call__`). An instance of the class should be
   what is registered with the worker.
+* The `@activity.defn` can have `dynamic=True` set which means all otherwise unhandled activities fall through to this.
+  If present, cannot have `name` argument, and the activity function must accept a single parameter of
+  `Sequence[temporalio.common.RawValue]`. The payload of the raw value can be converted via
+  `activity.payload_converter().from_payload`.
 
 #### Types of Activities
 
 There are 3 types of activity callables accepted and described below: asynchronous, synchronous multithreaded, and
 synchronous multiprocess/other. Only positional parameters are allowed in activity callables.
 
 ##### Asynchronous Activities
```

### Comparing `temporalio-1.2.0/build.py` & `temporalio-1.3.0/build.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/pyproject.toml` & `temporalio-1.3.0/pyproject.toml`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 [tool.poetry]
 name = "temporalio"
-version = "1.2.0"
+version = "1.3.0"
 description = "Temporal.io Python SDK"
 license = "MIT"
 authors = ["Temporal Technologies Inc <sdk@temporal.io>"]
 readme = "README.md"
 homepage = "https://github.com/temporalio/sdk-python"
 repository = "https://github.com/temporalio/sdk-python"
 documentation = "https://docs.temporal.io/docs/python"
@@ -47,17 +47,15 @@
 isort = "^5.11.5"
 mypy = "^1.0.0"
 mypy-protobuf = "^3.3.0"
 protoc-wheel-0 = "^21.1"
 psutil = "^5.9.3"
 pydantic = "^1.9.1"
 pydocstyle = "^6.1.1"
-# TODO(cretz): Update when https://github.com/twisted/pydoctor/pull/595 released
-# pydoctor = "^22.5.1"
-pydoctor = { git = "https://github.com/cretz/pydoctor.git", branch = "overloads" }
+pydoctor = "^23.4.1"
 pytest = "^7.1.2"
 pytest-asyncio = "^0.18.3"
 pytest-timeout = "^2.1.0"
 setuptools = ">=65.0.0"
 setuptools-rust = ">=1.3.0"
 toml = "^0.10.2"
 twine = "^4.0.1"
```

### Comparing `temporalio-1.2.0/temporalio/activity.py` & `temporalio-1.3.0/temporalio/activity.py`

 * *Files 13% similar despite different names*

```diff
@@ -31,14 +31,15 @@
     Tuple,
     Type,
     Union,
     overload,
 )
 
 import temporalio.common
+import temporalio.converter
 
 from .types import CallableType
 
 
 @overload
 def defn(fn: CallableType) -> CallableType:
     ...
@@ -47,36 +48,48 @@
 @overload
 def defn(
     *, name: Optional[str] = None, no_thread_cancel_exception: bool = False
 ) -> Callable[[CallableType], CallableType]:
     ...
 
 
+@overload
+def defn(
+    *, no_thread_cancel_exception: bool = False, dynamic: bool = False
+) -> Callable[[CallableType], CallableType]:
+    ...
+
+
 def defn(
     fn: Optional[CallableType] = None,
     *,
     name: Optional[str] = None,
     no_thread_cancel_exception: bool = False,
+    dynamic: bool = False,
 ):
     """Decorator for activity functions.
 
     Activities can be async or non-async.
 
     Args:
         fn: The function to decorate.
         name: Name to use for the activity. Defaults to function ``__name__``.
+            This cannot be set if dynamic is set.
         no_thread_cancel_exception: If set to true, an exception will not be
             raised in synchronous, threaded activities upon cancellation.
+        dynamic: If true, this activity will be dynamic. Dynamic activities have
+            to accept a single 'Sequence[RawValue]' parameter. This cannot be
+            set to true if name is present.
     """
 
     def decorator(fn: CallableType) -> CallableType:
         # This performs validation
         _Definition._apply_to_callable(
             fn,
-            activity_name=name or fn.__name__,
+            activity_name=name or fn.__name__ if not dynamic else None,
             no_thread_cancel_exception=no_thread_cancel_exception,
         )
         return fn
 
     if fn is not None:
         return decorator(fn)
     return decorator
@@ -128,15 +141,20 @@
 class _Context:
     info: Callable[[], Info]
     # This is optional because during interceptor init it is not present
     heartbeat: Optional[Callable[..., None]]
     cancelled_event: _CompositeEvent
     worker_shutdown_event: _CompositeEvent
     shield_thread_cancel_exception: Optional[Callable[[], AbstractContextManager]]
+    payload_converter_class_or_instance: Union[
+        Type[temporalio.converter.PayloadConverter],
+        temporalio.converter.PayloadConverter,
+    ]
     _logger_details: Optional[Mapping[str, Any]] = None
+    _payload_converter: Optional[temporalio.converter.PayloadConverter] = None
 
     @staticmethod
     def current() -> _Context:
         context = _current_context.get(None)
         if not context:
             raise RuntimeError("Not in activity context")
         return context
@@ -151,14 +169,26 @@
 
     @property
     def logger_details(self) -> Mapping[str, Any]:
         if self._logger_details is None:
             self._logger_details = self.info()._logger_details()
         return self._logger_details
 
+    @property
+    def payload_converter(self) -> temporalio.converter.PayloadConverter:
+        if not self._payload_converter:
+            if isinstance(
+                self.payload_converter_class_or_instance,
+                temporalio.converter.PayloadConverter,
+            ):
+                self._payload_converter = self.payload_converter_class_or_instance
+            else:
+                self._payload_converter = self.payload_converter_class_or_instance()
+        return self._payload_converter
+
 
 @dataclass
 class _CompositeEvent:
     # This should always be present, but is sometimes lazily set internally
     thread_event: Optional[threading.Event]
     # Async event only for async activities
     async_event: Optional[asyncio.Event]
@@ -335,14 +365,22 @@
     raise _CompleteAsyncError()
 
 
 class _CompleteAsyncError(BaseException):
     pass
 
 
+def payload_converter() -> temporalio.converter.PayloadConverter:
+    """Get the payload converter for the current activity.
+
+    This is often used for dynamic activities to convert payloads.
+    """
+    return _Context.current().payload_converter
+
+
 class LoggerAdapter(logging.LoggerAdapter):
     """Adapter that adds details to the log about the running activity.
 
     Attributes:
         activity_info_on_message: Boolean for whether a string representation of
             a dict of some activity info will be appended to each message.
             Default is True.
@@ -383,17 +421,17 @@
         return self.logger
 
 
 logger = LoggerAdapter(logging.getLogger(__name__), None)
 """Logger that will have contextual activity details embedded."""
 
 
-@dataclass
+@dataclass(frozen=True)
 class _Definition:
-    name: str
+    name: Optional[str]
     fn: Callable
     is_async: bool
     no_thread_cancel_exception: bool
     # Types loaded on post init if both are None
     arg_types: Optional[List[Type]] = None
     ret_type: Optional[Type] = None
 
@@ -416,15 +454,18 @@
         fn_name = getattr(fn, "__name__", "<unknown>")
         raise TypeError(
             f"Activity {fn_name} missing attributes, was it decorated with @activity.defn?"
         )
 
     @staticmethod
     def _apply_to_callable(
-        fn: Callable, *, activity_name: str, no_thread_cancel_exception: bool = False
+        fn: Callable,
+        *,
+        activity_name: Optional[str],
+        no_thread_cancel_exception: bool = False,
     ) -> None:
         # Validate the activity
         if hasattr(fn, "__temporal_activity_definition"):
             raise ValueError("Function already contains activity definition")
         elif not callable(fn):
             raise TypeError("Activity is not callable")
         # We do not allow keyword only arguments in activities
@@ -443,10 +484,20 @@
                 is_async=inspect.iscoroutinefunction(fn) or inspect.iscoroutinefunction(fn.__call__),  # type: ignore
                 no_thread_cancel_exception=no_thread_cancel_exception,
             ),
         )
 
     def __post_init__(self) -> None:
         if self.arg_types is None and self.ret_type is None:
+            dynamic = self.name is None
             arg_types, ret_type = temporalio.common._type_hints_from_func(self.fn)
+            # If dynamic, must be a sequence of raw values
+            if dynamic and (
+                not arg_types
+                or len(arg_types) != 1
+                or arg_types[0] != Sequence[temporalio.common.RawValue]
+            ):
+                raise TypeError(
+                    "Dynamic activity must accept a single Sequence[temporalio.common.RawValue]"
+                )
             object.__setattr__(self, "arg_types", arg_types)
             object.__setattr__(self, "ret_type", ret_type)
```

### Comparing `temporalio-1.2.0/temporalio/api/batch/v1/message_pb2.py` & `temporalio-1.3.0/temporalio/api/batch/v1/message_pb2.py`

 * *Files 14% similar despite different names*

```diff
@@ -20,29 +20,33 @@
 )
 from temporalio.api.dependencies.gogoproto import (
     gogo_pb2 as dependencies_dot_gogoproto_dot_gogo__pb2,
 )
 from temporalio.api.enums.v1 import (
     batch_operation_pb2 as temporal_dot_api_dot_enums_dot_v1_dot_batch__operation__pb2,
 )
+from temporalio.api.enums.v1 import (
+    reset_pb2 as temporal_dot_api_dot_enums_dot_v1_dot_reset__pb2,
+)
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n#temporal/api/batch/v1/message.proto\x12\x15temporal.api.batch.v1\x1a!dependencies/gogoproto/gogo.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a$temporal/api/common/v1/message.proto\x1a+temporal/api/enums/v1/batch_operation.proto"\xcb\x01\n\x12\x42\x61tchOperationInfo\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x39\n\x05state\x18\x02 \x01(\x0e\x32*.temporal.api.enums.v1.BatchOperationState\x12\x34\n\nstart_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x34\n\nclose_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01"`\n\x19\x42\x61tchOperationTermination\x12\x31\n\x07\x64\x65tails\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x02 \x01(\t"\x99\x01\n\x14\x42\x61tchOperationSignal\x12\x0e\n\x06signal\x18\x01 \x01(\t\x12/\n\x05input\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12.\n\x06header\x18\x03 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12\x10\n\x08identity\x18\x04 \x01(\t".\n\x1a\x42\x61tchOperationCancellation\x12\x10\n\x08identity\x18\x01 \x01(\t"*\n\x16\x42\x61tchOperationDeletion\x12\x10\n\x08identity\x18\x01 \x01(\tB\x84\x01\n\x18io.temporal.api.batch.v1B\x0cMessageProtoP\x01Z!go.temporal.io/api/batch/v1;batch\xaa\x02\x17Temporalio.Api.Batch.V1\xea\x02\x1aTemporalio::Api::Batch::V1b\x06proto3'
+    b'\n#temporal/api/batch/v1/message.proto\x12\x15temporal.api.batch.v1\x1a!dependencies/gogoproto/gogo.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a$temporal/api/common/v1/message.proto\x1a+temporal/api/enums/v1/batch_operation.proto\x1a!temporal/api/enums/v1/reset.proto"\xcb\x01\n\x12\x42\x61tchOperationInfo\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x39\n\x05state\x18\x02 \x01(\x0e\x32*.temporal.api.enums.v1.BatchOperationState\x12\x34\n\nstart_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x34\n\nclose_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01"`\n\x19\x42\x61tchOperationTermination\x12\x31\n\x07\x64\x65tails\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x02 \x01(\t"\x99\x01\n\x14\x42\x61tchOperationSignal\x12\x0e\n\x06signal\x18\x01 \x01(\t\x12/\n\x05input\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12.\n\x06header\x18\x03 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12\x10\n\x08identity\x18\x04 \x01(\t".\n\x1a\x42\x61tchOperationCancellation\x12\x10\n\x08identity\x18\x01 \x01(\t"*\n\x16\x42\x61tchOperationDeletion\x12\x10\n\x08identity\x18\x01 \x01(\t"\xa2\x01\n\x13\x42\x61tchOperationReset\x12\x34\n\nreset_type\x18\x01 \x01(\x0e\x32 .temporal.api.enums.v1.ResetType\x12\x43\n\x12reset_reapply_type\x18\x02 \x01(\x0e\x32\'.temporal.api.enums.v1.ResetReapplyType\x12\x10\n\x08identity\x18\x03 \x01(\tB\x84\x01\n\x18io.temporal.api.batch.v1B\x0cMessageProtoP\x01Z!go.temporal.io/api/batch/v1;batch\xaa\x02\x17Temporalio.Api.Batch.V1\xea\x02\x1aTemporalio::Api::Batch::V1b\x06proto3'
 )
 
 
 _BATCHOPERATIONINFO = DESCRIPTOR.message_types_by_name["BatchOperationInfo"]
 _BATCHOPERATIONTERMINATION = DESCRIPTOR.message_types_by_name[
     "BatchOperationTermination"
 ]
 _BATCHOPERATIONSIGNAL = DESCRIPTOR.message_types_by_name["BatchOperationSignal"]
 _BATCHOPERATIONCANCELLATION = DESCRIPTOR.message_types_by_name[
     "BatchOperationCancellation"
 ]
 _BATCHOPERATIONDELETION = DESCRIPTOR.message_types_by_name["BatchOperationDeletion"]
+_BATCHOPERATIONRESET = DESCRIPTOR.message_types_by_name["BatchOperationReset"]
 BatchOperationInfo = _reflection.GeneratedProtocolMessageType(
     "BatchOperationInfo",
     (_message.Message,),
     {
         "DESCRIPTOR": _BATCHOPERATIONINFO,
         "__module__": "temporal.api.batch.v1.message_pb2"
         # @@protoc_insertion_point(class_scope:temporal.api.batch.v1.BatchOperationInfo)
@@ -90,29 +94,42 @@
         "DESCRIPTOR": _BATCHOPERATIONDELETION,
         "__module__": "temporal.api.batch.v1.message_pb2"
         # @@protoc_insertion_point(class_scope:temporal.api.batch.v1.BatchOperationDeletion)
     },
 )
 _sym_db.RegisterMessage(BatchOperationDeletion)
 
+BatchOperationReset = _reflection.GeneratedProtocolMessageType(
+    "BatchOperationReset",
+    (_message.Message,),
+    {
+        "DESCRIPTOR": _BATCHOPERATIONRESET,
+        "__module__": "temporal.api.batch.v1.message_pb2"
+        # @@protoc_insertion_point(class_scope:temporal.api.batch.v1.BatchOperationReset)
+    },
+)
+_sym_db.RegisterMessage(BatchOperationReset)
+
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
     DESCRIPTOR._serialized_options = b"\n\030io.temporal.api.batch.v1B\014MessageProtoP\001Z!go.temporal.io/api/batch/v1;batch\252\002\027Temporalio.Api.Batch.V1\352\002\032Temporalio::Api::Batch::V1"
     _BATCHOPERATIONINFO.fields_by_name["start_time"]._options = None
     _BATCHOPERATIONINFO.fields_by_name[
         "start_time"
     ]._serialized_options = b"\220\337\037\001"
     _BATCHOPERATIONINFO.fields_by_name["close_time"]._options = None
     _BATCHOPERATIONINFO.fields_by_name[
         "close_time"
     ]._serialized_options = b"\220\337\037\001"
-    _BATCHOPERATIONINFO._serialized_start = 214
-    _BATCHOPERATIONINFO._serialized_end = 417
-    _BATCHOPERATIONTERMINATION._serialized_start = 419
-    _BATCHOPERATIONTERMINATION._serialized_end = 515
-    _BATCHOPERATIONSIGNAL._serialized_start = 518
-    _BATCHOPERATIONSIGNAL._serialized_end = 671
-    _BATCHOPERATIONCANCELLATION._serialized_start = 673
-    _BATCHOPERATIONCANCELLATION._serialized_end = 719
-    _BATCHOPERATIONDELETION._serialized_start = 721
-    _BATCHOPERATIONDELETION._serialized_end = 763
+    _BATCHOPERATIONINFO._serialized_start = 249
+    _BATCHOPERATIONINFO._serialized_end = 452
+    _BATCHOPERATIONTERMINATION._serialized_start = 454
+    _BATCHOPERATIONTERMINATION._serialized_end = 550
+    _BATCHOPERATIONSIGNAL._serialized_start = 553
+    _BATCHOPERATIONSIGNAL._serialized_end = 706
+    _BATCHOPERATIONCANCELLATION._serialized_start = 708
+    _BATCHOPERATIONCANCELLATION._serialized_end = 754
+    _BATCHOPERATIONDELETION._serialized_start = 756
+    _BATCHOPERATIONDELETION._serialized_end = 798
+    _BATCHOPERATIONRESET._serialized_start = 801
+    _BATCHOPERATIONRESET._serialized_end = 963
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.2.0/temporalio/api/batch/v1/message_pb2.pyi` & `temporalio-1.3.0/temporalio/api/batch/v1/message_pb2.pyi`

 * *Files 12% similar despite different names*

```diff
@@ -26,14 +26,15 @@
 import builtins
 import google.protobuf.descriptor
 import google.protobuf.message
 import google.protobuf.timestamp_pb2
 import sys
 import temporalio.api.common.v1.message_pb2
 import temporalio.api.enums.v1.batch_operation_pb2
+import temporalio.api.enums.v1.reset_pb2
 
 if sys.version_info >= (3, 8):
     import typing as typing_extensions
 else:
     import typing_extensions
 
 DESCRIPTOR: google.protobuf.descriptor.FileDescriptor
@@ -207,7 +208,44 @@
         identity: builtins.str = ...,
     ) -> None: ...
     def ClearField(
         self, field_name: typing_extensions.Literal["identity", b"identity"]
     ) -> None: ...
 
 global___BatchOperationDeletion = BatchOperationDeletion
+
+class BatchOperationReset(google.protobuf.message.Message):
+    """BatchOperationReset sends reset requests to batch workflows.
+    Keep the parameter in sync with temporalio.api.workflowservice.v1.ResetWorkflowExecutionRequest.
+    """
+
+    DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+    RESET_TYPE_FIELD_NUMBER: builtins.int
+    RESET_REAPPLY_TYPE_FIELD_NUMBER: builtins.int
+    IDENTITY_FIELD_NUMBER: builtins.int
+    reset_type: temporalio.api.enums.v1.reset_pb2.ResetType.ValueType
+    """Reset type."""
+    reset_reapply_type: temporalio.api.enums.v1.reset_pb2.ResetReapplyType.ValueType
+    """History event reapply options."""
+    identity: builtins.str
+    """The identity of the worker/client."""
+    def __init__(
+        self,
+        *,
+        reset_type: temporalio.api.enums.v1.reset_pb2.ResetType.ValueType = ...,
+        reset_reapply_type: temporalio.api.enums.v1.reset_pb2.ResetReapplyType.ValueType = ...,
+        identity: builtins.str = ...,
+    ) -> None: ...
+    def ClearField(
+        self,
+        field_name: typing_extensions.Literal[
+            "identity",
+            b"identity",
+            "reset_reapply_type",
+            b"reset_reapply_type",
+            "reset_type",
+            b"reset_type",
+        ],
+    ) -> None: ...
+
+global___BatchOperationReset = BatchOperationReset
```

### Comparing `temporalio-1.2.0/temporalio/api/cluster/v1/message_pb2.py` & `temporalio-1.3.0/temporalio/api/cluster/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/cluster/v1/message_pb2.pyi` & `temporalio-1.3.0/temporalio/api/cluster/v1/message_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/cluster/v1/message_pb2_grpc.pyi` & `temporalio-1.3.0/temporalio/api/cluster/v1/message_pb2_grpc.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/command/v1/__init__.py` & `temporalio-1.3.0/temporalio/api/command/v1/__init__.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/command/v1/message_pb2.py` & `temporalio-1.3.0/temporalio/api/command/v1/message_pb2.py`

 * *Files 1% similar despite different names*

```diff
@@ -31,15 +31,15 @@
     message_pb2 as temporal_dot_api_dot_failure_dot_v1_dot_message__pb2,
 )
 from temporalio.api.taskqueue.v1 import (
     message_pb2 as temporal_dot_api_dot_taskqueue_dot_v1_dot_message__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n%temporal/api/command/v1/message.proto\x12\x17temporal.api.command.v1\x1a\x1egoogle/protobuf/duration.proto\x1a!dependencies/gogoproto/gogo.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a(temporal/api/enums/v1/command_type.proto\x1a$temporal/api/common/v1/message.proto\x1a%temporal/api/failure/v1/message.proto\x1a\'temporal/api/taskqueue/v1/message.proto"\xfb\x04\n%ScheduleActivityTaskCommandAttributes\x12\x13\n\x0b\x61\x63tivity_id\x18\x01 \x01(\t\x12;\n\ractivity_type\x18\x02 \x01(\x0b\x32$.temporal.api.common.v1.ActivityType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12.\n\x06header\x18\x05 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12/\n\x05input\x18\x06 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x42\n\x19schedule_to_close_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x42\n\x19schedule_to_start_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12?\n\x16start_to_close_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12:\n\x11heartbeat_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x39\n\x0cretry_policy\x18\x0b \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x1f\n\x17request_eager_execution\x18\x0c \x01(\x08J\x04\x08\x03\x10\x04"H\n*RequestCancelActivityTaskCommandAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03"o\n\x1bStartTimerCommandAttributes\x12\x10\n\x08timer_id\x18\x01 \x01(\t\x12>\n\x15start_to_fire_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01"^\n*CompleteWorkflowExecutionCommandAttributes\x12\x30\n\x06result\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads"[\n&FailWorkflowExecutionCommandAttributes\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"0\n\x1c\x43\x61ncelTimerCommandAttributes\x12\x10\n\x08timer_id\x18\x01 \x01(\t"]\n(CancelWorkflowExecutionCommandAttributes\x12\x31\n\x07\x64\x65tails\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads"\xaf\x01\n7RequestCancelExternalWorkflowExecutionCommandAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x0f\n\x07\x63ontrol\x18\x04 \x01(\t\x12\x1b\n\x13\x63hild_workflow_only\x18\x05 \x01(\x08\x12\x0e\n\x06reason\x18\x06 \x01(\t"\xa7\x02\n0SignalExternalWorkflowExecutionCommandAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x13\n\x0bsignal_name\x18\x03 \x01(\t\x12/\n\x05input\x18\x04 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x0f\n\x07\x63ontrol\x18\x05 \x01(\t\x12\x1b\n\x13\x63hild_workflow_only\x18\x06 \x01(\x08\x12.\n\x06header\x18\x07 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header"v\n/UpsertWorkflowSearchAttributesCommandAttributes\x12\x43\n\x11search_attributes\x18\x01 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"`\n)ModifyWorkflowPropertiesCommandAttributes\x12\x33\n\rupserted_memo\x18\x01 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo"\xbf\x02\n\x1dRecordMarkerCommandAttributes\x12\x13\n\x0bmarker_name\x18\x01 \x01(\t\x12T\n\x07\x64\x65tails\x18\x02 \x03(\x0b\x32\x43.temporal.api.command.v1.RecordMarkerCommandAttributes.DetailsEntry\x12.\n\x06header\x18\x03 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12\x31\n\x07\x66\x61ilure\x18\x04 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x1aP\n\x0c\x44\x65tailsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12/\n\x05value\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads:\x02\x38\x01"\xc3\x06\n/ContinueAsNewWorkflowExecutionCommandAttributes\x12;\n\rworkflow_type\x18\x01 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x02 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x03 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12=\n\x14workflow_run_timeout\x18\x04 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x05 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12?\n\x16\x62\x61\x63koff_start_interval\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x39\n\x0cretry_policy\x18\x07 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12@\n\tinitiator\x18\x08 \x01(\x0e\x32-.temporal.api.enums.v1.ContinueAsNewInitiator\x12\x31\n\x07\x66\x61ilure\x18\t \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12@\n\x16last_completion_result\x18\n \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x15\n\rcron_schedule\x18\x0b \x01(\t\x12.\n\x06header\x18\x0c \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12*\n\x04memo\x18\r \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x0e \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"\xdd\x06\n,StartChildWorkflowExecutionCommandAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x45\n\x13parent_close_policy\x18\t \x01(\x0e\x32(.temporal.api.enums.v1.ParentClosePolicy\x12\x0f\n\x07\x63ontrol\x18\n \x01(\t\x12N\n\x18workflow_id_reuse_policy\x18\x0b \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x39\n\x0cretry_policy\x18\x0c \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\r \x01(\t\x12.\n\x06header\x18\x0e \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12*\n\x04memo\x18\x0f \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x10 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"6\n ProtocolMessageCommandAttributes\x12\x12\n\nmessage_id\x18\x01 \x01(\t"\x89\x0f\n\x07\x43ommand\x12\x38\n\x0c\x63ommand_type\x18\x01 \x01(\x0e\x32".temporal.api.enums.v1.CommandType\x12s\n)schedule_activity_task_command_attributes\x18\x02 \x01(\x0b\x32>.temporal.api.command.v1.ScheduleActivityTaskCommandAttributesH\x00\x12^\n\x1estart_timer_command_attributes\x18\x03 \x01(\x0b\x32\x34.temporal.api.command.v1.StartTimerCommandAttributesH\x00\x12}\n.complete_workflow_execution_command_attributes\x18\x04 \x01(\x0b\x32\x43.temporal.api.command.v1.CompleteWorkflowExecutionCommandAttributesH\x00\x12u\n*fail_workflow_execution_command_attributes\x18\x05 \x01(\x0b\x32?.temporal.api.command.v1.FailWorkflowExecutionCommandAttributesH\x00\x12~\n/request_cancel_activity_task_command_attributes\x18\x06 \x01(\x0b\x32\x43.temporal.api.command.v1.RequestCancelActivityTaskCommandAttributesH\x00\x12`\n\x1f\x63\x61ncel_timer_command_attributes\x18\x07 \x01(\x0b\x32\x35.temporal.api.command.v1.CancelTimerCommandAttributesH\x00\x12y\n,cancel_workflow_execution_command_attributes\x18\x08 \x01(\x0b\x32\x41.temporal.api.command.v1.CancelWorkflowExecutionCommandAttributesH\x00\x12\x99\x01\n=request_cancel_external_workflow_execution_command_attributes\x18\t \x01(\x0b\x32P.temporal.api.command.v1.RequestCancelExternalWorkflowExecutionCommandAttributesH\x00\x12\x62\n record_marker_command_attributes\x18\n \x01(\x0b\x32\x36.temporal.api.command.v1.RecordMarkerCommandAttributesH\x00\x12\x89\x01\n5continue_as_new_workflow_execution_command_attributes\x18\x0b \x01(\x0b\x32H.temporal.api.command.v1.ContinueAsNewWorkflowExecutionCommandAttributesH\x00\x12\x82\x01\n1start_child_workflow_execution_command_attributes\x18\x0c \x01(\x0b\x32\x45.temporal.api.command.v1.StartChildWorkflowExecutionCommandAttributesH\x00\x12\x8a\x01\n5signal_external_workflow_execution_command_attributes\x18\r \x01(\x0b\x32I.temporal.api.command.v1.SignalExternalWorkflowExecutionCommandAttributesH\x00\x12\x88\x01\n4upsert_workflow_search_attributes_command_attributes\x18\x0e \x01(\x0b\x32H.temporal.api.command.v1.UpsertWorkflowSearchAttributesCommandAttributesH\x00\x12h\n#protocol_message_command_attributes\x18\x0f \x01(\x0b\x32\x39.temporal.api.command.v1.ProtocolMessageCommandAttributesH\x00\x12{\n-modify_workflow_properties_command_attributes\x18\x11 \x01(\x0b\x32\x42.temporal.api.command.v1.ModifyWorkflowPropertiesCommandAttributesH\x00\x42\x0c\n\nattributesB\x8e\x01\n\x1aio.temporal.api.command.v1B\x0cMessageProtoP\x01Z%go.temporal.io/api/command/v1;command\xaa\x02\x19Temporalio.Api.Command.V1\xea\x02\x1cTemporalio::Api::Command::V1b\x06proto3'
+    b'\n%temporal/api/command/v1/message.proto\x12\x17temporal.api.command.v1\x1a\x1egoogle/protobuf/duration.proto\x1a!dependencies/gogoproto/gogo.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a(temporal/api/enums/v1/command_type.proto\x1a$temporal/api/common/v1/message.proto\x1a%temporal/api/failure/v1/message.proto\x1a\'temporal/api/taskqueue/v1/message.proto"\x9b\x05\n%ScheduleActivityTaskCommandAttributes\x12\x13\n\x0b\x61\x63tivity_id\x18\x01 \x01(\t\x12;\n\ractivity_type\x18\x02 \x01(\x0b\x32$.temporal.api.common.v1.ActivityType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12.\n\x06header\x18\x05 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12/\n\x05input\x18\x06 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x42\n\x19schedule_to_close_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x42\n\x19schedule_to_start_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12?\n\x16start_to_close_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12:\n\x11heartbeat_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x39\n\x0cretry_policy\x18\x0b \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x1f\n\x17request_eager_execution\x18\x0c \x01(\x08\x12\x1e\n\x16use_compatible_version\x18\r \x01(\x08J\x04\x08\x03\x10\x04"H\n*RequestCancelActivityTaskCommandAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03"o\n\x1bStartTimerCommandAttributes\x12\x10\n\x08timer_id\x18\x01 \x01(\t\x12>\n\x15start_to_fire_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01"^\n*CompleteWorkflowExecutionCommandAttributes\x12\x30\n\x06result\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads"[\n&FailWorkflowExecutionCommandAttributes\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"0\n\x1c\x43\x61ncelTimerCommandAttributes\x12\x10\n\x08timer_id\x18\x01 \x01(\t"]\n(CancelWorkflowExecutionCommandAttributes\x12\x31\n\x07\x64\x65tails\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads"\xaf\x01\n7RequestCancelExternalWorkflowExecutionCommandAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x0f\n\x07\x63ontrol\x18\x04 \x01(\t\x12\x1b\n\x13\x63hild_workflow_only\x18\x05 \x01(\x08\x12\x0e\n\x06reason\x18\x06 \x01(\t"\xa7\x02\n0SignalExternalWorkflowExecutionCommandAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x13\n\x0bsignal_name\x18\x03 \x01(\t\x12/\n\x05input\x18\x04 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x0f\n\x07\x63ontrol\x18\x05 \x01(\t\x12\x1b\n\x13\x63hild_workflow_only\x18\x06 \x01(\x08\x12.\n\x06header\x18\x07 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header"v\n/UpsertWorkflowSearchAttributesCommandAttributes\x12\x43\n\x11search_attributes\x18\x01 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"`\n)ModifyWorkflowPropertiesCommandAttributes\x12\x33\n\rupserted_memo\x18\x01 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo"\xbf\x02\n\x1dRecordMarkerCommandAttributes\x12\x13\n\x0bmarker_name\x18\x01 \x01(\t\x12T\n\x07\x64\x65tails\x18\x02 \x03(\x0b\x32\x43.temporal.api.command.v1.RecordMarkerCommandAttributes.DetailsEntry\x12.\n\x06header\x18\x03 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12\x31\n\x07\x66\x61ilure\x18\x04 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x1aP\n\x0c\x44\x65tailsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12/\n\x05value\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads:\x02\x38\x01"\xe3\x06\n/ContinueAsNewWorkflowExecutionCommandAttributes\x12;\n\rworkflow_type\x18\x01 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x02 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x03 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12=\n\x14workflow_run_timeout\x18\x04 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x05 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12?\n\x16\x62\x61\x63koff_start_interval\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x39\n\x0cretry_policy\x18\x07 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12@\n\tinitiator\x18\x08 \x01(\x0e\x32-.temporal.api.enums.v1.ContinueAsNewInitiator\x12\x31\n\x07\x66\x61ilure\x18\t \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12@\n\x16last_completion_result\x18\n \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x15\n\rcron_schedule\x18\x0b \x01(\t\x12.\n\x06header\x18\x0c \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12*\n\x04memo\x18\r \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x0e \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12\x1e\n\x16use_compatible_version\x18\x0f \x01(\x08"\xfd\x06\n,StartChildWorkflowExecutionCommandAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x45\n\x13parent_close_policy\x18\t \x01(\x0e\x32(.temporal.api.enums.v1.ParentClosePolicy\x12\x0f\n\x07\x63ontrol\x18\n \x01(\t\x12N\n\x18workflow_id_reuse_policy\x18\x0b \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x39\n\x0cretry_policy\x18\x0c \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\r \x01(\t\x12.\n\x06header\x18\x0e \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12*\n\x04memo\x18\x0f \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x10 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12\x1e\n\x16use_compatible_version\x18\x11 \x01(\x08"6\n ProtocolMessageCommandAttributes\x12\x12\n\nmessage_id\x18\x01 \x01(\t"\x89\x0f\n\x07\x43ommand\x12\x38\n\x0c\x63ommand_type\x18\x01 \x01(\x0e\x32".temporal.api.enums.v1.CommandType\x12s\n)schedule_activity_task_command_attributes\x18\x02 \x01(\x0b\x32>.temporal.api.command.v1.ScheduleActivityTaskCommandAttributesH\x00\x12^\n\x1estart_timer_command_attributes\x18\x03 \x01(\x0b\x32\x34.temporal.api.command.v1.StartTimerCommandAttributesH\x00\x12}\n.complete_workflow_execution_command_attributes\x18\x04 \x01(\x0b\x32\x43.temporal.api.command.v1.CompleteWorkflowExecutionCommandAttributesH\x00\x12u\n*fail_workflow_execution_command_attributes\x18\x05 \x01(\x0b\x32?.temporal.api.command.v1.FailWorkflowExecutionCommandAttributesH\x00\x12~\n/request_cancel_activity_task_command_attributes\x18\x06 \x01(\x0b\x32\x43.temporal.api.command.v1.RequestCancelActivityTaskCommandAttributesH\x00\x12`\n\x1f\x63\x61ncel_timer_command_attributes\x18\x07 \x01(\x0b\x32\x35.temporal.api.command.v1.CancelTimerCommandAttributesH\x00\x12y\n,cancel_workflow_execution_command_attributes\x18\x08 \x01(\x0b\x32\x41.temporal.api.command.v1.CancelWorkflowExecutionCommandAttributesH\x00\x12\x99\x01\n=request_cancel_external_workflow_execution_command_attributes\x18\t \x01(\x0b\x32P.temporal.api.command.v1.RequestCancelExternalWorkflowExecutionCommandAttributesH\x00\x12\x62\n record_marker_command_attributes\x18\n \x01(\x0b\x32\x36.temporal.api.command.v1.RecordMarkerCommandAttributesH\x00\x12\x89\x01\n5continue_as_new_workflow_execution_command_attributes\x18\x0b \x01(\x0b\x32H.temporal.api.command.v1.ContinueAsNewWorkflowExecutionCommandAttributesH\x00\x12\x82\x01\n1start_child_workflow_execution_command_attributes\x18\x0c \x01(\x0b\x32\x45.temporal.api.command.v1.StartChildWorkflowExecutionCommandAttributesH\x00\x12\x8a\x01\n5signal_external_workflow_execution_command_attributes\x18\r \x01(\x0b\x32I.temporal.api.command.v1.SignalExternalWorkflowExecutionCommandAttributesH\x00\x12\x88\x01\n4upsert_workflow_search_attributes_command_attributes\x18\x0e \x01(\x0b\x32H.temporal.api.command.v1.UpsertWorkflowSearchAttributesCommandAttributesH\x00\x12h\n#protocol_message_command_attributes\x18\x0f \x01(\x0b\x32\x39.temporal.api.command.v1.ProtocolMessageCommandAttributesH\x00\x12{\n-modify_workflow_properties_command_attributes\x18\x11 \x01(\x0b\x32\x42.temporal.api.command.v1.ModifyWorkflowPropertiesCommandAttributesH\x00\x42\x0c\n\nattributesB\x8e\x01\n\x1aio.temporal.api.command.v1B\x0cMessageProtoP\x01Z%go.temporal.io/api/command/v1;command\xaa\x02\x19Temporalio.Api.Command.V1\xea\x02\x1cTemporalio::Api::Command::V1b\x06proto3'
 )
 
 
 _SCHEDULEACTIVITYTASKCOMMANDATTRIBUTES = DESCRIPTOR.message_types_by_name[
     "ScheduleActivityTaskCommandAttributes"
 ]
 _REQUESTCANCELACTIVITYTASKCOMMANDATTRIBUTES = DESCRIPTOR.message_types_by_name[
@@ -342,41 +342,41 @@
     _STARTCHILDWORKFLOWEXECUTIONCOMMANDATTRIBUTES.fields_by_name[
         "workflow_task_timeout"
     ]._options = None
     _STARTCHILDWORKFLOWEXECUTIONCOMMANDATTRIBUTES.fields_by_name[
         "workflow_task_timeout"
     ]._serialized_options = b"\230\337\037\001"
     _SCHEDULEACTIVITYTASKCOMMANDATTRIBUTES._serialized_start = 332
-    _SCHEDULEACTIVITYTASKCOMMANDATTRIBUTES._serialized_end = 967
-    _REQUESTCANCELACTIVITYTASKCOMMANDATTRIBUTES._serialized_start = 969
-    _REQUESTCANCELACTIVITYTASKCOMMANDATTRIBUTES._serialized_end = 1041
-    _STARTTIMERCOMMANDATTRIBUTES._serialized_start = 1043
-    _STARTTIMERCOMMANDATTRIBUTES._serialized_end = 1154
-    _COMPLETEWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 1156
-    _COMPLETEWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 1250
-    _FAILWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 1252
-    _FAILWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 1343
-    _CANCELTIMERCOMMANDATTRIBUTES._serialized_start = 1345
-    _CANCELTIMERCOMMANDATTRIBUTES._serialized_end = 1393
-    _CANCELWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 1395
-    _CANCELWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 1488
-    _REQUESTCANCELEXTERNALWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 1491
-    _REQUESTCANCELEXTERNALWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 1666
-    _SIGNALEXTERNALWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 1669
-    _SIGNALEXTERNALWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 1964
-    _UPSERTWORKFLOWSEARCHATTRIBUTESCOMMANDATTRIBUTES._serialized_start = 1966
-    _UPSERTWORKFLOWSEARCHATTRIBUTESCOMMANDATTRIBUTES._serialized_end = 2084
-    _MODIFYWORKFLOWPROPERTIESCOMMANDATTRIBUTES._serialized_start = 2086
-    _MODIFYWORKFLOWPROPERTIESCOMMANDATTRIBUTES._serialized_end = 2182
-    _RECORDMARKERCOMMANDATTRIBUTES._serialized_start = 2185
-    _RECORDMARKERCOMMANDATTRIBUTES._serialized_end = 2504
-    _RECORDMARKERCOMMANDATTRIBUTES_DETAILSENTRY._serialized_start = 2424
-    _RECORDMARKERCOMMANDATTRIBUTES_DETAILSENTRY._serialized_end = 2504
-    _CONTINUEASNEWWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 2507
-    _CONTINUEASNEWWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 3342
-    _STARTCHILDWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 3345
-    _STARTCHILDWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 4206
-    _PROTOCOLMESSAGECOMMANDATTRIBUTES._serialized_start = 4208
-    _PROTOCOLMESSAGECOMMANDATTRIBUTES._serialized_end = 4262
-    _COMMAND._serialized_start = 4265
-    _COMMAND._serialized_end = 6194
+    _SCHEDULEACTIVITYTASKCOMMANDATTRIBUTES._serialized_end = 999
+    _REQUESTCANCELACTIVITYTASKCOMMANDATTRIBUTES._serialized_start = 1001
+    _REQUESTCANCELACTIVITYTASKCOMMANDATTRIBUTES._serialized_end = 1073
+    _STARTTIMERCOMMANDATTRIBUTES._serialized_start = 1075
+    _STARTTIMERCOMMANDATTRIBUTES._serialized_end = 1186
+    _COMPLETEWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 1188
+    _COMPLETEWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 1282
+    _FAILWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 1284
+    _FAILWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 1375
+    _CANCELTIMERCOMMANDATTRIBUTES._serialized_start = 1377
+    _CANCELTIMERCOMMANDATTRIBUTES._serialized_end = 1425
+    _CANCELWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 1427
+    _CANCELWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 1520
+    _REQUESTCANCELEXTERNALWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 1523
+    _REQUESTCANCELEXTERNALWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 1698
+    _SIGNALEXTERNALWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 1701
+    _SIGNALEXTERNALWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 1996
+    _UPSERTWORKFLOWSEARCHATTRIBUTESCOMMANDATTRIBUTES._serialized_start = 1998
+    _UPSERTWORKFLOWSEARCHATTRIBUTESCOMMANDATTRIBUTES._serialized_end = 2116
+    _MODIFYWORKFLOWPROPERTIESCOMMANDATTRIBUTES._serialized_start = 2118
+    _MODIFYWORKFLOWPROPERTIESCOMMANDATTRIBUTES._serialized_end = 2214
+    _RECORDMARKERCOMMANDATTRIBUTES._serialized_start = 2217
+    _RECORDMARKERCOMMANDATTRIBUTES._serialized_end = 2536
+    _RECORDMARKERCOMMANDATTRIBUTES_DETAILSENTRY._serialized_start = 2456
+    _RECORDMARKERCOMMANDATTRIBUTES_DETAILSENTRY._serialized_end = 2536
+    _CONTINUEASNEWWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 2539
+    _CONTINUEASNEWWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 3406
+    _STARTCHILDWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 3409
+    _STARTCHILDWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 4302
+    _PROTOCOLMESSAGECOMMANDATTRIBUTES._serialized_start = 4304
+    _PROTOCOLMESSAGECOMMANDATTRIBUTES._serialized_end = 4358
+    _COMMAND._serialized_start = 4361
+    _COMMAND._serialized_end = 6290
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.2.0/temporalio/api/command/v1/message_pb2.pyi` & `temporalio-1.3.0/temporalio/api/command/v1/message_pb2.pyi`

 * *Files 2% similar despite different names*

```diff
@@ -53,14 +53,15 @@
     INPUT_FIELD_NUMBER: builtins.int
     SCHEDULE_TO_CLOSE_TIMEOUT_FIELD_NUMBER: builtins.int
     SCHEDULE_TO_START_TIMEOUT_FIELD_NUMBER: builtins.int
     START_TO_CLOSE_TIMEOUT_FIELD_NUMBER: builtins.int
     HEARTBEAT_TIMEOUT_FIELD_NUMBER: builtins.int
     RETRY_POLICY_FIELD_NUMBER: builtins.int
     REQUEST_EAGER_EXECUTION_FIELD_NUMBER: builtins.int
+    USE_COMPATIBLE_VERSION_FIELD_NUMBER: builtins.int
     activity_id: builtins.str
     @property
     def activity_type(self) -> temporalio.api.common.v1.message_pb2.ActivityType: ...
     @property
     def task_queue(self) -> temporalio.api.taskqueue.v1.message_pb2.TaskQueue: ...
     @property
     def header(self) -> temporalio.api.common.v1.message_pb2.Header: ...
@@ -106,28 +107,34 @@
         dynamic configuration. Retries will be attempted until `schedule_to_close_timeout` has
         elapsed. To disable retries set retry_policy.maximum_attempts to 1.
         """
     request_eager_execution: builtins.bool
     """Request to start the activity directly bypassing matching service and worker polling
     The slot for executing the activity should be reserved when setting this field to true.
     """
+    use_compatible_version: builtins.bool
+    """If this is set, the workflow executing this command wishes to start the activity using
+    a version compatible with the version that this workflow most recently ran on, if such
+    behavior is possible.
+    """
     def __init__(
         self,
         *,
         activity_id: builtins.str = ...,
         activity_type: temporalio.api.common.v1.message_pb2.ActivityType | None = ...,
         task_queue: temporalio.api.taskqueue.v1.message_pb2.TaskQueue | None = ...,
         header: temporalio.api.common.v1.message_pb2.Header | None = ...,
         input: temporalio.api.common.v1.message_pb2.Payloads | None = ...,
         schedule_to_close_timeout: google.protobuf.duration_pb2.Duration | None = ...,
         schedule_to_start_timeout: google.protobuf.duration_pb2.Duration | None = ...,
         start_to_close_timeout: google.protobuf.duration_pb2.Duration | None = ...,
         heartbeat_timeout: google.protobuf.duration_pb2.Duration | None = ...,
         retry_policy: temporalio.api.common.v1.message_pb2.RetryPolicy | None = ...,
         request_eager_execution: builtins.bool = ...,
+        use_compatible_version: builtins.bool = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
             "activity_type",
             b"activity_type",
             "header",
@@ -169,14 +176,16 @@
             b"schedule_to_close_timeout",
             "schedule_to_start_timeout",
             b"schedule_to_start_timeout",
             "start_to_close_timeout",
             b"start_to_close_timeout",
             "task_queue",
             b"task_queue",
+            "use_compatible_version",
+            b"use_compatible_version",
         ],
     ) -> None: ...
 
 global___ScheduleActivityTaskCommandAttributes = ScheduleActivityTaskCommandAttributes
 
 class RequestCancelActivityTaskCommandAttributes(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -587,14 +596,15 @@
     INITIATOR_FIELD_NUMBER: builtins.int
     FAILURE_FIELD_NUMBER: builtins.int
     LAST_COMPLETION_RESULT_FIELD_NUMBER: builtins.int
     CRON_SCHEDULE_FIELD_NUMBER: builtins.int
     HEADER_FIELD_NUMBER: builtins.int
     MEMO_FIELD_NUMBER: builtins.int
     SEARCH_ATTRIBUTES_FIELD_NUMBER: builtins.int
+    USE_COMPATIBLE_VERSION_FIELD_NUMBER: builtins.int
     @property
     def workflow_type(self) -> temporalio.api.common.v1.message_pb2.WorkflowType: ...
     @property
     def task_queue(self) -> temporalio.api.taskqueue.v1.message_pb2.TaskQueue: ...
     @property
     def input(self) -> temporalio.api.common.v1.message_pb2.Payloads: ...
     @property
@@ -622,14 +632,18 @@
     def header(self) -> temporalio.api.common.v1.message_pb2.Header: ...
     @property
     def memo(self) -> temporalio.api.common.v1.message_pb2.Memo: ...
     @property
     def search_attributes(
         self,
     ) -> temporalio.api.common.v1.message_pb2.SearchAttributes: ...
+    use_compatible_version: builtins.bool
+    """If this is set, the workflow executing this command wishes to continue as new using a version
+    compatible with the version that this workflow most recently ran on.
+    """
     def __init__(
         self,
         *,
         workflow_type: temporalio.api.common.v1.message_pb2.WorkflowType | None = ...,
         task_queue: temporalio.api.taskqueue.v1.message_pb2.TaskQueue | None = ...,
         input: temporalio.api.common.v1.message_pb2.Payloads | None = ...,
         workflow_run_timeout: google.protobuf.duration_pb2.Duration | None = ...,
@@ -641,14 +655,15 @@
         last_completion_result: temporalio.api.common.v1.message_pb2.Payloads
         | None = ...,
         cron_schedule: builtins.str = ...,
         header: temporalio.api.common.v1.message_pb2.Header | None = ...,
         memo: temporalio.api.common.v1.message_pb2.Memo | None = ...,
         search_attributes: temporalio.api.common.v1.message_pb2.SearchAttributes
         | None = ...,
+        use_compatible_version: builtins.bool = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
             "backoff_start_interval",
             b"backoff_start_interval",
             "failure",
@@ -696,14 +711,16 @@
             b"memo",
             "retry_policy",
             b"retry_policy",
             "search_attributes",
             b"search_attributes",
             "task_queue",
             b"task_queue",
+            "use_compatible_version",
+            b"use_compatible_version",
             "workflow_run_timeout",
             b"workflow_run_timeout",
             "workflow_task_timeout",
             b"workflow_task_timeout",
             "workflow_type",
             b"workflow_type",
         ],
@@ -728,14 +745,15 @@
     CONTROL_FIELD_NUMBER: builtins.int
     WORKFLOW_ID_REUSE_POLICY_FIELD_NUMBER: builtins.int
     RETRY_POLICY_FIELD_NUMBER: builtins.int
     CRON_SCHEDULE_FIELD_NUMBER: builtins.int
     HEADER_FIELD_NUMBER: builtins.int
     MEMO_FIELD_NUMBER: builtins.int
     SEARCH_ATTRIBUTES_FIELD_NUMBER: builtins.int
+    USE_COMPATIBLE_VERSION_FIELD_NUMBER: builtins.int
     namespace: builtins.str
     workflow_id: builtins.str
     @property
     def workflow_type(self) -> temporalio.api.common.v1.message_pb2.WorkflowType: ...
     @property
     def task_queue(self) -> temporalio.api.taskqueue.v1.message_pb2.TaskQueue: ...
     @property
@@ -762,14 +780,19 @@
     def header(self) -> temporalio.api.common.v1.message_pb2.Header: ...
     @property
     def memo(self) -> temporalio.api.common.v1.message_pb2.Memo: ...
     @property
     def search_attributes(
         self,
     ) -> temporalio.api.common.v1.message_pb2.SearchAttributes: ...
+    use_compatible_version: builtins.bool
+    """If this is set, the workflow executing this command wishes to start the child workflow using
+    a version compatible with the version that this workflow most recently ran on, if such
+    behavior is possible.
+    """
     def __init__(
         self,
         *,
         namespace: builtins.str = ...,
         workflow_id: builtins.str = ...,
         workflow_type: temporalio.api.common.v1.message_pb2.WorkflowType | None = ...,
         task_queue: temporalio.api.taskqueue.v1.message_pb2.TaskQueue | None = ...,
@@ -782,14 +805,15 @@
         workflow_id_reuse_policy: temporalio.api.enums.v1.workflow_pb2.WorkflowIdReusePolicy.ValueType = ...,
         retry_policy: temporalio.api.common.v1.message_pb2.RetryPolicy | None = ...,
         cron_schedule: builtins.str = ...,
         header: temporalio.api.common.v1.message_pb2.Header | None = ...,
         memo: temporalio.api.common.v1.message_pb2.Memo | None = ...,
         search_attributes: temporalio.api.common.v1.message_pb2.SearchAttributes
         | None = ...,
+        use_compatible_version: builtins.bool = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
             "header",
             b"header",
             "input",
@@ -831,14 +855,16 @@
             b"parent_close_policy",
             "retry_policy",
             b"retry_policy",
             "search_attributes",
             b"search_attributes",
             "task_queue",
             b"task_queue",
+            "use_compatible_version",
+            b"use_compatible_version",
             "workflow_execution_timeout",
             b"workflow_execution_timeout",
             "workflow_id",
             b"workflow_id",
             "workflow_id_reuse_policy",
             b"workflow_id_reuse_policy",
             "workflow_run_timeout",
```

### Comparing `temporalio-1.2.0/temporalio/api/common/v1/__init__.py` & `temporalio-1.3.0/temporalio/api/common/v1/__init__.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/common/v1/grpc_status_pb2.py` & `temporalio-1.3.0/temporalio/api/common/v1/grpc_status_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/common/v1/grpc_status_pb2.pyi` & `temporalio-1.3.0/temporalio/api/common/v1/grpc_status_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/common/v1/message_pb2.py` & `temporalio-1.3.0/temporalio/api/common/v1/message_pb2.py`

 * *Files 1% similar despite different names*

```diff
@@ -19,15 +19,15 @@
     gogo_pb2 as dependencies_dot_gogoproto_dot_gogo__pb2,
 )
 from temporalio.api.enums.v1 import (
     common_pb2 as temporal_dot_api_dot_enums_dot_v1_dot_common__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n$temporal/api/common/v1/message.proto\x12\x16temporal.api.common.v1\x1a\x1egoogle/protobuf/duration.proto\x1a!dependencies/gogoproto/gogo.proto\x1a"temporal/api/enums/v1/common.proto"T\n\x08\x44\x61taBlob\x12:\n\rencoding_type\x18\x01 \x01(\x0e\x32#.temporal.api.enums.v1.EncodingType\x12\x0c\n\x04\x64\x61ta\x18\x02 \x01(\x0c"=\n\x08Payloads\x12\x31\n\x08payloads\x18\x01 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload"\x89\x01\n\x07Payload\x12?\n\x08metadata\x18\x01 \x03(\x0b\x32-.temporal.api.common.v1.Payload.MetadataEntry\x12\x0c\n\x04\x64\x61ta\x18\x02 \x01(\x0c\x1a/\n\rMetadataEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\x0c:\x02\x38\x01"\xbe\x01\n\x10SearchAttributes\x12S\n\x0eindexed_fields\x18\x01 \x03(\x0b\x32;.temporal.api.common.v1.SearchAttributes.IndexedFieldsEntry\x1aU\n\x12IndexedFieldsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"\x90\x01\n\x04Memo\x12\x38\n\x06\x66ields\x18\x01 \x03(\x0b\x32(.temporal.api.common.v1.Memo.FieldsEntry\x1aN\n\x0b\x46ieldsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"\x94\x01\n\x06Header\x12:\n\x06\x66ields\x18\x01 \x03(\x0b\x32*.temporal.api.common.v1.Header.FieldsEntry\x1aN\n\x0b\x46ieldsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"8\n\x11WorkflowExecution\x12\x13\n\x0bworkflow_id\x18\x01 \x01(\t\x12\x0e\n\x06run_id\x18\x02 \x01(\t"\x1c\n\x0cWorkflowType\x12\x0c\n\x04name\x18\x01 \x01(\t"\x1c\n\x0c\x41\x63tivityType\x12\x0c\n\x04name\x18\x01 \x01(\t"\xdd\x01\n\x0bRetryPolicy\x12\x39\n\x10initial_interval\x18\x01 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x1b\n\x13\x62\x61\x63koff_coefficient\x18\x02 \x01(\x01\x12\x39\n\x10maximum_interval\x18\x03 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x18\n\x10maximum_attempts\x18\x04 \x01(\x05\x12!\n\x19non_retryable_error_types\x18\x05 \x03(\t"F\n\x10MeteringMetadata\x12\x32\n*nonfirst_local_activity_execution_attempts\x18\r \x01(\r"9\n\x12WorkerVersionStamp\x12\x10\n\x08\x62uild_id\x18\x01 \x01(\t\x12\x11\n\tbundle_id\x18\x02 \x01(\t"-\n\x19WorkerVersionCapabilities\x12\x10\n\x08\x62uild_id\x18\x01 \x01(\tB\x89\x01\n\x19io.temporal.api.common.v1B\x0cMessageProtoP\x01Z#go.temporal.io/api/common/v1;common\xaa\x02\x18Temporalio.Api.Common.V1\xea\x02\x1bTemporalio::Api::Common::V1b\x06proto3'
+    b'\n$temporal/api/common/v1/message.proto\x12\x16temporal.api.common.v1\x1a\x1egoogle/protobuf/duration.proto\x1a!dependencies/gogoproto/gogo.proto\x1a"temporal/api/enums/v1/common.proto"T\n\x08\x44\x61taBlob\x12:\n\rencoding_type\x18\x01 \x01(\x0e\x32#.temporal.api.enums.v1.EncodingType\x12\x0c\n\x04\x64\x61ta\x18\x02 \x01(\x0c"=\n\x08Payloads\x12\x31\n\x08payloads\x18\x01 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload"\x89\x01\n\x07Payload\x12?\n\x08metadata\x18\x01 \x03(\x0b\x32-.temporal.api.common.v1.Payload.MetadataEntry\x12\x0c\n\x04\x64\x61ta\x18\x02 \x01(\x0c\x1a/\n\rMetadataEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\x0c:\x02\x38\x01"\xbe\x01\n\x10SearchAttributes\x12S\n\x0eindexed_fields\x18\x01 \x03(\x0b\x32;.temporal.api.common.v1.SearchAttributes.IndexedFieldsEntry\x1aU\n\x12IndexedFieldsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"\x90\x01\n\x04Memo\x12\x38\n\x06\x66ields\x18\x01 \x03(\x0b\x32(.temporal.api.common.v1.Memo.FieldsEntry\x1aN\n\x0b\x46ieldsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"\x94\x01\n\x06Header\x12:\n\x06\x66ields\x18\x01 \x03(\x0b\x32*.temporal.api.common.v1.Header.FieldsEntry\x1aN\n\x0b\x46ieldsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"8\n\x11WorkflowExecution\x12\x13\n\x0bworkflow_id\x18\x01 \x01(\t\x12\x0e\n\x06run_id\x18\x02 \x01(\t"\x1c\n\x0cWorkflowType\x12\x0c\n\x04name\x18\x01 \x01(\t"\x1c\n\x0c\x41\x63tivityType\x12\x0c\n\x04name\x18\x01 \x01(\t"\xdd\x01\n\x0bRetryPolicy\x12\x39\n\x10initial_interval\x18\x01 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x1b\n\x13\x62\x61\x63koff_coefficient\x18\x02 \x01(\x01\x12\x39\n\x10maximum_interval\x18\x03 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x18\n\x10maximum_attempts\x18\x04 \x01(\x05\x12!\n\x19non_retryable_error_types\x18\x05 \x03(\t"F\n\x10MeteringMetadata\x12\x32\n*nonfirst_local_activity_execution_attempts\x18\r \x01(\r"Q\n\x12WorkerVersionStamp\x12\x10\n\x08\x62uild_id\x18\x01 \x01(\t\x12\x11\n\tbundle_id\x18\x02 \x01(\t\x12\x16\n\x0euse_versioning\x18\x03 \x01(\x08"E\n\x19WorkerVersionCapabilities\x12\x10\n\x08\x62uild_id\x18\x01 \x01(\t\x12\x16\n\x0euse_versioning\x18\x02 \x01(\x08\x42\x89\x01\n\x19io.temporal.api.common.v1B\x0cMessageProtoP\x01Z#go.temporal.io/api/common/v1;common\xaa\x02\x18Temporalio.Api.Common.V1\xea\x02\x1bTemporalio::Api::Common::V1b\x06proto3'
 )
 
 
 _DATABLOB = DESCRIPTOR.message_types_by_name["DataBlob"]
 _PAYLOADS = DESCRIPTOR.message_types_by_name["Payloads"]
 _PAYLOAD = DESCRIPTOR.message_types_by_name["Payload"]
 _PAYLOAD_METADATAENTRY = _PAYLOAD.nested_types_by_name["MetadataEntry"]
@@ -277,11 +277,11 @@
     _ACTIVITYTYPE._serialized_start = 1035
     _ACTIVITYTYPE._serialized_end = 1063
     _RETRYPOLICY._serialized_start = 1066
     _RETRYPOLICY._serialized_end = 1287
     _METERINGMETADATA._serialized_start = 1289
     _METERINGMETADATA._serialized_end = 1359
     _WORKERVERSIONSTAMP._serialized_start = 1361
-    _WORKERVERSIONSTAMP._serialized_end = 1418
-    _WORKERVERSIONCAPABILITIES._serialized_start = 1420
-    _WORKERVERSIONCAPABILITIES._serialized_end = 1465
+    _WORKERVERSIONSTAMP._serialized_end = 1442
+    _WORKERVERSIONCAPABILITIES._serialized_start = 1444
+    _WORKERVERSIONCAPABILITIES._serialized_end = 1513
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.2.0/temporalio/api/common/v1/message_pb2.pyi` & `temporalio-1.3.0/temporalio/api/common/v1/message_pb2.pyi`

 * *Files 4% similar despite different names*

```diff
@@ -441,46 +441,71 @@
 class WorkerVersionStamp(google.protobuf.message.Message):
     """Identifies the version(s) of a worker that processed a task"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     BUILD_ID_FIELD_NUMBER: builtins.int
     BUNDLE_ID_FIELD_NUMBER: builtins.int
+    USE_VERSIONING_FIELD_NUMBER: builtins.int
     build_id: builtins.str
-    """An opaque whole-worker identifier"""
+    """An opaque whole-worker identifier. Replaces the deprecated `binary_checksum` field when this
+    message is included in requests which previously used that.
+    """
     bundle_id: builtins.str
     """Set if the worker used a dynamically loadable bundle to process
     the task. The bundle could be a WASM blob, JS bundle, etc.
     """
+    use_versioning: builtins.bool
+    """If set, the worker is opting in to worker versioning. Otherwise, this is used only as a
+    marker for workflow reset points and the BuildIDs search attribute.
+    """
     def __init__(
         self,
         *,
         build_id: builtins.str = ...,
         bundle_id: builtins.str = ...,
+        use_versioning: builtins.bool = ...,
     ) -> None: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
-            "build_id", b"build_id", "bundle_id", b"bundle_id"
+            "build_id",
+            b"build_id",
+            "bundle_id",
+            b"bundle_id",
+            "use_versioning",
+            b"use_versioning",
         ],
     ) -> None: ...
 
 global___WorkerVersionStamp = WorkerVersionStamp
 
 class WorkerVersionCapabilities(google.protobuf.message.Message):
-    """Identifies the version(s) that a worker is compatible with when polling or identifying itself"""
+    """Identifies the version(s) that a worker is compatible with when polling or identifying itself,
+    and whether or not this worker is opting into the build-id based versioning feature. This is
+    used by matching to determine which workers ought to receive what tasks.
+    """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     BUILD_ID_FIELD_NUMBER: builtins.int
+    USE_VERSIONING_FIELD_NUMBER: builtins.int
     build_id: builtins.str
     """An opaque whole-worker identifier"""
+    use_versioning: builtins.bool
+    """If set, the worker is opting in to worker versioning, and wishes to only receive appropriate
+    tasks.
+    """
     def __init__(
         self,
         *,
         build_id: builtins.str = ...,
+        use_versioning: builtins.bool = ...,
     ) -> None: ...
     def ClearField(
-        self, field_name: typing_extensions.Literal["build_id", b"build_id"]
+        self,
+        field_name: typing_extensions.Literal[
+            "build_id", b"build_id", "use_versioning", b"use_versioning"
+        ],
     ) -> None: ...
 
 global___WorkerVersionCapabilities = WorkerVersionCapabilities
```

### Comparing `temporalio-1.2.0/temporalio/api/dependencies/gogoproto/gogo_pb2.py` & `temporalio-1.3.0/temporalio/api/dependencies/gogoproto/gogo_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/dependencies/gogoproto/gogo_pb2.pyi` & `temporalio-1.3.0/temporalio/api/dependencies/gogoproto/gogo_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/__init__.py` & `temporalio-1.3.0/temporalio/api/enums/v1/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -7,17 +7,17 @@
     ResourceExhaustedCause,
     SignalExternalWorkflowExecutionFailedCause,
     StartChildWorkflowExecutionFailedCause,
     WorkflowTaskFailedCause,
 )
 from .namespace_pb2 import ArchivalState, NamespaceState, ReplicationState
 from .query_pb2 import QueryRejectCondition, QueryResultType
-from .reset_pb2 import ResetReapplyType
+from .reset_pb2 import ResetReapplyType, ResetType
 from .schedule_pb2 import ScheduleOverlapPolicy
-from .task_queue_pb2 import TaskQueueKind, TaskQueueType
+from .task_queue_pb2 import TaskQueueKind, TaskQueueType, TaskReachability
 from .update_pb2 import UpdateWorkflowExecutionLifecycleStage
 from .workflow_pb2 import (
     ContinueAsNewInitiator,
     HistoryEventFilterType,
     ParentClosePolicy,
     PendingActivityState,
     PendingWorkflowTaskState,
@@ -42,21 +42,23 @@
     "ParentClosePolicy",
     "PendingActivityState",
     "PendingWorkflowTaskState",
     "QueryRejectCondition",
     "QueryResultType",
     "ReplicationState",
     "ResetReapplyType",
+    "ResetType",
     "ResourceExhaustedCause",
     "RetryState",
     "ScheduleOverlapPolicy",
     "Severity",
     "SignalExternalWorkflowExecutionFailedCause",
     "StartChildWorkflowExecutionFailedCause",
     "TaskQueueKind",
     "TaskQueueType",
+    "TaskReachability",
     "TimeoutType",
     "UpdateWorkflowExecutionLifecycleStage",
     "WorkflowExecutionStatus",
     "WorkflowIdReusePolicy",
     "WorkflowTaskFailedCause",
 ]
```

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/batch_operation_pb2.py` & `temporalio-1.3.0/temporalio/api/enums/v1/batch_operation_pb2.py`

 * *Files 5% similar despite different names*

```diff
@@ -11,33 +11,34 @@
 
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n+temporal/api/enums/v1/batch_operation.proto\x12\x15temporal.api.enums.v1*\xc1\x01\n\x12\x42\x61tchOperationType\x12$\n BATCH_OPERATION_TYPE_UNSPECIFIED\x10\x00\x12"\n\x1e\x42\x41TCH_OPERATION_TYPE_TERMINATE\x10\x01\x12\x1f\n\x1b\x42\x41TCH_OPERATION_TYPE_CANCEL\x10\x02\x12\x1f\n\x1b\x42\x41TCH_OPERATION_TYPE_SIGNAL\x10\x03\x12\x1f\n\x1b\x42\x41TCH_OPERATION_TYPE_DELETE\x10\x04*\xa6\x01\n\x13\x42\x61tchOperationState\x12%\n!BATCH_OPERATION_STATE_UNSPECIFIED\x10\x00\x12!\n\x1d\x42\x41TCH_OPERATION_STATE_RUNNING\x10\x01\x12#\n\x1f\x42\x41TCH_OPERATION_STATE_COMPLETED\x10\x02\x12 \n\x1c\x42\x41TCH_OPERATION_STATE_FAILED\x10\x03\x42\x8b\x01\n\x18io.temporal.api.enums.v1B\x13\x42\x61tchOperationProtoP\x01Z!go.temporal.io/api/enums/v1;enums\xaa\x02\x17Temporalio.Api.Enums.V1\xea\x02\x1aTemporalio::Api::Enums::V1b\x06proto3'
+    b'\n+temporal/api/enums/v1/batch_operation.proto\x12\x15temporal.api.enums.v1*\xe1\x01\n\x12\x42\x61tchOperationType\x12$\n BATCH_OPERATION_TYPE_UNSPECIFIED\x10\x00\x12"\n\x1e\x42\x41TCH_OPERATION_TYPE_TERMINATE\x10\x01\x12\x1f\n\x1b\x42\x41TCH_OPERATION_TYPE_CANCEL\x10\x02\x12\x1f\n\x1b\x42\x41TCH_OPERATION_TYPE_SIGNAL\x10\x03\x12\x1f\n\x1b\x42\x41TCH_OPERATION_TYPE_DELETE\x10\x04\x12\x1e\n\x1a\x42\x41TCH_OPERATION_TYPE_RESET\x10\x05*\xa6\x01\n\x13\x42\x61tchOperationState\x12%\n!BATCH_OPERATION_STATE_UNSPECIFIED\x10\x00\x12!\n\x1d\x42\x41TCH_OPERATION_STATE_RUNNING\x10\x01\x12#\n\x1f\x42\x41TCH_OPERATION_STATE_COMPLETED\x10\x02\x12 \n\x1c\x42\x41TCH_OPERATION_STATE_FAILED\x10\x03\x42\x8b\x01\n\x18io.temporal.api.enums.v1B\x13\x42\x61tchOperationProtoP\x01Z!go.temporal.io/api/enums/v1;enums\xaa\x02\x17Temporalio.Api.Enums.V1\xea\x02\x1aTemporalio::Api::Enums::V1b\x06proto3'
 )
 
 _BATCHOPERATIONTYPE = DESCRIPTOR.enum_types_by_name["BatchOperationType"]
 BatchOperationType = enum_type_wrapper.EnumTypeWrapper(_BATCHOPERATIONTYPE)
 _BATCHOPERATIONSTATE = DESCRIPTOR.enum_types_by_name["BatchOperationState"]
 BatchOperationState = enum_type_wrapper.EnumTypeWrapper(_BATCHOPERATIONSTATE)
 BATCH_OPERATION_TYPE_UNSPECIFIED = 0
 BATCH_OPERATION_TYPE_TERMINATE = 1
 BATCH_OPERATION_TYPE_CANCEL = 2
 BATCH_OPERATION_TYPE_SIGNAL = 3
 BATCH_OPERATION_TYPE_DELETE = 4
+BATCH_OPERATION_TYPE_RESET = 5
 BATCH_OPERATION_STATE_UNSPECIFIED = 0
 BATCH_OPERATION_STATE_RUNNING = 1
 BATCH_OPERATION_STATE_COMPLETED = 2
 BATCH_OPERATION_STATE_FAILED = 3
 
 
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
     DESCRIPTOR._serialized_options = b"\n\030io.temporal.api.enums.v1B\023BatchOperationProtoP\001Z!go.temporal.io/api/enums/v1;enums\252\002\027Temporalio.Api.Enums.V1\352\002\032Temporalio::Api::Enums::V1"
     _BATCHOPERATIONTYPE._serialized_start = 71
-    _BATCHOPERATIONTYPE._serialized_end = 264
-    _BATCHOPERATIONSTATE._serialized_start = 267
-    _BATCHOPERATIONSTATE._serialized_end = 433
+    _BATCHOPERATIONTYPE._serialized_end = 296
+    _BATCHOPERATIONSTATE._serialized_start = 299
+    _BATCHOPERATIONSTATE._serialized_end = 465
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/batch_operation_pb2.pyi` & `temporalio-1.3.0/temporalio/api/enums/v1/batch_operation_pb2.pyi`

 * *Files 4% similar despite different names*

```diff
@@ -48,24 +48,26 @@
 ):  # noqa: F821
     DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
     BATCH_OPERATION_TYPE_UNSPECIFIED: _BatchOperationType.ValueType  # 0
     BATCH_OPERATION_TYPE_TERMINATE: _BatchOperationType.ValueType  # 1
     BATCH_OPERATION_TYPE_CANCEL: _BatchOperationType.ValueType  # 2
     BATCH_OPERATION_TYPE_SIGNAL: _BatchOperationType.ValueType  # 3
     BATCH_OPERATION_TYPE_DELETE: _BatchOperationType.ValueType  # 4
+    BATCH_OPERATION_TYPE_RESET: _BatchOperationType.ValueType  # 5
 
 class BatchOperationType(
     _BatchOperationType, metaclass=_BatchOperationTypeEnumTypeWrapper
 ): ...
 
 BATCH_OPERATION_TYPE_UNSPECIFIED: BatchOperationType.ValueType  # 0
 BATCH_OPERATION_TYPE_TERMINATE: BatchOperationType.ValueType  # 1
 BATCH_OPERATION_TYPE_CANCEL: BatchOperationType.ValueType  # 2
 BATCH_OPERATION_TYPE_SIGNAL: BatchOperationType.ValueType  # 3
 BATCH_OPERATION_TYPE_DELETE: BatchOperationType.ValueType  # 4
+BATCH_OPERATION_TYPE_RESET: BatchOperationType.ValueType  # 5
 global___BatchOperationType = BatchOperationType
 
 class _BatchOperationState:
     ValueType = typing.NewType("ValueType", builtins.int)
     V: typing_extensions.TypeAlias = ValueType
 
 class _BatchOperationStateEnumTypeWrapper(
```

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/command_type_pb2.py` & `temporalio-1.3.0/temporalio/api/enums/v1/command_type_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/command_type_pb2.pyi` & `temporalio-1.3.0/temporalio/api/enums/v1/command_type_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/common_pb2.py` & `temporalio-1.3.0/temporalio/api/enums/v1/common_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/common_pb2.pyi` & `temporalio-1.3.0/temporalio/api/enums/v1/common_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/event_type_pb2.py` & `temporalio-1.3.0/temporalio/api/enums/v1/event_type_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/event_type_pb2.pyi` & `temporalio-1.3.0/temporalio/api/enums/v1/event_type_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/failed_cause_pb2.py` & `temporalio-1.3.0/temporalio/api/enums/v1/failed_cause_pb2.py`

 * *Files 1% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n(temporal/api/enums/v1/failed_cause.proto\x12\x15temporal.api.enums.v1*\xdf\x0f\n\x17WorkflowTaskFailedCause\x12*\n&WORKFLOW_TASK_FAILED_CAUSE_UNSPECIFIED\x10\x00\x12\x30\n,WORKFLOW_TASK_FAILED_CAUSE_UNHANDLED_COMMAND\x10\x01\x12?\n;WORKFLOW_TASK_FAILED_CAUSE_BAD_SCHEDULE_ACTIVITY_ATTRIBUTES\x10\x02\x12\x45\nAWORKFLOW_TASK_FAILED_CAUSE_BAD_REQUEST_CANCEL_ACTIVITY_ATTRIBUTES\x10\x03\x12\x39\n5WORKFLOW_TASK_FAILED_CAUSE_BAD_START_TIMER_ATTRIBUTES\x10\x04\x12:\n6WORKFLOW_TASK_FAILED_CAUSE_BAD_CANCEL_TIMER_ATTRIBUTES\x10\x05\x12;\n7WORKFLOW_TASK_FAILED_CAUSE_BAD_RECORD_MARKER_ATTRIBUTES\x10\x06\x12I\nEWORKFLOW_TASK_FAILED_CAUSE_BAD_COMPLETE_WORKFLOW_EXECUTION_ATTRIBUTES\x10\x07\x12\x45\nAWORKFLOW_TASK_FAILED_CAUSE_BAD_FAIL_WORKFLOW_EXECUTION_ATTRIBUTES\x10\x08\x12G\nCWORKFLOW_TASK_FAILED_CAUSE_BAD_CANCEL_WORKFLOW_EXECUTION_ATTRIBUTES\x10\t\x12X\nTWORKFLOW_TASK_FAILED_CAUSE_BAD_REQUEST_CANCEL_EXTERNAL_WORKFLOW_EXECUTION_ATTRIBUTES\x10\n\x12=\n9WORKFLOW_TASK_FAILED_CAUSE_BAD_CONTINUE_AS_NEW_ATTRIBUTES\x10\x0b\x12\x37\n3WORKFLOW_TASK_FAILED_CAUSE_START_TIMER_DUPLICATE_ID\x10\x0c\x12\x36\n2WORKFLOW_TASK_FAILED_CAUSE_RESET_STICKY_TASK_QUEUE\x10\r\x12@\n<WORKFLOW_TASK_FAILED_CAUSE_WORKFLOW_WORKER_UNHANDLED_FAILURE\x10\x0e\x12G\nCWORKFLOW_TASK_FAILED_CAUSE_BAD_SIGNAL_WORKFLOW_EXECUTION_ATTRIBUTES\x10\x0f\x12\x43\n?WORKFLOW_TASK_FAILED_CAUSE_BAD_START_CHILD_EXECUTION_ATTRIBUTES\x10\x10\x12\x32\n.WORKFLOW_TASK_FAILED_CAUSE_FORCE_CLOSE_COMMAND\x10\x11\x12\x35\n1WORKFLOW_TASK_FAILED_CAUSE_FAILOVER_CLOSE_COMMAND\x10\x12\x12\x34\n0WORKFLOW_TASK_FAILED_CAUSE_BAD_SIGNAL_INPUT_SIZE\x10\x13\x12-\n)WORKFLOW_TASK_FAILED_CAUSE_RESET_WORKFLOW\x10\x14\x12)\n%WORKFLOW_TASK_FAILED_CAUSE_BAD_BINARY\x10\x15\x12=\n9WORKFLOW_TASK_FAILED_CAUSE_SCHEDULE_ACTIVITY_DUPLICATE_ID\x10\x16\x12\x34\n0WORKFLOW_TASK_FAILED_CAUSE_BAD_SEARCH_ATTRIBUTES\x10\x17\x12\x36\n2WORKFLOW_TASK_FAILED_CAUSE_NON_DETERMINISTIC_ERROR\x10\x18\x12H\nDWORKFLOW_TASK_FAILED_CAUSE_BAD_MODIFY_WORKFLOW_PROPERTIES_ATTRIBUTES\x10\x19\x12\x45\nAWORKFLOW_TASK_FAILED_CAUSE_PENDING_CHILD_WORKFLOWS_LIMIT_EXCEEDED\x10\x1a\x12@\n<WORKFLOW_TASK_FAILED_CAUSE_PENDING_ACTIVITIES_LIMIT_EXCEEDED\x10\x1b\x12=\n9WORKFLOW_TASK_FAILED_CAUSE_PENDING_SIGNALS_LIMIT_EXCEEDED\x10\x1c\x12\x44\n@WORKFLOW_TASK_FAILED_CAUSE_PENDING_REQUEST_CANCEL_LIMIT_EXCEEDED\x10\x1d\x12\x44\n@WORKFLOW_TASK_FAILED_CAUSE_BAD_UPDATE_WORKFLOW_EXECUTION_MESSAGE\x10\x1e\x12/\n+WORKFLOW_TASK_FAILED_CAUSE_UNHANDLED_UPDATE\x10\x1f*\xf3\x01\n&StartChildWorkflowExecutionFailedCause\x12;\n7START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED\x10\x00\x12G\nCSTART_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_WORKFLOW_ALREADY_EXISTS\x10\x01\x12\x43\n?START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_NAMESPACE_NOT_FOUND\x10\x02*\x91\x02\n*CancelExternalWorkflowExecutionFailedCause\x12?\n;CANCEL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED\x10\x00\x12Y\nUCANCEL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_EXTERNAL_WORKFLOW_EXECUTION_NOT_FOUND\x10\x01\x12G\nCCANCEL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_NAMESPACE_NOT_FOUND\x10\x02*\xe2\x02\n*SignalExternalWorkflowExecutionFailedCause\x12?\n;SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED\x10\x00\x12Y\nUSIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_EXTERNAL_WORKFLOW_EXECUTION_NOT_FOUND\x10\x01\x12G\nCSIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_NAMESPACE_NOT_FOUND\x10\x02\x12O\nKSIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_SIGNAL_COUNT_LIMIT_EXCEEDED\x10\x03*\xf9\x01\n\x16ResourceExhaustedCause\x12(\n$RESOURCE_EXHAUSTED_CAUSE_UNSPECIFIED\x10\x00\x12&\n"RESOURCE_EXHAUSTED_CAUSE_RPS_LIMIT\x10\x01\x12-\n)RESOURCE_EXHAUSTED_CAUSE_CONCURRENT_LIMIT\x10\x02\x12.\n*RESOURCE_EXHAUSTED_CAUSE_SYSTEM_OVERLOADED\x10\x03\x12.\n*RESOURCE_EXHAUSTED_CAUSE_PERSISTENCE_LIMIT\x10\x04\x42\x88\x01\n\x18io.temporal.api.enums.v1B\x10\x46\x61iledCauseProtoP\x01Z!go.temporal.io/api/enums/v1;enums\xaa\x02\x17Temporalio.Api.Enums.V1\xea\x02\x1aTemporalio::Api::Enums::V1b\x06proto3'
+    b'\n(temporal/api/enums/v1/failed_cause.proto\x12\x15temporal.api.enums.v1*\xdf\x0f\n\x17WorkflowTaskFailedCause\x12*\n&WORKFLOW_TASK_FAILED_CAUSE_UNSPECIFIED\x10\x00\x12\x30\n,WORKFLOW_TASK_FAILED_CAUSE_UNHANDLED_COMMAND\x10\x01\x12?\n;WORKFLOW_TASK_FAILED_CAUSE_BAD_SCHEDULE_ACTIVITY_ATTRIBUTES\x10\x02\x12\x45\nAWORKFLOW_TASK_FAILED_CAUSE_BAD_REQUEST_CANCEL_ACTIVITY_ATTRIBUTES\x10\x03\x12\x39\n5WORKFLOW_TASK_FAILED_CAUSE_BAD_START_TIMER_ATTRIBUTES\x10\x04\x12:\n6WORKFLOW_TASK_FAILED_CAUSE_BAD_CANCEL_TIMER_ATTRIBUTES\x10\x05\x12;\n7WORKFLOW_TASK_FAILED_CAUSE_BAD_RECORD_MARKER_ATTRIBUTES\x10\x06\x12I\nEWORKFLOW_TASK_FAILED_CAUSE_BAD_COMPLETE_WORKFLOW_EXECUTION_ATTRIBUTES\x10\x07\x12\x45\nAWORKFLOW_TASK_FAILED_CAUSE_BAD_FAIL_WORKFLOW_EXECUTION_ATTRIBUTES\x10\x08\x12G\nCWORKFLOW_TASK_FAILED_CAUSE_BAD_CANCEL_WORKFLOW_EXECUTION_ATTRIBUTES\x10\t\x12X\nTWORKFLOW_TASK_FAILED_CAUSE_BAD_REQUEST_CANCEL_EXTERNAL_WORKFLOW_EXECUTION_ATTRIBUTES\x10\n\x12=\n9WORKFLOW_TASK_FAILED_CAUSE_BAD_CONTINUE_AS_NEW_ATTRIBUTES\x10\x0b\x12\x37\n3WORKFLOW_TASK_FAILED_CAUSE_START_TIMER_DUPLICATE_ID\x10\x0c\x12\x36\n2WORKFLOW_TASK_FAILED_CAUSE_RESET_STICKY_TASK_QUEUE\x10\r\x12@\n<WORKFLOW_TASK_FAILED_CAUSE_WORKFLOW_WORKER_UNHANDLED_FAILURE\x10\x0e\x12G\nCWORKFLOW_TASK_FAILED_CAUSE_BAD_SIGNAL_WORKFLOW_EXECUTION_ATTRIBUTES\x10\x0f\x12\x43\n?WORKFLOW_TASK_FAILED_CAUSE_BAD_START_CHILD_EXECUTION_ATTRIBUTES\x10\x10\x12\x32\n.WORKFLOW_TASK_FAILED_CAUSE_FORCE_CLOSE_COMMAND\x10\x11\x12\x35\n1WORKFLOW_TASK_FAILED_CAUSE_FAILOVER_CLOSE_COMMAND\x10\x12\x12\x34\n0WORKFLOW_TASK_FAILED_CAUSE_BAD_SIGNAL_INPUT_SIZE\x10\x13\x12-\n)WORKFLOW_TASK_FAILED_CAUSE_RESET_WORKFLOW\x10\x14\x12)\n%WORKFLOW_TASK_FAILED_CAUSE_BAD_BINARY\x10\x15\x12=\n9WORKFLOW_TASK_FAILED_CAUSE_SCHEDULE_ACTIVITY_DUPLICATE_ID\x10\x16\x12\x34\n0WORKFLOW_TASK_FAILED_CAUSE_BAD_SEARCH_ATTRIBUTES\x10\x17\x12\x36\n2WORKFLOW_TASK_FAILED_CAUSE_NON_DETERMINISTIC_ERROR\x10\x18\x12H\nDWORKFLOW_TASK_FAILED_CAUSE_BAD_MODIFY_WORKFLOW_PROPERTIES_ATTRIBUTES\x10\x19\x12\x45\nAWORKFLOW_TASK_FAILED_CAUSE_PENDING_CHILD_WORKFLOWS_LIMIT_EXCEEDED\x10\x1a\x12@\n<WORKFLOW_TASK_FAILED_CAUSE_PENDING_ACTIVITIES_LIMIT_EXCEEDED\x10\x1b\x12=\n9WORKFLOW_TASK_FAILED_CAUSE_PENDING_SIGNALS_LIMIT_EXCEEDED\x10\x1c\x12\x44\n@WORKFLOW_TASK_FAILED_CAUSE_PENDING_REQUEST_CANCEL_LIMIT_EXCEEDED\x10\x1d\x12\x44\n@WORKFLOW_TASK_FAILED_CAUSE_BAD_UPDATE_WORKFLOW_EXECUTION_MESSAGE\x10\x1e\x12/\n+WORKFLOW_TASK_FAILED_CAUSE_UNHANDLED_UPDATE\x10\x1f*\xf3\x01\n&StartChildWorkflowExecutionFailedCause\x12;\n7START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED\x10\x00\x12G\nCSTART_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_WORKFLOW_ALREADY_EXISTS\x10\x01\x12\x43\n?START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_NAMESPACE_NOT_FOUND\x10\x02*\x91\x02\n*CancelExternalWorkflowExecutionFailedCause\x12?\n;CANCEL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED\x10\x00\x12Y\nUCANCEL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_EXTERNAL_WORKFLOW_EXECUTION_NOT_FOUND\x10\x01\x12G\nCCANCEL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_NAMESPACE_NOT_FOUND\x10\x02*\xe2\x02\n*SignalExternalWorkflowExecutionFailedCause\x12?\n;SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED\x10\x00\x12Y\nUSIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_EXTERNAL_WORKFLOW_EXECUTION_NOT_FOUND\x10\x01\x12G\nCSIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_NAMESPACE_NOT_FOUND\x10\x02\x12O\nKSIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_SIGNAL_COUNT_LIMIT_EXCEEDED\x10\x03*\xa5\x02\n\x16ResourceExhaustedCause\x12(\n$RESOURCE_EXHAUSTED_CAUSE_UNSPECIFIED\x10\x00\x12&\n"RESOURCE_EXHAUSTED_CAUSE_RPS_LIMIT\x10\x01\x12-\n)RESOURCE_EXHAUSTED_CAUSE_CONCURRENT_LIMIT\x10\x02\x12.\n*RESOURCE_EXHAUSTED_CAUSE_SYSTEM_OVERLOADED\x10\x03\x12.\n*RESOURCE_EXHAUSTED_CAUSE_PERSISTENCE_LIMIT\x10\x04\x12*\n&RESOURCE_EXHAUSTED_CAUSE_BUSY_WORKFLOW\x10\x05\x42\x88\x01\n\x18io.temporal.api.enums.v1B\x10\x46\x61iledCauseProtoP\x01Z!go.temporal.io/api/enums/v1;enums\xaa\x02\x17Temporalio.Api.Enums.V1\xea\x02\x1aTemporalio::Api::Enums::V1b\x06proto3'
 )
 
 _WORKFLOWTASKFAILEDCAUSE = DESCRIPTOR.enum_types_by_name["WorkflowTaskFailedCause"]
 WorkflowTaskFailedCause = enum_type_wrapper.EnumTypeWrapper(_WORKFLOWTASKFAILEDCAUSE)
 _STARTCHILDWORKFLOWEXECUTIONFAILEDCAUSE = DESCRIPTOR.enum_types_by_name[
     "StartChildWorkflowExecutionFailedCause"
 ]
@@ -89,23 +89,24 @@
 SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_NAMESPACE_NOT_FOUND = 2
 SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_SIGNAL_COUNT_LIMIT_EXCEEDED = 3
 RESOURCE_EXHAUSTED_CAUSE_UNSPECIFIED = 0
 RESOURCE_EXHAUSTED_CAUSE_RPS_LIMIT = 1
 RESOURCE_EXHAUSTED_CAUSE_CONCURRENT_LIMIT = 2
 RESOURCE_EXHAUSTED_CAUSE_SYSTEM_OVERLOADED = 3
 RESOURCE_EXHAUSTED_CAUSE_PERSISTENCE_LIMIT = 4
+RESOURCE_EXHAUSTED_CAUSE_BUSY_WORKFLOW = 5
 
 
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
     DESCRIPTOR._serialized_options = b"\n\030io.temporal.api.enums.v1B\020FailedCauseProtoP\001Z!go.temporal.io/api/enums/v1;enums\252\002\027Temporalio.Api.Enums.V1\352\002\032Temporalio::Api::Enums::V1"
     _WORKFLOWTASKFAILEDCAUSE._serialized_start = 68
     _WORKFLOWTASKFAILEDCAUSE._serialized_end = 2083
     _STARTCHILDWORKFLOWEXECUTIONFAILEDCAUSE._serialized_start = 2086
     _STARTCHILDWORKFLOWEXECUTIONFAILEDCAUSE._serialized_end = 2329
     _CANCELEXTERNALWORKFLOWEXECUTIONFAILEDCAUSE._serialized_start = 2332
     _CANCELEXTERNALWORKFLOWEXECUTIONFAILEDCAUSE._serialized_end = 2605
     _SIGNALEXTERNALWORKFLOWEXECUTIONFAILEDCAUSE._serialized_start = 2608
     _SIGNALEXTERNALWORKFLOWEXECUTIONFAILEDCAUSE._serialized_end = 2962
     _RESOURCEEXHAUSTEDCAUSE._serialized_start = 2965
-    _RESOURCEEXHAUSTEDCAUSE._serialized_end = 3214
+    _RESOURCEEXHAUSTEDCAUSE._serialized_end = 3258
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/failed_cause_pb2.pyi` & `temporalio-1.3.0/temporalio/api/enums/v1/failed_cause_pb2.pyi`

 * *Files 0% similar despite different names*

```diff
@@ -282,22 +282,26 @@
     """Caller exceeds request per second limit."""
     RESOURCE_EXHAUSTED_CAUSE_CONCURRENT_LIMIT: _ResourceExhaustedCause.ValueType  # 2
     """Caller exceeds max concurrent request limit."""
     RESOURCE_EXHAUSTED_CAUSE_SYSTEM_OVERLOADED: _ResourceExhaustedCause.ValueType  # 3
     """System overloaded."""
     RESOURCE_EXHAUSTED_CAUSE_PERSISTENCE_LIMIT: _ResourceExhaustedCause.ValueType  # 4
     """Namespace exceeds persistence rate limit."""
+    RESOURCE_EXHAUSTED_CAUSE_BUSY_WORKFLOW: _ResourceExhaustedCause.ValueType  # 5
+    """Workflow is busy"""
 
 class ResourceExhaustedCause(
     _ResourceExhaustedCause, metaclass=_ResourceExhaustedCauseEnumTypeWrapper
 ): ...
 
 RESOURCE_EXHAUSTED_CAUSE_UNSPECIFIED: ResourceExhaustedCause.ValueType  # 0
 RESOURCE_EXHAUSTED_CAUSE_RPS_LIMIT: ResourceExhaustedCause.ValueType  # 1
 """Caller exceeds request per second limit."""
 RESOURCE_EXHAUSTED_CAUSE_CONCURRENT_LIMIT: ResourceExhaustedCause.ValueType  # 2
 """Caller exceeds max concurrent request limit."""
 RESOURCE_EXHAUSTED_CAUSE_SYSTEM_OVERLOADED: ResourceExhaustedCause.ValueType  # 3
 """System overloaded."""
 RESOURCE_EXHAUSTED_CAUSE_PERSISTENCE_LIMIT: ResourceExhaustedCause.ValueType  # 4
 """Namespace exceeds persistence rate limit."""
+RESOURCE_EXHAUSTED_CAUSE_BUSY_WORKFLOW: ResourceExhaustedCause.ValueType  # 5
+"""Workflow is busy"""
 global___ResourceExhaustedCause = ResourceExhaustedCause
```

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/namespace_pb2.py` & `temporalio-1.3.0/temporalio/api/enums/v1/namespace_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/namespace_pb2.pyi` & `temporalio-1.3.0/temporalio/api/enums/v1/namespace_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/query_pb2.py` & `temporalio-1.3.0/temporalio/api/enums/v1/query_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/query_pb2.pyi` & `temporalio-1.3.0/temporalio/api/enums/v1/query_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/reset_pb2.py` & `temporalio-1.3.0/temporalio/api/enums/v1/reset_pb2.py`

 * *Files 11% similar despite different names*

```diff
@@ -11,23 +11,30 @@
 
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n!temporal/api/enums/v1/reset.proto\x12\x15temporal.api.enums.v1*r\n\x10ResetReapplyType\x12"\n\x1eRESET_REAPPLY_TYPE_UNSPECIFIED\x10\x00\x12\x1d\n\x19RESET_REAPPLY_TYPE_SIGNAL\x10\x01\x12\x1b\n\x17RESET_REAPPLY_TYPE_NONE\x10\x02\x42\x82\x01\n\x18io.temporal.api.enums.v1B\nResetProtoP\x01Z!go.temporal.io/api/enums/v1;enums\xaa\x02\x17Temporalio.Api.Enums.V1\xea\x02\x1aTemporalio::Api::Enums::V1b\x06proto3'
+    b'\n!temporal/api/enums/v1/reset.proto\x12\x15temporal.api.enums.v1*r\n\x10ResetReapplyType\x12"\n\x1eRESET_REAPPLY_TYPE_UNSPECIFIED\x10\x00\x12\x1d\n\x19RESET_REAPPLY_TYPE_SIGNAL\x10\x01\x12\x1b\n\x17RESET_REAPPLY_TYPE_NONE\x10\x02*n\n\tResetType\x12\x1a\n\x16RESET_TYPE_UNSPECIFIED\x10\x00\x12"\n\x1eRESET_TYPE_FIRST_WORKFLOW_TASK\x10\x01\x12!\n\x1dRESET_TYPE_LAST_WORKFLOW_TASK\x10\x02\x42\x82\x01\n\x18io.temporal.api.enums.v1B\nResetProtoP\x01Z!go.temporal.io/api/enums/v1;enums\xaa\x02\x17Temporalio.Api.Enums.V1\xea\x02\x1aTemporalio::Api::Enums::V1b\x06proto3'
 )
 
 _RESETREAPPLYTYPE = DESCRIPTOR.enum_types_by_name["ResetReapplyType"]
 ResetReapplyType = enum_type_wrapper.EnumTypeWrapper(_RESETREAPPLYTYPE)
+_RESETTYPE = DESCRIPTOR.enum_types_by_name["ResetType"]
+ResetType = enum_type_wrapper.EnumTypeWrapper(_RESETTYPE)
 RESET_REAPPLY_TYPE_UNSPECIFIED = 0
 RESET_REAPPLY_TYPE_SIGNAL = 1
 RESET_REAPPLY_TYPE_NONE = 2
+RESET_TYPE_UNSPECIFIED = 0
+RESET_TYPE_FIRST_WORKFLOW_TASK = 1
+RESET_TYPE_LAST_WORKFLOW_TASK = 2
 
 
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
     DESCRIPTOR._serialized_options = b"\n\030io.temporal.api.enums.v1B\nResetProtoP\001Z!go.temporal.io/api/enums/v1;enums\252\002\027Temporalio.Api.Enums.V1\352\002\032Temporalio::Api::Enums::V1"
     _RESETREAPPLYTYPE._serialized_start = 60
     _RESETREAPPLYTYPE._serialized_end = 174
+    _RESETTYPE._serialized_start = 176
+    _RESETTYPE._serialized_end = 286
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/reset_pb2.pyi` & `temporalio-1.3.0/temporalio/api/enums/v1/reset_pb2.pyi`

 * *Files 18% similar despite different names*

```diff
@@ -57,7 +57,32 @@
     * RESET_REAPPLY_TYPE_NONE - nothing is reapplied
     """
 
 RESET_REAPPLY_TYPE_UNSPECIFIED: ResetReapplyType.ValueType  # 0
 RESET_REAPPLY_TYPE_SIGNAL: ResetReapplyType.ValueType  # 1
 RESET_REAPPLY_TYPE_NONE: ResetReapplyType.ValueType  # 2
 global___ResetReapplyType = ResetReapplyType
+
+class _ResetType:
+    ValueType = typing.NewType("ValueType", builtins.int)
+    V: typing_extensions.TypeAlias = ValueType
+
+class _ResetTypeEnumTypeWrapper(
+    google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_ResetType.ValueType],
+    builtins.type,
+):  # noqa: F821
+    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
+    RESET_TYPE_UNSPECIFIED: _ResetType.ValueType  # 0
+    RESET_TYPE_FIRST_WORKFLOW_TASK: _ResetType.ValueType  # 1
+    """Resets to event of the first workflow task completed, or if it does not exist, the event after task scheduled."""
+    RESET_TYPE_LAST_WORKFLOW_TASK: _ResetType.ValueType  # 2
+    """Resets to event of the last workflow task completed, or if it does not exist, the event after task scheduled."""
+
+class ResetType(_ResetType, metaclass=_ResetTypeEnumTypeWrapper):
+    """Reset type options"""
+
+RESET_TYPE_UNSPECIFIED: ResetType.ValueType  # 0
+RESET_TYPE_FIRST_WORKFLOW_TASK: ResetType.ValueType  # 1
+"""Resets to event of the first workflow task completed, or if it does not exist, the event after task scheduled."""
+RESET_TYPE_LAST_WORKFLOW_TASK: ResetType.ValueType  # 2
+"""Resets to event of the last workflow task completed, or if it does not exist, the event after task scheduled."""
+global___ResetType = ResetType
```

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/schedule_pb2.py` & `temporalio-1.3.0/temporalio/api/enums/v1/schedule_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/schedule_pb2.pyi` & `temporalio-1.3.0/temporalio/api/enums/v1/schedule_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/task_queue_pb2.py` & `temporalio-1.3.0/temporalio/api/enums/v1/task_queue_pb2.py`

 * *Files 21% similar despite different names*

```diff
@@ -11,30 +11,39 @@
 
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b"\n&temporal/api/enums/v1/task_queue.proto\x12\x15temporal.api.enums.v1*h\n\rTaskQueueKind\x12\x1f\n\x1bTASK_QUEUE_KIND_UNSPECIFIED\x10\x00\x12\x1a\n\x16TASK_QUEUE_KIND_NORMAL\x10\x01\x12\x1a\n\x16TASK_QUEUE_KIND_STICKY\x10\x02*l\n\rTaskQueueType\x12\x1f\n\x1bTASK_QUEUE_TYPE_UNSPECIFIED\x10\x00\x12\x1c\n\x18TASK_QUEUE_TYPE_WORKFLOW\x10\x01\x12\x1c\n\x18TASK_QUEUE_TYPE_ACTIVITY\x10\x02\x42\x86\x01\n\x18io.temporal.api.enums.v1B\x0eTaskQueueProtoP\x01Z!go.temporal.io/api/enums/v1;enums\xaa\x02\x17Temporalio.Api.Enums.V1\xea\x02\x1aTemporalio::Api::Enums::V1b\x06proto3"
+    b'\n&temporal/api/enums/v1/task_queue.proto\x12\x15temporal.api.enums.v1*h\n\rTaskQueueKind\x12\x1f\n\x1bTASK_QUEUE_KIND_UNSPECIFIED\x10\x00\x12\x1a\n\x16TASK_QUEUE_KIND_NORMAL\x10\x01\x12\x1a\n\x16TASK_QUEUE_KIND_STICKY\x10\x02*l\n\rTaskQueueType\x12\x1f\n\x1bTASK_QUEUE_TYPE_UNSPECIFIED\x10\x00\x12\x1c\n\x18TASK_QUEUE_TYPE_WORKFLOW\x10\x01\x12\x1c\n\x18TASK_QUEUE_TYPE_ACTIVITY\x10\x02*\xd2\x01\n\x10TaskReachability\x12!\n\x1dTASK_REACHABILITY_UNSPECIFIED\x10\x00\x12#\n\x1fTASK_REACHABILITY_NEW_WORKFLOWS\x10\x01\x12(\n$TASK_REACHABILITY_EXISTING_WORKFLOWS\x10\x02\x12$\n TASK_REACHABILITY_OPEN_WORKFLOWS\x10\x03\x12&\n"TASK_REACHABILITY_CLOSED_WORKFLOWS\x10\x04\x42\x86\x01\n\x18io.temporal.api.enums.v1B\x0eTaskQueueProtoP\x01Z!go.temporal.io/api/enums/v1;enums\xaa\x02\x17Temporalio.Api.Enums.V1\xea\x02\x1aTemporalio::Api::Enums::V1b\x06proto3'
 )
 
 _TASKQUEUEKIND = DESCRIPTOR.enum_types_by_name["TaskQueueKind"]
 TaskQueueKind = enum_type_wrapper.EnumTypeWrapper(_TASKQUEUEKIND)
 _TASKQUEUETYPE = DESCRIPTOR.enum_types_by_name["TaskQueueType"]
 TaskQueueType = enum_type_wrapper.EnumTypeWrapper(_TASKQUEUETYPE)
+_TASKREACHABILITY = DESCRIPTOR.enum_types_by_name["TaskReachability"]
+TaskReachability = enum_type_wrapper.EnumTypeWrapper(_TASKREACHABILITY)
 TASK_QUEUE_KIND_UNSPECIFIED = 0
 TASK_QUEUE_KIND_NORMAL = 1
 TASK_QUEUE_KIND_STICKY = 2
 TASK_QUEUE_TYPE_UNSPECIFIED = 0
 TASK_QUEUE_TYPE_WORKFLOW = 1
 TASK_QUEUE_TYPE_ACTIVITY = 2
+TASK_REACHABILITY_UNSPECIFIED = 0
+TASK_REACHABILITY_NEW_WORKFLOWS = 1
+TASK_REACHABILITY_EXISTING_WORKFLOWS = 2
+TASK_REACHABILITY_OPEN_WORKFLOWS = 3
+TASK_REACHABILITY_CLOSED_WORKFLOWS = 4
 
 
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
     DESCRIPTOR._serialized_options = b"\n\030io.temporal.api.enums.v1B\016TaskQueueProtoP\001Z!go.temporal.io/api/enums/v1;enums\252\002\027Temporalio.Api.Enums.V1\352\002\032Temporalio::Api::Enums::V1"
     _TASKQUEUEKIND._serialized_start = 65
     _TASKQUEUEKIND._serialized_end = 169
     _TASKQUEUETYPE._serialized_start = 171
     _TASKQUEUETYPE._serialized_end = 279
+    _TASKREACHABILITY._serialized_start = 282
+    _TASKREACHABILITY._serialized_end = 492
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/update_pb2.py` & `temporalio-1.3.0/temporalio/api/enums/v1/update_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/update_pb2.pyi` & `temporalio-1.3.0/temporalio/api/enums/v1/update_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/workflow_pb2.py` & `temporalio-1.3.0/temporalio/api/enums/v1/workflow_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/enums/v1/workflow_pb2.pyi` & `temporalio-1.3.0/temporalio/api/enums/v1/workflow_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/errordetails/v1/__init__.py` & `temporalio-1.3.0/temporalio/api/errordetails/v1/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 from .message_pb2 import (
     CancellationAlreadyRequestedFailure,
     ClientVersionNotSupportedFailure,
     NamespaceAlreadyExistsFailure,
     NamespaceInvalidStateFailure,
     NamespaceNotActiveFailure,
     NamespaceNotFoundFailure,
+    NewerBuildExistsFailure,
     NotFoundFailure,
     PermissionDeniedFailure,
     QueryFailedFailure,
     ResourceExhaustedFailure,
     ServerVersionNotSupportedFailure,
     SystemWorkflowFailure,
     WorkflowExecutionAlreadyStartedFailure,
@@ -18,14 +19,15 @@
 __all__ = [
     "CancellationAlreadyRequestedFailure",
     "ClientVersionNotSupportedFailure",
     "NamespaceAlreadyExistsFailure",
     "NamespaceInvalidStateFailure",
     "NamespaceNotActiveFailure",
     "NamespaceNotFoundFailure",
+    "NewerBuildExistsFailure",
     "NotFoundFailure",
     "PermissionDeniedFailure",
     "QueryFailedFailure",
     "ResourceExhaustedFailure",
     "ServerVersionNotSupportedFailure",
     "SystemWorkflowFailure",
     "WorkflowExecutionAlreadyStartedFailure",
```

### Comparing `temporalio-1.2.0/temporalio/api/errordetails/v1/message_pb2.py` & `temporalio-1.3.0/temporalio/api/errordetails/v1/message_pb2.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,15 +20,15 @@
     failed_cause_pb2 as temporal_dot_api_dot_enums_dot_v1_dot_failed__cause__pb2,
 )
 from temporalio.api.enums.v1 import (
     namespace_pb2 as temporal_dot_api_dot_enums_dot_v1_dot_namespace__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n*temporal/api/errordetails/v1/message.proto\x12\x1ctemporal.api.errordetails.v1\x1a$temporal/api/common/v1/message.proto\x1a(temporal/api/enums/v1/failed_cause.proto\x1a%temporal/api/enums/v1/namespace.proto"B\n\x0fNotFoundFailure\x12\x17\n\x0f\x63urrent_cluster\x18\x01 \x01(\t\x12\x16\n\x0e\x61\x63tive_cluster\x18\x02 \x01(\t"R\n&WorkflowExecutionAlreadyStartedFailure\x12\x18\n\x10start_request_id\x18\x01 \x01(\t\x12\x0e\n\x06run_id\x18\x02 \x01(\t"_\n\x19NamespaceNotActiveFailure\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x17\n\x0f\x63urrent_cluster\x18\x02 \x01(\t\x12\x16\n\x0e\x61\x63tive_cluster\x18\x03 \x01(\t"\xa6\x01\n\x1cNamespaceInvalidStateFailure\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x34\n\x05state\x18\x02 \x01(\x0e\x32%.temporal.api.enums.v1.NamespaceState\x12=\n\x0e\x61llowed_states\x18\x03 \x03(\x0e\x32%.temporal.api.enums.v1.NamespaceState"-\n\x18NamespaceNotFoundFailure\x12\x11\n\tnamespace\x18\x01 \x01(\t"\x1f\n\x1dNamespaceAlreadyExistsFailure"k\n ClientVersionNotSupportedFailure\x12\x16\n\x0e\x63lient_version\x18\x01 \x01(\t\x12\x13\n\x0b\x63lient_name\x18\x02 \x01(\t\x12\x1a\n\x12supported_versions\x18\x03 \x01(\t"d\n ServerVersionNotSupportedFailure\x12\x16\n\x0eserver_version\x18\x01 \x01(\t\x12(\n client_supported_server_versions\x18\x02 \x01(\t"%\n#CancellationAlreadyRequestedFailure"\x14\n\x12QueryFailedFailure")\n\x17PermissionDeniedFailure\x12\x0e\n\x06reason\x18\x01 \x01(\t"X\n\x18ResourceExhaustedFailure\x12<\n\x05\x63\x61use\x18\x01 \x01(\x0e\x32-.temporal.api.enums.v1.ResourceExhaustedCause"v\n\x15SystemWorkflowFailure\x12\x45\n\x12workflow_execution\x18\x01 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x16\n\x0eworkflow_error\x18\x02 \x01(\t"\x19\n\x17WorkflowNotReadyFailureB\xa7\x01\n\x1fio.temporal.api.errordetails.v1B\x0cMessageProtoP\x01Z/go.temporal.io/api/errordetails/v1;errordetails\xaa\x02\x1eTemporalio.Api.ErrorDetails.V1\xea\x02!Temporalio::Api::ErrorDetails::V1b\x06proto3'
+    b'\n*temporal/api/errordetails/v1/message.proto\x12\x1ctemporal.api.errordetails.v1\x1a$temporal/api/common/v1/message.proto\x1a(temporal/api/enums/v1/failed_cause.proto\x1a%temporal/api/enums/v1/namespace.proto"B\n\x0fNotFoundFailure\x12\x17\n\x0f\x63urrent_cluster\x18\x01 \x01(\t\x12\x16\n\x0e\x61\x63tive_cluster\x18\x02 \x01(\t"R\n&WorkflowExecutionAlreadyStartedFailure\x12\x18\n\x10start_request_id\x18\x01 \x01(\t\x12\x0e\n\x06run_id\x18\x02 \x01(\t"_\n\x19NamespaceNotActiveFailure\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x17\n\x0f\x63urrent_cluster\x18\x02 \x01(\t\x12\x16\n\x0e\x61\x63tive_cluster\x18\x03 \x01(\t"\xa6\x01\n\x1cNamespaceInvalidStateFailure\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x34\n\x05state\x18\x02 \x01(\x0e\x32%.temporal.api.enums.v1.NamespaceState\x12=\n\x0e\x61llowed_states\x18\x03 \x03(\x0e\x32%.temporal.api.enums.v1.NamespaceState"-\n\x18NamespaceNotFoundFailure\x12\x11\n\tnamespace\x18\x01 \x01(\t"\x1f\n\x1dNamespaceAlreadyExistsFailure"k\n ClientVersionNotSupportedFailure\x12\x16\n\x0e\x63lient_version\x18\x01 \x01(\t\x12\x13\n\x0b\x63lient_name\x18\x02 \x01(\t\x12\x1a\n\x12supported_versions\x18\x03 \x01(\t"d\n ServerVersionNotSupportedFailure\x12\x16\n\x0eserver_version\x18\x01 \x01(\t\x12(\n client_supported_server_versions\x18\x02 \x01(\t"%\n#CancellationAlreadyRequestedFailure"\x14\n\x12QueryFailedFailure")\n\x17PermissionDeniedFailure\x12\x0e\n\x06reason\x18\x01 \x01(\t"X\n\x18ResourceExhaustedFailure\x12<\n\x05\x63\x61use\x18\x01 \x01(\x0e\x32-.temporal.api.enums.v1.ResourceExhaustedCause"v\n\x15SystemWorkflowFailure\x12\x45\n\x12workflow_execution\x18\x01 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x16\n\x0eworkflow_error\x18\x02 \x01(\t"\x19\n\x17WorkflowNotReadyFailure"3\n\x17NewerBuildExistsFailure\x12\x18\n\x10\x64\x65\x66\x61ult_build_id\x18\x01 \x01(\tB\xa7\x01\n\x1fio.temporal.api.errordetails.v1B\x0cMessageProtoP\x01Z/go.temporal.io/api/errordetails/v1;errordetails\xaa\x02\x1eTemporalio.Api.ErrorDetails.V1\xea\x02!Temporalio::Api::ErrorDetails::V1b\x06proto3'
 )
 
 
 _NOTFOUNDFAILURE = DESCRIPTOR.message_types_by_name["NotFoundFailure"]
 _WORKFLOWEXECUTIONALREADYSTARTEDFAILURE = DESCRIPTOR.message_types_by_name[
     "WorkflowExecutionAlreadyStartedFailure"
 ]
@@ -52,14 +52,15 @@
     "CancellationAlreadyRequestedFailure"
 ]
 _QUERYFAILEDFAILURE = DESCRIPTOR.message_types_by_name["QueryFailedFailure"]
 _PERMISSIONDENIEDFAILURE = DESCRIPTOR.message_types_by_name["PermissionDeniedFailure"]
 _RESOURCEEXHAUSTEDFAILURE = DESCRIPTOR.message_types_by_name["ResourceExhaustedFailure"]
 _SYSTEMWORKFLOWFAILURE = DESCRIPTOR.message_types_by_name["SystemWorkflowFailure"]
 _WORKFLOWNOTREADYFAILURE = DESCRIPTOR.message_types_by_name["WorkflowNotReadyFailure"]
+_NEWERBUILDEXISTSFAILURE = DESCRIPTOR.message_types_by_name["NewerBuildExistsFailure"]
 NotFoundFailure = _reflection.GeneratedProtocolMessageType(
     "NotFoundFailure",
     (_message.Message,),
     {
         "DESCRIPTOR": _NOTFOUNDFAILURE,
         "__module__": "temporal.api.errordetails.v1.message_pb2"
         # @@protoc_insertion_point(class_scope:temporal.api.errordetails.v1.NotFoundFailure)
@@ -206,14 +207,25 @@
         "DESCRIPTOR": _WORKFLOWNOTREADYFAILURE,
         "__module__": "temporal.api.errordetails.v1.message_pb2"
         # @@protoc_insertion_point(class_scope:temporal.api.errordetails.v1.WorkflowNotReadyFailure)
     },
 )
 _sym_db.RegisterMessage(WorkflowNotReadyFailure)
 
+NewerBuildExistsFailure = _reflection.GeneratedProtocolMessageType(
+    "NewerBuildExistsFailure",
+    (_message.Message,),
+    {
+        "DESCRIPTOR": _NEWERBUILDEXISTSFAILURE,
+        "__module__": "temporal.api.errordetails.v1.message_pb2"
+        # @@protoc_insertion_point(class_scope:temporal.api.errordetails.v1.NewerBuildExistsFailure)
+    },
+)
+_sym_db.RegisterMessage(NewerBuildExistsFailure)
+
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
     DESCRIPTOR._serialized_options = b"\n\037io.temporal.api.errordetails.v1B\014MessageProtoP\001Z/go.temporal.io/api/errordetails/v1;errordetails\252\002\036Temporalio.Api.ErrorDetails.V1\352\002!Temporalio::Api::ErrorDetails::V1"
     _NOTFOUNDFAILURE._serialized_start = 195
     _NOTFOUNDFAILURE._serialized_end = 261
     _WORKFLOWEXECUTIONALREADYSTARTEDFAILURE._serialized_start = 263
     _WORKFLOWEXECUTIONALREADYSTARTEDFAILURE._serialized_end = 345
@@ -237,8 +249,10 @@
     _PERMISSIONDENIEDFAILURE._serialized_end = 1006
     _RESOURCEEXHAUSTEDFAILURE._serialized_start = 1008
     _RESOURCEEXHAUSTEDFAILURE._serialized_end = 1096
     _SYSTEMWORKFLOWFAILURE._serialized_start = 1098
     _SYSTEMWORKFLOWFAILURE._serialized_end = 1216
     _WORKFLOWNOTREADYFAILURE._serialized_start = 1218
     _WORKFLOWNOTREADYFAILURE._serialized_end = 1243
+    _NEWERBUILDEXISTSFAILURE._serialized_start = 1245
+    _NEWERBUILDEXISTSFAILURE._serialized_end = 1296
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.2.0/temporalio/api/errordetails/v1/message_pb2.pyi` & `temporalio-1.3.0/temporalio/api/errordetails/v1/message_pb2.pyi`

 * *Files 2% similar despite different names*

```diff
@@ -310,7 +310,25 @@
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     def __init__(
         self,
     ) -> None: ...
 
 global___WorkflowNotReadyFailure = WorkflowNotReadyFailure
+
+class NewerBuildExistsFailure(google.protobuf.message.Message):
+    DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+    DEFAULT_BUILD_ID_FIELD_NUMBER: builtins.int
+    default_build_id: builtins.str
+    """The current default compatible build ID which will receive tasks"""
+    def __init__(
+        self,
+        *,
+        default_build_id: builtins.str = ...,
+    ) -> None: ...
+    def ClearField(
+        self,
+        field_name: typing_extensions.Literal["default_build_id", b"default_build_id"],
+    ) -> None: ...
+
+global___NewerBuildExistsFailure = NewerBuildExistsFailure
```

### Comparing `temporalio-1.2.0/temporalio/api/failure/v1/__init__.py` & `temporalio-1.3.0/temporalio/api/failure/v1/__init__.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/failure/v1/message_pb2.py` & `temporalio-1.3.0/temporalio/api/failure/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/failure/v1/message_pb2.pyi` & `temporalio-1.3.0/temporalio/api/failure/v1/message_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/filter/v1/message_pb2.py` & `temporalio-1.3.0/temporalio/api/filter/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/filter/v1/message_pb2.pyi` & `temporalio-1.3.0/temporalio/api/filter/v1/message_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/history/v1/__init__.py` & `temporalio-1.3.0/temporalio/api/history/v1/__init__.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/history/v1/message_pb2.py` & `temporalio-1.3.0/temporalio/api/history/v1/message_pb2.py`

 * *Files 1% similar despite different names*

```diff
@@ -44,15 +44,15 @@
     message_pb2 as temporal_dot_api_dot_update_dot_v1_dot_message__pb2,
 )
 from temporalio.api.workflow.v1 import (
     message_pb2 as temporal_dot_api_dot_workflow_dot_v1_dot_message__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n%temporal/api/history/v1/message.proto\x12\x17temporal.api.history.v1\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a!dependencies/gogoproto/gogo.proto\x1a&temporal/api/enums/v1/event_type.proto\x1a(temporal/api/enums/v1/failed_cause.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a$temporal/api/common/v1/message.proto\x1a%temporal/api/failure/v1/message.proto\x1a\'temporal/api/taskqueue/v1/message.proto\x1a$temporal/api/update/v1/message.proto\x1a&temporal/api/workflow/v1/message.proto\x1a\x30temporal/api/sdk/v1/task_complete_metadata.proto"\x90\x0b\n\'WorkflowExecutionStartedEventAttributes\x12;\n\rworkflow_type\x18\x01 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12!\n\x19parent_workflow_namespace\x18\x02 \x01(\t\x12$\n\x1cparent_workflow_namespace_id\x18\x1b \x01(\t\x12L\n\x19parent_workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12!\n\x19parent_initiated_event_id\x18\x04 \x01(\x03\x12\x38\n\ntask_queue\x18\x05 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x06 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12"\n\x1a\x63ontinued_execution_run_id\x18\n \x01(\t\x12@\n\tinitiator\x18\x0b \x01(\x0e\x32-.temporal.api.enums.v1.ContinueAsNewInitiator\x12;\n\x11\x63ontinued_failure\x18\x0c \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12@\n\x16last_completion_result\x18\r \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12!\n\x19original_execution_run_id\x18\x0e \x01(\t\x12\x10\n\x08identity\x18\x0f \x01(\t\x12\x1e\n\x16\x66irst_execution_run_id\x18\x10 \x01(\t\x12\x39\n\x0cretry_policy\x18\x11 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x0f\n\x07\x61ttempt\x18\x12 \x01(\x05\x12L\n"workflow_execution_expiration_time\x18\x13 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x15\n\rcron_schedule\x18\x14 \x01(\t\x12\x44\n\x1b\x66irst_workflow_task_backoff\x18\x15 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12*\n\x04memo\x18\x16 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x17 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12\x45\n\x16prev_auto_reset_points\x18\x18 \x01(\x0b\x32%.temporal.api.workflow.v1.ResetPoints\x12.\n\x06header\x18\x19 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12&\n\x1eparent_initiated_event_version\x18\x1a \x01(\x03"\xa5\x01\n)WorkflowExecutionCompletedEventAttributes\x12\x30\n\x06result\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12(\n workflow_task_completed_event_id\x18\x02 \x01(\x03\x12\x1c\n\x14new_execution_run_id\x18\x03 \x01(\t"\xdb\x01\n&WorkflowExecutionFailedEventAttributes\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x36\n\x0bretry_state\x18\x02 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState\x12(\n workflow_task_completed_event_id\x18\x03 \x01(\x03\x12\x1c\n\x14new_execution_run_id\x18\x04 \x01(\t"\x80\x01\n(WorkflowExecutionTimedOutEventAttributes\x12\x36\n\x0bretry_state\x18\x01 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState\x12\x1c\n\x14new_execution_run_id\x18\x02 \x01(\t"\xb8\x06\n.WorkflowExecutionContinuedAsNewEventAttributes\x12\x1c\n\x14new_execution_run_id\x18\x01 \x01(\t\x12;\n\rworkflow_type\x18\x02 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x03 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x04 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12=\n\x14workflow_run_timeout\x18\x05 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12(\n workflow_task_completed_event_id\x18\x07 \x01(\x03\x12?\n\x16\x62\x61\x63koff_start_interval\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12@\n\tinitiator\x18\t \x01(\x0e\x32-.temporal.api.enums.v1.ContinueAsNewInitiator\x12\x31\n\x07\x66\x61ilure\x18\n \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12@\n\x16last_completion_result\x18\x0b \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12.\n\x06header\x18\x0c \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12*\n\x04memo\x18\r \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x0e \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"\xb2\x01\n$WorkflowTaskScheduledEventAttributes\x12\x38\n\ntask_queue\x18\x01 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12?\n\x16start_to_close_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x0f\n\x07\x61ttempt\x18\x03 \x01(\x05"\xa3\x01\n"WorkflowTaskStartedEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12\x10\n\x08identity\x18\x02 \x01(\t\x12\x12\n\nrequest_id\x18\x03 \x01(\t\x12\x1f\n\x17suggest_continue_as_new\x18\x04 \x01(\x08\x12\x1a\n\x12history_size_bytes\x18\x05 \x01(\x03"\xda\x02\n$WorkflowTaskCompletedEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12\x18\n\x10started_event_id\x18\x02 \x01(\x03\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x17\n\x0f\x62inary_checksum\x18\x04 \x01(\t\x12\x42\n\x0eworker_version\x18\x05 \x01(\x0b\x32*.temporal.api.common.v1.WorkerVersionStamp\x12H\n\x0csdk_metadata\x18\x06 \x01(\x0b\x32\x32.temporal.api.sdk.v1.WorkflowTaskCompletedMetadata\x12\x43\n\x11metering_metadata\x18\r \x01(\x0b\x32(.temporal.api.common.v1.MeteringMetadata"\x95\x01\n#WorkflowTaskTimedOutEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12\x18\n\x10started_event_id\x18\x02 \x01(\x03\x12\x38\n\x0ctimeout_type\x18\x03 \x01(\x0e\x32".temporal.api.enums.v1.TimeoutType"\xbb\x02\n!WorkflowTaskFailedEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12\x18\n\x10started_event_id\x18\x02 \x01(\x03\x12=\n\x05\x63\x61use\x18\x03 \x01(\x0e\x32..temporal.api.enums.v1.WorkflowTaskFailedCause\x12\x31\n\x07\x66\x61ilure\x18\x04 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x10\n\x08identity\x18\x05 \x01(\t\x12\x13\n\x0b\x62\x61se_run_id\x18\x06 \x01(\t\x12\x12\n\nnew_run_id\x18\x07 \x01(\t\x12\x1a\n\x12\x66ork_event_version\x18\x08 \x01(\x03\x12\x17\n\x0f\x62inary_checksum\x18\t \x01(\t"\x83\x05\n$ActivityTaskScheduledEventAttributes\x12\x13\n\x0b\x61\x63tivity_id\x18\x01 \x01(\t\x12;\n\ractivity_type\x18\x02 \x01(\x0b\x32$.temporal.api.common.v1.ActivityType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12.\n\x06header\x18\x05 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12/\n\x05input\x18\x06 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x42\n\x19schedule_to_close_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x42\n\x19schedule_to_start_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12?\n\x16start_to_close_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12:\n\x11heartbeat_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12(\n workflow_task_completed_event_id\x18\x0b \x01(\x03\x12\x39\n\x0cretry_policy\x18\x0c \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicyJ\x04\x08\x03\x10\x04"\xaf\x01\n"ActivityTaskStartedEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12\x10\n\x08identity\x18\x02 \x01(\t\x12\x12\n\nrequest_id\x18\x03 \x01(\t\x12\x0f\n\x07\x61ttempt\x18\x04 \x01(\x05\x12\x36\n\x0clast_failure\x18\x05 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"\xa0\x01\n$ActivityTaskCompletedEventAttributes\x12\x30\n\x06result\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x1a\n\x12scheduled_event_id\x18\x02 \x01(\x03\x12\x18\n\x10started_event_id\x18\x03 \x01(\x03\x12\x10\n\x08identity\x18\x04 \x01(\t"\xd6\x01\n!ActivityTaskFailedEventAttributes\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x1a\n\x12scheduled_event_id\x18\x02 \x01(\x03\x12\x18\n\x10started_event_id\x18\x03 \x01(\x03\x12\x10\n\x08identity\x18\x04 \x01(\t\x12\x36\n\x0bretry_state\x18\x05 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState"\xc6\x01\n#ActivityTaskTimedOutEventAttributes\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x1a\n\x12scheduled_event_id\x18\x02 \x01(\x03\x12\x18\n\x10started_event_id\x18\x03 \x01(\x03\x12\x36\n\x0bretry_state\x18\x04 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState"r\n*ActivityTaskCancelRequestedEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12(\n workflow_task_completed_event_id\x18\x02 \x01(\x03"\xca\x01\n#ActivityTaskCanceledEventAttributes\x12\x31\n\x07\x64\x65tails\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12(\n latest_cancel_requested_event_id\x18\x02 \x01(\x03\x12\x1a\n\x12scheduled_event_id\x18\x03 \x01(\x03\x12\x18\n\x10started_event_id\x18\x04 \x01(\x03\x12\x10\n\x08identity\x18\x05 \x01(\t"\x99\x01\n\x1bTimerStartedEventAttributes\x12\x10\n\x08timer_id\x18\x01 \x01(\t\x12>\n\x15start_to_fire_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12(\n workflow_task_completed_event_id\x18\x03 \x01(\x03"G\n\x19TimerFiredEventAttributes\x12\x10\n\x08timer_id\x18\x01 \x01(\t\x12\x18\n\x10started_event_id\x18\x02 \x01(\x03"\x86\x01\n\x1cTimerCanceledEventAttributes\x12\x10\n\x08timer_id\x18\x01 \x01(\t\x12\x18\n\x10started_event_id\x18\x02 \x01(\x03\x12(\n workflow_task_completed_event_id\x18\x03 \x01(\x03\x12\x10\n\x08identity\x18\x04 \x01(\t"\xc7\x01\n/WorkflowExecutionCancelRequestedEventAttributes\x12\r\n\x05\x63\x61use\x18\x01 \x01(\t\x12#\n\x1b\x65xternal_initiated_event_id\x18\x02 \x01(\x03\x12N\n\x1b\x65xternal_workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x10\n\x08identity\x18\x04 \x01(\t"\x87\x01\n(WorkflowExecutionCanceledEventAttributes\x12(\n workflow_task_completed_event_id\x18\x01 \x01(\x03\x12\x31\n\x07\x64\x65tails\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads"\xe9\x02\n\x1dMarkerRecordedEventAttributes\x12\x13\n\x0bmarker_name\x18\x01 \x01(\t\x12T\n\x07\x64\x65tails\x18\x02 \x03(\x0b\x32\x43.temporal.api.history.v1.MarkerRecordedEventAttributes.DetailsEntry\x12(\n workflow_task_completed_event_id\x18\x03 \x01(\x03\x12.\n\x06header\x18\x04 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12\x31\n\x07\x66\x61ilure\x18\x05 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x1aP\n\x0c\x44\x65tailsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12/\n\x05value\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads:\x02\x38\x01"\xd7\x01\n(WorkflowExecutionSignaledEventAttributes\x12\x13\n\x0bsignal_name\x18\x01 \x01(\t\x12/\n\x05input\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x03 \x01(\t\x12.\n\x06header\x18\x04 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12#\n\x1bskip_generate_workflow_task\x18\x05 \x01(\x08"\x81\x01\n*WorkflowExecutionTerminatedEventAttributes\x12\x0e\n\x06reason\x18\x01 \x01(\t\x12\x31\n\x07\x64\x65tails\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x03 \x01(\t"\x98\x02\n>RequestCancelExternalWorkflowExecutionInitiatedEventAttributes\x12(\n workflow_task_completed_event_id\x18\x01 \x01(\x03\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x0f\n\x07\x63ontrol\x18\x04 \x01(\t\x12\x1b\n\x13\x63hild_workflow_only\x18\x05 \x01(\x08\x12\x0e\n\x06reason\x18\x06 \x01(\t"\xd6\x02\n;RequestCancelExternalWorkflowExecutionFailedEventAttributes\x12P\n\x05\x63\x61use\x18\x01 \x01(\x0e\x32\x41.temporal.api.enums.v1.CancelExternalWorkflowExecutionFailedCause\x12(\n workflow_task_completed_event_id\x18\x02 \x01(\x03\x12\x11\n\tnamespace\x18\x03 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x04 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x1a\n\x12initiated_event_id\x18\x05 \x01(\x03\x12\x0f\n\x07\x63ontrol\x18\x06 \x01(\t"\xc5\x01\n7ExternalWorkflowExecutionCancelRequestedEventAttributes\x12\x1a\n\x12initiated_event_id\x18\x01 \x01(\x03\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x04 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution"\xf7\x02\n7SignalExternalWorkflowExecutionInitiatedEventAttributes\x12(\n workflow_task_completed_event_id\x18\x01 \x01(\x03\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\t \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x13\n\x0bsignal_name\x18\x04 \x01(\t\x12/\n\x05input\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x0f\n\x07\x63ontrol\x18\x06 \x01(\t\x12\x1b\n\x13\x63hild_workflow_only\x18\x07 \x01(\x08\x12.\n\x06header\x18\x08 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header"\xcf\x02\n4SignalExternalWorkflowExecutionFailedEventAttributes\x12P\n\x05\x63\x61use\x18\x01 \x01(\x0e\x32\x41.temporal.api.enums.v1.SignalExternalWorkflowExecutionFailedCause\x12(\n workflow_task_completed_event_id\x18\x02 \x01(\x03\x12\x11\n\tnamespace\x18\x03 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x04 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x1a\n\x12initiated_event_id\x18\x05 \x01(\x03\x12\x0f\n\x07\x63ontrol\x18\x06 \x01(\t"\xcf\x01\n0ExternalWorkflowExecutionSignaledEventAttributes\x12\x1a\n\x12initiated_event_id\x18\x01 \x01(\x03\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x05 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x0f\n\x07\x63ontrol\x18\x04 \x01(\t"\x9e\x01\n-UpsertWorkflowSearchAttributesEventAttributes\x12(\n workflow_task_completed_event_id\x18\x01 \x01(\x03\x12\x43\n\x11search_attributes\x18\x02 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"\x8a\x01\n)WorkflowPropertiesModifiedEventAttributes\x12(\n workflow_task_completed_event_id\x18\x01 \x01(\x03\x12\x33\n\rupserted_memo\x18\x02 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo"\xa4\x07\n3StartChildWorkflowExecutionInitiatedEventAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x12 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x45\n\x13parent_close_policy\x18\t \x01(\x0e\x32(.temporal.api.enums.v1.ParentClosePolicy\x12\x0f\n\x07\x63ontrol\x18\n \x01(\t\x12(\n workflow_task_completed_event_id\x18\x0b \x01(\x03\x12N\n\x18workflow_id_reuse_policy\x18\x0c \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x39\n\x0cretry_policy\x18\r \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\x0e \x01(\t\x12.\n\x06header\x18\x0f \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12*\n\x04memo\x18\x10 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x11 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"\xd2\x02\n0StartChildWorkflowExecutionFailedEventAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x08 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12L\n\x05\x63\x61use\x18\x04 \x01(\x0e\x32=.temporal.api.enums.v1.StartChildWorkflowExecutionFailedCause\x12\x0f\n\x07\x63ontrol\x18\x05 \x01(\t\x12\x1a\n\x12initiated_event_id\x18\x06 \x01(\x03\x12(\n workflow_task_completed_event_id\x18\x07 \x01(\x03"\xa7\x02\n,ChildWorkflowExecutionStartedEventAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x06 \x01(\t\x12\x1a\n\x12initiated_event_id\x18\x02 \x01(\x03\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x04 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12.\n\x06header\x18\x05 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header"\xc5\x02\n.ChildWorkflowExecutionCompletedEventAttributes\x12\x30\n\x06result\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x04 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x1a\n\x12initiated_event_id\x18\x05 \x01(\x03\x12\x18\n\x10started_event_id\x18\x06 \x01(\x03"\xfb\x02\n+ChildWorkflowExecutionFailedEventAttributes\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x08 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x04 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x1a\n\x12initiated_event_id\x18\x05 \x01(\x03\x12\x18\n\x10started_event_id\x18\x06 \x01(\x03\x12\x36\n\x0bretry_state\x18\x07 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState"\xc5\x02\n-ChildWorkflowExecutionCanceledEventAttributes\x12\x31\n\x07\x64\x65tails\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x04 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x1a\n\x12initiated_event_id\x18\x05 \x01(\x03\x12\x18\n\x10started_event_id\x18\x06 \x01(\x03"\xca\x02\n-ChildWorkflowExecutionTimedOutEventAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x1a\n\x12initiated_event_id\x18\x04 \x01(\x03\x12\x18\n\x10started_event_id\x18\x05 \x01(\x03\x12\x36\n\x0bretry_state\x18\x06 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState"\x94\x02\n/ChildWorkflowExecutionTerminatedEventAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x06 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x1a\n\x12initiated_event_id\x18\x04 \x01(\x03\x12\x18\n\x10started_event_id\x18\x05 \x01(\x03"\xd2\x02\n3WorkflowPropertiesModifiedExternallyEventAttributes\x12\x16\n\x0enew_task_queue\x18\x01 \x01(\t\x12\x42\n\x19new_workflow_task_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x41\n\x18new_workflow_run_timeout\x18\x03 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12G\n\x1enew_workflow_execution_timeout\x18\x04 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x33\n\rupserted_memo\x18\x05 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo"\x90\x01\n3ActivityPropertiesModifiedExternallyEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12=\n\x10new_retry_policy\x18\x02 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy"\xdc\x01\n.WorkflowExecutionUpdateAcceptedEventAttributes\x12\x1c\n\x14protocol_instance_id\x18\x01 \x01(\t\x12#\n\x1b\x61\x63\x63\x65pted_request_message_id\x18\x02 \x01(\t\x12,\n$accepted_request_sequencing_event_id\x18\x03 \x01(\x03\x12\x39\n\x10\x61\x63\x63\x65pted_request\x18\x04 \x01(\x0b\x32\x1f.temporal.api.update.v1.Request"\x8f\x01\n/WorkflowExecutionUpdateCompletedEventAttributes\x12*\n\x04meta\x18\x01 \x01(\x0b\x32\x1c.temporal.api.update.v1.Meta\x12\x30\n\x07outcome\x18\x02 \x01(\x0b\x32\x1f.temporal.api.update.v1.Outcome"\x8f\x02\n.WorkflowExecutionUpdateRejectedEventAttributes\x12\x1c\n\x14protocol_instance_id\x18\x01 \x01(\t\x12#\n\x1brejected_request_message_id\x18\x02 \x01(\t\x12,\n$rejected_request_sequencing_event_id\x18\x03 \x01(\x03\x12\x39\n\x10rejected_request\x18\x04 \x01(\x0b\x32\x1f.temporal.api.update.v1.Request\x12\x31\n\x07\x66\x61ilure\x18\x05 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"\xe5/\n\x0cHistoryEvent\x12\x10\n\x08\x65vent_id\x18\x01 \x01(\x03\x12\x34\n\nevent_time\x18\x02 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x34\n\nevent_type\x18\x03 \x01(\x0e\x32 .temporal.api.enums.v1.EventType\x12\x0f\n\x07version\x18\x04 \x01(\x03\x12\x0f\n\x07task_id\x18\x05 \x01(\x03\x12\x1a\n\x11worker_may_ignore\x18\xac\x02 \x01(\x08\x12w\n+workflow_execution_started_event_attributes\x18\x06 \x01(\x0b\x32@.temporal.api.history.v1.WorkflowExecutionStartedEventAttributesH\x00\x12{\n-workflow_execution_completed_event_attributes\x18\x07 \x01(\x0b\x32\x42.temporal.api.history.v1.WorkflowExecutionCompletedEventAttributesH\x00\x12u\n*workflow_execution_failed_event_attributes\x18\x08 \x01(\x0b\x32?.temporal.api.history.v1.WorkflowExecutionFailedEventAttributesH\x00\x12z\n-workflow_execution_timed_out_event_attributes\x18\t \x01(\x0b\x32\x41.temporal.api.history.v1.WorkflowExecutionTimedOutEventAttributesH\x00\x12q\n(workflow_task_scheduled_event_attributes\x18\n \x01(\x0b\x32=.temporal.api.history.v1.WorkflowTaskScheduledEventAttributesH\x00\x12m\n&workflow_task_started_event_attributes\x18\x0b \x01(\x0b\x32;.temporal.api.history.v1.WorkflowTaskStartedEventAttributesH\x00\x12q\n(workflow_task_completed_event_attributes\x18\x0c \x01(\x0b\x32=.temporal.api.history.v1.WorkflowTaskCompletedEventAttributesH\x00\x12p\n(workflow_task_timed_out_event_attributes\x18\r \x01(\x0b\x32<.temporal.api.history.v1.WorkflowTaskTimedOutEventAttributesH\x00\x12k\n%workflow_task_failed_event_attributes\x18\x0e \x01(\x0b\x32:.temporal.api.history.v1.WorkflowTaskFailedEventAttributesH\x00\x12q\n(activity_task_scheduled_event_attributes\x18\x0f \x01(\x0b\x32=.temporal.api.history.v1.ActivityTaskScheduledEventAttributesH\x00\x12m\n&activity_task_started_event_attributes\x18\x10 \x01(\x0b\x32;.temporal.api.history.v1.ActivityTaskStartedEventAttributesH\x00\x12q\n(activity_task_completed_event_attributes\x18\x11 \x01(\x0b\x32=.temporal.api.history.v1.ActivityTaskCompletedEventAttributesH\x00\x12k\n%activity_task_failed_event_attributes\x18\x12 \x01(\x0b\x32:.temporal.api.history.v1.ActivityTaskFailedEventAttributesH\x00\x12p\n(activity_task_timed_out_event_attributes\x18\x13 \x01(\x0b\x32<.temporal.api.history.v1.ActivityTaskTimedOutEventAttributesH\x00\x12^\n\x1etimer_started_event_attributes\x18\x14 \x01(\x0b\x32\x34.temporal.api.history.v1.TimerStartedEventAttributesH\x00\x12Z\n\x1ctimer_fired_event_attributes\x18\x15 \x01(\x0b\x32\x32.temporal.api.history.v1.TimerFiredEventAttributesH\x00\x12~\n/activity_task_cancel_requested_event_attributes\x18\x16 \x01(\x0b\x32\x43.temporal.api.history.v1.ActivityTaskCancelRequestedEventAttributesH\x00\x12o\n\'activity_task_canceled_event_attributes\x18\x17 \x01(\x0b\x32<.temporal.api.history.v1.ActivityTaskCanceledEventAttributesH\x00\x12`\n\x1ftimer_canceled_event_attributes\x18\x18 \x01(\x0b\x32\x35.temporal.api.history.v1.TimerCanceledEventAttributesH\x00\x12\x62\n marker_recorded_event_attributes\x18\x19 \x01(\x0b\x32\x36.temporal.api.history.v1.MarkerRecordedEventAttributesH\x00\x12y\n,workflow_execution_signaled_event_attributes\x18\x1a \x01(\x0b\x32\x41.temporal.api.history.v1.WorkflowExecutionSignaledEventAttributesH\x00\x12}\n.workflow_execution_terminated_event_attributes\x18\x1b \x01(\x0b\x32\x43.temporal.api.history.v1.WorkflowExecutionTerminatedEventAttributesH\x00\x12\x88\x01\n4workflow_execution_cancel_requested_event_attributes\x18\x1c \x01(\x0b\x32H.temporal.api.history.v1.WorkflowExecutionCancelRequestedEventAttributesH\x00\x12y\n,workflow_execution_canceled_event_attributes\x18\x1d \x01(\x0b\x32\x41.temporal.api.history.v1.WorkflowExecutionCanceledEventAttributesH\x00\x12\xa8\x01\nErequest_cancel_external_workflow_execution_initiated_event_attributes\x18\x1e \x01(\x0b\x32W.temporal.api.history.v1.RequestCancelExternalWorkflowExecutionInitiatedEventAttributesH\x00\x12\xa2\x01\nBrequest_cancel_external_workflow_execution_failed_event_attributes\x18\x1f \x01(\x0b\x32T.temporal.api.history.v1.RequestCancelExternalWorkflowExecutionFailedEventAttributesH\x00\x12\x99\x01\n=external_workflow_execution_cancel_requested_event_attributes\x18  \x01(\x0b\x32P.temporal.api.history.v1.ExternalWorkflowExecutionCancelRequestedEventAttributesH\x00\x12\x87\x01\n4workflow_execution_continued_as_new_event_attributes\x18! \x01(\x0b\x32G.temporal.api.history.v1.WorkflowExecutionContinuedAsNewEventAttributesH\x00\x12\x91\x01\n9start_child_workflow_execution_initiated_event_attributes\x18" \x01(\x0b\x32L.temporal.api.history.v1.StartChildWorkflowExecutionInitiatedEventAttributesH\x00\x12\x8b\x01\n6start_child_workflow_execution_failed_event_attributes\x18# \x01(\x0b\x32I.temporal.api.history.v1.StartChildWorkflowExecutionFailedEventAttributesH\x00\x12\x82\x01\n1child_workflow_execution_started_event_attributes\x18$ \x01(\x0b\x32\x45.temporal.api.history.v1.ChildWorkflowExecutionStartedEventAttributesH\x00\x12\x86\x01\n3child_workflow_execution_completed_event_attributes\x18% \x01(\x0b\x32G.temporal.api.history.v1.ChildWorkflowExecutionCompletedEventAttributesH\x00\x12\x80\x01\n0child_workflow_execution_failed_event_attributes\x18& \x01(\x0b\x32\x44.temporal.api.history.v1.ChildWorkflowExecutionFailedEventAttributesH\x00\x12\x84\x01\n2child_workflow_execution_canceled_event_attributes\x18\' \x01(\x0b\x32\x46.temporal.api.history.v1.ChildWorkflowExecutionCanceledEventAttributesH\x00\x12\x85\x01\n3child_workflow_execution_timed_out_event_attributes\x18( \x01(\x0b\x32\x46.temporal.api.history.v1.ChildWorkflowExecutionTimedOutEventAttributesH\x00\x12\x88\x01\n4child_workflow_execution_terminated_event_attributes\x18) \x01(\x0b\x32H.temporal.api.history.v1.ChildWorkflowExecutionTerminatedEventAttributesH\x00\x12\x99\x01\n=signal_external_workflow_execution_initiated_event_attributes\x18* \x01(\x0b\x32P.temporal.api.history.v1.SignalExternalWorkflowExecutionInitiatedEventAttributesH\x00\x12\x93\x01\n:signal_external_workflow_execution_failed_event_attributes\x18+ \x01(\x0b\x32M.temporal.api.history.v1.SignalExternalWorkflowExecutionFailedEventAttributesH\x00\x12\x8a\x01\n5external_workflow_execution_signaled_event_attributes\x18, \x01(\x0b\x32I.temporal.api.history.v1.ExternalWorkflowExecutionSignaledEventAttributesH\x00\x12\x84\x01\n2upsert_workflow_search_attributes_event_attributes\x18- \x01(\x0b\x32\x46.temporal.api.history.v1.UpsertWorkflowSearchAttributesEventAttributesH\x00\x12\x86\x01\n3workflow_execution_update_accepted_event_attributes\x18. \x01(\x0b\x32G.temporal.api.history.v1.WorkflowExecutionUpdateAcceptedEventAttributesH\x00\x12\x86\x01\n3workflow_execution_update_rejected_event_attributes\x18/ \x01(\x0b\x32G.temporal.api.history.v1.WorkflowExecutionUpdateRejectedEventAttributesH\x00\x12\x88\x01\n4workflow_execution_update_completed_event_attributes\x18\x30 \x01(\x0b\x32H.temporal.api.history.v1.WorkflowExecutionUpdateCompletedEventAttributesH\x00\x12\x90\x01\n8workflow_properties_modified_externally_event_attributes\x18\x31 \x01(\x0b\x32L.temporal.api.history.v1.WorkflowPropertiesModifiedExternallyEventAttributesH\x00\x12\x90\x01\n8activity_properties_modified_externally_event_attributes\x18\x32 \x01(\x0b\x32L.temporal.api.history.v1.ActivityPropertiesModifiedExternallyEventAttributesH\x00\x12{\n-workflow_properties_modified_event_attributes\x18\x33 \x01(\x0b\x32\x42.temporal.api.history.v1.WorkflowPropertiesModifiedEventAttributesH\x00\x42\x0c\n\nattributes"@\n\x07History\x12\x35\n\x06\x65vents\x18\x01 \x03(\x0b\x32%.temporal.api.history.v1.HistoryEventB\x8e\x01\n\x1aio.temporal.api.history.v1B\x0cMessageProtoP\x01Z%go.temporal.io/api/history/v1;history\xaa\x02\x19Temporalio.Api.History.V1\xea\x02\x1cTemporalio::Api::History::V1b\x06proto3'
+    b'\n%temporal/api/history/v1/message.proto\x12\x17temporal.api.history.v1\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a!dependencies/gogoproto/gogo.proto\x1a&temporal/api/enums/v1/event_type.proto\x1a(temporal/api/enums/v1/failed_cause.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a$temporal/api/common/v1/message.proto\x1a%temporal/api/failure/v1/message.proto\x1a\'temporal/api/taskqueue/v1/message.proto\x1a$temporal/api/update/v1/message.proto\x1a&temporal/api/workflow/v1/message.proto\x1a\x30temporal/api/sdk/v1/task_complete_metadata.proto"\xef\x0b\n\'WorkflowExecutionStartedEventAttributes\x12;\n\rworkflow_type\x18\x01 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12!\n\x19parent_workflow_namespace\x18\x02 \x01(\t\x12$\n\x1cparent_workflow_namespace_id\x18\x1b \x01(\t\x12L\n\x19parent_workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12!\n\x19parent_initiated_event_id\x18\x04 \x01(\x03\x12\x38\n\ntask_queue\x18\x05 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x06 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12"\n\x1a\x63ontinued_execution_run_id\x18\n \x01(\t\x12@\n\tinitiator\x18\x0b \x01(\x0e\x32-.temporal.api.enums.v1.ContinueAsNewInitiator\x12;\n\x11\x63ontinued_failure\x18\x0c \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12@\n\x16last_completion_result\x18\r \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12!\n\x19original_execution_run_id\x18\x0e \x01(\t\x12\x10\n\x08identity\x18\x0f \x01(\t\x12\x1e\n\x16\x66irst_execution_run_id\x18\x10 \x01(\t\x12\x39\n\x0cretry_policy\x18\x11 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x0f\n\x07\x61ttempt\x18\x12 \x01(\x05\x12L\n"workflow_execution_expiration_time\x18\x13 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x15\n\rcron_schedule\x18\x14 \x01(\t\x12\x44\n\x1b\x66irst_workflow_task_backoff\x18\x15 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12*\n\x04memo\x18\x16 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x17 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12\x45\n\x16prev_auto_reset_points\x18\x18 \x01(\x0b\x32%.temporal.api.workflow.v1.ResetPoints\x12.\n\x06header\x18\x19 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12&\n\x1eparent_initiated_event_version\x18\x1a \x01(\x03\x12\x13\n\x0bworkflow_id\x18\x1c \x01(\t\x12H\n\x14source_version_stamp\x18\x1d \x01(\x0b\x32*.temporal.api.common.v1.WorkerVersionStamp"\xa5\x01\n)WorkflowExecutionCompletedEventAttributes\x12\x30\n\x06result\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12(\n workflow_task_completed_event_id\x18\x02 \x01(\x03\x12\x1c\n\x14new_execution_run_id\x18\x03 \x01(\t"\xdb\x01\n&WorkflowExecutionFailedEventAttributes\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x36\n\x0bretry_state\x18\x02 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState\x12(\n workflow_task_completed_event_id\x18\x03 \x01(\x03\x12\x1c\n\x14new_execution_run_id\x18\x04 \x01(\t"\x80\x01\n(WorkflowExecutionTimedOutEventAttributes\x12\x36\n\x0bretry_state\x18\x01 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState\x12\x1c\n\x14new_execution_run_id\x18\x02 \x01(\t"\xd8\x06\n.WorkflowExecutionContinuedAsNewEventAttributes\x12\x1c\n\x14new_execution_run_id\x18\x01 \x01(\t\x12;\n\rworkflow_type\x18\x02 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x03 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x04 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12=\n\x14workflow_run_timeout\x18\x05 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12(\n workflow_task_completed_event_id\x18\x07 \x01(\x03\x12?\n\x16\x62\x61\x63koff_start_interval\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12@\n\tinitiator\x18\t \x01(\x0e\x32-.temporal.api.enums.v1.ContinueAsNewInitiator\x12\x31\n\x07\x66\x61ilure\x18\n \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12@\n\x16last_completion_result\x18\x0b \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12.\n\x06header\x18\x0c \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12*\n\x04memo\x18\r \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x0e \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12\x1e\n\x16use_compatible_version\x18\x0f \x01(\x08"\xb2\x01\n$WorkflowTaskScheduledEventAttributes\x12\x38\n\ntask_queue\x18\x01 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12?\n\x16start_to_close_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x0f\n\x07\x61ttempt\x18\x03 \x01(\x05"\xa3\x01\n"WorkflowTaskStartedEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12\x10\n\x08identity\x18\x02 \x01(\t\x12\x12\n\nrequest_id\x18\x03 \x01(\t\x12\x1f\n\x17suggest_continue_as_new\x18\x04 \x01(\x08\x12\x1a\n\x12history_size_bytes\x18\x05 \x01(\x03"\xda\x02\n$WorkflowTaskCompletedEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12\x18\n\x10started_event_id\x18\x02 \x01(\x03\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x17\n\x0f\x62inary_checksum\x18\x04 \x01(\t\x12\x42\n\x0eworker_version\x18\x05 \x01(\x0b\x32*.temporal.api.common.v1.WorkerVersionStamp\x12H\n\x0csdk_metadata\x18\x06 \x01(\x0b\x32\x32.temporal.api.sdk.v1.WorkflowTaskCompletedMetadata\x12\x43\n\x11metering_metadata\x18\r \x01(\x0b\x32(.temporal.api.common.v1.MeteringMetadata"\x95\x01\n#WorkflowTaskTimedOutEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12\x18\n\x10started_event_id\x18\x02 \x01(\x03\x12\x38\n\x0ctimeout_type\x18\x03 \x01(\x0e\x32".temporal.api.enums.v1.TimeoutType"\xff\x02\n!WorkflowTaskFailedEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12\x18\n\x10started_event_id\x18\x02 \x01(\x03\x12=\n\x05\x63\x61use\x18\x03 \x01(\x0e\x32..temporal.api.enums.v1.WorkflowTaskFailedCause\x12\x31\n\x07\x66\x61ilure\x18\x04 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x10\n\x08identity\x18\x05 \x01(\t\x12\x13\n\x0b\x62\x61se_run_id\x18\x06 \x01(\t\x12\x12\n\nnew_run_id\x18\x07 \x01(\t\x12\x1a\n\x12\x66ork_event_version\x18\x08 \x01(\x03\x12\x17\n\x0f\x62inary_checksum\x18\t \x01(\t\x12\x42\n\x0eworker_version\x18\n \x01(\x0b\x32*.temporal.api.common.v1.WorkerVersionStamp"\xa3\x05\n$ActivityTaskScheduledEventAttributes\x12\x13\n\x0b\x61\x63tivity_id\x18\x01 \x01(\t\x12;\n\ractivity_type\x18\x02 \x01(\x0b\x32$.temporal.api.common.v1.ActivityType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12.\n\x06header\x18\x05 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12/\n\x05input\x18\x06 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x42\n\x19schedule_to_close_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x42\n\x19schedule_to_start_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12?\n\x16start_to_close_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12:\n\x11heartbeat_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12(\n workflow_task_completed_event_id\x18\x0b \x01(\x03\x12\x39\n\x0cretry_policy\x18\x0c \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x1e\n\x16use_compatible_version\x18\r \x01(\x08J\x04\x08\x03\x10\x04"\xaf\x01\n"ActivityTaskStartedEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12\x10\n\x08identity\x18\x02 \x01(\t\x12\x12\n\nrequest_id\x18\x03 \x01(\t\x12\x0f\n\x07\x61ttempt\x18\x04 \x01(\x05\x12\x36\n\x0clast_failure\x18\x05 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"\xe4\x01\n$ActivityTaskCompletedEventAttributes\x12\x30\n\x06result\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x1a\n\x12scheduled_event_id\x18\x02 \x01(\x03\x12\x18\n\x10started_event_id\x18\x03 \x01(\x03\x12\x10\n\x08identity\x18\x04 \x01(\t\x12\x42\n\x0eworker_version\x18\x05 \x01(\x0b\x32*.temporal.api.common.v1.WorkerVersionStamp"\x9a\x02\n!ActivityTaskFailedEventAttributes\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x1a\n\x12scheduled_event_id\x18\x02 \x01(\x03\x12\x18\n\x10started_event_id\x18\x03 \x01(\x03\x12\x10\n\x08identity\x18\x04 \x01(\t\x12\x36\n\x0bretry_state\x18\x05 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState\x12\x42\n\x0eworker_version\x18\x06 \x01(\x0b\x32*.temporal.api.common.v1.WorkerVersionStamp"\xc6\x01\n#ActivityTaskTimedOutEventAttributes\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x1a\n\x12scheduled_event_id\x18\x02 \x01(\x03\x12\x18\n\x10started_event_id\x18\x03 \x01(\x03\x12\x36\n\x0bretry_state\x18\x04 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState"r\n*ActivityTaskCancelRequestedEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12(\n workflow_task_completed_event_id\x18\x02 \x01(\x03"\x8e\x02\n#ActivityTaskCanceledEventAttributes\x12\x31\n\x07\x64\x65tails\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12(\n latest_cancel_requested_event_id\x18\x02 \x01(\x03\x12\x1a\n\x12scheduled_event_id\x18\x03 \x01(\x03\x12\x18\n\x10started_event_id\x18\x04 \x01(\x03\x12\x10\n\x08identity\x18\x05 \x01(\t\x12\x42\n\x0eworker_version\x18\x06 \x01(\x0b\x32*.temporal.api.common.v1.WorkerVersionStamp"\x99\x01\n\x1bTimerStartedEventAttributes\x12\x10\n\x08timer_id\x18\x01 \x01(\t\x12>\n\x15start_to_fire_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12(\n workflow_task_completed_event_id\x18\x03 \x01(\x03"G\n\x19TimerFiredEventAttributes\x12\x10\n\x08timer_id\x18\x01 \x01(\t\x12\x18\n\x10started_event_id\x18\x02 \x01(\x03"\x86\x01\n\x1cTimerCanceledEventAttributes\x12\x10\n\x08timer_id\x18\x01 \x01(\t\x12\x18\n\x10started_event_id\x18\x02 \x01(\x03\x12(\n workflow_task_completed_event_id\x18\x03 \x01(\x03\x12\x10\n\x08identity\x18\x04 \x01(\t"\xc7\x01\n/WorkflowExecutionCancelRequestedEventAttributes\x12\r\n\x05\x63\x61use\x18\x01 \x01(\t\x12#\n\x1b\x65xternal_initiated_event_id\x18\x02 \x01(\x03\x12N\n\x1b\x65xternal_workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x10\n\x08identity\x18\x04 \x01(\t"\x87\x01\n(WorkflowExecutionCanceledEventAttributes\x12(\n workflow_task_completed_event_id\x18\x01 \x01(\x03\x12\x31\n\x07\x64\x65tails\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads"\xe9\x02\n\x1dMarkerRecordedEventAttributes\x12\x13\n\x0bmarker_name\x18\x01 \x01(\t\x12T\n\x07\x64\x65tails\x18\x02 \x03(\x0b\x32\x43.temporal.api.history.v1.MarkerRecordedEventAttributes.DetailsEntry\x12(\n workflow_task_completed_event_id\x18\x03 \x01(\x03\x12.\n\x06header\x18\x04 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12\x31\n\x07\x66\x61ilure\x18\x05 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x1aP\n\x0c\x44\x65tailsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12/\n\x05value\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads:\x02\x38\x01"\xd7\x01\n(WorkflowExecutionSignaledEventAttributes\x12\x13\n\x0bsignal_name\x18\x01 \x01(\t\x12/\n\x05input\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x03 \x01(\t\x12.\n\x06header\x18\x04 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12#\n\x1bskip_generate_workflow_task\x18\x05 \x01(\x08"\x81\x01\n*WorkflowExecutionTerminatedEventAttributes\x12\x0e\n\x06reason\x18\x01 \x01(\t\x12\x31\n\x07\x64\x65tails\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x03 \x01(\t"\x98\x02\n>RequestCancelExternalWorkflowExecutionInitiatedEventAttributes\x12(\n workflow_task_completed_event_id\x18\x01 \x01(\x03\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x0f\n\x07\x63ontrol\x18\x04 \x01(\t\x12\x1b\n\x13\x63hild_workflow_only\x18\x05 \x01(\x08\x12\x0e\n\x06reason\x18\x06 \x01(\t"\xd6\x02\n;RequestCancelExternalWorkflowExecutionFailedEventAttributes\x12P\n\x05\x63\x61use\x18\x01 \x01(\x0e\x32\x41.temporal.api.enums.v1.CancelExternalWorkflowExecutionFailedCause\x12(\n workflow_task_completed_event_id\x18\x02 \x01(\x03\x12\x11\n\tnamespace\x18\x03 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x04 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x1a\n\x12initiated_event_id\x18\x05 \x01(\x03\x12\x0f\n\x07\x63ontrol\x18\x06 \x01(\t"\xc5\x01\n7ExternalWorkflowExecutionCancelRequestedEventAttributes\x12\x1a\n\x12initiated_event_id\x18\x01 \x01(\x03\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x04 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution"\xf7\x02\n7SignalExternalWorkflowExecutionInitiatedEventAttributes\x12(\n workflow_task_completed_event_id\x18\x01 \x01(\x03\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\t \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x13\n\x0bsignal_name\x18\x04 \x01(\t\x12/\n\x05input\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x0f\n\x07\x63ontrol\x18\x06 \x01(\t\x12\x1b\n\x13\x63hild_workflow_only\x18\x07 \x01(\x08\x12.\n\x06header\x18\x08 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header"\xcf\x02\n4SignalExternalWorkflowExecutionFailedEventAttributes\x12P\n\x05\x63\x61use\x18\x01 \x01(\x0e\x32\x41.temporal.api.enums.v1.SignalExternalWorkflowExecutionFailedCause\x12(\n workflow_task_completed_event_id\x18\x02 \x01(\x03\x12\x11\n\tnamespace\x18\x03 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x04 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x1a\n\x12initiated_event_id\x18\x05 \x01(\x03\x12\x0f\n\x07\x63ontrol\x18\x06 \x01(\t"\xcf\x01\n0ExternalWorkflowExecutionSignaledEventAttributes\x12\x1a\n\x12initiated_event_id\x18\x01 \x01(\x03\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x05 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x0f\n\x07\x63ontrol\x18\x04 \x01(\t"\x9e\x01\n-UpsertWorkflowSearchAttributesEventAttributes\x12(\n workflow_task_completed_event_id\x18\x01 \x01(\x03\x12\x43\n\x11search_attributes\x18\x02 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"\x8a\x01\n)WorkflowPropertiesModifiedEventAttributes\x12(\n workflow_task_completed_event_id\x18\x01 \x01(\x03\x12\x33\n\rupserted_memo\x18\x02 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo"\xc4\x07\n3StartChildWorkflowExecutionInitiatedEventAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x12 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x45\n\x13parent_close_policy\x18\t \x01(\x0e\x32(.temporal.api.enums.v1.ParentClosePolicy\x12\x0f\n\x07\x63ontrol\x18\n \x01(\t\x12(\n workflow_task_completed_event_id\x18\x0b \x01(\x03\x12N\n\x18workflow_id_reuse_policy\x18\x0c \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x39\n\x0cretry_policy\x18\r \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\x0e \x01(\t\x12.\n\x06header\x18\x0f \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12*\n\x04memo\x18\x10 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x11 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12\x1e\n\x16use_compatible_version\x18\x13 \x01(\x08"\xd2\x02\n0StartChildWorkflowExecutionFailedEventAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x08 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12L\n\x05\x63\x61use\x18\x04 \x01(\x0e\x32=.temporal.api.enums.v1.StartChildWorkflowExecutionFailedCause\x12\x0f\n\x07\x63ontrol\x18\x05 \x01(\t\x12\x1a\n\x12initiated_event_id\x18\x06 \x01(\x03\x12(\n workflow_task_completed_event_id\x18\x07 \x01(\x03"\xa7\x02\n,ChildWorkflowExecutionStartedEventAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x06 \x01(\t\x12\x1a\n\x12initiated_event_id\x18\x02 \x01(\x03\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x04 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12.\n\x06header\x18\x05 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header"\xc5\x02\n.ChildWorkflowExecutionCompletedEventAttributes\x12\x30\n\x06result\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x04 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x1a\n\x12initiated_event_id\x18\x05 \x01(\x03\x12\x18\n\x10started_event_id\x18\x06 \x01(\x03"\xfb\x02\n+ChildWorkflowExecutionFailedEventAttributes\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x08 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x04 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x1a\n\x12initiated_event_id\x18\x05 \x01(\x03\x12\x18\n\x10started_event_id\x18\x06 \x01(\x03\x12\x36\n\x0bretry_state\x18\x07 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState"\xc5\x02\n-ChildWorkflowExecutionCanceledEventAttributes\x12\x31\n\x07\x64\x65tails\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x04 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x1a\n\x12initiated_event_id\x18\x05 \x01(\x03\x12\x18\n\x10started_event_id\x18\x06 \x01(\x03"\xca\x02\n-ChildWorkflowExecutionTimedOutEventAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x1a\n\x12initiated_event_id\x18\x04 \x01(\x03\x12\x18\n\x10started_event_id\x18\x05 \x01(\x03\x12\x36\n\x0bretry_state\x18\x06 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState"\x94\x02\n/ChildWorkflowExecutionTerminatedEventAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x06 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x1a\n\x12initiated_event_id\x18\x04 \x01(\x03\x12\x18\n\x10started_event_id\x18\x05 \x01(\x03"\xd2\x02\n3WorkflowPropertiesModifiedExternallyEventAttributes\x12\x16\n\x0enew_task_queue\x18\x01 \x01(\t\x12\x42\n\x19new_workflow_task_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x41\n\x18new_workflow_run_timeout\x18\x03 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12G\n\x1enew_workflow_execution_timeout\x18\x04 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x33\n\rupserted_memo\x18\x05 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo"\x90\x01\n3ActivityPropertiesModifiedExternallyEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12=\n\x10new_retry_policy\x18\x02 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy"\xdc\x01\n.WorkflowExecutionUpdateAcceptedEventAttributes\x12\x1c\n\x14protocol_instance_id\x18\x01 \x01(\t\x12#\n\x1b\x61\x63\x63\x65pted_request_message_id\x18\x02 \x01(\t\x12,\n$accepted_request_sequencing_event_id\x18\x03 \x01(\x03\x12\x39\n\x10\x61\x63\x63\x65pted_request\x18\x04 \x01(\x0b\x32\x1f.temporal.api.update.v1.Request"\xaa\x01\n/WorkflowExecutionUpdateCompletedEventAttributes\x12*\n\x04meta\x18\x01 \x01(\x0b\x32\x1c.temporal.api.update.v1.Meta\x12\x19\n\x11\x61\x63\x63\x65pted_event_id\x18\x03 \x01(\x03\x12\x30\n\x07outcome\x18\x02 \x01(\x0b\x32\x1f.temporal.api.update.v1.Outcome"\x8f\x02\n.WorkflowExecutionUpdateRejectedEventAttributes\x12\x1c\n\x14protocol_instance_id\x18\x01 \x01(\t\x12#\n\x1brejected_request_message_id\x18\x02 \x01(\t\x12,\n$rejected_request_sequencing_event_id\x18\x03 \x01(\x03\x12\x39\n\x10rejected_request\x18\x04 \x01(\x0b\x32\x1f.temporal.api.update.v1.Request\x12\x31\n\x07\x66\x61ilure\x18\x05 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"\xe5/\n\x0cHistoryEvent\x12\x10\n\x08\x65vent_id\x18\x01 \x01(\x03\x12\x34\n\nevent_time\x18\x02 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x34\n\nevent_type\x18\x03 \x01(\x0e\x32 .temporal.api.enums.v1.EventType\x12\x0f\n\x07version\x18\x04 \x01(\x03\x12\x0f\n\x07task_id\x18\x05 \x01(\x03\x12\x1a\n\x11worker_may_ignore\x18\xac\x02 \x01(\x08\x12w\n+workflow_execution_started_event_attributes\x18\x06 \x01(\x0b\x32@.temporal.api.history.v1.WorkflowExecutionStartedEventAttributesH\x00\x12{\n-workflow_execution_completed_event_attributes\x18\x07 \x01(\x0b\x32\x42.temporal.api.history.v1.WorkflowExecutionCompletedEventAttributesH\x00\x12u\n*workflow_execution_failed_event_attributes\x18\x08 \x01(\x0b\x32?.temporal.api.history.v1.WorkflowExecutionFailedEventAttributesH\x00\x12z\n-workflow_execution_timed_out_event_attributes\x18\t \x01(\x0b\x32\x41.temporal.api.history.v1.WorkflowExecutionTimedOutEventAttributesH\x00\x12q\n(workflow_task_scheduled_event_attributes\x18\n \x01(\x0b\x32=.temporal.api.history.v1.WorkflowTaskScheduledEventAttributesH\x00\x12m\n&workflow_task_started_event_attributes\x18\x0b \x01(\x0b\x32;.temporal.api.history.v1.WorkflowTaskStartedEventAttributesH\x00\x12q\n(workflow_task_completed_event_attributes\x18\x0c \x01(\x0b\x32=.temporal.api.history.v1.WorkflowTaskCompletedEventAttributesH\x00\x12p\n(workflow_task_timed_out_event_attributes\x18\r \x01(\x0b\x32<.temporal.api.history.v1.WorkflowTaskTimedOutEventAttributesH\x00\x12k\n%workflow_task_failed_event_attributes\x18\x0e \x01(\x0b\x32:.temporal.api.history.v1.WorkflowTaskFailedEventAttributesH\x00\x12q\n(activity_task_scheduled_event_attributes\x18\x0f \x01(\x0b\x32=.temporal.api.history.v1.ActivityTaskScheduledEventAttributesH\x00\x12m\n&activity_task_started_event_attributes\x18\x10 \x01(\x0b\x32;.temporal.api.history.v1.ActivityTaskStartedEventAttributesH\x00\x12q\n(activity_task_completed_event_attributes\x18\x11 \x01(\x0b\x32=.temporal.api.history.v1.ActivityTaskCompletedEventAttributesH\x00\x12k\n%activity_task_failed_event_attributes\x18\x12 \x01(\x0b\x32:.temporal.api.history.v1.ActivityTaskFailedEventAttributesH\x00\x12p\n(activity_task_timed_out_event_attributes\x18\x13 \x01(\x0b\x32<.temporal.api.history.v1.ActivityTaskTimedOutEventAttributesH\x00\x12^\n\x1etimer_started_event_attributes\x18\x14 \x01(\x0b\x32\x34.temporal.api.history.v1.TimerStartedEventAttributesH\x00\x12Z\n\x1ctimer_fired_event_attributes\x18\x15 \x01(\x0b\x32\x32.temporal.api.history.v1.TimerFiredEventAttributesH\x00\x12~\n/activity_task_cancel_requested_event_attributes\x18\x16 \x01(\x0b\x32\x43.temporal.api.history.v1.ActivityTaskCancelRequestedEventAttributesH\x00\x12o\n\'activity_task_canceled_event_attributes\x18\x17 \x01(\x0b\x32<.temporal.api.history.v1.ActivityTaskCanceledEventAttributesH\x00\x12`\n\x1ftimer_canceled_event_attributes\x18\x18 \x01(\x0b\x32\x35.temporal.api.history.v1.TimerCanceledEventAttributesH\x00\x12\x62\n marker_recorded_event_attributes\x18\x19 \x01(\x0b\x32\x36.temporal.api.history.v1.MarkerRecordedEventAttributesH\x00\x12y\n,workflow_execution_signaled_event_attributes\x18\x1a \x01(\x0b\x32\x41.temporal.api.history.v1.WorkflowExecutionSignaledEventAttributesH\x00\x12}\n.workflow_execution_terminated_event_attributes\x18\x1b \x01(\x0b\x32\x43.temporal.api.history.v1.WorkflowExecutionTerminatedEventAttributesH\x00\x12\x88\x01\n4workflow_execution_cancel_requested_event_attributes\x18\x1c \x01(\x0b\x32H.temporal.api.history.v1.WorkflowExecutionCancelRequestedEventAttributesH\x00\x12y\n,workflow_execution_canceled_event_attributes\x18\x1d \x01(\x0b\x32\x41.temporal.api.history.v1.WorkflowExecutionCanceledEventAttributesH\x00\x12\xa8\x01\nErequest_cancel_external_workflow_execution_initiated_event_attributes\x18\x1e \x01(\x0b\x32W.temporal.api.history.v1.RequestCancelExternalWorkflowExecutionInitiatedEventAttributesH\x00\x12\xa2\x01\nBrequest_cancel_external_workflow_execution_failed_event_attributes\x18\x1f \x01(\x0b\x32T.temporal.api.history.v1.RequestCancelExternalWorkflowExecutionFailedEventAttributesH\x00\x12\x99\x01\n=external_workflow_execution_cancel_requested_event_attributes\x18  \x01(\x0b\x32P.temporal.api.history.v1.ExternalWorkflowExecutionCancelRequestedEventAttributesH\x00\x12\x87\x01\n4workflow_execution_continued_as_new_event_attributes\x18! \x01(\x0b\x32G.temporal.api.history.v1.WorkflowExecutionContinuedAsNewEventAttributesH\x00\x12\x91\x01\n9start_child_workflow_execution_initiated_event_attributes\x18" \x01(\x0b\x32L.temporal.api.history.v1.StartChildWorkflowExecutionInitiatedEventAttributesH\x00\x12\x8b\x01\n6start_child_workflow_execution_failed_event_attributes\x18# \x01(\x0b\x32I.temporal.api.history.v1.StartChildWorkflowExecutionFailedEventAttributesH\x00\x12\x82\x01\n1child_workflow_execution_started_event_attributes\x18$ \x01(\x0b\x32\x45.temporal.api.history.v1.ChildWorkflowExecutionStartedEventAttributesH\x00\x12\x86\x01\n3child_workflow_execution_completed_event_attributes\x18% \x01(\x0b\x32G.temporal.api.history.v1.ChildWorkflowExecutionCompletedEventAttributesH\x00\x12\x80\x01\n0child_workflow_execution_failed_event_attributes\x18& \x01(\x0b\x32\x44.temporal.api.history.v1.ChildWorkflowExecutionFailedEventAttributesH\x00\x12\x84\x01\n2child_workflow_execution_canceled_event_attributes\x18\' \x01(\x0b\x32\x46.temporal.api.history.v1.ChildWorkflowExecutionCanceledEventAttributesH\x00\x12\x85\x01\n3child_workflow_execution_timed_out_event_attributes\x18( \x01(\x0b\x32\x46.temporal.api.history.v1.ChildWorkflowExecutionTimedOutEventAttributesH\x00\x12\x88\x01\n4child_workflow_execution_terminated_event_attributes\x18) \x01(\x0b\x32H.temporal.api.history.v1.ChildWorkflowExecutionTerminatedEventAttributesH\x00\x12\x99\x01\n=signal_external_workflow_execution_initiated_event_attributes\x18* \x01(\x0b\x32P.temporal.api.history.v1.SignalExternalWorkflowExecutionInitiatedEventAttributesH\x00\x12\x93\x01\n:signal_external_workflow_execution_failed_event_attributes\x18+ \x01(\x0b\x32M.temporal.api.history.v1.SignalExternalWorkflowExecutionFailedEventAttributesH\x00\x12\x8a\x01\n5external_workflow_execution_signaled_event_attributes\x18, \x01(\x0b\x32I.temporal.api.history.v1.ExternalWorkflowExecutionSignaledEventAttributesH\x00\x12\x84\x01\n2upsert_workflow_search_attributes_event_attributes\x18- \x01(\x0b\x32\x46.temporal.api.history.v1.UpsertWorkflowSearchAttributesEventAttributesH\x00\x12\x86\x01\n3workflow_execution_update_accepted_event_attributes\x18. \x01(\x0b\x32G.temporal.api.history.v1.WorkflowExecutionUpdateAcceptedEventAttributesH\x00\x12\x86\x01\n3workflow_execution_update_rejected_event_attributes\x18/ \x01(\x0b\x32G.temporal.api.history.v1.WorkflowExecutionUpdateRejectedEventAttributesH\x00\x12\x88\x01\n4workflow_execution_update_completed_event_attributes\x18\x30 \x01(\x0b\x32H.temporal.api.history.v1.WorkflowExecutionUpdateCompletedEventAttributesH\x00\x12\x90\x01\n8workflow_properties_modified_externally_event_attributes\x18\x31 \x01(\x0b\x32L.temporal.api.history.v1.WorkflowPropertiesModifiedExternallyEventAttributesH\x00\x12\x90\x01\n8activity_properties_modified_externally_event_attributes\x18\x32 \x01(\x0b\x32L.temporal.api.history.v1.ActivityPropertiesModifiedExternallyEventAttributesH\x00\x12{\n-workflow_properties_modified_event_attributes\x18\x33 \x01(\x0b\x32\x42.temporal.api.history.v1.WorkflowPropertiesModifiedEventAttributesH\x00\x42\x0c\n\nattributes"@\n\x07History\x12\x35\n\x06\x65vents\x18\x01 \x03(\x0b\x32%.temporal.api.history.v1.HistoryEventB\x8e\x01\n\x1aio.temporal.api.history.v1B\x0cMessageProtoP\x01Z%go.temporal.io/api/history/v1;history\xaa\x02\x19Temporalio.Api.History.V1\xea\x02\x1cTemporalio::Api::History::V1b\x06proto3'
 )
 
 
 _WORKFLOWEXECUTIONSTARTEDEVENTATTRIBUTES = DESCRIPTOR.message_types_by_name[
     "WorkflowExecutionStartedEventAttributes"
 ]
 _WORKFLOWEXECUTIONCOMPLETEDEVENTATTRIBUTES = DESCRIPTOR.message_types_by_name[
@@ -865,111 +865,111 @@
     ]._options = None
     _WORKFLOWPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES.fields_by_name[
         "new_workflow_execution_timeout"
     ]._serialized_options = b"\230\337\037\001"
     _HISTORYEVENT.fields_by_name["event_time"]._options = None
     _HISTORYEVENT.fields_by_name["event_time"]._serialized_options = b"\220\337\037\001"
     _WORKFLOWEXECUTIONSTARTEDEVENTATTRIBUTES._serialized_start = 533
-    _WORKFLOWEXECUTIONSTARTEDEVENTATTRIBUTES._serialized_end = 1957
-    _WORKFLOWEXECUTIONCOMPLETEDEVENTATTRIBUTES._serialized_start = 1960
-    _WORKFLOWEXECUTIONCOMPLETEDEVENTATTRIBUTES._serialized_end = 2125
-    _WORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_start = 2128
-    _WORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_end = 2347
-    _WORKFLOWEXECUTIONTIMEDOUTEVENTATTRIBUTES._serialized_start = 2350
-    _WORKFLOWEXECUTIONTIMEDOUTEVENTATTRIBUTES._serialized_end = 2478
-    _WORKFLOWEXECUTIONCONTINUEDASNEWEVENTATTRIBUTES._serialized_start = 2481
-    _WORKFLOWEXECUTIONCONTINUEDASNEWEVENTATTRIBUTES._serialized_end = 3305
-    _WORKFLOWTASKSCHEDULEDEVENTATTRIBUTES._serialized_start = 3308
-    _WORKFLOWTASKSCHEDULEDEVENTATTRIBUTES._serialized_end = 3486
-    _WORKFLOWTASKSTARTEDEVENTATTRIBUTES._serialized_start = 3489
-    _WORKFLOWTASKSTARTEDEVENTATTRIBUTES._serialized_end = 3652
-    _WORKFLOWTASKCOMPLETEDEVENTATTRIBUTES._serialized_start = 3655
-    _WORKFLOWTASKCOMPLETEDEVENTATTRIBUTES._serialized_end = 4001
-    _WORKFLOWTASKTIMEDOUTEVENTATTRIBUTES._serialized_start = 4004
-    _WORKFLOWTASKTIMEDOUTEVENTATTRIBUTES._serialized_end = 4153
-    _WORKFLOWTASKFAILEDEVENTATTRIBUTES._serialized_start = 4156
-    _WORKFLOWTASKFAILEDEVENTATTRIBUTES._serialized_end = 4471
-    _ACTIVITYTASKSCHEDULEDEVENTATTRIBUTES._serialized_start = 4474
-    _ACTIVITYTASKSCHEDULEDEVENTATTRIBUTES._serialized_end = 5117
-    _ACTIVITYTASKSTARTEDEVENTATTRIBUTES._serialized_start = 5120
-    _ACTIVITYTASKSTARTEDEVENTATTRIBUTES._serialized_end = 5295
-    _ACTIVITYTASKCOMPLETEDEVENTATTRIBUTES._serialized_start = 5298
-    _ACTIVITYTASKCOMPLETEDEVENTATTRIBUTES._serialized_end = 5458
-    _ACTIVITYTASKFAILEDEVENTATTRIBUTES._serialized_start = 5461
-    _ACTIVITYTASKFAILEDEVENTATTRIBUTES._serialized_end = 5675
-    _ACTIVITYTASKTIMEDOUTEVENTATTRIBUTES._serialized_start = 5678
-    _ACTIVITYTASKTIMEDOUTEVENTATTRIBUTES._serialized_end = 5876
-    _ACTIVITYTASKCANCELREQUESTEDEVENTATTRIBUTES._serialized_start = 5878
-    _ACTIVITYTASKCANCELREQUESTEDEVENTATTRIBUTES._serialized_end = 5992
-    _ACTIVITYTASKCANCELEDEVENTATTRIBUTES._serialized_start = 5995
-    _ACTIVITYTASKCANCELEDEVENTATTRIBUTES._serialized_end = 6197
-    _TIMERSTARTEDEVENTATTRIBUTES._serialized_start = 6200
-    _TIMERSTARTEDEVENTATTRIBUTES._serialized_end = 6353
-    _TIMERFIREDEVENTATTRIBUTES._serialized_start = 6355
-    _TIMERFIREDEVENTATTRIBUTES._serialized_end = 6426
-    _TIMERCANCELEDEVENTATTRIBUTES._serialized_start = 6429
-    _TIMERCANCELEDEVENTATTRIBUTES._serialized_end = 6563
-    _WORKFLOWEXECUTIONCANCELREQUESTEDEVENTATTRIBUTES._serialized_start = 6566
-    _WORKFLOWEXECUTIONCANCELREQUESTEDEVENTATTRIBUTES._serialized_end = 6765
-    _WORKFLOWEXECUTIONCANCELEDEVENTATTRIBUTES._serialized_start = 6768
-    _WORKFLOWEXECUTIONCANCELEDEVENTATTRIBUTES._serialized_end = 6903
-    _MARKERRECORDEDEVENTATTRIBUTES._serialized_start = 6906
-    _MARKERRECORDEDEVENTATTRIBUTES._serialized_end = 7267
-    _MARKERRECORDEDEVENTATTRIBUTES_DETAILSENTRY._serialized_start = 7187
-    _MARKERRECORDEDEVENTATTRIBUTES_DETAILSENTRY._serialized_end = 7267
-    _WORKFLOWEXECUTIONSIGNALEDEVENTATTRIBUTES._serialized_start = 7270
-    _WORKFLOWEXECUTIONSIGNALEDEVENTATTRIBUTES._serialized_end = 7485
-    _WORKFLOWEXECUTIONTERMINATEDEVENTATTRIBUTES._serialized_start = 7488
-    _WORKFLOWEXECUTIONTERMINATEDEVENTATTRIBUTES._serialized_end = 7617
+    _WORKFLOWEXECUTIONSTARTEDEVENTATTRIBUTES._serialized_end = 2052
+    _WORKFLOWEXECUTIONCOMPLETEDEVENTATTRIBUTES._serialized_start = 2055
+    _WORKFLOWEXECUTIONCOMPLETEDEVENTATTRIBUTES._serialized_end = 2220
+    _WORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_start = 2223
+    _WORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_end = 2442
+    _WORKFLOWEXECUTIONTIMEDOUTEVENTATTRIBUTES._serialized_start = 2445
+    _WORKFLOWEXECUTIONTIMEDOUTEVENTATTRIBUTES._serialized_end = 2573
+    _WORKFLOWEXECUTIONCONTINUEDASNEWEVENTATTRIBUTES._serialized_start = 2576
+    _WORKFLOWEXECUTIONCONTINUEDASNEWEVENTATTRIBUTES._serialized_end = 3432
+    _WORKFLOWTASKSCHEDULEDEVENTATTRIBUTES._serialized_start = 3435
+    _WORKFLOWTASKSCHEDULEDEVENTATTRIBUTES._serialized_end = 3613
+    _WORKFLOWTASKSTARTEDEVENTATTRIBUTES._serialized_start = 3616
+    _WORKFLOWTASKSTARTEDEVENTATTRIBUTES._serialized_end = 3779
+    _WORKFLOWTASKCOMPLETEDEVENTATTRIBUTES._serialized_start = 3782
+    _WORKFLOWTASKCOMPLETEDEVENTATTRIBUTES._serialized_end = 4128
+    _WORKFLOWTASKTIMEDOUTEVENTATTRIBUTES._serialized_start = 4131
+    _WORKFLOWTASKTIMEDOUTEVENTATTRIBUTES._serialized_end = 4280
+    _WORKFLOWTASKFAILEDEVENTATTRIBUTES._serialized_start = 4283
+    _WORKFLOWTASKFAILEDEVENTATTRIBUTES._serialized_end = 4666
+    _ACTIVITYTASKSCHEDULEDEVENTATTRIBUTES._serialized_start = 4669
+    _ACTIVITYTASKSCHEDULEDEVENTATTRIBUTES._serialized_end = 5344
+    _ACTIVITYTASKSTARTEDEVENTATTRIBUTES._serialized_start = 5347
+    _ACTIVITYTASKSTARTEDEVENTATTRIBUTES._serialized_end = 5522
+    _ACTIVITYTASKCOMPLETEDEVENTATTRIBUTES._serialized_start = 5525
+    _ACTIVITYTASKCOMPLETEDEVENTATTRIBUTES._serialized_end = 5753
+    _ACTIVITYTASKFAILEDEVENTATTRIBUTES._serialized_start = 5756
+    _ACTIVITYTASKFAILEDEVENTATTRIBUTES._serialized_end = 6038
+    _ACTIVITYTASKTIMEDOUTEVENTATTRIBUTES._serialized_start = 6041
+    _ACTIVITYTASKTIMEDOUTEVENTATTRIBUTES._serialized_end = 6239
+    _ACTIVITYTASKCANCELREQUESTEDEVENTATTRIBUTES._serialized_start = 6241
+    _ACTIVITYTASKCANCELREQUESTEDEVENTATTRIBUTES._serialized_end = 6355
+    _ACTIVITYTASKCANCELEDEVENTATTRIBUTES._serialized_start = 6358
+    _ACTIVITYTASKCANCELEDEVENTATTRIBUTES._serialized_end = 6628
+    _TIMERSTARTEDEVENTATTRIBUTES._serialized_start = 6631
+    _TIMERSTARTEDEVENTATTRIBUTES._serialized_end = 6784
+    _TIMERFIREDEVENTATTRIBUTES._serialized_start = 6786
+    _TIMERFIREDEVENTATTRIBUTES._serialized_end = 6857
+    _TIMERCANCELEDEVENTATTRIBUTES._serialized_start = 6860
+    _TIMERCANCELEDEVENTATTRIBUTES._serialized_end = 6994
+    _WORKFLOWEXECUTIONCANCELREQUESTEDEVENTATTRIBUTES._serialized_start = 6997
+    _WORKFLOWEXECUTIONCANCELREQUESTEDEVENTATTRIBUTES._serialized_end = 7196
+    _WORKFLOWEXECUTIONCANCELEDEVENTATTRIBUTES._serialized_start = 7199
+    _WORKFLOWEXECUTIONCANCELEDEVENTATTRIBUTES._serialized_end = 7334
+    _MARKERRECORDEDEVENTATTRIBUTES._serialized_start = 7337
+    _MARKERRECORDEDEVENTATTRIBUTES._serialized_end = 7698
+    _MARKERRECORDEDEVENTATTRIBUTES_DETAILSENTRY._serialized_start = 7618
+    _MARKERRECORDEDEVENTATTRIBUTES_DETAILSENTRY._serialized_end = 7698
+    _WORKFLOWEXECUTIONSIGNALEDEVENTATTRIBUTES._serialized_start = 7701
+    _WORKFLOWEXECUTIONSIGNALEDEVENTATTRIBUTES._serialized_end = 7916
+    _WORKFLOWEXECUTIONTERMINATEDEVENTATTRIBUTES._serialized_start = 7919
+    _WORKFLOWEXECUTIONTERMINATEDEVENTATTRIBUTES._serialized_end = 8048
     _REQUESTCANCELEXTERNALWORKFLOWEXECUTIONINITIATEDEVENTATTRIBUTES._serialized_start = (
-        7620
+        8051
     )
     _REQUESTCANCELEXTERNALWORKFLOWEXECUTIONINITIATEDEVENTATTRIBUTES._serialized_end = (
-        7900
+        8331
     )
     _REQUESTCANCELEXTERNALWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_start = (
-        7903
+        8334
     )
-    _REQUESTCANCELEXTERNALWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_end = 8245
-    _EXTERNALWORKFLOWEXECUTIONCANCELREQUESTEDEVENTATTRIBUTES._serialized_start = 8248
-    _EXTERNALWORKFLOWEXECUTIONCANCELREQUESTEDEVENTATTRIBUTES._serialized_end = 8445
-    _SIGNALEXTERNALWORKFLOWEXECUTIONINITIATEDEVENTATTRIBUTES._serialized_start = 8448
-    _SIGNALEXTERNALWORKFLOWEXECUTIONINITIATEDEVENTATTRIBUTES._serialized_end = 8823
-    _SIGNALEXTERNALWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_start = 8826
-    _SIGNALEXTERNALWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_end = 9161
-    _EXTERNALWORKFLOWEXECUTIONSIGNALEDEVENTATTRIBUTES._serialized_start = 9164
-    _EXTERNALWORKFLOWEXECUTIONSIGNALEDEVENTATTRIBUTES._serialized_end = 9371
-    _UPSERTWORKFLOWSEARCHATTRIBUTESEVENTATTRIBUTES._serialized_start = 9374
-    _UPSERTWORKFLOWSEARCHATTRIBUTESEVENTATTRIBUTES._serialized_end = 9532
-    _WORKFLOWPROPERTIESMODIFIEDEVENTATTRIBUTES._serialized_start = 9535
-    _WORKFLOWPROPERTIESMODIFIEDEVENTATTRIBUTES._serialized_end = 9673
-    _STARTCHILDWORKFLOWEXECUTIONINITIATEDEVENTATTRIBUTES._serialized_start = 9676
-    _STARTCHILDWORKFLOWEXECUTIONINITIATEDEVENTATTRIBUTES._serialized_end = 10608
-    _STARTCHILDWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_start = 10611
-    _STARTCHILDWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_end = 10949
-    _CHILDWORKFLOWEXECUTIONSTARTEDEVENTATTRIBUTES._serialized_start = 10952
-    _CHILDWORKFLOWEXECUTIONSTARTEDEVENTATTRIBUTES._serialized_end = 11247
-    _CHILDWORKFLOWEXECUTIONCOMPLETEDEVENTATTRIBUTES._serialized_start = 11250
-    _CHILDWORKFLOWEXECUTIONCOMPLETEDEVENTATTRIBUTES._serialized_end = 11575
-    _CHILDWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_start = 11578
-    _CHILDWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_end = 11957
-    _CHILDWORKFLOWEXECUTIONCANCELEDEVENTATTRIBUTES._serialized_start = 11960
-    _CHILDWORKFLOWEXECUTIONCANCELEDEVENTATTRIBUTES._serialized_end = 12285
-    _CHILDWORKFLOWEXECUTIONTIMEDOUTEVENTATTRIBUTES._serialized_start = 12288
-    _CHILDWORKFLOWEXECUTIONTIMEDOUTEVENTATTRIBUTES._serialized_end = 12618
-    _CHILDWORKFLOWEXECUTIONTERMINATEDEVENTATTRIBUTES._serialized_start = 12621
-    _CHILDWORKFLOWEXECUTIONTERMINATEDEVENTATTRIBUTES._serialized_end = 12897
-    _WORKFLOWPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES._serialized_start = 12900
-    _WORKFLOWPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES._serialized_end = 13238
-    _ACTIVITYPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES._serialized_start = 13241
-    _ACTIVITYPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES._serialized_end = 13385
-    _WORKFLOWEXECUTIONUPDATEACCEPTEDEVENTATTRIBUTES._serialized_start = 13388
-    _WORKFLOWEXECUTIONUPDATEACCEPTEDEVENTATTRIBUTES._serialized_end = 13608
-    _WORKFLOWEXECUTIONUPDATECOMPLETEDEVENTATTRIBUTES._serialized_start = 13611
-    _WORKFLOWEXECUTIONUPDATECOMPLETEDEVENTATTRIBUTES._serialized_end = 13754
-    _WORKFLOWEXECUTIONUPDATEREJECTEDEVENTATTRIBUTES._serialized_start = 13757
-    _WORKFLOWEXECUTIONUPDATEREJECTEDEVENTATTRIBUTES._serialized_end = 14028
-    _HISTORYEVENT._serialized_start = 14031
-    _HISTORYEVENT._serialized_end = 20148
-    _HISTORY._serialized_start = 20150
-    _HISTORY._serialized_end = 20214
+    _REQUESTCANCELEXTERNALWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_end = 8676
+    _EXTERNALWORKFLOWEXECUTIONCANCELREQUESTEDEVENTATTRIBUTES._serialized_start = 8679
+    _EXTERNALWORKFLOWEXECUTIONCANCELREQUESTEDEVENTATTRIBUTES._serialized_end = 8876
+    _SIGNALEXTERNALWORKFLOWEXECUTIONINITIATEDEVENTATTRIBUTES._serialized_start = 8879
+    _SIGNALEXTERNALWORKFLOWEXECUTIONINITIATEDEVENTATTRIBUTES._serialized_end = 9254
+    _SIGNALEXTERNALWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_start = 9257
+    _SIGNALEXTERNALWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_end = 9592
+    _EXTERNALWORKFLOWEXECUTIONSIGNALEDEVENTATTRIBUTES._serialized_start = 9595
+    _EXTERNALWORKFLOWEXECUTIONSIGNALEDEVENTATTRIBUTES._serialized_end = 9802
+    _UPSERTWORKFLOWSEARCHATTRIBUTESEVENTATTRIBUTES._serialized_start = 9805
+    _UPSERTWORKFLOWSEARCHATTRIBUTESEVENTATTRIBUTES._serialized_end = 9963
+    _WORKFLOWPROPERTIESMODIFIEDEVENTATTRIBUTES._serialized_start = 9966
+    _WORKFLOWPROPERTIESMODIFIEDEVENTATTRIBUTES._serialized_end = 10104
+    _STARTCHILDWORKFLOWEXECUTIONINITIATEDEVENTATTRIBUTES._serialized_start = 10107
+    _STARTCHILDWORKFLOWEXECUTIONINITIATEDEVENTATTRIBUTES._serialized_end = 11071
+    _STARTCHILDWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_start = 11074
+    _STARTCHILDWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_end = 11412
+    _CHILDWORKFLOWEXECUTIONSTARTEDEVENTATTRIBUTES._serialized_start = 11415
+    _CHILDWORKFLOWEXECUTIONSTARTEDEVENTATTRIBUTES._serialized_end = 11710
+    _CHILDWORKFLOWEXECUTIONCOMPLETEDEVENTATTRIBUTES._serialized_start = 11713
+    _CHILDWORKFLOWEXECUTIONCOMPLETEDEVENTATTRIBUTES._serialized_end = 12038
+    _CHILDWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_start = 12041
+    _CHILDWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_end = 12420
+    _CHILDWORKFLOWEXECUTIONCANCELEDEVENTATTRIBUTES._serialized_start = 12423
+    _CHILDWORKFLOWEXECUTIONCANCELEDEVENTATTRIBUTES._serialized_end = 12748
+    _CHILDWORKFLOWEXECUTIONTIMEDOUTEVENTATTRIBUTES._serialized_start = 12751
+    _CHILDWORKFLOWEXECUTIONTIMEDOUTEVENTATTRIBUTES._serialized_end = 13081
+    _CHILDWORKFLOWEXECUTIONTERMINATEDEVENTATTRIBUTES._serialized_start = 13084
+    _CHILDWORKFLOWEXECUTIONTERMINATEDEVENTATTRIBUTES._serialized_end = 13360
+    _WORKFLOWPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES._serialized_start = 13363
+    _WORKFLOWPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES._serialized_end = 13701
+    _ACTIVITYPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES._serialized_start = 13704
+    _ACTIVITYPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES._serialized_end = 13848
+    _WORKFLOWEXECUTIONUPDATEACCEPTEDEVENTATTRIBUTES._serialized_start = 13851
+    _WORKFLOWEXECUTIONUPDATEACCEPTEDEVENTATTRIBUTES._serialized_end = 14071
+    _WORKFLOWEXECUTIONUPDATECOMPLETEDEVENTATTRIBUTES._serialized_start = 14074
+    _WORKFLOWEXECUTIONUPDATECOMPLETEDEVENTATTRIBUTES._serialized_end = 14244
+    _WORKFLOWEXECUTIONUPDATEREJECTEDEVENTATTRIBUTES._serialized_start = 14247
+    _WORKFLOWEXECUTIONUPDATEREJECTEDEVENTATTRIBUTES._serialized_end = 14518
+    _HISTORYEVENT._serialized_start = 14521
+    _HISTORYEVENT._serialized_end = 20638
+    _HISTORY._serialized_start = 20640
+    _HISTORY._serialized_end = 20704
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.2.0/temporalio/api/history/v1/message_pb2.pyi` & `temporalio-1.3.0/temporalio/api/history/v1/message_pb2.pyi`

 * *Files 0% similar despite different names*

```diff
@@ -76,14 +76,16 @@
     CRON_SCHEDULE_FIELD_NUMBER: builtins.int
     FIRST_WORKFLOW_TASK_BACKOFF_FIELD_NUMBER: builtins.int
     MEMO_FIELD_NUMBER: builtins.int
     SEARCH_ATTRIBUTES_FIELD_NUMBER: builtins.int
     PREV_AUTO_RESET_POINTS_FIELD_NUMBER: builtins.int
     HEADER_FIELD_NUMBER: builtins.int
     PARENT_INITIATED_EVENT_VERSION_FIELD_NUMBER: builtins.int
+    WORKFLOW_ID_FIELD_NUMBER: builtins.int
+    SOURCE_VERSION_STAMP_FIELD_NUMBER: builtins.int
     @property
     def workflow_type(self) -> temporalio.api.common.v1.message_pb2.WorkflowType: ...
     parent_workflow_namespace: builtins.str
     """If this workflow is a child, the namespace our parent lives in.
     SDKs and UI tools should use `parent_workflow_namespace` field but server must use `parent_workflow_namespace_id` only.
     """
     parent_workflow_namespace_id: builtins.str
@@ -162,14 +164,23 @@
     @property
     def header(self) -> temporalio.api.common.v1.message_pb2.Header: ...
     parent_initiated_event_version: builtins.int
     """Version of the child execution initiated event in parent workflow
     It should be used together with parent_initiated_event_id to identify
     a child initiated event for global namespace
     """
+    workflow_id: builtins.str
+    """This field is new in 1.21."""
+    @property
+    def source_version_stamp(
+        self,
+    ) -> temporalio.api.common.v1.message_pb2.WorkerVersionStamp:
+        """If this workflow intends to use anything other than the current overall default version for
+        the queue, then we include it here.
+        """
     def __init__(
         self,
         *,
         workflow_type: temporalio.api.common.v1.message_pb2.WorkflowType | None = ...,
         parent_workflow_namespace: builtins.str = ...,
         parent_workflow_namespace_id: builtins.str = ...,
         parent_workflow_execution: temporalio.api.common.v1.message_pb2.WorkflowExecution
@@ -197,14 +208,17 @@
         memo: temporalio.api.common.v1.message_pb2.Memo | None = ...,
         search_attributes: temporalio.api.common.v1.message_pb2.SearchAttributes
         | None = ...,
         prev_auto_reset_points: temporalio.api.workflow.v1.message_pb2.ResetPoints
         | None = ...,
         header: temporalio.api.common.v1.message_pb2.Header | None = ...,
         parent_initiated_event_version: builtins.int = ...,
+        workflow_id: builtins.str = ...,
+        source_version_stamp: temporalio.api.common.v1.message_pb2.WorkerVersionStamp
+        | None = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
             "continued_failure",
             b"continued_failure",
             "first_workflow_task_backoff",
@@ -221,14 +235,16 @@
             b"parent_workflow_execution",
             "prev_auto_reset_points",
             b"prev_auto_reset_points",
             "retry_policy",
             b"retry_policy",
             "search_attributes",
             b"search_attributes",
+            "source_version_stamp",
+            b"source_version_stamp",
             "task_queue",
             b"task_queue",
             "workflow_execution_expiration_time",
             b"workflow_execution_expiration_time",
             "workflow_execution_timeout",
             b"workflow_execution_timeout",
             "workflow_run_timeout",
@@ -280,20 +296,24 @@
             b"parent_workflow_namespace_id",
             "prev_auto_reset_points",
             b"prev_auto_reset_points",
             "retry_policy",
             b"retry_policy",
             "search_attributes",
             b"search_attributes",
+            "source_version_stamp",
+            b"source_version_stamp",
             "task_queue",
             b"task_queue",
             "workflow_execution_expiration_time",
             b"workflow_execution_expiration_time",
             "workflow_execution_timeout",
             b"workflow_execution_timeout",
+            "workflow_id",
+            b"workflow_id",
             "workflow_run_timeout",
             b"workflow_run_timeout",
             "workflow_task_timeout",
             b"workflow_task_timeout",
             "workflow_type",
             b"workflow_type",
         ],
@@ -425,14 +445,15 @@
     BACKOFF_START_INTERVAL_FIELD_NUMBER: builtins.int
     INITIATOR_FIELD_NUMBER: builtins.int
     FAILURE_FIELD_NUMBER: builtins.int
     LAST_COMPLETION_RESULT_FIELD_NUMBER: builtins.int
     HEADER_FIELD_NUMBER: builtins.int
     MEMO_FIELD_NUMBER: builtins.int
     SEARCH_ATTRIBUTES_FIELD_NUMBER: builtins.int
+    USE_COMPATIBLE_VERSION_FIELD_NUMBER: builtins.int
     new_execution_run_id: builtins.str
     """The run ID of the new workflow started by this continue-as-new"""
     @property
     def workflow_type(self) -> temporalio.api.common.v1.message_pb2.WorkflowType: ...
     @property
     def task_queue(self) -> temporalio.api.taskqueue.v1.message_pb2.TaskQueue: ...
     @property
@@ -463,14 +484,18 @@
     def header(self) -> temporalio.api.common.v1.message_pb2.Header: ...
     @property
     def memo(self) -> temporalio.api.common.v1.message_pb2.Memo: ...
     @property
     def search_attributes(
         self,
     ) -> temporalio.api.common.v1.message_pb2.SearchAttributes: ...
+    use_compatible_version: builtins.bool
+    """If this is set, the workflow executing this command wishes to continue as new using a version
+    compatible with the version that this workflow most recently ran on.
+    """
     def __init__(
         self,
         *,
         new_execution_run_id: builtins.str = ...,
         workflow_type: temporalio.api.common.v1.message_pb2.WorkflowType | None = ...,
         task_queue: temporalio.api.taskqueue.v1.message_pb2.TaskQueue | None = ...,
         input: temporalio.api.common.v1.message_pb2.Payloads | None = ...,
@@ -482,14 +507,15 @@
         failure: temporalio.api.failure.v1.message_pb2.Failure | None = ...,
         last_completion_result: temporalio.api.common.v1.message_pb2.Payloads
         | None = ...,
         header: temporalio.api.common.v1.message_pb2.Header | None = ...,
         memo: temporalio.api.common.v1.message_pb2.Memo | None = ...,
         search_attributes: temporalio.api.common.v1.message_pb2.SearchAttributes
         | None = ...,
+        use_compatible_version: builtins.bool = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
             "backoff_start_interval",
             b"backoff_start_interval",
             "failure",
@@ -533,14 +559,16 @@
             b"memo",
             "new_execution_run_id",
             b"new_execution_run_id",
             "search_attributes",
             b"search_attributes",
             "task_queue",
             b"task_queue",
+            "use_compatible_version",
+            b"use_compatible_version",
             "workflow_run_timeout",
             b"workflow_run_timeout",
             "workflow_task_completed_event_id",
             b"workflow_task_completed_event_id",
             "workflow_task_timeout",
             b"workflow_task_timeout",
             "workflow_type",
@@ -666,17 +694,17 @@
     """The id of the `WORKFLOW_TASK_STARTED` event this task corresponds to"""
     identity: builtins.str
     """Identity of the worker who completed this task"""
     binary_checksum: builtins.str
     """Binary ID of the worker who completed this task"""
     @property
     def worker_version(self) -> temporalio.api.common.v1.message_pb2.WorkerVersionStamp:
-        """Version info of the worker who processed this workflow task, or missing if worker is not
-        using versioning. If present, the `build_id` field within is also used as `binary_checksum`,
-        which may be omitted in that case (it may also be populated to preserve compatibility).
+        """Version info of the worker who processed this workflow task. If present, the `build_id` field
+        within is also used as `binary_checksum`, which may be omitted in that case (it may also be
+        populated to preserve compatibility).
         """
     @property
     def sdk_metadata(
         self,
     ) -> temporalio.api.sdk.v1.task_complete_metadata_pb2.WorkflowTaskCompletedMetadata:
         """Data the SDK wishes to record for itself, but server need not interpret, and does not
         directly impact workflow state.
@@ -773,14 +801,15 @@
     CAUSE_FIELD_NUMBER: builtins.int
     FAILURE_FIELD_NUMBER: builtins.int
     IDENTITY_FIELD_NUMBER: builtins.int
     BASE_RUN_ID_FIELD_NUMBER: builtins.int
     NEW_RUN_ID_FIELD_NUMBER: builtins.int
     FORK_EVENT_VERSION_FIELD_NUMBER: builtins.int
     BINARY_CHECKSUM_FIELD_NUMBER: builtins.int
+    WORKER_VERSION_FIELD_NUMBER: builtins.int
     scheduled_event_id: builtins.int
     """The id of the `WORKFLOW_TASK_SCHEDULED` event this task corresponds to"""
     started_event_id: builtins.int
     """The id of the `WORKFLOW_TASK_STARTED` event this task corresponds to"""
     cause: temporalio.api.enums.v1.failed_cause_pb2.WorkflowTaskFailedCause.ValueType
     @property
     def failure(self) -> temporalio.api.failure.v1.message_pb2.Failure:
@@ -790,30 +819,43 @@
     base_run_id: builtins.str
     """The original run id of the workflow. For reset workflow."""
     new_run_id: builtins.str
     """If the workflow is being reset, the new run id."""
     fork_event_version: builtins.int
     """TODO: ?"""
     binary_checksum: builtins.str
-    """If a worker explicitly failed this task, it's binary id"""
+    """DEPRECATED since 1.21 - use `worker_version` instead.
+    If a worker explicitly failed this task, its binary id
+    """
+    @property
+    def worker_version(self) -> temporalio.api.common.v1.message_pb2.WorkerVersionStamp:
+        """Version info of the worker who processed this workflow task. If present, the `build_id` field
+        within is also used as `binary_checksum`, which may be omitted in that case (it may also be
+        populated to preserve compatibility).
+        """
     def __init__(
         self,
         *,
         scheduled_event_id: builtins.int = ...,
         started_event_id: builtins.int = ...,
         cause: temporalio.api.enums.v1.failed_cause_pb2.WorkflowTaskFailedCause.ValueType = ...,
         failure: temporalio.api.failure.v1.message_pb2.Failure | None = ...,
         identity: builtins.str = ...,
         base_run_id: builtins.str = ...,
         new_run_id: builtins.str = ...,
         fork_event_version: builtins.int = ...,
         binary_checksum: builtins.str = ...,
+        worker_version: temporalio.api.common.v1.message_pb2.WorkerVersionStamp
+        | None = ...,
     ) -> None: ...
     def HasField(
-        self, field_name: typing_extensions.Literal["failure", b"failure"]
+        self,
+        field_name: typing_extensions.Literal[
+            "failure", b"failure", "worker_version", b"worker_version"
+        ],
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
             "base_run_id",
             b"base_run_id",
             "binary_checksum",
@@ -828,14 +870,16 @@
             b"identity",
             "new_run_id",
             b"new_run_id",
             "scheduled_event_id",
             b"scheduled_event_id",
             "started_event_id",
             b"started_event_id",
+            "worker_version",
+            b"worker_version",
         ],
     ) -> None: ...
 
 global___WorkflowTaskFailedEventAttributes = WorkflowTaskFailedEventAttributes
 
 class ActivityTaskScheduledEventAttributes(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -847,14 +891,15 @@
     INPUT_FIELD_NUMBER: builtins.int
     SCHEDULE_TO_CLOSE_TIMEOUT_FIELD_NUMBER: builtins.int
     SCHEDULE_TO_START_TIMEOUT_FIELD_NUMBER: builtins.int
     START_TO_CLOSE_TIMEOUT_FIELD_NUMBER: builtins.int
     HEARTBEAT_TIMEOUT_FIELD_NUMBER: builtins.int
     WORKFLOW_TASK_COMPLETED_EVENT_ID_FIELD_NUMBER: builtins.int
     RETRY_POLICY_FIELD_NUMBER: builtins.int
+    USE_COMPATIBLE_VERSION_FIELD_NUMBER: builtins.int
     activity_id: builtins.str
     """The worker/user assigned identifier for the activity"""
     @property
     def activity_type(self) -> temporalio.api.common.v1.message_pb2.ActivityType: ...
     @property
     def task_queue(self) -> temporalio.api.taskqueue.v1.message_pb2.TaskQueue: ...
     @property
@@ -895,28 +940,34 @@
     """The `WORKFLOW_TASK_COMPLETED` event which this command was reported with"""
     @property
     def retry_policy(self) -> temporalio.api.common.v1.message_pb2.RetryPolicy:
         """Activities are assigned a default retry policy controlled by the service's dynamic
         configuration. Retries will happen up to `schedule_to_close_timeout`. To disable retries set
         retry_policy.maximum_attempts to 1.
         """
+    use_compatible_version: builtins.bool
+    """If this is set, the workflow executing this command wishes to start the activity using
+    a version compatible with the version that this workflow most recently ran on, if such
+    behavior is possible.
+    """
     def __init__(
         self,
         *,
         activity_id: builtins.str = ...,
         activity_type: temporalio.api.common.v1.message_pb2.ActivityType | None = ...,
         task_queue: temporalio.api.taskqueue.v1.message_pb2.TaskQueue | None = ...,
         header: temporalio.api.common.v1.message_pb2.Header | None = ...,
         input: temporalio.api.common.v1.message_pb2.Payloads | None = ...,
         schedule_to_close_timeout: google.protobuf.duration_pb2.Duration | None = ...,
         schedule_to_start_timeout: google.protobuf.duration_pb2.Duration | None = ...,
         start_to_close_timeout: google.protobuf.duration_pb2.Duration | None = ...,
         heartbeat_timeout: google.protobuf.duration_pb2.Duration | None = ...,
         workflow_task_completed_event_id: builtins.int = ...,
         retry_policy: temporalio.api.common.v1.message_pb2.RetryPolicy | None = ...,
+        use_compatible_version: builtins.bool = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
             "activity_type",
             b"activity_type",
             "header",
@@ -956,14 +1007,16 @@
             b"schedule_to_close_timeout",
             "schedule_to_start_timeout",
             b"schedule_to_start_timeout",
             "start_to_close_timeout",
             b"start_to_close_timeout",
             "task_queue",
             b"task_queue",
+            "use_compatible_version",
+            b"use_compatible_version",
             "workflow_task_completed_event_id",
             b"workflow_task_completed_event_id",
         ],
     ) -> None: ...
 
 global___ActivityTaskScheduledEventAttributes = ActivityTaskScheduledEventAttributes
 
@@ -1021,93 +1074,115 @@
 class ActivityTaskCompletedEventAttributes(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     RESULT_FIELD_NUMBER: builtins.int
     SCHEDULED_EVENT_ID_FIELD_NUMBER: builtins.int
     STARTED_EVENT_ID_FIELD_NUMBER: builtins.int
     IDENTITY_FIELD_NUMBER: builtins.int
+    WORKER_VERSION_FIELD_NUMBER: builtins.int
     @property
     def result(self) -> temporalio.api.common.v1.message_pb2.Payloads:
         """Serialized results of the activity. IE: The return value of the activity function"""
     scheduled_event_id: builtins.int
     """The id of the `ACTIVITY_TASK_SCHEDULED` event this completion corresponds to"""
     started_event_id: builtins.int
     """The id of the `ACTIVITY_TASK_STARTED` event this completion corresponds to"""
     identity: builtins.str
     """id of the worker that completed this task"""
+    @property
+    def worker_version(self) -> temporalio.api.common.v1.message_pb2.WorkerVersionStamp:
+        """Version info of the worker who processed this workflow task."""
     def __init__(
         self,
         *,
         result: temporalio.api.common.v1.message_pb2.Payloads | None = ...,
         scheduled_event_id: builtins.int = ...,
         started_event_id: builtins.int = ...,
         identity: builtins.str = ...,
+        worker_version: temporalio.api.common.v1.message_pb2.WorkerVersionStamp
+        | None = ...,
     ) -> None: ...
     def HasField(
-        self, field_name: typing_extensions.Literal["result", b"result"]
+        self,
+        field_name: typing_extensions.Literal[
+            "result", b"result", "worker_version", b"worker_version"
+        ],
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
             "identity",
             b"identity",
             "result",
             b"result",
             "scheduled_event_id",
             b"scheduled_event_id",
             "started_event_id",
             b"started_event_id",
+            "worker_version",
+            b"worker_version",
         ],
     ) -> None: ...
 
 global___ActivityTaskCompletedEventAttributes = ActivityTaskCompletedEventAttributes
 
 class ActivityTaskFailedEventAttributes(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     FAILURE_FIELD_NUMBER: builtins.int
     SCHEDULED_EVENT_ID_FIELD_NUMBER: builtins.int
     STARTED_EVENT_ID_FIELD_NUMBER: builtins.int
     IDENTITY_FIELD_NUMBER: builtins.int
     RETRY_STATE_FIELD_NUMBER: builtins.int
+    WORKER_VERSION_FIELD_NUMBER: builtins.int
     @property
     def failure(self) -> temporalio.api.failure.v1.message_pb2.Failure:
         """Failure details"""
     scheduled_event_id: builtins.int
     """The id of the `ACTIVITY_TASK_SCHEDULED` event this failure corresponds to"""
     started_event_id: builtins.int
     """The id of the `ACTIVITY_TASK_STARTED` event this failure corresponds to"""
     identity: builtins.str
     """id of the worker that failed this task"""
     retry_state: temporalio.api.enums.v1.workflow_pb2.RetryState.ValueType
+    @property
+    def worker_version(self) -> temporalio.api.common.v1.message_pb2.WorkerVersionStamp:
+        """Version info of the worker who processed this workflow task."""
     def __init__(
         self,
         *,
         failure: temporalio.api.failure.v1.message_pb2.Failure | None = ...,
         scheduled_event_id: builtins.int = ...,
         started_event_id: builtins.int = ...,
         identity: builtins.str = ...,
         retry_state: temporalio.api.enums.v1.workflow_pb2.RetryState.ValueType = ...,
+        worker_version: temporalio.api.common.v1.message_pb2.WorkerVersionStamp
+        | None = ...,
     ) -> None: ...
     def HasField(
-        self, field_name: typing_extensions.Literal["failure", b"failure"]
+        self,
+        field_name: typing_extensions.Literal[
+            "failure", b"failure", "worker_version", b"worker_version"
+        ],
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
             "failure",
             b"failure",
             "identity",
             b"identity",
             "retry_state",
             b"retry_state",
             "scheduled_event_id",
             b"scheduled_event_id",
             "started_event_id",
             b"started_event_id",
+            "worker_version",
+            b"worker_version",
         ],
     ) -> None: ...
 
 global___ActivityTaskFailedEventAttributes = ActivityTaskFailedEventAttributes
 
 class ActivityTaskTimedOutEventAttributes(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -1186,52 +1261,63 @@
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     DETAILS_FIELD_NUMBER: builtins.int
     LATEST_CANCEL_REQUESTED_EVENT_ID_FIELD_NUMBER: builtins.int
     SCHEDULED_EVENT_ID_FIELD_NUMBER: builtins.int
     STARTED_EVENT_ID_FIELD_NUMBER: builtins.int
     IDENTITY_FIELD_NUMBER: builtins.int
+    WORKER_VERSION_FIELD_NUMBER: builtins.int
     @property
     def details(self) -> temporalio.api.common.v1.message_pb2.Payloads:
         """Additional information that the activity reported upon confirming cancellation"""
     latest_cancel_requested_event_id: builtins.int
     """id of the most recent `ACTIVITY_TASK_CANCEL_REQUESTED` event which refers to the same
     activity
     """
     scheduled_event_id: builtins.int
     """The id of the `ACTIVITY_TASK_SCHEDULED` event this cancel confirmation corresponds to"""
     started_event_id: builtins.int
     """The id of the `ACTIVITY_TASK_STARTED` event this cancel confirmation corresponds to"""
     identity: builtins.str
     """id of the worker who canceled this activity"""
+    @property
+    def worker_version(self) -> temporalio.api.common.v1.message_pb2.WorkerVersionStamp:
+        """Version info of the worker who processed this workflow task."""
     def __init__(
         self,
         *,
         details: temporalio.api.common.v1.message_pb2.Payloads | None = ...,
         latest_cancel_requested_event_id: builtins.int = ...,
         scheduled_event_id: builtins.int = ...,
         started_event_id: builtins.int = ...,
         identity: builtins.str = ...,
+        worker_version: temporalio.api.common.v1.message_pb2.WorkerVersionStamp
+        | None = ...,
     ) -> None: ...
     def HasField(
-        self, field_name: typing_extensions.Literal["details", b"details"]
+        self,
+        field_name: typing_extensions.Literal[
+            "details", b"details", "worker_version", b"worker_version"
+        ],
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
             "details",
             b"details",
             "identity",
             b"identity",
             "latest_cancel_requested_event_id",
             b"latest_cancel_requested_event_id",
             "scheduled_event_id",
             b"scheduled_event_id",
             "started_event_id",
             b"started_event_id",
+            "worker_version",
+            b"worker_version",
         ],
     ) -> None: ...
 
 global___ActivityTaskCanceledEventAttributes = ActivityTaskCanceledEventAttributes
 
 class TimerStartedEventAttributes(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -2104,14 +2190,15 @@
     WORKFLOW_TASK_COMPLETED_EVENT_ID_FIELD_NUMBER: builtins.int
     WORKFLOW_ID_REUSE_POLICY_FIELD_NUMBER: builtins.int
     RETRY_POLICY_FIELD_NUMBER: builtins.int
     CRON_SCHEDULE_FIELD_NUMBER: builtins.int
     HEADER_FIELD_NUMBER: builtins.int
     MEMO_FIELD_NUMBER: builtins.int
     SEARCH_ATTRIBUTES_FIELD_NUMBER: builtins.int
+    USE_COMPATIBLE_VERSION_FIELD_NUMBER: builtins.int
     namespace: builtins.str
     """Namespace of the child workflow.
     SDKs and UI tools should use `namespace` field but server must use `namespace_id` only.
     """
     namespace_id: builtins.str
     workflow_id: builtins.str
     @property
@@ -2145,14 +2232,19 @@
     def header(self) -> temporalio.api.common.v1.message_pb2.Header: ...
     @property
     def memo(self) -> temporalio.api.common.v1.message_pb2.Memo: ...
     @property
     def search_attributes(
         self,
     ) -> temporalio.api.common.v1.message_pb2.SearchAttributes: ...
+    use_compatible_version: builtins.bool
+    """If this is set, the workflow executing this command wishes to start the child workflow using
+    a version compatible with the version that this workflow most recently ran on, if such
+    behavior is possible.
+    """
     def __init__(
         self,
         *,
         namespace: builtins.str = ...,
         namespace_id: builtins.str = ...,
         workflow_id: builtins.str = ...,
         workflow_type: temporalio.api.common.v1.message_pb2.WorkflowType | None = ...,
@@ -2167,14 +2259,15 @@
         workflow_id_reuse_policy: temporalio.api.enums.v1.workflow_pb2.WorkflowIdReusePolicy.ValueType = ...,
         retry_policy: temporalio.api.common.v1.message_pb2.RetryPolicy | None = ...,
         cron_schedule: builtins.str = ...,
         header: temporalio.api.common.v1.message_pb2.Header | None = ...,
         memo: temporalio.api.common.v1.message_pb2.Memo | None = ...,
         search_attributes: temporalio.api.common.v1.message_pb2.SearchAttributes
         | None = ...,
+        use_compatible_version: builtins.bool = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
             "header",
             b"header",
             "input",
@@ -2218,14 +2311,16 @@
             b"parent_close_policy",
             "retry_policy",
             b"retry_policy",
             "search_attributes",
             b"search_attributes",
             "task_queue",
             b"task_queue",
+            "use_compatible_version",
+            b"use_compatible_version",
             "workflow_execution_timeout",
             b"workflow_execution_timeout",
             "workflow_id",
             b"workflow_id",
             "workflow_id_reuse_policy",
             b"workflow_id_reuse_policy",
             "workflow_run_timeout",
@@ -2903,34 +2998,45 @@
     WorkflowExecutionUpdateAcceptedEventAttributes
 )
 
 class WorkflowExecutionUpdateCompletedEventAttributes(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     META_FIELD_NUMBER: builtins.int
+    ACCEPTED_EVENT_ID_FIELD_NUMBER: builtins.int
     OUTCOME_FIELD_NUMBER: builtins.int
     @property
     def meta(self) -> temporalio.api.update.v1.message_pb2.Meta:
         """The metadata about this update."""
+    accepted_event_id: builtins.int
+    """The event ID indicating the acceptance of this update."""
     @property
     def outcome(self) -> temporalio.api.update.v1.message_pb2.Outcome:
         """The outcome of executing the workflow update function."""
     def __init__(
         self,
         *,
         meta: temporalio.api.update.v1.message_pb2.Meta | None = ...,
+        accepted_event_id: builtins.int = ...,
         outcome: temporalio.api.update.v1.message_pb2.Outcome | None = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal["meta", b"meta", "outcome", b"outcome"],
     ) -> builtins.bool: ...
     def ClearField(
         self,
-        field_name: typing_extensions.Literal["meta", b"meta", "outcome", b"outcome"],
+        field_name: typing_extensions.Literal[
+            "accepted_event_id",
+            b"accepted_event_id",
+            "meta",
+            b"meta",
+            "outcome",
+            b"outcome",
+        ],
     ) -> None: ...
 
 global___WorkflowExecutionUpdateCompletedEventAttributes = (
     WorkflowExecutionUpdateCompletedEventAttributes
 )
 
 class WorkflowExecutionUpdateRejectedEventAttributes(google.protobuf.message.Message):
```

### Comparing `temporalio-1.2.0/temporalio/api/interaction/v1/message_pb2.py` & `temporalio-1.3.0/temporalio/api/interaction/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/interaction/v1/message_pb2.pyi` & `temporalio-1.3.0/temporalio/api/interaction/v1/message_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/namespace/v1/message_pb2.py` & `temporalio-1.3.0/temporalio/api/namespace/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/namespace/v1/message_pb2.pyi` & `temporalio-1.3.0/temporalio/api/namespace/v1/message_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/operatorservice/v1/__init__.py` & `temporalio-1.3.0/temporalio/api/operatorservice/v1/__init__.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/operatorservice/v1/request_response_pb2.py` & `temporalio-1.3.0/temporalio/api/operatorservice/v1/request_response_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/operatorservice/v1/request_response_pb2.pyi` & `temporalio-1.3.0/temporalio/api/operatorservice/v1/request_response_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/operatorservice/v1/request_response_pb2_grpc.pyi` & `temporalio-1.3.0/temporalio/api/operatorservice/v1/request_response_pb2_grpc.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/operatorservice/v1/service_pb2.py` & `temporalio-1.3.0/temporalio/api/operatorservice/v1/service_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/operatorservice/v1/service_pb2.pyi` & `temporalio-1.3.0/temporalio/api/operatorservice/v1/service_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/operatorservice/v1/service_pb2_grpc.py` & `temporalio-1.3.0/temporalio/api/operatorservice/v1/service_pb2_grpc.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/operatorservice/v1/service_pb2_grpc.pyi` & `temporalio-1.3.0/temporalio/api/operatorservice/v1/service_pb2_grpc.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/protocol/v1/message_pb2.py` & `temporalio-1.3.0/temporalio/api/protocol/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/protocol/v1/message_pb2.pyi` & `temporalio-1.3.0/temporalio/api/protocol/v1/message_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/query/v1/message_pb2.py` & `temporalio-1.3.0/temporalio/api/query/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/query/v1/message_pb2.pyi` & `temporalio-1.3.0/temporalio/api/query/v1/message_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/replication/v1/message_pb2.py` & `temporalio-1.3.0/temporalio/api/replication/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/replication/v1/message_pb2.pyi` & `temporalio-1.3.0/temporalio/api/replication/v1/message_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/schedule/v1/__init__.py` & `temporalio-1.3.0/temporalio/api/schedule/v1/__init__.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/schedule/v1/message_pb2.py` & `temporalio-1.3.0/temporalio/api/schedule/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/schedule/v1/message_pb2.pyi` & `temporalio-1.3.0/temporalio/api/schedule/v1/message_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/sdk/v1/task_complete_metadata_pb2.py` & `temporalio-1.3.0/temporalio/api/sdk/v1/task_complete_metadata_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/sdk/v1/task_complete_metadata_pb2.pyi` & `temporalio-1.3.0/temporalio/api/sdk/v1/task_complete_metadata_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/taskqueue/v1/message_pb2.py` & `temporalio-1.3.0/temporalio/api/taskqueue/v1/message_pb2.py`

 * *Files 15% similar despite different names*

```diff
@@ -24,15 +24,15 @@
     gogo_pb2 as dependencies_dot_gogoproto_dot_gogo__pb2,
 )
 from temporalio.api.enums.v1 import (
     task_queue_pb2 as temporal_dot_api_dot_enums_dot_v1_dot_task__queue__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n\'temporal/api/taskqueue/v1/message.proto\x12\x19temporal.api.taskqueue.v1\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a\x1egoogle/protobuf/wrappers.proto\x1a!dependencies/gogoproto/gogo.proto\x1a&temporal/api/enums/v1/task_queue.proto\x1a$temporal/api/common/v1/message.proto"M\n\tTaskQueue\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x32\n\x04kind\x18\x02 \x01(\x0e\x32$.temporal.api.enums.v1.TaskQueueKind"O\n\x11TaskQueueMetadata\x12:\n\x14max_tasks_per_second\x18\x01 \x01(\x0b\x32\x1c.google.protobuf.DoubleValue"\xac\x01\n\x0fTaskQueueStatus\x12\x1a\n\x12\x62\x61\x63klog_count_hint\x18\x01 \x01(\x03\x12\x12\n\nread_level\x18\x02 \x01(\x03\x12\x11\n\tack_level\x18\x03 \x01(\x03\x12\x17\n\x0frate_per_second\x18\x04 \x01(\x01\x12=\n\rtask_id_block\x18\x05 \x01(\x0b\x32&.temporal.api.taskqueue.v1.TaskIdBlock"/\n\x0bTaskIdBlock\x12\x10\n\x08start_id\x18\x01 \x01(\x03\x12\x0e\n\x06\x65nd_id\x18\x02 \x01(\x03"B\n\x1aTaskQueuePartitionMetadata\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x17\n\x0fowner_host_name\x18\x02 \x01(\t"\xcb\x01\n\nPollerInfo\x12:\n\x10last_access_time\x18\x01 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x10\n\x08identity\x18\x02 \x01(\t\x12\x17\n\x0frate_per_second\x18\x03 \x01(\x01\x12V\n\x1bworker_version_capabilities\x18\x04 \x01(\x0b\x32\x31.temporal.api.common.v1.WorkerVersionCapabilities"\xa0\x01\n\x19StickyExecutionAttributes\x12?\n\x11worker_task_queue\x18\x01 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12\x42\n\x19schedule_to_start_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01"A\n\x14\x43ompatibleVersionSet\x12\x16\n\x0eversion_set_id\x18\x01 \x01(\t\x12\x11\n\tbuild_ids\x18\x02 \x03(\tB\x98\x01\n\x1cio.temporal.api.taskqueue.v1B\x0cMessageProtoP\x01Z)go.temporal.io/api/taskqueue/v1;taskqueue\xaa\x02\x1bTemporalio.Api.TaskQueue.V1\xea\x02\x1eTemporalio::Api::TaskQueue::V1b\x06proto3'
+    b'\n\'temporal/api/taskqueue/v1/message.proto\x12\x19temporal.api.taskqueue.v1\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a\x1egoogle/protobuf/wrappers.proto\x1a!dependencies/gogoproto/gogo.proto\x1a&temporal/api/enums/v1/task_queue.proto\x1a$temporal/api/common/v1/message.proto"b\n\tTaskQueue\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x32\n\x04kind\x18\x02 \x01(\x0e\x32$.temporal.api.enums.v1.TaskQueueKind\x12\x13\n\x0bnormal_name\x18\x03 \x01(\t"O\n\x11TaskQueueMetadata\x12:\n\x14max_tasks_per_second\x18\x01 \x01(\x0b\x32\x1c.google.protobuf.DoubleValue"\xac\x01\n\x0fTaskQueueStatus\x12\x1a\n\x12\x62\x61\x63klog_count_hint\x18\x01 \x01(\x03\x12\x12\n\nread_level\x18\x02 \x01(\x03\x12\x11\n\tack_level\x18\x03 \x01(\x03\x12\x17\n\x0frate_per_second\x18\x04 \x01(\x01\x12=\n\rtask_id_block\x18\x05 \x01(\x0b\x32&.temporal.api.taskqueue.v1.TaskIdBlock"/\n\x0bTaskIdBlock\x12\x10\n\x08start_id\x18\x01 \x01(\x03\x12\x0e\n\x06\x65nd_id\x18\x02 \x01(\x03"B\n\x1aTaskQueuePartitionMetadata\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x17\n\x0fowner_host_name\x18\x02 \x01(\t"\xcb\x01\n\nPollerInfo\x12:\n\x10last_access_time\x18\x01 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x10\n\x08identity\x18\x02 \x01(\t\x12\x17\n\x0frate_per_second\x18\x03 \x01(\x01\x12V\n\x1bworker_version_capabilities\x18\x04 \x01(\x0b\x32\x31.temporal.api.common.v1.WorkerVersionCapabilities"\xa0\x01\n\x19StickyExecutionAttributes\x12?\n\x11worker_task_queue\x18\x01 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12\x42\n\x19schedule_to_start_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01")\n\x14\x43ompatibleVersionSet\x12\x11\n\tbuild_ids\x18\x01 \x03(\t"j\n\x15TaskQueueReachability\x12\x12\n\ntask_queue\x18\x01 \x01(\t\x12=\n\x0creachability\x18\x02 \x03(\x0e\x32\'.temporal.api.enums.v1.TaskReachability"z\n\x13\x42uildIdReachability\x12\x10\n\x08\x62uild_id\x18\x01 \x01(\t\x12Q\n\x17task_queue_reachability\x18\x02 \x03(\x0b\x32\x30.temporal.api.taskqueue.v1.TaskQueueReachabilityB\x98\x01\n\x1cio.temporal.api.taskqueue.v1B\x0cMessageProtoP\x01Z)go.temporal.io/api/taskqueue/v1;taskqueue\xaa\x02\x1bTemporalio.Api.TaskQueue.V1\xea\x02\x1eTemporalio::Api::TaskQueue::V1b\x06proto3'
 )
 
 
 _TASKQUEUE = DESCRIPTOR.message_types_by_name["TaskQueue"]
 _TASKQUEUEMETADATA = DESCRIPTOR.message_types_by_name["TaskQueueMetadata"]
 _TASKQUEUESTATUS = DESCRIPTOR.message_types_by_name["TaskQueueStatus"]
 _TASKIDBLOCK = DESCRIPTOR.message_types_by_name["TaskIdBlock"]
@@ -40,14 +40,16 @@
     "TaskQueuePartitionMetadata"
 ]
 _POLLERINFO = DESCRIPTOR.message_types_by_name["PollerInfo"]
 _STICKYEXECUTIONATTRIBUTES = DESCRIPTOR.message_types_by_name[
     "StickyExecutionAttributes"
 ]
 _COMPATIBLEVERSIONSET = DESCRIPTOR.message_types_by_name["CompatibleVersionSet"]
+_TASKQUEUEREACHABILITY = DESCRIPTOR.message_types_by_name["TaskQueueReachability"]
+_BUILDIDREACHABILITY = DESCRIPTOR.message_types_by_name["BuildIdReachability"]
 TaskQueue = _reflection.GeneratedProtocolMessageType(
     "TaskQueue",
     (_message.Message,),
     {
         "DESCRIPTOR": _TASKQUEUE,
         "__module__": "temporal.api.taskqueue.v1.message_pb2"
         # @@protoc_insertion_point(class_scope:temporal.api.taskqueue.v1.TaskQueue)
@@ -128,37 +130,63 @@
         "DESCRIPTOR": _COMPATIBLEVERSIONSET,
         "__module__": "temporal.api.taskqueue.v1.message_pb2"
         # @@protoc_insertion_point(class_scope:temporal.api.taskqueue.v1.CompatibleVersionSet)
     },
 )
 _sym_db.RegisterMessage(CompatibleVersionSet)
 
+TaskQueueReachability = _reflection.GeneratedProtocolMessageType(
+    "TaskQueueReachability",
+    (_message.Message,),
+    {
+        "DESCRIPTOR": _TASKQUEUEREACHABILITY,
+        "__module__": "temporal.api.taskqueue.v1.message_pb2"
+        # @@protoc_insertion_point(class_scope:temporal.api.taskqueue.v1.TaskQueueReachability)
+    },
+)
+_sym_db.RegisterMessage(TaskQueueReachability)
+
+BuildIdReachability = _reflection.GeneratedProtocolMessageType(
+    "BuildIdReachability",
+    (_message.Message,),
+    {
+        "DESCRIPTOR": _BUILDIDREACHABILITY,
+        "__module__": "temporal.api.taskqueue.v1.message_pb2"
+        # @@protoc_insertion_point(class_scope:temporal.api.taskqueue.v1.BuildIdReachability)
+    },
+)
+_sym_db.RegisterMessage(BuildIdReachability)
+
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
     DESCRIPTOR._serialized_options = b"\n\034io.temporal.api.taskqueue.v1B\014MessageProtoP\001Z)go.temporal.io/api/taskqueue/v1;taskqueue\252\002\033Temporalio.Api.TaskQueue.V1\352\002\036Temporalio::Api::TaskQueue::V1"
     _POLLERINFO.fields_by_name["last_access_time"]._options = None
     _POLLERINFO.fields_by_name[
         "last_access_time"
     ]._serialized_options = b"\220\337\037\001"
     _STICKYEXECUTIONATTRIBUTES.fields_by_name[
         "schedule_to_start_timeout"
     ]._options = None
     _STICKYEXECUTIONATTRIBUTES.fields_by_name[
         "schedule_to_start_timeout"
     ]._serialized_options = b"\230\337\037\001"
     _TASKQUEUE._serialized_start = 280
-    _TASKQUEUE._serialized_end = 357
-    _TASKQUEUEMETADATA._serialized_start = 359
-    _TASKQUEUEMETADATA._serialized_end = 438
-    _TASKQUEUESTATUS._serialized_start = 441
-    _TASKQUEUESTATUS._serialized_end = 613
-    _TASKIDBLOCK._serialized_start = 615
-    _TASKIDBLOCK._serialized_end = 662
-    _TASKQUEUEPARTITIONMETADATA._serialized_start = 664
-    _TASKQUEUEPARTITIONMETADATA._serialized_end = 730
-    _POLLERINFO._serialized_start = 733
-    _POLLERINFO._serialized_end = 936
-    _STICKYEXECUTIONATTRIBUTES._serialized_start = 939
-    _STICKYEXECUTIONATTRIBUTES._serialized_end = 1099
-    _COMPATIBLEVERSIONSET._serialized_start = 1101
-    _COMPATIBLEVERSIONSET._serialized_end = 1166
+    _TASKQUEUE._serialized_end = 378
+    _TASKQUEUEMETADATA._serialized_start = 380
+    _TASKQUEUEMETADATA._serialized_end = 459
+    _TASKQUEUESTATUS._serialized_start = 462
+    _TASKQUEUESTATUS._serialized_end = 634
+    _TASKIDBLOCK._serialized_start = 636
+    _TASKIDBLOCK._serialized_end = 683
+    _TASKQUEUEPARTITIONMETADATA._serialized_start = 685
+    _TASKQUEUEPARTITIONMETADATA._serialized_end = 751
+    _POLLERINFO._serialized_start = 754
+    _POLLERINFO._serialized_end = 957
+    _STICKYEXECUTIONATTRIBUTES._serialized_start = 960
+    _STICKYEXECUTIONATTRIBUTES._serialized_end = 1120
+    _COMPATIBLEVERSIONSET._serialized_start = 1122
+    _COMPATIBLEVERSIONSET._serialized_end = 1163
+    _TASKQUEUEREACHABILITY._serialized_start = 1165
+    _TASKQUEUEREACHABILITY._serialized_end = 1271
+    _BUILDIDREACHABILITY._serialized_start = 1273
+    _BUILDIDREACHABILITY._serialized_end = 1395
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.2.0/temporalio/api/taskqueue/v1/message_pb2.pyi` & `temporalio-1.3.0/temporalio/api/taskqueue/v1/message_pb2.pyi`

 * *Files 22% similar despite different names*

```diff
@@ -45,25 +45,34 @@
 class TaskQueue(google.protobuf.message.Message):
     """See https://docs.temporal.io/docs/concepts/task-queues/"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAME_FIELD_NUMBER: builtins.int
     KIND_FIELD_NUMBER: builtins.int
+    NORMAL_NAME_FIELD_NUMBER: builtins.int
     name: builtins.str
     kind: temporalio.api.enums.v1.task_queue_pb2.TaskQueueKind.ValueType
     """Default: TASK_QUEUE_KIND_NORMAL."""
+    normal_name: builtins.str
+    """Iff kind == TASK_QUEUE_KIND_STICKY, then this field contains the name of
+    the normal task queue that the sticky worker is running on.
+    """
     def __init__(
         self,
         *,
         name: builtins.str = ...,
         kind: temporalio.api.enums.v1.task_queue_pb2.TaskQueueKind.ValueType = ...,
+        normal_name: builtins.str = ...,
     ) -> None: ...
     def ClearField(
-        self, field_name: typing_extensions.Literal["kind", b"kind", "name", b"name"]
+        self,
+        field_name: typing_extensions.Literal[
+            "kind", b"kind", "name", b"name", "normal_name", b"normal_name"
+        ],
     ) -> None: ...
 
 global___TaskQueue = TaskQueue
 
 class TaskQueueMetadata(google.protobuf.message.Message):
     """Only applies to activity task queues"""
 
@@ -269,38 +278,102 @@
             b"worker_task_queue",
         ],
     ) -> None: ...
 
 global___StickyExecutionAttributes = StickyExecutionAttributes
 
 class CompatibleVersionSet(google.protobuf.message.Message):
-    """Used by the worker versioning APIs, represents an ordering of one or more versions which are
-    considered to be compatible with each other. Currently the versions are always worker build ids.
+    """Used by the worker versioning APIs, represents an unordered set of one or more versions which are
+    considered to be compatible with each other. Currently the versions are always worker build IDs.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    VERSION_SET_ID_FIELD_NUMBER: builtins.int
     BUILD_IDS_FIELD_NUMBER: builtins.int
-    version_set_id: builtins.str
-    """A unique identifier for this version set. Users don't need to understand or care about this
-    value, but it has value for debugging purposes.
-    """
     @property
     def build_ids(
         self,
     ) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
-        """All the compatible versions, ordered from oldest to newest"""
+        """All the compatible versions, unordered, except for the last element, which is considered the set "default"."""
     def __init__(
         self,
         *,
-        version_set_id: builtins.str = ...,
         build_ids: collections.abc.Iterable[builtins.str] | None = ...,
     ) -> None: ...
     def ClearField(
+        self, field_name: typing_extensions.Literal["build_ids", b"build_ids"]
+    ) -> None: ...
+
+global___CompatibleVersionSet = CompatibleVersionSet
+
+class TaskQueueReachability(google.protobuf.message.Message):
+    """Reachability of tasks for a worker on a single task queue."""
+
+    DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+    TASK_QUEUE_FIELD_NUMBER: builtins.int
+    REACHABILITY_FIELD_NUMBER: builtins.int
+    task_queue: builtins.str
+    @property
+    def reachability(
+        self,
+    ) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[
+        temporalio.api.enums.v1.task_queue_pb2.TaskReachability.ValueType
+    ]:
+        """Task reachability for a worker in a single task queue.
+        See the TaskReachability docstring for information about each enum variant.
+        If reachability is empty, this worker is considered unreachable in this task queue.
+        """
+    def __init__(
+        self,
+        *,
+        task_queue: builtins.str = ...,
+        reachability: collections.abc.Iterable[
+            temporalio.api.enums.v1.task_queue_pb2.TaskReachability.ValueType
+        ]
+        | None = ...,
+    ) -> None: ...
+    def ClearField(
         self,
         field_name: typing_extensions.Literal[
-            "build_ids", b"build_ids", "version_set_id", b"version_set_id"
+            "reachability", b"reachability", "task_queue", b"task_queue"
         ],
     ) -> None: ...
 
-global___CompatibleVersionSet = CompatibleVersionSet
+global___TaskQueueReachability = TaskQueueReachability
+
+class BuildIdReachability(google.protobuf.message.Message):
+    """Reachability of tasks for a worker by build id, in one or more task queues."""
+
+    DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+    BUILD_ID_FIELD_NUMBER: builtins.int
+    TASK_QUEUE_REACHABILITY_FIELD_NUMBER: builtins.int
+    build_id: builtins.str
+    """A build id or empty if unversioned."""
+    @property
+    def task_queue_reachability(
+        self,
+    ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
+        global___TaskQueueReachability
+    ]:
+        """Reachability per task queue."""
+    def __init__(
+        self,
+        *,
+        build_id: builtins.str = ...,
+        task_queue_reachability: collections.abc.Iterable[
+            global___TaskQueueReachability
+        ]
+        | None = ...,
+    ) -> None: ...
+    def ClearField(
+        self,
+        field_name: typing_extensions.Literal[
+            "build_id",
+            b"build_id",
+            "task_queue_reachability",
+            b"task_queue_reachability",
+        ],
+    ) -> None: ...
+
+global___BuildIdReachability = BuildIdReachability
```

### Comparing `temporalio-1.2.0/temporalio/api/testservice/v1/__init__.py` & `temporalio-1.3.0/temporalio/api/testservice/v1/__init__.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/testservice/v1/request_response_pb2.py` & `temporalio-1.3.0/temporalio/api/testservice/v1/request_response_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/testservice/v1/request_response_pb2.pyi` & `temporalio-1.3.0/temporalio/api/testservice/v1/request_response_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/testservice/v1/request_response_pb2_grpc.pyi` & `temporalio-1.3.0/temporalio/api/testservice/v1/request_response_pb2_grpc.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/testservice/v1/service_pb2.py` & `temporalio-1.3.0/temporalio/api/testservice/v1/service_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/testservice/v1/service_pb2.pyi` & `temporalio-1.3.0/temporalio/api/testservice/v1/service_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/testservice/v1/service_pb2_grpc.py` & `temporalio-1.3.0/temporalio/api/testservice/v1/service_pb2_grpc.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/testservice/v1/service_pb2_grpc.pyi` & `temporalio-1.3.0/temporalio/api/testservice/v1/service_pb2_grpc.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/update/v1/message_pb2.py` & `temporalio-1.3.0/temporalio/api/update/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/update/v1/message_pb2.pyi` & `temporalio-1.3.0/temporalio/api/update/v1/message_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/version/v1/message_pb2.py` & `temporalio-1.3.0/temporalio/api/version/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/version/v1/message_pb2.pyi` & `temporalio-1.3.0/temporalio/api/version/v1/message_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/workflow/v1/message_pb2.py` & `temporalio-1.3.0/temporalio/api/workflow/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/workflow/v1/message_pb2.pyi` & `temporalio-1.3.0/temporalio/api/workflow/v1/message_pb2.pyi`

 * *Files 1% similar despite different names*

```diff
@@ -466,16 +466,21 @@
     BINARY_CHECKSUM_FIELD_NUMBER: builtins.int
     RUN_ID_FIELD_NUMBER: builtins.int
     FIRST_WORKFLOW_TASK_COMPLETED_ID_FIELD_NUMBER: builtins.int
     CREATE_TIME_FIELD_NUMBER: builtins.int
     EXPIRE_TIME_FIELD_NUMBER: builtins.int
     RESETTABLE_FIELD_NUMBER: builtins.int
     binary_checksum: builtins.str
+    """A worker binary version identifier, will be deprecated and superseded by a newer concept of
+    build_id.
+    """
     run_id: builtins.str
+    """The first run ID in the execution chain that was touched by this worker build."""
     first_workflow_task_completed_id: builtins.int
+    """Event ID of the first WorkflowTaskCompleted event processed by this worker build."""
     @property
     def create_time(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     @property
     def expire_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
         """(-- api-linter: core::0214::resource-expiry=disabled
             aip.dev/not-precedent: TTL is not defined for ResetPointInfo. --)
         The time that the run is deleted due to retention.
```

### Comparing `temporalio-1.2.0/temporalio/api/workflowservice/v1/__init__.py` & `temporalio-1.3.0/temporalio/api/workflowservice/v1/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -23,14 +23,16 @@
     GetClusterInfoResponse,
     GetSearchAttributesRequest,
     GetSearchAttributesResponse,
     GetSystemInfoRequest,
     GetSystemInfoResponse,
     GetWorkerBuildIdCompatibilityRequest,
     GetWorkerBuildIdCompatibilityResponse,
+    GetWorkerTaskReachabilityRequest,
+    GetWorkerTaskReachabilityResponse,
     GetWorkflowExecutionHistoryRequest,
     GetWorkflowExecutionHistoryResponse,
     GetWorkflowExecutionHistoryReverseRequest,
     GetWorkflowExecutionHistoryReverseResponse,
     ListArchivedWorkflowExecutionsRequest,
     ListArchivedWorkflowExecutionsResponse,
     ListBatchOperationsRequest,
@@ -138,14 +140,16 @@
     "GetClusterInfoResponse",
     "GetSearchAttributesRequest",
     "GetSearchAttributesResponse",
     "GetSystemInfoRequest",
     "GetSystemInfoResponse",
     "GetWorkerBuildIdCompatibilityRequest",
     "GetWorkerBuildIdCompatibilityResponse",
+    "GetWorkerTaskReachabilityRequest",
+    "GetWorkerTaskReachabilityResponse",
     "GetWorkflowExecutionHistoryRequest",
     "GetWorkflowExecutionHistoryResponse",
     "GetWorkflowExecutionHistoryReverseRequest",
     "GetWorkflowExecutionHistoryReverseResponse",
     "ListArchivedWorkflowExecutionsRequest",
     "ListArchivedWorkflowExecutionsResponse",
     "ListBatchOperationsRequest",
```

### Comparing `temporalio-1.2.0/temporalio/api/workflowservice/v1/request_response_pb2.py` & `temporalio-1.3.0/temporalio/api/workflowservice/v1/request_response_pb2.py`

 * *Files 2% similar despite different names*

```diff
@@ -89,15 +89,15 @@
     message_pb2 as temporal_dot_api_dot_version_dot_v1_dot_message__pb2,
 )
 from temporalio.api.workflow.v1 import (
     message_pb2 as temporal_dot_api_dot_workflow_dot_v1_dot_message__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n6temporal/api/workflowservice/v1/request_response.proto\x12\x1ftemporal.api.workflowservice.v1\x1a+temporal/api/enums/v1/batch_operation.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a%temporal/api/enums/v1/namespace.proto\x1a(temporal/api/enums/v1/failed_cause.proto\x1a"temporal/api/enums/v1/common.proto\x1a!temporal/api/enums/v1/query.proto\x1a!temporal/api/enums/v1/reset.proto\x1a&temporal/api/enums/v1/task_queue.proto\x1a$temporal/api/common/v1/message.proto\x1a%temporal/api/history/v1/message.proto\x1a&temporal/api/workflow/v1/message.proto\x1a%temporal/api/command/v1/message.proto\x1a%temporal/api/failure/v1/message.proto\x1a$temporal/api/filter/v1/message.proto\x1a&temporal/api/protocol/v1/message.proto\x1a\'temporal/api/namespace/v1/message.proto\x1a#temporal/api/query/v1/message.proto\x1a)temporal/api/replication/v1/message.proto\x1a&temporal/api/schedule/v1/message.proto\x1a\'temporal/api/taskqueue/v1/message.proto\x1a$temporal/api/update/v1/message.proto\x1a%temporal/api/version/v1/message.proto\x1a#temporal/api/batch/v1/message.proto\x1a\x30temporal/api/sdk/v1/task_complete_metadata.proto\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a!dependencies/gogoproto/gogo.proto"\x8e\x05\n\x18RegisterNamespaceRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x02 \x01(\t\x12\x13\n\x0bowner_email\x18\x03 \x01(\t\x12L\n#workflow_execution_retention_period\x18\x04 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12G\n\x08\x63lusters\x18\x05 \x03(\x0b\x32\x35.temporal.api.replication.v1.ClusterReplicationConfig\x12\x1b\n\x13\x61\x63tive_cluster_name\x18\x06 \x01(\t\x12Q\n\x04\x64\x61ta\x18\x07 \x03(\x0b\x32\x43.temporal.api.workflowservice.v1.RegisterNamespaceRequest.DataEntry\x12\x16\n\x0esecurity_token\x18\x08 \x01(\t\x12\x1b\n\x13is_global_namespace\x18\t \x01(\x08\x12\x44\n\x16history_archival_state\x18\n \x01(\x0e\x32$.temporal.api.enums.v1.ArchivalState\x12\x1c\n\x14history_archival_uri\x18\x0b \x01(\t\x12G\n\x19visibility_archival_state\x18\x0c \x01(\x0e\x32$.temporal.api.enums.v1.ArchivalState\x12\x1f\n\x17visibility_archival_uri\x18\r \x01(\t\x1a+\n\tDataEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01"\x1b\n\x19RegisterNamespaceResponse"\x89\x01\n\x15ListNamespacesRequest\x12\x11\n\tpage_size\x18\x01 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c\x12\x44\n\x10namespace_filter\x18\x03 \x01(\x0b\x32*.temporal.api.namespace.v1.NamespaceFilter"\x81\x01\n\x16ListNamespacesResponse\x12N\n\nnamespaces\x18\x01 \x03(\x0b\x32:.temporal.api.workflowservice.v1.DescribeNamespaceResponse\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"9\n\x18\x44\x65scribeNamespaceRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\n\n\x02id\x18\x02 \x01(\t"\xec\x02\n\x19\x44\x65scribeNamespaceResponse\x12@\n\x0enamespace_info\x18\x01 \x01(\x0b\x32(.temporal.api.namespace.v1.NamespaceInfo\x12:\n\x06\x63onfig\x18\x02 \x01(\x0b\x32*.temporal.api.namespace.v1.NamespaceConfig\x12S\n\x12replication_config\x18\x03 \x01(\x0b\x32\x37.temporal.api.replication.v1.NamespaceReplicationConfig\x12\x18\n\x10\x66\x61ilover_version\x18\x04 \x01(\x03\x12\x1b\n\x13is_global_namespace\x18\x05 \x01(\x08\x12\x45\n\x10\x66\x61ilover_history\x18\x06 \x03(\x0b\x32+.temporal.api.replication.v1.FailoverStatus"\xcf\x02\n\x16UpdateNamespaceRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x43\n\x0bupdate_info\x18\x02 \x01(\x0b\x32..temporal.api.namespace.v1.UpdateNamespaceInfo\x12:\n\x06\x63onfig\x18\x03 \x01(\x0b\x32*.temporal.api.namespace.v1.NamespaceConfig\x12S\n\x12replication_config\x18\x04 \x01(\x0b\x32\x37.temporal.api.replication.v1.NamespaceReplicationConfig\x12\x16\n\x0esecurity_token\x18\x05 \x01(\t\x12\x19\n\x11\x64\x65lete_bad_binary\x18\x06 \x01(\t\x12\x19\n\x11promote_namespace\x18\x07 \x01(\x08"\xa3\x02\n\x17UpdateNamespaceResponse\x12@\n\x0enamespace_info\x18\x01 \x01(\x0b\x32(.temporal.api.namespace.v1.NamespaceInfo\x12:\n\x06\x63onfig\x18\x02 \x01(\x0b\x32*.temporal.api.namespace.v1.NamespaceConfig\x12S\n\x12replication_config\x18\x03 \x01(\x0b\x32\x37.temporal.api.replication.v1.NamespaceReplicationConfig\x12\x18\n\x10\x66\x61ilover_version\x18\x04 \x01(\x03\x12\x1b\n\x13is_global_namespace\x18\x05 \x01(\x08"F\n\x19\x44\x65precateNamespaceRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x16\n\x0esecurity_token\x18\x02 \x01(\t"\x1c\n\x1a\x44\x65precateNamespaceResponse"\xfb\x07\n\x1dStartWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x10\n\x08identity\x18\t \x01(\t\x12\x12\n\nrequest_id\x18\n \x01(\t\x12N\n\x18workflow_id_reuse_policy\x18\x0b \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x39\n\x0cretry_policy\x18\x0c \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\r \x01(\t\x12*\n\x04memo\x18\x0e \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x0f \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12.\n\x06header\x18\x10 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12\x1f\n\x17request_eager_execution\x18\x11 \x01(\x08\x12;\n\x11\x63ontinued_failure\x18\x12 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12@\n\x16last_completion_result\x18\x13 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12=\n\x14workflow_start_delay\x18\x14 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01"\x8d\x01\n\x1eStartWorkflowExecutionResponse\x12\x0e\n\x06run_id\x18\x01 \x01(\t\x12[\n\x13\x65\x61ger_workflow_task\x18\x02 \x01(\x0b\x32>.temporal.api.workflowservice.v1.PollWorkflowTaskQueueResponse"\xaa\x02\n"GetWorkflowExecutionHistoryRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x19\n\x11maximum_page_size\x18\x03 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x04 \x01(\x0c\x12\x16\n\x0ewait_new_event\x18\x05 \x01(\x08\x12P\n\x19history_event_filter_type\x18\x06 \x01(\x0e\x32-.temporal.api.enums.v1.HistoryEventFilterType\x12\x15\n\rskip_archival\x18\x07 \x01(\x08"\xba\x01\n#GetWorkflowExecutionHistoryResponse\x12\x31\n\x07history\x18\x01 \x01(\x0b\x32 .temporal.api.history.v1.History\x12\x35\n\x0braw_history\x18\x02 \x03(\x0b\x32 .temporal.api.common.v1.DataBlob\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\x10\n\x08\x61rchived\x18\x04 \x01(\x08"\xb0\x01\n)GetWorkflowExecutionHistoryReverseRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x19\n\x11maximum_page_size\x18\x03 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x04 \x01(\x0c"x\n*GetWorkflowExecutionHistoryReverseResponse\x12\x31\n\x07history\x18\x01 \x01(\x0b\x32 .temporal.api.history.v1.History\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c"\xee\x01\n\x1cPollWorkflowTaskQueueRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x38\n\ntask_queue\x18\x02 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x17\n\x0f\x62inary_checksum\x18\x04 \x01(\t\x12V\n\x1bworker_version_capabilities\x18\x05 \x01(\x0b\x32\x31.temporal.api.common.v1.WorkerVersionCapabilities"\xca\x06\n\x1dPollWorkflowTaskQueueResponse\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12!\n\x19previous_started_event_id\x18\x04 \x01(\x03\x12\x18\n\x10started_event_id\x18\x05 \x01(\x03\x12\x0f\n\x07\x61ttempt\x18\x06 \x01(\x05\x12\x1a\n\x12\x62\x61\x63klog_count_hint\x18\x07 \x01(\x03\x12\x31\n\x07history\x18\x08 \x01(\x0b\x32 .temporal.api.history.v1.History\x12\x17\n\x0fnext_page_token\x18\t \x01(\x0c\x12\x33\n\x05query\x18\n \x01(\x0b\x32$.temporal.api.query.v1.WorkflowQuery\x12K\n\x1dworkflow_execution_task_queue\x18\x0b \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12\x38\n\x0escheduled_time\x18\x0c \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x36\n\x0cstarted_time\x18\r \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\\\n\x07queries\x18\x0e \x03(\x0b\x32K.temporal.api.workflowservice.v1.PollWorkflowTaskQueueResponse.QueriesEntry\x12\x33\n\x08messages\x18\x0f \x03(\x0b\x32!.temporal.api.protocol.v1.Message\x1aT\n\x0cQueriesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x33\n\x05value\x18\x02 \x01(\x0b\x32$.temporal.api.query.v1.WorkflowQuery:\x02\x38\x01"\xa4\x06\n#RespondWorkflowTaskCompletedRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x32\n\x08\x63ommands\x18\x02 \x03(\x0b\x32 .temporal.api.command.v1.Command\x12\x10\n\x08identity\x18\x03 \x01(\t\x12O\n\x11sticky_attributes\x18\x04 \x01(\x0b\x32\x34.temporal.api.taskqueue.v1.StickyExecutionAttributes\x12 \n\x18return_new_workflow_task\x18\x05 \x01(\x08\x12&\n\x1e\x66orce_create_new_workflow_task\x18\x06 \x01(\x08\x12\x17\n\x0f\x62inary_checksum\x18\x07 \x01(\t\x12m\n\rquery_results\x18\x08 \x03(\x0b\x32V.temporal.api.workflowservice.v1.RespondWorkflowTaskCompletedRequest.QueryResultsEntry\x12\x11\n\tnamespace\x18\t \x01(\t\x12H\n\x14worker_version_stamp\x18\n \x01(\x0b\x32*.temporal.api.common.v1.WorkerVersionStamp\x12\x33\n\x08messages\x18\x0b \x03(\x0b\x32!.temporal.api.protocol.v1.Message\x12H\n\x0csdk_metadata\x18\x0c \x01(\x0b\x32\x32.temporal.api.sdk.v1.WorkflowTaskCompletedMetadata\x12\x43\n\x11metering_metadata\x18\r \x01(\x0b\x32(.temporal.api.common.v1.MeteringMetadata\x1a_\n\x11QueryResultsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x39\n\x05value\x18\x02 \x01(\x0b\x32*.temporal.api.query.v1.WorkflowQueryResult:\x02\x38\x01"\xf5\x01\n$RespondWorkflowTaskCompletedResponse\x12U\n\rworkflow_task\x18\x01 \x01(\x0b\x32>.temporal.api.workflowservice.v1.PollWorkflowTaskQueueResponse\x12V\n\x0e\x61\x63tivity_tasks\x18\x02 \x03(\x0b\x32>.temporal.api.workflowservice.v1.PollActivityTaskQueueResponse\x12\x1e\n\x16reset_history_event_id\x18\x03 \x01(\x03"\x9b\x02\n RespondWorkflowTaskFailedRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12=\n\x05\x63\x61use\x18\x02 \x01(\x0e\x32..temporal.api.enums.v1.WorkflowTaskFailedCause\x12\x31\n\x07\x66\x61ilure\x18\x03 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x10\n\x08identity\x18\x04 \x01(\t\x12\x17\n\x0f\x62inary_checksum\x18\x05 \x01(\t\x12\x11\n\tnamespace\x18\x06 \x01(\t\x12\x33\n\x08messages\x18\x07 \x03(\x0b\x32!.temporal.api.protocol.v1.Message"#\n!RespondWorkflowTaskFailedResponse"\xa0\x02\n\x1cPollActivityTaskQueueRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x38\n\ntask_queue\x18\x02 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12\x10\n\x08identity\x18\x03 \x01(\t\x12I\n\x13task_queue_metadata\x18\x04 \x01(\x0b\x32,.temporal.api.taskqueue.v1.TaskQueueMetadata\x12V\n\x1bworker_version_capabilities\x18\x05 \x01(\x0b\x32\x31.temporal.api.common.v1.WorkerVersionCapabilities"\x8c\x07\n\x1dPollActivityTaskQueueResponse\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x1a\n\x12workflow_namespace\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x45\n\x12workflow_execution\x18\x04 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\ractivity_type\x18\x05 \x01(\x0b\x32$.temporal.api.common.v1.ActivityType\x12\x13\n\x0b\x61\x63tivity_id\x18\x06 \x01(\t\x12.\n\x06header\x18\x07 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12/\n\x05input\x18\x08 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12;\n\x11heartbeat_details\x18\t \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x38\n\x0escheduled_time\x18\n \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12H\n\x1e\x63urrent_attempt_scheduled_time\x18\x0b \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x36\n\x0cstarted_time\x18\x0c \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x0f\n\x07\x61ttempt\x18\r \x01(\x05\x12\x42\n\x19schedule_to_close_timeout\x18\x0e \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12?\n\x16start_to_close_timeout\x18\x0f \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12:\n\x11heartbeat_timeout\x18\x10 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x39\n\x0cretry_policy\x18\x11 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy"\x90\x01\n"RecordActivityTaskHeartbeatRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x31\n\x07\x64\x65tails\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x11\n\tnamespace\x18\x04 \x01(\t"?\n#RecordActivityTaskHeartbeatResponse\x12\x18\n\x10\x63\x61ncel_requested\x18\x01 \x01(\x08"\xba\x01\n&RecordActivityTaskHeartbeatByIdRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x13\n\x0b\x61\x63tivity_id\x18\x04 \x01(\t\x12\x31\n\x07\x64\x65tails\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x06 \x01(\t"C\n\'RecordActivityTaskHeartbeatByIdResponse\x12\x18\n\x10\x63\x61ncel_requested\x18\x01 \x01(\x08"\x90\x01\n#RespondActivityTaskCompletedRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x30\n\x06result\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x11\n\tnamespace\x18\x04 \x01(\t"&\n$RespondActivityTaskCompletedResponse"\xba\x01\n\'RespondActivityTaskCompletedByIdRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x13\n\x0b\x61\x63tivity_id\x18\x04 \x01(\t\x12\x30\n\x06result\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x06 \x01(\t"*\n(RespondActivityTaskCompletedByIdResponse"\xd0\x01\n RespondActivityTaskFailedRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x31\n\x07\x66\x61ilure\x18\x02 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x11\n\tnamespace\x18\x04 \x01(\t\x12@\n\x16last_heartbeat_details\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads"W\n!RespondActivityTaskFailedResponse\x12\x32\n\x08\x66\x61ilures\x18\x01 \x03(\x0b\x32 .temporal.api.failure.v1.Failure"\xfa\x01\n$RespondActivityTaskFailedByIdRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x13\n\x0b\x61\x63tivity_id\x18\x04 \x01(\t\x12\x31\n\x07\x66\x61ilure\x18\x05 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x10\n\x08identity\x18\x06 \x01(\t\x12@\n\x16last_heartbeat_details\x18\x07 \x01(\x0b\x32 .temporal.api.common.v1.Payloads"[\n%RespondActivityTaskFailedByIdResponse\x12\x32\n\x08\x66\x61ilures\x18\x01 \x03(\x0b\x32 .temporal.api.failure.v1.Failure"\x90\x01\n"RespondActivityTaskCanceledRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x31\n\x07\x64\x65tails\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x11\n\tnamespace\x18\x04 \x01(\t"%\n#RespondActivityTaskCanceledResponse"\xba\x01\n&RespondActivityTaskCanceledByIdRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x13\n\x0b\x61\x63tivity_id\x18\x04 \x01(\t\x12\x31\n\x07\x64\x65tails\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x06 \x01(\t")\n\'RespondActivityTaskCanceledByIdResponse"\xd7\x01\n%RequestCancelWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x12\n\nrequest_id\x18\x04 \x01(\t\x12\x1e\n\x16\x66irst_execution_run_id\x18\x05 \x01(\t\x12\x0e\n\x06reason\x18\x06 \x01(\t"(\n&RequestCancelWorkflowExecutionResponse"\xcc\x02\n\x1eSignalWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x13\n\x0bsignal_name\x18\x03 \x01(\t\x12/\n\x05input\x18\x04 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x05 \x01(\t\x12\x12\n\nrequest_id\x18\x06 \x01(\t\x12\x0f\n\x07\x63ontrol\x18\x07 \x01(\t\x12.\n\x06header\x18\x08 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12#\n\x1bskip_generate_workflow_task\x18\t \x01(\x08"!\n\x1fSignalWorkflowExecutionResponse"\xe8\x07\n\'SignalWithStartWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x10\n\x08identity\x18\t \x01(\t\x12\x12\n\nrequest_id\x18\n \x01(\t\x12N\n\x18workflow_id_reuse_policy\x18\x0b \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x13\n\x0bsignal_name\x18\x0c \x01(\t\x12\x36\n\x0csignal_input\x18\r \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x0f\n\x07\x63ontrol\x18\x0e \x01(\t\x12\x39\n\x0cretry_policy\x18\x0f \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\x10 \x01(\t\x12*\n\x04memo\x18\x11 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x12 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12.\n\x06header\x18\x13 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12=\n\x14workflow_start_delay\x18\x14 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12#\n\x1bskip_generate_workflow_task\x18\x15 \x01(\x08":\n(SignalWithStartWorkflowExecutionResponse\x12\x0e\n\x06run_id\x18\x01 \x01(\t"\x89\x02\n\x1dResetWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x0e\n\x06reason\x18\x03 \x01(\t\x12%\n\x1dworkflow_task_finish_event_id\x18\x04 \x01(\x03\x12\x12\n\nrequest_id\x18\x05 \x01(\t\x12\x43\n\x12reset_reapply_type\x18\x06 \x01(\x0e\x32\'.temporal.api.enums.v1.ResetReapplyType"0\n\x1eResetWorkflowExecutionResponse\x12\x0e\n\x06run_id\x18\x01 \x01(\t"\xf2\x01\n!TerminateWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x0e\n\x06reason\x18\x03 \x01(\t\x12\x31\n\x07\x64\x65tails\x18\x04 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x05 \x01(\t\x12\x1e\n\x16\x66irst_execution_run_id\x18\x06 \x01(\t"$\n"TerminateWorkflowExecutionResponse"z\n\x1e\x44\x65leteWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution"!\n\x1f\x44\x65leteWorkflowExecutionResponse"\xc9\x02\n!ListOpenWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x19\n\x11maximum_page_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\x42\n\x11start_time_filter\x18\x04 \x01(\x0b\x32\'.temporal.api.filter.v1.StartTimeFilter\x12K\n\x10\x65xecution_filter\x18\x05 \x01(\x0b\x32/.temporal.api.filter.v1.WorkflowExecutionFilterH\x00\x12\x41\n\x0btype_filter\x18\x06 \x01(\x0b\x32*.temporal.api.filter.v1.WorkflowTypeFilterH\x00\x42\t\n\x07\x66ilters"\x82\x01\n"ListOpenWorkflowExecutionsResponse\x12\x43\n\nexecutions\x18\x01 \x03(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"\x8a\x03\n#ListClosedWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x19\n\x11maximum_page_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\x42\n\x11start_time_filter\x18\x04 \x01(\x0b\x32\'.temporal.api.filter.v1.StartTimeFilter\x12K\n\x10\x65xecution_filter\x18\x05 \x01(\x0b\x32/.temporal.api.filter.v1.WorkflowExecutionFilterH\x00\x12\x41\n\x0btype_filter\x18\x06 \x01(\x0b\x32*.temporal.api.filter.v1.WorkflowTypeFilterH\x00\x12=\n\rstatus_filter\x18\x07 \x01(\x0b\x32$.temporal.api.filter.v1.StatusFilterH\x00\x42\t\n\x07\x66ilters"\x84\x01\n$ListClosedWorkflowExecutionsResponse\x12\x43\n\nexecutions\x18\x01 \x03(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"m\n\x1dListWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x11\n\tpage_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\r\n\x05query\x18\x04 \x01(\t"~\n\x1eListWorkflowExecutionsResponse\x12\x43\n\nexecutions\x18\x01 \x03(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"u\n%ListArchivedWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x11\n\tpage_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\r\n\x05query\x18\x04 \x01(\t"\x86\x01\n&ListArchivedWorkflowExecutionsResponse\x12\x43\n\nexecutions\x18\x01 \x03(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"m\n\x1dScanWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x11\n\tpage_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\r\n\x05query\x18\x04 \x01(\t"~\n\x1eScanWorkflowExecutionsResponse\x12\x43\n\nexecutions\x18\x01 \x03(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"B\n\x1e\x43ountWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\r\n\x05query\x18\x02 \x01(\t"0\n\x1f\x43ountWorkflowExecutionsResponse\x12\r\n\x05\x63ount\x18\x01 \x01(\x03"\x1c\n\x1aGetSearchAttributesRequest"\xc9\x01\n\x1bGetSearchAttributesResponse\x12T\n\x04keys\x18\x01 \x03(\x0b\x32\x46.temporal.api.workflowservice.v1.GetSearchAttributesResponse.KeysEntry\x1aT\n\tKeysEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x36\n\x05value\x18\x02 \x01(\x0e\x32\'.temporal.api.enums.v1.IndexedValueType:\x02\x38\x01"\xde\x01\n RespondQueryTaskCompletedRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12>\n\x0e\x63ompleted_type\x18\x02 \x01(\x0e\x32&.temporal.api.enums.v1.QueryResultType\x12\x36\n\x0cquery_result\x18\x03 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x15\n\rerror_message\x18\x04 \x01(\t\x12\x11\n\tnamespace\x18\x06 \x01(\tJ\x04\x08\x05\x10\x06"#\n!RespondQueryTaskCompletedResponse"n\n\x1bResetStickyTaskQueueRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution"\x1e\n\x1cResetStickyTaskQueueResponse"\xe9\x01\n\x14QueryWorkflowRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x33\n\x05query\x18\x03 \x01(\x0b\x32$.temporal.api.query.v1.WorkflowQuery\x12K\n\x16query_reject_condition\x18\x04 \x01(\x0e\x32+.temporal.api.enums.v1.QueryRejectCondition"\x8d\x01\n\x15QueryWorkflowResponse\x12\x36\n\x0cquery_result\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12<\n\x0equery_rejected\x18\x02 \x01(\x0b\x32$.temporal.api.query.v1.QueryRejected"s\n DescribeWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution"\xae\x03\n!DescribeWorkflowExecutionResponse\x12K\n\x10\x65xecution_config\x18\x01 \x01(\x0b\x32\x31.temporal.api.workflow.v1.WorkflowExecutionConfig\x12P\n\x17workflow_execution_info\x18\x02 \x01(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12I\n\x12pending_activities\x18\x03 \x03(\x0b\x32-.temporal.api.workflow.v1.PendingActivityInfo\x12M\n\x10pending_children\x18\x04 \x03(\x0b\x32\x33.temporal.api.workflow.v1.PendingChildExecutionInfo\x12P\n\x15pending_workflow_task\x18\x05 \x01(\x0b\x32\x31.temporal.api.workflow.v1.PendingWorkflowTaskInfo"\xc9\x01\n\x18\x44\x65scribeTaskQueueRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x38\n\ntask_queue\x18\x02 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12=\n\x0ftask_queue_type\x18\x03 \x01(\x0e\x32$.temporal.api.enums.v1.TaskQueueType\x12!\n\x19include_task_queue_status\x18\x04 \x01(\x08"\x9a\x01\n\x19\x44\x65scribeTaskQueueResponse\x12\x36\n\x07pollers\x18\x01 \x03(\x0b\x32%.temporal.api.taskqueue.v1.PollerInfo\x12\x45\n\x11task_queue_status\x18\x02 \x01(\x0b\x32*.temporal.api.taskqueue.v1.TaskQueueStatus"\x17\n\x15GetClusterInfoRequest"\x8b\x03\n\x16GetClusterInfoResponse\x12h\n\x11supported_clients\x18\x01 \x03(\x0b\x32M.temporal.api.workflowservice.v1.GetClusterInfoResponse.SupportedClientsEntry\x12\x16\n\x0eserver_version\x18\x02 \x01(\t\x12\x12\n\ncluster_id\x18\x03 \x01(\t\x12:\n\x0cversion_info\x18\x04 \x01(\x0b\x32$.temporal.api.version.v1.VersionInfo\x12\x14\n\x0c\x63luster_name\x18\x05 \x01(\t\x12\x1b\n\x13history_shard_count\x18\x06 \x01(\x05\x12\x19\n\x11persistence_store\x18\x07 \x01(\t\x12\x18\n\x10visibility_store\x18\x08 \x01(\t\x1a\x37\n\x15SupportedClientsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01"\x16\n\x14GetSystemInfoRequest"\xbc\x03\n\x15GetSystemInfoResponse\x12\x16\n\x0eserver_version\x18\x01 \x01(\t\x12Y\n\x0c\x63\x61pabilities\x18\x02 \x01(\x0b\x32\x43.temporal.api.workflowservice.v1.GetSystemInfoResponse.Capabilities\x1a\xaf\x02\n\x0c\x43\x61pabilities\x12\x1f\n\x17signal_and_query_header\x18\x01 \x01(\x08\x12&\n\x1einternal_error_differentiation\x18\x02 \x01(\x08\x12*\n"activity_failure_include_heartbeat\x18\x03 \x01(\x08\x12\x1a\n\x12supports_schedules\x18\x04 \x01(\x08\x12"\n\x1a\x65ncoded_failure_attributes\x18\x05 \x01(\x08\x12!\n\x19\x62uild_id_based_versioning\x18\x06 \x01(\x08\x12\x13\n\x0bupsert_memo\x18\x07 \x01(\x08\x12\x1c\n\x14\x65\x61ger_workflow_start\x18\x08 \x01(\x08\x12\x14\n\x0csdk_metadata\x18\t \x01(\x08"m\n\x1eListTaskQueuePartitionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x38\n\ntask_queue\x18\x02 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue"\xdf\x01\n\x1fListTaskQueuePartitionsResponse\x12]\n\x1e\x61\x63tivity_task_queue_partitions\x18\x01 \x03(\x0b\x32\x35.temporal.api.taskqueue.v1.TaskQueuePartitionMetadata\x12]\n\x1eworkflow_task_queue_partitions\x18\x02 \x03(\x0b\x32\x35.temporal.api.taskqueue.v1.TaskQueuePartitionMetadata"\xcc\x02\n\x15\x43reateScheduleRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t\x12\x34\n\x08schedule\x18\x03 \x01(\x0b\x32".temporal.api.schedule.v1.Schedule\x12>\n\rinitial_patch\x18\x04 \x01(\x0b\x32\'.temporal.api.schedule.v1.SchedulePatch\x12\x10\n\x08identity\x18\x05 \x01(\t\x12\x12\n\nrequest_id\x18\x06 \x01(\t\x12*\n\x04memo\x18\x07 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x08 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"0\n\x16\x43reateScheduleResponse\x12\x16\n\x0e\x63onflict_token\x18\x01 \x01(\x0c"A\n\x17\x44\x65scribeScheduleRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t"\x8f\x02\n\x18\x44\x65scribeScheduleResponse\x12\x34\n\x08schedule\x18\x01 \x01(\x0b\x32".temporal.api.schedule.v1.Schedule\x12\x34\n\x04info\x18\x02 \x01(\x0b\x32&.temporal.api.schedule.v1.ScheduleInfo\x12*\n\x04memo\x18\x03 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x04 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12\x16\n\x0e\x63onflict_token\x18\x05 \x01(\x0c"\xb3\x01\n\x15UpdateScheduleRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t\x12\x34\n\x08schedule\x18\x03 \x01(\x0b\x32".temporal.api.schedule.v1.Schedule\x12\x16\n\x0e\x63onflict_token\x18\x04 \x01(\x0c\x12\x10\n\x08identity\x18\x05 \x01(\t\x12\x12\n\nrequest_id\x18\x06 \x01(\t"\x18\n\x16UpdateScheduleResponse"\x9c\x01\n\x14PatchScheduleRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t\x12\x36\n\x05patch\x18\x03 \x01(\x0b\x32\'.temporal.api.schedule.v1.SchedulePatch\x12\x10\n\x08identity\x18\x04 \x01(\t\x12\x12\n\nrequest_id\x18\x05 \x01(\t"\x17\n\x15PatchScheduleResponse"\xb4\x01\n ListScheduleMatchingTimesRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t\x12\x34\n\nstart_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x32\n\x08\x65nd_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01"Y\n!ListScheduleMatchingTimesResponse\x12\x34\n\nstart_time\x18\x01 \x03(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01"Q\n\x15\x44\x65leteScheduleRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t\x12\x10\n\x08identity\x18\x03 \x01(\t"\x18\n\x16\x44\x65leteScheduleResponse"]\n\x14ListSchedulesRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x19\n\x11maximum_page_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c"p\n\x15ListSchedulesResponse\x12>\n\tschedules\x18\x01 \x03(\x0b\x32+.temporal.api.schedule.v1.ScheduleListEntry\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"\xd1\x03\n\'UpdateWorkerBuildIdCompatibilityRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x12\n\ntask_queue\x18\x02 \x01(\t\x12-\n#add_new_build_id_in_new_default_set\x18\x03 \x01(\tH\x00\x12\x87\x01\n\x1b\x61\x64\x64_new_compatible_build_id\x18\x04 \x01(\x0b\x32`.temporal.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest.AddNewCompatibleVersionH\x00\x12!\n\x17promote_set_by_build_id\x18\x05 \x01(\tH\x00\x12%\n\x1bpromote_build_id_within_set\x18\x06 \x01(\tH\x00\x1ao\n\x17\x41\x64\x64NewCompatibleVersion\x12\x14\n\x0cnew_build_id\x18\x01 \x01(\t\x12$\n\x1c\x65xisting_compatible_build_id\x18\x02 \x01(\t\x12\x18\n\x10make_set_default\x18\x03 \x01(\x08\x42\x0b\n\toperation"B\n(UpdateWorkerBuildIdCompatibilityResponse\x12\x16\n\x0eversion_set_id\x18\x01 \x01(\t"\xac\x01\n$GetWorkerBuildIdCompatibilityRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x12\n\ntask_queue\x18\x02 \x01(\t\x12\x10\n\x08max_sets\x18\x03 \x01(\x05\x12%\n\x1dinclude_retirement_candidates\x18\x04 \x01(\x08\x12$\n\x1cinclude_poller_compatibility\x18\x05 \x01(\x08"\xf8\x04\n%GetWorkerBuildIdCompatibilityResponse\x12K\n\x12major_version_sets\x18\x01 \x03(\x0b\x32/.temporal.api.taskqueue.v1.CompatibleVersionSet\x12y\n\x15retirement_candidates\x18\x02 \x03(\x0b\x32Z.temporal.api.workflowservice.v1.GetWorkerBuildIdCompatibilityResponse.RetirementCandidate\x12\x89\x01\n\x1b\x61\x63tive_versions_and_pollers\x18\x03 \x03(\x0b\x32\x64.temporal.api.workflowservice.v1.GetWorkerBuildIdCompatibilityResponse.VersionsWithCompatiblePollers\x1a\x83\x01\n\x13RetirementCandidate\x12\x10\n\x08\x62uild_id\x18\x01 \x01(\t\x12"\n\x1a\x61ll_workflows_are_archived\x18\x02 \x01(\x08\x12\x36\n\x07pollers\x18\x03 \x03(\x0b\x32%.temporal.api.taskqueue.v1.PollerInfo\x1au\n\x1dVersionsWithCompatiblePollers\x12\x1c\n\x14most_recent_build_id\x18\x01 \x01(\t\x12\x36\n\x07pollers\x18\x02 \x03(\x0b\x32%.temporal.api.taskqueue.v1.PollerInfo"\x85\x02\n\x1eUpdateWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x1e\n\x16\x66irst_execution_run_id\x18\x03 \x01(\t\x12\x37\n\x0bwait_policy\x18\x04 \x01(\x0b\x32".temporal.api.update.v1.WaitPolicy\x12\x30\n\x07request\x18\x05 \x01(\x0b\x32\x1f.temporal.api.update.v1.Request"\x8a\x01\n\x1fUpdateWorkflowExecutionResponse\x12\x35\n\nupdate_ref\x18\x01 \x01(\x0b\x32!.temporal.api.update.v1.UpdateRef\x12\x30\n\x07outcome\x18\x02 \x01(\x0b\x32\x1f.temporal.api.update.v1.Outcome"\xf3\x03\n\x1aStartBatchOperationRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x18\n\x10visibility_query\x18\x02 \x01(\t\x12\x0e\n\x06job_id\x18\x03 \x01(\t\x12\x0e\n\x06reason\x18\x04 \x01(\t\x12=\n\nexecutions\x18\x05 \x03(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12Q\n\x15termination_operation\x18\n \x01(\x0b\x32\x30.temporal.api.batch.v1.BatchOperationTerminationH\x00\x12G\n\x10signal_operation\x18\x0b \x01(\x0b\x32+.temporal.api.batch.v1.BatchOperationSignalH\x00\x12S\n\x16\x63\x61ncellation_operation\x18\x0c \x01(\x0b\x32\x31.temporal.api.batch.v1.BatchOperationCancellationH\x00\x12K\n\x12\x64\x65letion_operation\x18\r \x01(\x0b\x32-.temporal.api.batch.v1.BatchOperationDeletionH\x00\x42\x0b\n\toperation"\x1d\n\x1bStartBatchOperationResponse"`\n\x19StopBatchOperationRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x0e\n\x06job_id\x18\x02 \x01(\t\x12\x0e\n\x06reason\x18\x03 \x01(\t\x12\x10\n\x08identity\x18\x04 \x01(\t"\x1c\n\x1aStopBatchOperationResponse"B\n\x1d\x44\x65scribeBatchOperationRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x0e\n\x06job_id\x18\x02 \x01(\t"\x9e\x03\n\x1e\x44\x65scribeBatchOperationResponse\x12\x41\n\x0eoperation_type\x18\x01 \x01(\x0e\x32).temporal.api.enums.v1.BatchOperationType\x12\x0e\n\x06job_id\x18\x02 \x01(\t\x12\x39\n\x05state\x18\x03 \x01(\x0e\x32*.temporal.api.enums.v1.BatchOperationState\x12\x34\n\nstart_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x34\n\nclose_time\x18\x05 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x1d\n\x15total_operation_count\x18\x06 \x01(\x03\x12 \n\x18\x63omplete_operation_count\x18\x07 \x01(\x03\x12\x1f\n\x17\x66\x61ilure_operation_count\x18\x08 \x01(\x03\x12\x10\n\x08identity\x18\t \x01(\t\x12\x0e\n\x06reason\x18\n \x01(\t"[\n\x1aListBatchOperationsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x11\n\tpage_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c"y\n\x1bListBatchOperationsResponse\x12\x41\n\x0eoperation_info\x18\x01 \x03(\x0b\x32).temporal.api.batch.v1.BatchOperationInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"\xb9\x01\n"PollWorkflowExecutionUpdateRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x35\n\nupdate_ref\x18\x02 \x01(\x0b\x32!.temporal.api.update.v1.UpdateRef\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x37\n\x0bwait_policy\x18\x04 \x01(\x0b\x32".temporal.api.update.v1.WaitPolicy"W\n#PollWorkflowExecutionUpdateResponse\x12\x30\n\x07outcome\x18\x01 \x01(\x0b\x32\x1f.temporal.api.update.v1.OutcomeB\xbe\x01\n"io.temporal.api.workflowservice.v1B\x14RequestResponseProtoP\x01Z5go.temporal.io/api/workflowservice/v1;workflowservice\xaa\x02!Temporalio.Api.WorkflowService.V1\xea\x02$Temporalio::Api::WorkflowService::V1b\x06proto3'
+    b'\n6temporal/api/workflowservice/v1/request_response.proto\x12\x1ftemporal.api.workflowservice.v1\x1a+temporal/api/enums/v1/batch_operation.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a%temporal/api/enums/v1/namespace.proto\x1a(temporal/api/enums/v1/failed_cause.proto\x1a"temporal/api/enums/v1/common.proto\x1a!temporal/api/enums/v1/query.proto\x1a!temporal/api/enums/v1/reset.proto\x1a&temporal/api/enums/v1/task_queue.proto\x1a$temporal/api/common/v1/message.proto\x1a%temporal/api/history/v1/message.proto\x1a&temporal/api/workflow/v1/message.proto\x1a%temporal/api/command/v1/message.proto\x1a%temporal/api/failure/v1/message.proto\x1a$temporal/api/filter/v1/message.proto\x1a&temporal/api/protocol/v1/message.proto\x1a\'temporal/api/namespace/v1/message.proto\x1a#temporal/api/query/v1/message.proto\x1a)temporal/api/replication/v1/message.proto\x1a&temporal/api/schedule/v1/message.proto\x1a\'temporal/api/taskqueue/v1/message.proto\x1a$temporal/api/update/v1/message.proto\x1a%temporal/api/version/v1/message.proto\x1a#temporal/api/batch/v1/message.proto\x1a\x30temporal/api/sdk/v1/task_complete_metadata.proto\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a!dependencies/gogoproto/gogo.proto"\x8e\x05\n\x18RegisterNamespaceRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x02 \x01(\t\x12\x13\n\x0bowner_email\x18\x03 \x01(\t\x12L\n#workflow_execution_retention_period\x18\x04 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12G\n\x08\x63lusters\x18\x05 \x03(\x0b\x32\x35.temporal.api.replication.v1.ClusterReplicationConfig\x12\x1b\n\x13\x61\x63tive_cluster_name\x18\x06 \x01(\t\x12Q\n\x04\x64\x61ta\x18\x07 \x03(\x0b\x32\x43.temporal.api.workflowservice.v1.RegisterNamespaceRequest.DataEntry\x12\x16\n\x0esecurity_token\x18\x08 \x01(\t\x12\x1b\n\x13is_global_namespace\x18\t \x01(\x08\x12\x44\n\x16history_archival_state\x18\n \x01(\x0e\x32$.temporal.api.enums.v1.ArchivalState\x12\x1c\n\x14history_archival_uri\x18\x0b \x01(\t\x12G\n\x19visibility_archival_state\x18\x0c \x01(\x0e\x32$.temporal.api.enums.v1.ArchivalState\x12\x1f\n\x17visibility_archival_uri\x18\r \x01(\t\x1a+\n\tDataEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01"\x1b\n\x19RegisterNamespaceResponse"\x89\x01\n\x15ListNamespacesRequest\x12\x11\n\tpage_size\x18\x01 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c\x12\x44\n\x10namespace_filter\x18\x03 \x01(\x0b\x32*.temporal.api.namespace.v1.NamespaceFilter"\x81\x01\n\x16ListNamespacesResponse\x12N\n\nnamespaces\x18\x01 \x03(\x0b\x32:.temporal.api.workflowservice.v1.DescribeNamespaceResponse\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"9\n\x18\x44\x65scribeNamespaceRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\n\n\x02id\x18\x02 \x01(\t"\xec\x02\n\x19\x44\x65scribeNamespaceResponse\x12@\n\x0enamespace_info\x18\x01 \x01(\x0b\x32(.temporal.api.namespace.v1.NamespaceInfo\x12:\n\x06\x63onfig\x18\x02 \x01(\x0b\x32*.temporal.api.namespace.v1.NamespaceConfig\x12S\n\x12replication_config\x18\x03 \x01(\x0b\x32\x37.temporal.api.replication.v1.NamespaceReplicationConfig\x12\x18\n\x10\x66\x61ilover_version\x18\x04 \x01(\x03\x12\x1b\n\x13is_global_namespace\x18\x05 \x01(\x08\x12\x45\n\x10\x66\x61ilover_history\x18\x06 \x03(\x0b\x32+.temporal.api.replication.v1.FailoverStatus"\xcf\x02\n\x16UpdateNamespaceRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x43\n\x0bupdate_info\x18\x02 \x01(\x0b\x32..temporal.api.namespace.v1.UpdateNamespaceInfo\x12:\n\x06\x63onfig\x18\x03 \x01(\x0b\x32*.temporal.api.namespace.v1.NamespaceConfig\x12S\n\x12replication_config\x18\x04 \x01(\x0b\x32\x37.temporal.api.replication.v1.NamespaceReplicationConfig\x12\x16\n\x0esecurity_token\x18\x05 \x01(\t\x12\x19\n\x11\x64\x65lete_bad_binary\x18\x06 \x01(\t\x12\x19\n\x11promote_namespace\x18\x07 \x01(\x08"\xa3\x02\n\x17UpdateNamespaceResponse\x12@\n\x0enamespace_info\x18\x01 \x01(\x0b\x32(.temporal.api.namespace.v1.NamespaceInfo\x12:\n\x06\x63onfig\x18\x02 \x01(\x0b\x32*.temporal.api.namespace.v1.NamespaceConfig\x12S\n\x12replication_config\x18\x03 \x01(\x0b\x32\x37.temporal.api.replication.v1.NamespaceReplicationConfig\x12\x18\n\x10\x66\x61ilover_version\x18\x04 \x01(\x03\x12\x1b\n\x13is_global_namespace\x18\x05 \x01(\x08"F\n\x19\x44\x65precateNamespaceRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x16\n\x0esecurity_token\x18\x02 \x01(\t"\x1c\n\x1a\x44\x65precateNamespaceResponse"\xfb\x07\n\x1dStartWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x10\n\x08identity\x18\t \x01(\t\x12\x12\n\nrequest_id\x18\n \x01(\t\x12N\n\x18workflow_id_reuse_policy\x18\x0b \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x39\n\x0cretry_policy\x18\x0c \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\r \x01(\t\x12*\n\x04memo\x18\x0e \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x0f \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12.\n\x06header\x18\x10 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12\x1f\n\x17request_eager_execution\x18\x11 \x01(\x08\x12;\n\x11\x63ontinued_failure\x18\x12 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12@\n\x16last_completion_result\x18\x13 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12=\n\x14workflow_start_delay\x18\x14 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01"\x8d\x01\n\x1eStartWorkflowExecutionResponse\x12\x0e\n\x06run_id\x18\x01 \x01(\t\x12[\n\x13\x65\x61ger_workflow_task\x18\x02 \x01(\x0b\x32>.temporal.api.workflowservice.v1.PollWorkflowTaskQueueResponse"\xaa\x02\n"GetWorkflowExecutionHistoryRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x19\n\x11maximum_page_size\x18\x03 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x04 \x01(\x0c\x12\x16\n\x0ewait_new_event\x18\x05 \x01(\x08\x12P\n\x19history_event_filter_type\x18\x06 \x01(\x0e\x32-.temporal.api.enums.v1.HistoryEventFilterType\x12\x15\n\rskip_archival\x18\x07 \x01(\x08"\xba\x01\n#GetWorkflowExecutionHistoryResponse\x12\x31\n\x07history\x18\x01 \x01(\x0b\x32 .temporal.api.history.v1.History\x12\x35\n\x0braw_history\x18\x02 \x03(\x0b\x32 .temporal.api.common.v1.DataBlob\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\x10\n\x08\x61rchived\x18\x04 \x01(\x08"\xb0\x01\n)GetWorkflowExecutionHistoryReverseRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x19\n\x11maximum_page_size\x18\x03 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x04 \x01(\x0c"x\n*GetWorkflowExecutionHistoryReverseResponse\x12\x31\n\x07history\x18\x01 \x01(\x0b\x32 .temporal.api.history.v1.History\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c"\xee\x01\n\x1cPollWorkflowTaskQueueRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x38\n\ntask_queue\x18\x02 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x17\n\x0f\x62inary_checksum\x18\x04 \x01(\t\x12V\n\x1bworker_version_capabilities\x18\x05 \x01(\x0b\x32\x31.temporal.api.common.v1.WorkerVersionCapabilities"\xca\x06\n\x1dPollWorkflowTaskQueueResponse\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12!\n\x19previous_started_event_id\x18\x04 \x01(\x03\x12\x18\n\x10started_event_id\x18\x05 \x01(\x03\x12\x0f\n\x07\x61ttempt\x18\x06 \x01(\x05\x12\x1a\n\x12\x62\x61\x63klog_count_hint\x18\x07 \x01(\x03\x12\x31\n\x07history\x18\x08 \x01(\x0b\x32 .temporal.api.history.v1.History\x12\x17\n\x0fnext_page_token\x18\t \x01(\x0c\x12\x33\n\x05query\x18\n \x01(\x0b\x32$.temporal.api.query.v1.WorkflowQuery\x12K\n\x1dworkflow_execution_task_queue\x18\x0b \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12\x38\n\x0escheduled_time\x18\x0c \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x36\n\x0cstarted_time\x18\r \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\\\n\x07queries\x18\x0e \x03(\x0b\x32K.temporal.api.workflowservice.v1.PollWorkflowTaskQueueResponse.QueriesEntry\x12\x33\n\x08messages\x18\x0f \x03(\x0b\x32!.temporal.api.protocol.v1.Message\x1aT\n\x0cQueriesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x33\n\x05value\x18\x02 \x01(\x0b\x32$.temporal.api.query.v1.WorkflowQuery:\x02\x38\x01"\xa4\x06\n#RespondWorkflowTaskCompletedRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x32\n\x08\x63ommands\x18\x02 \x03(\x0b\x32 .temporal.api.command.v1.Command\x12\x10\n\x08identity\x18\x03 \x01(\t\x12O\n\x11sticky_attributes\x18\x04 \x01(\x0b\x32\x34.temporal.api.taskqueue.v1.StickyExecutionAttributes\x12 \n\x18return_new_workflow_task\x18\x05 \x01(\x08\x12&\n\x1e\x66orce_create_new_workflow_task\x18\x06 \x01(\x08\x12\x17\n\x0f\x62inary_checksum\x18\x07 \x01(\t\x12m\n\rquery_results\x18\x08 \x03(\x0b\x32V.temporal.api.workflowservice.v1.RespondWorkflowTaskCompletedRequest.QueryResultsEntry\x12\x11\n\tnamespace\x18\t \x01(\t\x12H\n\x14worker_version_stamp\x18\n \x01(\x0b\x32*.temporal.api.common.v1.WorkerVersionStamp\x12\x33\n\x08messages\x18\x0b \x03(\x0b\x32!.temporal.api.protocol.v1.Message\x12H\n\x0csdk_metadata\x18\x0c \x01(\x0b\x32\x32.temporal.api.sdk.v1.WorkflowTaskCompletedMetadata\x12\x43\n\x11metering_metadata\x18\r \x01(\x0b\x32(.temporal.api.common.v1.MeteringMetadata\x1a_\n\x11QueryResultsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x39\n\x05value\x18\x02 \x01(\x0b\x32*.temporal.api.query.v1.WorkflowQueryResult:\x02\x38\x01"\xf5\x01\n$RespondWorkflowTaskCompletedResponse\x12U\n\rworkflow_task\x18\x01 \x01(\x0b\x32>.temporal.api.workflowservice.v1.PollWorkflowTaskQueueResponse\x12V\n\x0e\x61\x63tivity_tasks\x18\x02 \x03(\x0b\x32>.temporal.api.workflowservice.v1.PollActivityTaskQueueResponse\x12\x1e\n\x16reset_history_event_id\x18\x03 \x01(\x03"\xdf\x02\n RespondWorkflowTaskFailedRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12=\n\x05\x63\x61use\x18\x02 \x01(\x0e\x32..temporal.api.enums.v1.WorkflowTaskFailedCause\x12\x31\n\x07\x66\x61ilure\x18\x03 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x10\n\x08identity\x18\x04 \x01(\t\x12\x17\n\x0f\x62inary_checksum\x18\x05 \x01(\t\x12\x11\n\tnamespace\x18\x06 \x01(\t\x12\x33\n\x08messages\x18\x07 \x03(\x0b\x32!.temporal.api.protocol.v1.Message\x12\x42\n\x0eworker_version\x18\x08 \x01(\x0b\x32*.temporal.api.common.v1.WorkerVersionStamp"#\n!RespondWorkflowTaskFailedResponse"\xa0\x02\n\x1cPollActivityTaskQueueRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x38\n\ntask_queue\x18\x02 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12\x10\n\x08identity\x18\x03 \x01(\t\x12I\n\x13task_queue_metadata\x18\x04 \x01(\x0b\x32,.temporal.api.taskqueue.v1.TaskQueueMetadata\x12V\n\x1bworker_version_capabilities\x18\x05 \x01(\x0b\x32\x31.temporal.api.common.v1.WorkerVersionCapabilities"\x8c\x07\n\x1dPollActivityTaskQueueResponse\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x1a\n\x12workflow_namespace\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x45\n\x12workflow_execution\x18\x04 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\ractivity_type\x18\x05 \x01(\x0b\x32$.temporal.api.common.v1.ActivityType\x12\x13\n\x0b\x61\x63tivity_id\x18\x06 \x01(\t\x12.\n\x06header\x18\x07 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12/\n\x05input\x18\x08 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12;\n\x11heartbeat_details\x18\t \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x38\n\x0escheduled_time\x18\n \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12H\n\x1e\x63urrent_attempt_scheduled_time\x18\x0b \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x36\n\x0cstarted_time\x18\x0c \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x0f\n\x07\x61ttempt\x18\r \x01(\x05\x12\x42\n\x19schedule_to_close_timeout\x18\x0e \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12?\n\x16start_to_close_timeout\x18\x0f \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12:\n\x11heartbeat_timeout\x18\x10 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x39\n\x0cretry_policy\x18\x11 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy"\x90\x01\n"RecordActivityTaskHeartbeatRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x31\n\x07\x64\x65tails\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x11\n\tnamespace\x18\x04 \x01(\t"?\n#RecordActivityTaskHeartbeatResponse\x12\x18\n\x10\x63\x61ncel_requested\x18\x01 \x01(\x08"\xba\x01\n&RecordActivityTaskHeartbeatByIdRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x13\n\x0b\x61\x63tivity_id\x18\x04 \x01(\t\x12\x31\n\x07\x64\x65tails\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x06 \x01(\t"C\n\'RecordActivityTaskHeartbeatByIdResponse\x12\x18\n\x10\x63\x61ncel_requested\x18\x01 \x01(\x08"\xd4\x01\n#RespondActivityTaskCompletedRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x30\n\x06result\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x11\n\tnamespace\x18\x04 \x01(\t\x12\x42\n\x0eworker_version\x18\x05 \x01(\x0b\x32*.temporal.api.common.v1.WorkerVersionStamp"&\n$RespondActivityTaskCompletedResponse"\xba\x01\n\'RespondActivityTaskCompletedByIdRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x13\n\x0b\x61\x63tivity_id\x18\x04 \x01(\t\x12\x30\n\x06result\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x06 \x01(\t"*\n(RespondActivityTaskCompletedByIdResponse"\x94\x02\n RespondActivityTaskFailedRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x31\n\x07\x66\x61ilure\x18\x02 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x11\n\tnamespace\x18\x04 \x01(\t\x12@\n\x16last_heartbeat_details\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x42\n\x0eworker_version\x18\x06 \x01(\x0b\x32*.temporal.api.common.v1.WorkerVersionStamp"W\n!RespondActivityTaskFailedResponse\x12\x32\n\x08\x66\x61ilures\x18\x01 \x03(\x0b\x32 .temporal.api.failure.v1.Failure"\xfa\x01\n$RespondActivityTaskFailedByIdRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x13\n\x0b\x61\x63tivity_id\x18\x04 \x01(\t\x12\x31\n\x07\x66\x61ilure\x18\x05 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x10\n\x08identity\x18\x06 \x01(\t\x12@\n\x16last_heartbeat_details\x18\x07 \x01(\x0b\x32 .temporal.api.common.v1.Payloads"[\n%RespondActivityTaskFailedByIdResponse\x12\x32\n\x08\x66\x61ilures\x18\x01 \x03(\x0b\x32 .temporal.api.failure.v1.Failure"\xd4\x01\n"RespondActivityTaskCanceledRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x31\n\x07\x64\x65tails\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x11\n\tnamespace\x18\x04 \x01(\t\x12\x42\n\x0eworker_version\x18\x05 \x01(\x0b\x32*.temporal.api.common.v1.WorkerVersionStamp"%\n#RespondActivityTaskCanceledResponse"\xba\x01\n&RespondActivityTaskCanceledByIdRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x13\n\x0b\x61\x63tivity_id\x18\x04 \x01(\t\x12\x31\n\x07\x64\x65tails\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x06 \x01(\t")\n\'RespondActivityTaskCanceledByIdResponse"\xd7\x01\n%RequestCancelWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x12\n\nrequest_id\x18\x04 \x01(\t\x12\x1e\n\x16\x66irst_execution_run_id\x18\x05 \x01(\t\x12\x0e\n\x06reason\x18\x06 \x01(\t"(\n&RequestCancelWorkflowExecutionResponse"\xcc\x02\n\x1eSignalWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x13\n\x0bsignal_name\x18\x03 \x01(\t\x12/\n\x05input\x18\x04 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x05 \x01(\t\x12\x12\n\nrequest_id\x18\x06 \x01(\t\x12\x0f\n\x07\x63ontrol\x18\x07 \x01(\t\x12.\n\x06header\x18\x08 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12#\n\x1bskip_generate_workflow_task\x18\t \x01(\x08"!\n\x1fSignalWorkflowExecutionResponse"\xe8\x07\n\'SignalWithStartWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x10\n\x08identity\x18\t \x01(\t\x12\x12\n\nrequest_id\x18\n \x01(\t\x12N\n\x18workflow_id_reuse_policy\x18\x0b \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x13\n\x0bsignal_name\x18\x0c \x01(\t\x12\x36\n\x0csignal_input\x18\r \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x0f\n\x07\x63ontrol\x18\x0e \x01(\t\x12\x39\n\x0cretry_policy\x18\x0f \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\x10 \x01(\t\x12*\n\x04memo\x18\x11 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x12 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12.\n\x06header\x18\x13 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12=\n\x14workflow_start_delay\x18\x14 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12#\n\x1bskip_generate_workflow_task\x18\x15 \x01(\x08":\n(SignalWithStartWorkflowExecutionResponse\x12\x0e\n\x06run_id\x18\x01 \x01(\t"\x89\x02\n\x1dResetWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x0e\n\x06reason\x18\x03 \x01(\t\x12%\n\x1dworkflow_task_finish_event_id\x18\x04 \x01(\x03\x12\x12\n\nrequest_id\x18\x05 \x01(\t\x12\x43\n\x12reset_reapply_type\x18\x06 \x01(\x0e\x32\'.temporal.api.enums.v1.ResetReapplyType"0\n\x1eResetWorkflowExecutionResponse\x12\x0e\n\x06run_id\x18\x01 \x01(\t"\xf2\x01\n!TerminateWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x0e\n\x06reason\x18\x03 \x01(\t\x12\x31\n\x07\x64\x65tails\x18\x04 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x05 \x01(\t\x12\x1e\n\x16\x66irst_execution_run_id\x18\x06 \x01(\t"$\n"TerminateWorkflowExecutionResponse"z\n\x1e\x44\x65leteWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution"!\n\x1f\x44\x65leteWorkflowExecutionResponse"\xc9\x02\n!ListOpenWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x19\n\x11maximum_page_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\x42\n\x11start_time_filter\x18\x04 \x01(\x0b\x32\'.temporal.api.filter.v1.StartTimeFilter\x12K\n\x10\x65xecution_filter\x18\x05 \x01(\x0b\x32/.temporal.api.filter.v1.WorkflowExecutionFilterH\x00\x12\x41\n\x0btype_filter\x18\x06 \x01(\x0b\x32*.temporal.api.filter.v1.WorkflowTypeFilterH\x00\x42\t\n\x07\x66ilters"\x82\x01\n"ListOpenWorkflowExecutionsResponse\x12\x43\n\nexecutions\x18\x01 \x03(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"\x8a\x03\n#ListClosedWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x19\n\x11maximum_page_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\x42\n\x11start_time_filter\x18\x04 \x01(\x0b\x32\'.temporal.api.filter.v1.StartTimeFilter\x12K\n\x10\x65xecution_filter\x18\x05 \x01(\x0b\x32/.temporal.api.filter.v1.WorkflowExecutionFilterH\x00\x12\x41\n\x0btype_filter\x18\x06 \x01(\x0b\x32*.temporal.api.filter.v1.WorkflowTypeFilterH\x00\x12=\n\rstatus_filter\x18\x07 \x01(\x0b\x32$.temporal.api.filter.v1.StatusFilterH\x00\x42\t\n\x07\x66ilters"\x84\x01\n$ListClosedWorkflowExecutionsResponse\x12\x43\n\nexecutions\x18\x01 \x03(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"m\n\x1dListWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x11\n\tpage_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\r\n\x05query\x18\x04 \x01(\t"~\n\x1eListWorkflowExecutionsResponse\x12\x43\n\nexecutions\x18\x01 \x03(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"u\n%ListArchivedWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x11\n\tpage_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\r\n\x05query\x18\x04 \x01(\t"\x86\x01\n&ListArchivedWorkflowExecutionsResponse\x12\x43\n\nexecutions\x18\x01 \x03(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"m\n\x1dScanWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x11\n\tpage_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\r\n\x05query\x18\x04 \x01(\t"~\n\x1eScanWorkflowExecutionsResponse\x12\x43\n\nexecutions\x18\x01 \x03(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"B\n\x1e\x43ountWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\r\n\x05query\x18\x02 \x01(\t"0\n\x1f\x43ountWorkflowExecutionsResponse\x12\r\n\x05\x63ount\x18\x01 \x01(\x03"\x1c\n\x1aGetSearchAttributesRequest"\xc9\x01\n\x1bGetSearchAttributesResponse\x12T\n\x04keys\x18\x01 \x03(\x0b\x32\x46.temporal.api.workflowservice.v1.GetSearchAttributesResponse.KeysEntry\x1aT\n\tKeysEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x36\n\x05value\x18\x02 \x01(\x0e\x32\'.temporal.api.enums.v1.IndexedValueType:\x02\x38\x01"\xde\x01\n RespondQueryTaskCompletedRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12>\n\x0e\x63ompleted_type\x18\x02 \x01(\x0e\x32&.temporal.api.enums.v1.QueryResultType\x12\x36\n\x0cquery_result\x18\x03 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x15\n\rerror_message\x18\x04 \x01(\t\x12\x11\n\tnamespace\x18\x06 \x01(\tJ\x04\x08\x05\x10\x06"#\n!RespondQueryTaskCompletedResponse"n\n\x1bResetStickyTaskQueueRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution"\x1e\n\x1cResetStickyTaskQueueResponse"\xe9\x01\n\x14QueryWorkflowRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x33\n\x05query\x18\x03 \x01(\x0b\x32$.temporal.api.query.v1.WorkflowQuery\x12K\n\x16query_reject_condition\x18\x04 \x01(\x0e\x32+.temporal.api.enums.v1.QueryRejectCondition"\x8d\x01\n\x15QueryWorkflowResponse\x12\x36\n\x0cquery_result\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12<\n\x0equery_rejected\x18\x02 \x01(\x0b\x32$.temporal.api.query.v1.QueryRejected"s\n DescribeWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution"\xae\x03\n!DescribeWorkflowExecutionResponse\x12K\n\x10\x65xecution_config\x18\x01 \x01(\x0b\x32\x31.temporal.api.workflow.v1.WorkflowExecutionConfig\x12P\n\x17workflow_execution_info\x18\x02 \x01(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12I\n\x12pending_activities\x18\x03 \x03(\x0b\x32-.temporal.api.workflow.v1.PendingActivityInfo\x12M\n\x10pending_children\x18\x04 \x03(\x0b\x32\x33.temporal.api.workflow.v1.PendingChildExecutionInfo\x12P\n\x15pending_workflow_task\x18\x05 \x01(\x0b\x32\x31.temporal.api.workflow.v1.PendingWorkflowTaskInfo"\xc9\x01\n\x18\x44\x65scribeTaskQueueRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x38\n\ntask_queue\x18\x02 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12=\n\x0ftask_queue_type\x18\x03 \x01(\x0e\x32$.temporal.api.enums.v1.TaskQueueType\x12!\n\x19include_task_queue_status\x18\x04 \x01(\x08"\x9a\x01\n\x19\x44\x65scribeTaskQueueResponse\x12\x36\n\x07pollers\x18\x01 \x03(\x0b\x32%.temporal.api.taskqueue.v1.PollerInfo\x12\x45\n\x11task_queue_status\x18\x02 \x01(\x0b\x32*.temporal.api.taskqueue.v1.TaskQueueStatus"\x17\n\x15GetClusterInfoRequest"\x8b\x03\n\x16GetClusterInfoResponse\x12h\n\x11supported_clients\x18\x01 \x03(\x0b\x32M.temporal.api.workflowservice.v1.GetClusterInfoResponse.SupportedClientsEntry\x12\x16\n\x0eserver_version\x18\x02 \x01(\t\x12\x12\n\ncluster_id\x18\x03 \x01(\t\x12:\n\x0cversion_info\x18\x04 \x01(\x0b\x32$.temporal.api.version.v1.VersionInfo\x12\x14\n\x0c\x63luster_name\x18\x05 \x01(\t\x12\x1b\n\x13history_shard_count\x18\x06 \x01(\x05\x12\x19\n\x11persistence_store\x18\x07 \x01(\t\x12\x18\n\x10visibility_store\x18\x08 \x01(\t\x1a\x37\n\x15SupportedClientsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01"\x16\n\x14GetSystemInfoRequest"\xbc\x03\n\x15GetSystemInfoResponse\x12\x16\n\x0eserver_version\x18\x01 \x01(\t\x12Y\n\x0c\x63\x61pabilities\x18\x02 \x01(\x0b\x32\x43.temporal.api.workflowservice.v1.GetSystemInfoResponse.Capabilities\x1a\xaf\x02\n\x0c\x43\x61pabilities\x12\x1f\n\x17signal_and_query_header\x18\x01 \x01(\x08\x12&\n\x1einternal_error_differentiation\x18\x02 \x01(\x08\x12*\n"activity_failure_include_heartbeat\x18\x03 \x01(\x08\x12\x1a\n\x12supports_schedules\x18\x04 \x01(\x08\x12"\n\x1a\x65ncoded_failure_attributes\x18\x05 \x01(\x08\x12!\n\x19\x62uild_id_based_versioning\x18\x06 \x01(\x08\x12\x13\n\x0bupsert_memo\x18\x07 \x01(\x08\x12\x1c\n\x14\x65\x61ger_workflow_start\x18\x08 \x01(\x08\x12\x14\n\x0csdk_metadata\x18\t \x01(\x08"m\n\x1eListTaskQueuePartitionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x38\n\ntask_queue\x18\x02 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue"\xdf\x01\n\x1fListTaskQueuePartitionsResponse\x12]\n\x1e\x61\x63tivity_task_queue_partitions\x18\x01 \x03(\x0b\x32\x35.temporal.api.taskqueue.v1.TaskQueuePartitionMetadata\x12]\n\x1eworkflow_task_queue_partitions\x18\x02 \x03(\x0b\x32\x35.temporal.api.taskqueue.v1.TaskQueuePartitionMetadata"\xcc\x02\n\x15\x43reateScheduleRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t\x12\x34\n\x08schedule\x18\x03 \x01(\x0b\x32".temporal.api.schedule.v1.Schedule\x12>\n\rinitial_patch\x18\x04 \x01(\x0b\x32\'.temporal.api.schedule.v1.SchedulePatch\x12\x10\n\x08identity\x18\x05 \x01(\t\x12\x12\n\nrequest_id\x18\x06 \x01(\t\x12*\n\x04memo\x18\x07 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x08 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"0\n\x16\x43reateScheduleResponse\x12\x16\n\x0e\x63onflict_token\x18\x01 \x01(\x0c"A\n\x17\x44\x65scribeScheduleRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t"\x8f\x02\n\x18\x44\x65scribeScheduleResponse\x12\x34\n\x08schedule\x18\x01 \x01(\x0b\x32".temporal.api.schedule.v1.Schedule\x12\x34\n\x04info\x18\x02 \x01(\x0b\x32&.temporal.api.schedule.v1.ScheduleInfo\x12*\n\x04memo\x18\x03 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x04 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12\x16\n\x0e\x63onflict_token\x18\x05 \x01(\x0c"\xb3\x01\n\x15UpdateScheduleRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t\x12\x34\n\x08schedule\x18\x03 \x01(\x0b\x32".temporal.api.schedule.v1.Schedule\x12\x16\n\x0e\x63onflict_token\x18\x04 \x01(\x0c\x12\x10\n\x08identity\x18\x05 \x01(\t\x12\x12\n\nrequest_id\x18\x06 \x01(\t"\x18\n\x16UpdateScheduleResponse"\x9c\x01\n\x14PatchScheduleRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t\x12\x36\n\x05patch\x18\x03 \x01(\x0b\x32\'.temporal.api.schedule.v1.SchedulePatch\x12\x10\n\x08identity\x18\x04 \x01(\t\x12\x12\n\nrequest_id\x18\x05 \x01(\t"\x17\n\x15PatchScheduleResponse"\xb4\x01\n ListScheduleMatchingTimesRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t\x12\x34\n\nstart_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x32\n\x08\x65nd_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01"Y\n!ListScheduleMatchingTimesResponse\x12\x34\n\nstart_time\x18\x01 \x03(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01"Q\n\x15\x44\x65leteScheduleRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t\x12\x10\n\x08identity\x18\x03 \x01(\t"\x18\n\x16\x44\x65leteScheduleResponse"]\n\x14ListSchedulesRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x19\n\x11maximum_page_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c"p\n\x15ListSchedulesResponse\x12>\n\tschedules\x18\x01 \x03(\x0b\x32+.temporal.api.schedule.v1.ScheduleListEntry\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"\x86\x05\n\'UpdateWorkerBuildIdCompatibilityRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x12\n\ntask_queue\x18\x02 \x01(\t\x12-\n#add_new_build_id_in_new_default_set\x18\x03 \x01(\tH\x00\x12\x87\x01\n\x1b\x61\x64\x64_new_compatible_build_id\x18\x04 \x01(\x0b\x32`.temporal.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest.AddNewCompatibleVersionH\x00\x12!\n\x17promote_set_by_build_id\x18\x05 \x01(\tH\x00\x12%\n\x1bpromote_build_id_within_set\x18\x06 \x01(\tH\x00\x12h\n\nmerge_sets\x18\x07 \x01(\x0b\x32R.temporal.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest.MergeSetsH\x00\x1ao\n\x17\x41\x64\x64NewCompatibleVersion\x12\x14\n\x0cnew_build_id\x18\x01 \x01(\t\x12$\n\x1c\x65xisting_compatible_build_id\x18\x02 \x01(\t\x12\x18\n\x10make_set_default\x18\x03 \x01(\x08\x1aI\n\tMergeSets\x12\x1c\n\x14primary_set_build_id\x18\x01 \x01(\t\x12\x1e\n\x16secondary_set_build_id\x18\x02 \x01(\tB\x0b\n\toperation"B\n(UpdateWorkerBuildIdCompatibilityResponse\x12\x16\n\x0eversion_set_id\x18\x01 \x01(\t"_\n$GetWorkerBuildIdCompatibilityRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x12\n\ntask_queue\x18\x02 \x01(\t\x12\x10\n\x08max_sets\x18\x03 \x01(\x05"t\n%GetWorkerBuildIdCompatibilityResponse\x12K\n\x12major_version_sets\x18\x01 \x03(\x0b\x32/.temporal.api.taskqueue.v1.CompatibleVersionSet"\x9c\x01\n GetWorkerTaskReachabilityRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x11\n\tbuild_ids\x18\x02 \x03(\t\x12\x13\n\x0btask_queues\x18\x03 \x03(\t\x12=\n\x0creachability\x18\x04 \x01(\x0e\x32\'.temporal.api.enums.v1.TaskReachability"r\n!GetWorkerTaskReachabilityResponse\x12M\n\x15\x62uild_id_reachability\x18\x01 \x03(\x0b\x32..temporal.api.taskqueue.v1.BuildIdReachability"\x85\x02\n\x1eUpdateWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x1e\n\x16\x66irst_execution_run_id\x18\x03 \x01(\t\x12\x37\n\x0bwait_policy\x18\x04 \x01(\x0b\x32".temporal.api.update.v1.WaitPolicy\x12\x30\n\x07request\x18\x05 \x01(\x0b\x32\x1f.temporal.api.update.v1.Request"\x8a\x01\n\x1fUpdateWorkflowExecutionResponse\x12\x35\n\nupdate_ref\x18\x01 \x01(\x0b\x32!.temporal.api.update.v1.UpdateRef\x12\x30\n\x07outcome\x18\x02 \x01(\x0b\x32\x1f.temporal.api.update.v1.Outcome"\xba\x04\n\x1aStartBatchOperationRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x18\n\x10visibility_query\x18\x02 \x01(\t\x12\x0e\n\x06job_id\x18\x03 \x01(\t\x12\x0e\n\x06reason\x18\x04 \x01(\t\x12=\n\nexecutions\x18\x05 \x03(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12Q\n\x15termination_operation\x18\n \x01(\x0b\x32\x30.temporal.api.batch.v1.BatchOperationTerminationH\x00\x12G\n\x10signal_operation\x18\x0b \x01(\x0b\x32+.temporal.api.batch.v1.BatchOperationSignalH\x00\x12S\n\x16\x63\x61ncellation_operation\x18\x0c \x01(\x0b\x32\x31.temporal.api.batch.v1.BatchOperationCancellationH\x00\x12K\n\x12\x64\x65letion_operation\x18\r \x01(\x0b\x32-.temporal.api.batch.v1.BatchOperationDeletionH\x00\x12\x45\n\x0freset_operation\x18\x0e \x01(\x0b\x32*.temporal.api.batch.v1.BatchOperationResetH\x00\x42\x0b\n\toperation"\x1d\n\x1bStartBatchOperationResponse"`\n\x19StopBatchOperationRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x0e\n\x06job_id\x18\x02 \x01(\t\x12\x0e\n\x06reason\x18\x03 \x01(\t\x12\x10\n\x08identity\x18\x04 \x01(\t"\x1c\n\x1aStopBatchOperationResponse"B\n\x1d\x44\x65scribeBatchOperationRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x0e\n\x06job_id\x18\x02 \x01(\t"\x9e\x03\n\x1e\x44\x65scribeBatchOperationResponse\x12\x41\n\x0eoperation_type\x18\x01 \x01(\x0e\x32).temporal.api.enums.v1.BatchOperationType\x12\x0e\n\x06job_id\x18\x02 \x01(\t\x12\x39\n\x05state\x18\x03 \x01(\x0e\x32*.temporal.api.enums.v1.BatchOperationState\x12\x34\n\nstart_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x34\n\nclose_time\x18\x05 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x1d\n\x15total_operation_count\x18\x06 \x01(\x03\x12 \n\x18\x63omplete_operation_count\x18\x07 \x01(\x03\x12\x1f\n\x17\x66\x61ilure_operation_count\x18\x08 \x01(\x03\x12\x10\n\x08identity\x18\t \x01(\t\x12\x0e\n\x06reason\x18\n \x01(\t"[\n\x1aListBatchOperationsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x11\n\tpage_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c"y\n\x1bListBatchOperationsResponse\x12\x41\n\x0eoperation_info\x18\x01 \x03(\x0b\x32).temporal.api.batch.v1.BatchOperationInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"\xb9\x01\n"PollWorkflowExecutionUpdateRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x35\n\nupdate_ref\x18\x02 \x01(\x0b\x32!.temporal.api.update.v1.UpdateRef\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x37\n\x0bwait_policy\x18\x04 \x01(\x0b\x32".temporal.api.update.v1.WaitPolicy"W\n#PollWorkflowExecutionUpdateResponse\x12\x30\n\x07outcome\x18\x01 \x01(\x0b\x32\x1f.temporal.api.update.v1.OutcomeB\xbe\x01\n"io.temporal.api.workflowservice.v1B\x14RequestResponseProtoP\x01Z5go.temporal.io/api/workflowservice/v1;workflowservice\xaa\x02!Temporalio.Api.WorkflowService.V1\xea\x02$Temporalio::Api::WorkflowService::V1b\x06proto3'
 )
 
 
 _REGISTERNAMESPACEREQUEST = DESCRIPTOR.message_types_by_name["RegisterNamespaceRequest"]
 _REGISTERNAMESPACEREQUEST_DATAENTRY = _REGISTERNAMESPACEREQUEST.nested_types_by_name[
     "DataEntry"
 ]
@@ -357,31 +357,32 @@
     "UpdateWorkerBuildIdCompatibilityRequest"
 ]
 _UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST_ADDNEWCOMPATIBLEVERSION = (
     _UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST.nested_types_by_name[
         "AddNewCompatibleVersion"
     ]
 )
+_UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST_MERGESETS = (
+    _UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST.nested_types_by_name["MergeSets"]
+)
 _UPDATEWORKERBUILDIDCOMPATIBILITYRESPONSE = DESCRIPTOR.message_types_by_name[
     "UpdateWorkerBuildIdCompatibilityResponse"
 ]
 _GETWORKERBUILDIDCOMPATIBILITYREQUEST = DESCRIPTOR.message_types_by_name[
     "GetWorkerBuildIdCompatibilityRequest"
 ]
 _GETWORKERBUILDIDCOMPATIBILITYRESPONSE = DESCRIPTOR.message_types_by_name[
     "GetWorkerBuildIdCompatibilityResponse"
 ]
-_GETWORKERBUILDIDCOMPATIBILITYRESPONSE_RETIREMENTCANDIDATE = (
-    _GETWORKERBUILDIDCOMPATIBILITYRESPONSE.nested_types_by_name["RetirementCandidate"]
-)
-_GETWORKERBUILDIDCOMPATIBILITYRESPONSE_VERSIONSWITHCOMPATIBLEPOLLERS = (
-    _GETWORKERBUILDIDCOMPATIBILITYRESPONSE.nested_types_by_name[
-        "VersionsWithCompatiblePollers"
-    ]
-)
+_GETWORKERTASKREACHABILITYREQUEST = DESCRIPTOR.message_types_by_name[
+    "GetWorkerTaskReachabilityRequest"
+]
+_GETWORKERTASKREACHABILITYRESPONSE = DESCRIPTOR.message_types_by_name[
+    "GetWorkerTaskReachabilityResponse"
+]
 _UPDATEWORKFLOWEXECUTIONREQUEST = DESCRIPTOR.message_types_by_name[
     "UpdateWorkflowExecutionRequest"
 ]
 _UPDATEWORKFLOWEXECUTIONRESPONSE = DESCRIPTOR.message_types_by_name[
     "UpdateWorkflowExecutionResponse"
 ]
 _STARTBATCHOPERATIONREQUEST = DESCRIPTOR.message_types_by_name[
@@ -1539,21 +1540,31 @@
             (_message.Message,),
             {
                 "DESCRIPTOR": _UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST_ADDNEWCOMPATIBLEVERSION,
                 "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
                 # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest.AddNewCompatibleVersion)
             },
         ),
+        "MergeSets": _reflection.GeneratedProtocolMessageType(
+            "MergeSets",
+            (_message.Message,),
+            {
+                "DESCRIPTOR": _UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST_MERGESETS,
+                "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
+                # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest.MergeSets)
+            },
+        ),
         "DESCRIPTOR": _UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST,
         "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
         # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest)
     },
 )
 _sym_db.RegisterMessage(UpdateWorkerBuildIdCompatibilityRequest)
 _sym_db.RegisterMessage(UpdateWorkerBuildIdCompatibilityRequest.AddNewCompatibleVersion)
+_sym_db.RegisterMessage(UpdateWorkerBuildIdCompatibilityRequest.MergeSets)
 
 UpdateWorkerBuildIdCompatibilityResponse = _reflection.GeneratedProtocolMessageType(
     "UpdateWorkerBuildIdCompatibilityResponse",
     (_message.Message,),
     {
         "DESCRIPTOR": _UPDATEWORKERBUILDIDCOMPATIBILITYRESPONSE,
         "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
@@ -1573,42 +1584,42 @@
 )
 _sym_db.RegisterMessage(GetWorkerBuildIdCompatibilityRequest)
 
 GetWorkerBuildIdCompatibilityResponse = _reflection.GeneratedProtocolMessageType(
     "GetWorkerBuildIdCompatibilityResponse",
     (_message.Message,),
     {
-        "RetirementCandidate": _reflection.GeneratedProtocolMessageType(
-            "RetirementCandidate",
-            (_message.Message,),
-            {
-                "DESCRIPTOR": _GETWORKERBUILDIDCOMPATIBILITYRESPONSE_RETIREMENTCANDIDATE,
-                "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
-                # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.GetWorkerBuildIdCompatibilityResponse.RetirementCandidate)
-            },
-        ),
-        "VersionsWithCompatiblePollers": _reflection.GeneratedProtocolMessageType(
-            "VersionsWithCompatiblePollers",
-            (_message.Message,),
-            {
-                "DESCRIPTOR": _GETWORKERBUILDIDCOMPATIBILITYRESPONSE_VERSIONSWITHCOMPATIBLEPOLLERS,
-                "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
-                # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.GetWorkerBuildIdCompatibilityResponse.VersionsWithCompatiblePollers)
-            },
-        ),
         "DESCRIPTOR": _GETWORKERBUILDIDCOMPATIBILITYRESPONSE,
         "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
         # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.GetWorkerBuildIdCompatibilityResponse)
     },
 )
 _sym_db.RegisterMessage(GetWorkerBuildIdCompatibilityResponse)
-_sym_db.RegisterMessage(GetWorkerBuildIdCompatibilityResponse.RetirementCandidate)
-_sym_db.RegisterMessage(
-    GetWorkerBuildIdCompatibilityResponse.VersionsWithCompatiblePollers
+
+GetWorkerTaskReachabilityRequest = _reflection.GeneratedProtocolMessageType(
+    "GetWorkerTaskReachabilityRequest",
+    (_message.Message,),
+    {
+        "DESCRIPTOR": _GETWORKERTASKREACHABILITYREQUEST,
+        "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
+        # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.GetWorkerTaskReachabilityRequest)
+    },
 )
+_sym_db.RegisterMessage(GetWorkerTaskReachabilityRequest)
+
+GetWorkerTaskReachabilityResponse = _reflection.GeneratedProtocolMessageType(
+    "GetWorkerTaskReachabilityResponse",
+    (_message.Message,),
+    {
+        "DESCRIPTOR": _GETWORKERTASKREACHABILITYRESPONSE,
+        "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
+        # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.GetWorkerTaskReachabilityResponse)
+    },
+)
+_sym_db.RegisterMessage(GetWorkerTaskReachabilityResponse)
 
 UpdateWorkflowExecutionRequest = _reflection.GeneratedProtocolMessageType(
     "UpdateWorkflowExecutionRequest",
     (_message.Message,),
     {
         "DESCRIPTOR": _UPDATEWORKFLOWEXECUTIONREQUEST,
         "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
@@ -1908,211 +1919,209 @@
     _RESPONDWORKFLOWTASKCOMPLETEDREQUEST._serialized_start = 6302
     _RESPONDWORKFLOWTASKCOMPLETEDREQUEST._serialized_end = 7106
     _RESPONDWORKFLOWTASKCOMPLETEDREQUEST_QUERYRESULTSENTRY._serialized_start = 7011
     _RESPONDWORKFLOWTASKCOMPLETEDREQUEST_QUERYRESULTSENTRY._serialized_end = 7106
     _RESPONDWORKFLOWTASKCOMPLETEDRESPONSE._serialized_start = 7109
     _RESPONDWORKFLOWTASKCOMPLETEDRESPONSE._serialized_end = 7354
     _RESPONDWORKFLOWTASKFAILEDREQUEST._serialized_start = 7357
-    _RESPONDWORKFLOWTASKFAILEDREQUEST._serialized_end = 7640
-    _RESPONDWORKFLOWTASKFAILEDRESPONSE._serialized_start = 7642
-    _RESPONDWORKFLOWTASKFAILEDRESPONSE._serialized_end = 7677
-    _POLLACTIVITYTASKQUEUEREQUEST._serialized_start = 7680
-    _POLLACTIVITYTASKQUEUEREQUEST._serialized_end = 7968
-    _POLLACTIVITYTASKQUEUERESPONSE._serialized_start = 7971
-    _POLLACTIVITYTASKQUEUERESPONSE._serialized_end = 8879
-    _RECORDACTIVITYTASKHEARTBEATREQUEST._serialized_start = 8882
-    _RECORDACTIVITYTASKHEARTBEATREQUEST._serialized_end = 9026
-    _RECORDACTIVITYTASKHEARTBEATRESPONSE._serialized_start = 9028
-    _RECORDACTIVITYTASKHEARTBEATRESPONSE._serialized_end = 9091
-    _RECORDACTIVITYTASKHEARTBEATBYIDREQUEST._serialized_start = 9094
-    _RECORDACTIVITYTASKHEARTBEATBYIDREQUEST._serialized_end = 9280
-    _RECORDACTIVITYTASKHEARTBEATBYIDRESPONSE._serialized_start = 9282
-    _RECORDACTIVITYTASKHEARTBEATBYIDRESPONSE._serialized_end = 9349
-    _RESPONDACTIVITYTASKCOMPLETEDREQUEST._serialized_start = 9352
-    _RESPONDACTIVITYTASKCOMPLETEDREQUEST._serialized_end = 9496
-    _RESPONDACTIVITYTASKCOMPLETEDRESPONSE._serialized_start = 9498
-    _RESPONDACTIVITYTASKCOMPLETEDRESPONSE._serialized_end = 9536
-    _RESPONDACTIVITYTASKCOMPLETEDBYIDREQUEST._serialized_start = 9539
-    _RESPONDACTIVITYTASKCOMPLETEDBYIDREQUEST._serialized_end = 9725
-    _RESPONDACTIVITYTASKCOMPLETEDBYIDRESPONSE._serialized_start = 9727
-    _RESPONDACTIVITYTASKCOMPLETEDBYIDRESPONSE._serialized_end = 9769
-    _RESPONDACTIVITYTASKFAILEDREQUEST._serialized_start = 9772
-    _RESPONDACTIVITYTASKFAILEDREQUEST._serialized_end = 9980
-    _RESPONDACTIVITYTASKFAILEDRESPONSE._serialized_start = 9982
-    _RESPONDACTIVITYTASKFAILEDRESPONSE._serialized_end = 10069
-    _RESPONDACTIVITYTASKFAILEDBYIDREQUEST._serialized_start = 10072
-    _RESPONDACTIVITYTASKFAILEDBYIDREQUEST._serialized_end = 10322
-    _RESPONDACTIVITYTASKFAILEDBYIDRESPONSE._serialized_start = 10324
-    _RESPONDACTIVITYTASKFAILEDBYIDRESPONSE._serialized_end = 10415
-    _RESPONDACTIVITYTASKCANCELEDREQUEST._serialized_start = 10418
-    _RESPONDACTIVITYTASKCANCELEDREQUEST._serialized_end = 10562
-    _RESPONDACTIVITYTASKCANCELEDRESPONSE._serialized_start = 10564
-    _RESPONDACTIVITYTASKCANCELEDRESPONSE._serialized_end = 10601
-    _RESPONDACTIVITYTASKCANCELEDBYIDREQUEST._serialized_start = 10604
-    _RESPONDACTIVITYTASKCANCELEDBYIDREQUEST._serialized_end = 10790
-    _RESPONDACTIVITYTASKCANCELEDBYIDRESPONSE._serialized_start = 10792
-    _RESPONDACTIVITYTASKCANCELEDBYIDRESPONSE._serialized_end = 10833
-    _REQUESTCANCELWORKFLOWEXECUTIONREQUEST._serialized_start = 10836
-    _REQUESTCANCELWORKFLOWEXECUTIONREQUEST._serialized_end = 11051
-    _REQUESTCANCELWORKFLOWEXECUTIONRESPONSE._serialized_start = 11053
-    _REQUESTCANCELWORKFLOWEXECUTIONRESPONSE._serialized_end = 11093
-    _SIGNALWORKFLOWEXECUTIONREQUEST._serialized_start = 11096
-    _SIGNALWORKFLOWEXECUTIONREQUEST._serialized_end = 11428
-    _SIGNALWORKFLOWEXECUTIONRESPONSE._serialized_start = 11430
-    _SIGNALWORKFLOWEXECUTIONRESPONSE._serialized_end = 11463
-    _SIGNALWITHSTARTWORKFLOWEXECUTIONREQUEST._serialized_start = 11466
-    _SIGNALWITHSTARTWORKFLOWEXECUTIONREQUEST._serialized_end = 12466
-    _SIGNALWITHSTARTWORKFLOWEXECUTIONRESPONSE._serialized_start = 12468
-    _SIGNALWITHSTARTWORKFLOWEXECUTIONRESPONSE._serialized_end = 12526
-    _RESETWORKFLOWEXECUTIONREQUEST._serialized_start = 12529
-    _RESETWORKFLOWEXECUTIONREQUEST._serialized_end = 12794
-    _RESETWORKFLOWEXECUTIONRESPONSE._serialized_start = 12796
-    _RESETWORKFLOWEXECUTIONRESPONSE._serialized_end = 12844
-    _TERMINATEWORKFLOWEXECUTIONREQUEST._serialized_start = 12847
-    _TERMINATEWORKFLOWEXECUTIONREQUEST._serialized_end = 13089
-    _TERMINATEWORKFLOWEXECUTIONRESPONSE._serialized_start = 13091
-    _TERMINATEWORKFLOWEXECUTIONRESPONSE._serialized_end = 13127
-    _DELETEWORKFLOWEXECUTIONREQUEST._serialized_start = 13129
-    _DELETEWORKFLOWEXECUTIONREQUEST._serialized_end = 13251
-    _DELETEWORKFLOWEXECUTIONRESPONSE._serialized_start = 13253
-    _DELETEWORKFLOWEXECUTIONRESPONSE._serialized_end = 13286
-    _LISTOPENWORKFLOWEXECUTIONSREQUEST._serialized_start = 13289
-    _LISTOPENWORKFLOWEXECUTIONSREQUEST._serialized_end = 13618
-    _LISTOPENWORKFLOWEXECUTIONSRESPONSE._serialized_start = 13621
-    _LISTOPENWORKFLOWEXECUTIONSRESPONSE._serialized_end = 13751
-    _LISTCLOSEDWORKFLOWEXECUTIONSREQUEST._serialized_start = 13754
-    _LISTCLOSEDWORKFLOWEXECUTIONSREQUEST._serialized_end = 14148
-    _LISTCLOSEDWORKFLOWEXECUTIONSRESPONSE._serialized_start = 14151
-    _LISTCLOSEDWORKFLOWEXECUTIONSRESPONSE._serialized_end = 14283
-    _LISTWORKFLOWEXECUTIONSREQUEST._serialized_start = 14285
-    _LISTWORKFLOWEXECUTIONSREQUEST._serialized_end = 14394
-    _LISTWORKFLOWEXECUTIONSRESPONSE._serialized_start = 14396
-    _LISTWORKFLOWEXECUTIONSRESPONSE._serialized_end = 14522
-    _LISTARCHIVEDWORKFLOWEXECUTIONSREQUEST._serialized_start = 14524
-    _LISTARCHIVEDWORKFLOWEXECUTIONSREQUEST._serialized_end = 14641
-    _LISTARCHIVEDWORKFLOWEXECUTIONSRESPONSE._serialized_start = 14644
-    _LISTARCHIVEDWORKFLOWEXECUTIONSRESPONSE._serialized_end = 14778
-    _SCANWORKFLOWEXECUTIONSREQUEST._serialized_start = 14780
-    _SCANWORKFLOWEXECUTIONSREQUEST._serialized_end = 14889
-    _SCANWORKFLOWEXECUTIONSRESPONSE._serialized_start = 14891
-    _SCANWORKFLOWEXECUTIONSRESPONSE._serialized_end = 15017
-    _COUNTWORKFLOWEXECUTIONSREQUEST._serialized_start = 15019
-    _COUNTWORKFLOWEXECUTIONSREQUEST._serialized_end = 15085
-    _COUNTWORKFLOWEXECUTIONSRESPONSE._serialized_start = 15087
-    _COUNTWORKFLOWEXECUTIONSRESPONSE._serialized_end = 15135
-    _GETSEARCHATTRIBUTESREQUEST._serialized_start = 15137
-    _GETSEARCHATTRIBUTESREQUEST._serialized_end = 15165
-    _GETSEARCHATTRIBUTESRESPONSE._serialized_start = 15168
-    _GETSEARCHATTRIBUTESRESPONSE._serialized_end = 15369
-    _GETSEARCHATTRIBUTESRESPONSE_KEYSENTRY._serialized_start = 15285
-    _GETSEARCHATTRIBUTESRESPONSE_KEYSENTRY._serialized_end = 15369
-    _RESPONDQUERYTASKCOMPLETEDREQUEST._serialized_start = 15372
-    _RESPONDQUERYTASKCOMPLETEDREQUEST._serialized_end = 15594
-    _RESPONDQUERYTASKCOMPLETEDRESPONSE._serialized_start = 15596
-    _RESPONDQUERYTASKCOMPLETEDRESPONSE._serialized_end = 15631
-    _RESETSTICKYTASKQUEUEREQUEST._serialized_start = 15633
-    _RESETSTICKYTASKQUEUEREQUEST._serialized_end = 15743
-    _RESETSTICKYTASKQUEUERESPONSE._serialized_start = 15745
-    _RESETSTICKYTASKQUEUERESPONSE._serialized_end = 15775
-    _QUERYWORKFLOWREQUEST._serialized_start = 15778
-    _QUERYWORKFLOWREQUEST._serialized_end = 16011
-    _QUERYWORKFLOWRESPONSE._serialized_start = 16014
-    _QUERYWORKFLOWRESPONSE._serialized_end = 16155
-    _DESCRIBEWORKFLOWEXECUTIONREQUEST._serialized_start = 16157
-    _DESCRIBEWORKFLOWEXECUTIONREQUEST._serialized_end = 16272
-    _DESCRIBEWORKFLOWEXECUTIONRESPONSE._serialized_start = 16275
-    _DESCRIBEWORKFLOWEXECUTIONRESPONSE._serialized_end = 16705
-    _DESCRIBETASKQUEUEREQUEST._serialized_start = 16708
-    _DESCRIBETASKQUEUEREQUEST._serialized_end = 16909
-    _DESCRIBETASKQUEUERESPONSE._serialized_start = 16912
-    _DESCRIBETASKQUEUERESPONSE._serialized_end = 17066
-    _GETCLUSTERINFOREQUEST._serialized_start = 17068
-    _GETCLUSTERINFOREQUEST._serialized_end = 17091
-    _GETCLUSTERINFORESPONSE._serialized_start = 17094
-    _GETCLUSTERINFORESPONSE._serialized_end = 17489
-    _GETCLUSTERINFORESPONSE_SUPPORTEDCLIENTSENTRY._serialized_start = 17434
-    _GETCLUSTERINFORESPONSE_SUPPORTEDCLIENTSENTRY._serialized_end = 17489
-    _GETSYSTEMINFOREQUEST._serialized_start = 17491
-    _GETSYSTEMINFOREQUEST._serialized_end = 17513
-    _GETSYSTEMINFORESPONSE._serialized_start = 17516
-    _GETSYSTEMINFORESPONSE._serialized_end = 17960
-    _GETSYSTEMINFORESPONSE_CAPABILITIES._serialized_start = 17657
-    _GETSYSTEMINFORESPONSE_CAPABILITIES._serialized_end = 17960
-    _LISTTASKQUEUEPARTITIONSREQUEST._serialized_start = 17962
-    _LISTTASKQUEUEPARTITIONSREQUEST._serialized_end = 18071
-    _LISTTASKQUEUEPARTITIONSRESPONSE._serialized_start = 18074
-    _LISTTASKQUEUEPARTITIONSRESPONSE._serialized_end = 18297
-    _CREATESCHEDULEREQUEST._serialized_start = 18300
-    _CREATESCHEDULEREQUEST._serialized_end = 18632
-    _CREATESCHEDULERESPONSE._serialized_start = 18634
-    _CREATESCHEDULERESPONSE._serialized_end = 18682
-    _DESCRIBESCHEDULEREQUEST._serialized_start = 18684
-    _DESCRIBESCHEDULEREQUEST._serialized_end = 18749
-    _DESCRIBESCHEDULERESPONSE._serialized_start = 18752
-    _DESCRIBESCHEDULERESPONSE._serialized_end = 19023
-    _UPDATESCHEDULEREQUEST._serialized_start = 19026
-    _UPDATESCHEDULEREQUEST._serialized_end = 19205
-    _UPDATESCHEDULERESPONSE._serialized_start = 19207
-    _UPDATESCHEDULERESPONSE._serialized_end = 19231
-    _PATCHSCHEDULEREQUEST._serialized_start = 19234
-    _PATCHSCHEDULEREQUEST._serialized_end = 19390
-    _PATCHSCHEDULERESPONSE._serialized_start = 19392
-    _PATCHSCHEDULERESPONSE._serialized_end = 19415
-    _LISTSCHEDULEMATCHINGTIMESREQUEST._serialized_start = 19418
-    _LISTSCHEDULEMATCHINGTIMESREQUEST._serialized_end = 19598
-    _LISTSCHEDULEMATCHINGTIMESRESPONSE._serialized_start = 19600
-    _LISTSCHEDULEMATCHINGTIMESRESPONSE._serialized_end = 19689
-    _DELETESCHEDULEREQUEST._serialized_start = 19691
-    _DELETESCHEDULEREQUEST._serialized_end = 19772
-    _DELETESCHEDULERESPONSE._serialized_start = 19774
-    _DELETESCHEDULERESPONSE._serialized_end = 19798
-    _LISTSCHEDULESREQUEST._serialized_start = 19800
-    _LISTSCHEDULESREQUEST._serialized_end = 19893
-    _LISTSCHEDULESRESPONSE._serialized_start = 19895
-    _LISTSCHEDULESRESPONSE._serialized_end = 20007
-    _UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST._serialized_start = 20010
-    _UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST._serialized_end = 20475
+    _RESPONDWORKFLOWTASKFAILEDREQUEST._serialized_end = 7708
+    _RESPONDWORKFLOWTASKFAILEDRESPONSE._serialized_start = 7710
+    _RESPONDWORKFLOWTASKFAILEDRESPONSE._serialized_end = 7745
+    _POLLACTIVITYTASKQUEUEREQUEST._serialized_start = 7748
+    _POLLACTIVITYTASKQUEUEREQUEST._serialized_end = 8036
+    _POLLACTIVITYTASKQUEUERESPONSE._serialized_start = 8039
+    _POLLACTIVITYTASKQUEUERESPONSE._serialized_end = 8947
+    _RECORDACTIVITYTASKHEARTBEATREQUEST._serialized_start = 8950
+    _RECORDACTIVITYTASKHEARTBEATREQUEST._serialized_end = 9094
+    _RECORDACTIVITYTASKHEARTBEATRESPONSE._serialized_start = 9096
+    _RECORDACTIVITYTASKHEARTBEATRESPONSE._serialized_end = 9159
+    _RECORDACTIVITYTASKHEARTBEATBYIDREQUEST._serialized_start = 9162
+    _RECORDACTIVITYTASKHEARTBEATBYIDREQUEST._serialized_end = 9348
+    _RECORDACTIVITYTASKHEARTBEATBYIDRESPONSE._serialized_start = 9350
+    _RECORDACTIVITYTASKHEARTBEATBYIDRESPONSE._serialized_end = 9417
+    _RESPONDACTIVITYTASKCOMPLETEDREQUEST._serialized_start = 9420
+    _RESPONDACTIVITYTASKCOMPLETEDREQUEST._serialized_end = 9632
+    _RESPONDACTIVITYTASKCOMPLETEDRESPONSE._serialized_start = 9634
+    _RESPONDACTIVITYTASKCOMPLETEDRESPONSE._serialized_end = 9672
+    _RESPONDACTIVITYTASKCOMPLETEDBYIDREQUEST._serialized_start = 9675
+    _RESPONDACTIVITYTASKCOMPLETEDBYIDREQUEST._serialized_end = 9861
+    _RESPONDACTIVITYTASKCOMPLETEDBYIDRESPONSE._serialized_start = 9863
+    _RESPONDACTIVITYTASKCOMPLETEDBYIDRESPONSE._serialized_end = 9905
+    _RESPONDACTIVITYTASKFAILEDREQUEST._serialized_start = 9908
+    _RESPONDACTIVITYTASKFAILEDREQUEST._serialized_end = 10184
+    _RESPONDACTIVITYTASKFAILEDRESPONSE._serialized_start = 10186
+    _RESPONDACTIVITYTASKFAILEDRESPONSE._serialized_end = 10273
+    _RESPONDACTIVITYTASKFAILEDBYIDREQUEST._serialized_start = 10276
+    _RESPONDACTIVITYTASKFAILEDBYIDREQUEST._serialized_end = 10526
+    _RESPONDACTIVITYTASKFAILEDBYIDRESPONSE._serialized_start = 10528
+    _RESPONDACTIVITYTASKFAILEDBYIDRESPONSE._serialized_end = 10619
+    _RESPONDACTIVITYTASKCANCELEDREQUEST._serialized_start = 10622
+    _RESPONDACTIVITYTASKCANCELEDREQUEST._serialized_end = 10834
+    _RESPONDACTIVITYTASKCANCELEDRESPONSE._serialized_start = 10836
+    _RESPONDACTIVITYTASKCANCELEDRESPONSE._serialized_end = 10873
+    _RESPONDACTIVITYTASKCANCELEDBYIDREQUEST._serialized_start = 10876
+    _RESPONDACTIVITYTASKCANCELEDBYIDREQUEST._serialized_end = 11062
+    _RESPONDACTIVITYTASKCANCELEDBYIDRESPONSE._serialized_start = 11064
+    _RESPONDACTIVITYTASKCANCELEDBYIDRESPONSE._serialized_end = 11105
+    _REQUESTCANCELWORKFLOWEXECUTIONREQUEST._serialized_start = 11108
+    _REQUESTCANCELWORKFLOWEXECUTIONREQUEST._serialized_end = 11323
+    _REQUESTCANCELWORKFLOWEXECUTIONRESPONSE._serialized_start = 11325
+    _REQUESTCANCELWORKFLOWEXECUTIONRESPONSE._serialized_end = 11365
+    _SIGNALWORKFLOWEXECUTIONREQUEST._serialized_start = 11368
+    _SIGNALWORKFLOWEXECUTIONREQUEST._serialized_end = 11700
+    _SIGNALWORKFLOWEXECUTIONRESPONSE._serialized_start = 11702
+    _SIGNALWORKFLOWEXECUTIONRESPONSE._serialized_end = 11735
+    _SIGNALWITHSTARTWORKFLOWEXECUTIONREQUEST._serialized_start = 11738
+    _SIGNALWITHSTARTWORKFLOWEXECUTIONREQUEST._serialized_end = 12738
+    _SIGNALWITHSTARTWORKFLOWEXECUTIONRESPONSE._serialized_start = 12740
+    _SIGNALWITHSTARTWORKFLOWEXECUTIONRESPONSE._serialized_end = 12798
+    _RESETWORKFLOWEXECUTIONREQUEST._serialized_start = 12801
+    _RESETWORKFLOWEXECUTIONREQUEST._serialized_end = 13066
+    _RESETWORKFLOWEXECUTIONRESPONSE._serialized_start = 13068
+    _RESETWORKFLOWEXECUTIONRESPONSE._serialized_end = 13116
+    _TERMINATEWORKFLOWEXECUTIONREQUEST._serialized_start = 13119
+    _TERMINATEWORKFLOWEXECUTIONREQUEST._serialized_end = 13361
+    _TERMINATEWORKFLOWEXECUTIONRESPONSE._serialized_start = 13363
+    _TERMINATEWORKFLOWEXECUTIONRESPONSE._serialized_end = 13399
+    _DELETEWORKFLOWEXECUTIONREQUEST._serialized_start = 13401
+    _DELETEWORKFLOWEXECUTIONREQUEST._serialized_end = 13523
+    _DELETEWORKFLOWEXECUTIONRESPONSE._serialized_start = 13525
+    _DELETEWORKFLOWEXECUTIONRESPONSE._serialized_end = 13558
+    _LISTOPENWORKFLOWEXECUTIONSREQUEST._serialized_start = 13561
+    _LISTOPENWORKFLOWEXECUTIONSREQUEST._serialized_end = 13890
+    _LISTOPENWORKFLOWEXECUTIONSRESPONSE._serialized_start = 13893
+    _LISTOPENWORKFLOWEXECUTIONSRESPONSE._serialized_end = 14023
+    _LISTCLOSEDWORKFLOWEXECUTIONSREQUEST._serialized_start = 14026
+    _LISTCLOSEDWORKFLOWEXECUTIONSREQUEST._serialized_end = 14420
+    _LISTCLOSEDWORKFLOWEXECUTIONSRESPONSE._serialized_start = 14423
+    _LISTCLOSEDWORKFLOWEXECUTIONSRESPONSE._serialized_end = 14555
+    _LISTWORKFLOWEXECUTIONSREQUEST._serialized_start = 14557
+    _LISTWORKFLOWEXECUTIONSREQUEST._serialized_end = 14666
+    _LISTWORKFLOWEXECUTIONSRESPONSE._serialized_start = 14668
+    _LISTWORKFLOWEXECUTIONSRESPONSE._serialized_end = 14794
+    _LISTARCHIVEDWORKFLOWEXECUTIONSREQUEST._serialized_start = 14796
+    _LISTARCHIVEDWORKFLOWEXECUTIONSREQUEST._serialized_end = 14913
+    _LISTARCHIVEDWORKFLOWEXECUTIONSRESPONSE._serialized_start = 14916
+    _LISTARCHIVEDWORKFLOWEXECUTIONSRESPONSE._serialized_end = 15050
+    _SCANWORKFLOWEXECUTIONSREQUEST._serialized_start = 15052
+    _SCANWORKFLOWEXECUTIONSREQUEST._serialized_end = 15161
+    _SCANWORKFLOWEXECUTIONSRESPONSE._serialized_start = 15163
+    _SCANWORKFLOWEXECUTIONSRESPONSE._serialized_end = 15289
+    _COUNTWORKFLOWEXECUTIONSREQUEST._serialized_start = 15291
+    _COUNTWORKFLOWEXECUTIONSREQUEST._serialized_end = 15357
+    _COUNTWORKFLOWEXECUTIONSRESPONSE._serialized_start = 15359
+    _COUNTWORKFLOWEXECUTIONSRESPONSE._serialized_end = 15407
+    _GETSEARCHATTRIBUTESREQUEST._serialized_start = 15409
+    _GETSEARCHATTRIBUTESREQUEST._serialized_end = 15437
+    _GETSEARCHATTRIBUTESRESPONSE._serialized_start = 15440
+    _GETSEARCHATTRIBUTESRESPONSE._serialized_end = 15641
+    _GETSEARCHATTRIBUTESRESPONSE_KEYSENTRY._serialized_start = 15557
+    _GETSEARCHATTRIBUTESRESPONSE_KEYSENTRY._serialized_end = 15641
+    _RESPONDQUERYTASKCOMPLETEDREQUEST._serialized_start = 15644
+    _RESPONDQUERYTASKCOMPLETEDREQUEST._serialized_end = 15866
+    _RESPONDQUERYTASKCOMPLETEDRESPONSE._serialized_start = 15868
+    _RESPONDQUERYTASKCOMPLETEDRESPONSE._serialized_end = 15903
+    _RESETSTICKYTASKQUEUEREQUEST._serialized_start = 15905
+    _RESETSTICKYTASKQUEUEREQUEST._serialized_end = 16015
+    _RESETSTICKYTASKQUEUERESPONSE._serialized_start = 16017
+    _RESETSTICKYTASKQUEUERESPONSE._serialized_end = 16047
+    _QUERYWORKFLOWREQUEST._serialized_start = 16050
+    _QUERYWORKFLOWREQUEST._serialized_end = 16283
+    _QUERYWORKFLOWRESPONSE._serialized_start = 16286
+    _QUERYWORKFLOWRESPONSE._serialized_end = 16427
+    _DESCRIBEWORKFLOWEXECUTIONREQUEST._serialized_start = 16429
+    _DESCRIBEWORKFLOWEXECUTIONREQUEST._serialized_end = 16544
+    _DESCRIBEWORKFLOWEXECUTIONRESPONSE._serialized_start = 16547
+    _DESCRIBEWORKFLOWEXECUTIONRESPONSE._serialized_end = 16977
+    _DESCRIBETASKQUEUEREQUEST._serialized_start = 16980
+    _DESCRIBETASKQUEUEREQUEST._serialized_end = 17181
+    _DESCRIBETASKQUEUERESPONSE._serialized_start = 17184
+    _DESCRIBETASKQUEUERESPONSE._serialized_end = 17338
+    _GETCLUSTERINFOREQUEST._serialized_start = 17340
+    _GETCLUSTERINFOREQUEST._serialized_end = 17363
+    _GETCLUSTERINFORESPONSE._serialized_start = 17366
+    _GETCLUSTERINFORESPONSE._serialized_end = 17761
+    _GETCLUSTERINFORESPONSE_SUPPORTEDCLIENTSENTRY._serialized_start = 17706
+    _GETCLUSTERINFORESPONSE_SUPPORTEDCLIENTSENTRY._serialized_end = 17761
+    _GETSYSTEMINFOREQUEST._serialized_start = 17763
+    _GETSYSTEMINFOREQUEST._serialized_end = 17785
+    _GETSYSTEMINFORESPONSE._serialized_start = 17788
+    _GETSYSTEMINFORESPONSE._serialized_end = 18232
+    _GETSYSTEMINFORESPONSE_CAPABILITIES._serialized_start = 17929
+    _GETSYSTEMINFORESPONSE_CAPABILITIES._serialized_end = 18232
+    _LISTTASKQUEUEPARTITIONSREQUEST._serialized_start = 18234
+    _LISTTASKQUEUEPARTITIONSREQUEST._serialized_end = 18343
+    _LISTTASKQUEUEPARTITIONSRESPONSE._serialized_start = 18346
+    _LISTTASKQUEUEPARTITIONSRESPONSE._serialized_end = 18569
+    _CREATESCHEDULEREQUEST._serialized_start = 18572
+    _CREATESCHEDULEREQUEST._serialized_end = 18904
+    _CREATESCHEDULERESPONSE._serialized_start = 18906
+    _CREATESCHEDULERESPONSE._serialized_end = 18954
+    _DESCRIBESCHEDULEREQUEST._serialized_start = 18956
+    _DESCRIBESCHEDULEREQUEST._serialized_end = 19021
+    _DESCRIBESCHEDULERESPONSE._serialized_start = 19024
+    _DESCRIBESCHEDULERESPONSE._serialized_end = 19295
+    _UPDATESCHEDULEREQUEST._serialized_start = 19298
+    _UPDATESCHEDULEREQUEST._serialized_end = 19477
+    _UPDATESCHEDULERESPONSE._serialized_start = 19479
+    _UPDATESCHEDULERESPONSE._serialized_end = 19503
+    _PATCHSCHEDULEREQUEST._serialized_start = 19506
+    _PATCHSCHEDULEREQUEST._serialized_end = 19662
+    _PATCHSCHEDULERESPONSE._serialized_start = 19664
+    _PATCHSCHEDULERESPONSE._serialized_end = 19687
+    _LISTSCHEDULEMATCHINGTIMESREQUEST._serialized_start = 19690
+    _LISTSCHEDULEMATCHINGTIMESREQUEST._serialized_end = 19870
+    _LISTSCHEDULEMATCHINGTIMESRESPONSE._serialized_start = 19872
+    _LISTSCHEDULEMATCHINGTIMESRESPONSE._serialized_end = 19961
+    _DELETESCHEDULEREQUEST._serialized_start = 19963
+    _DELETESCHEDULEREQUEST._serialized_end = 20044
+    _DELETESCHEDULERESPONSE._serialized_start = 20046
+    _DELETESCHEDULERESPONSE._serialized_end = 20070
+    _LISTSCHEDULESREQUEST._serialized_start = 20072
+    _LISTSCHEDULESREQUEST._serialized_end = 20165
+    _LISTSCHEDULESRESPONSE._serialized_start = 20167
+    _LISTSCHEDULESRESPONSE._serialized_end = 20279
+    _UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST._serialized_start = 20282
+    _UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST._serialized_end = 20928
     _UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST_ADDNEWCOMPATIBLEVERSION._serialized_start = (
-        20351
+        20729
     )
     _UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST_ADDNEWCOMPATIBLEVERSION._serialized_end = (
-        20462
-    )
-    _UPDATEWORKERBUILDIDCOMPATIBILITYRESPONSE._serialized_start = 20477
-    _UPDATEWORKERBUILDIDCOMPATIBILITYRESPONSE._serialized_end = 20543
-    _GETWORKERBUILDIDCOMPATIBILITYREQUEST._serialized_start = 20546
-    _GETWORKERBUILDIDCOMPATIBILITYREQUEST._serialized_end = 20718
-    _GETWORKERBUILDIDCOMPATIBILITYRESPONSE._serialized_start = 20721
-    _GETWORKERBUILDIDCOMPATIBILITYRESPONSE._serialized_end = 21353
-    _GETWORKERBUILDIDCOMPATIBILITYRESPONSE_RETIREMENTCANDIDATE._serialized_start = 21103
-    _GETWORKERBUILDIDCOMPATIBILITYRESPONSE_RETIREMENTCANDIDATE._serialized_end = 21234
-    _GETWORKERBUILDIDCOMPATIBILITYRESPONSE_VERSIONSWITHCOMPATIBLEPOLLERS._serialized_start = (
-        21236
-    )
-    _GETWORKERBUILDIDCOMPATIBILITYRESPONSE_VERSIONSWITHCOMPATIBLEPOLLERS._serialized_end = (
-        21353
+        20840
     )
-    _UPDATEWORKFLOWEXECUTIONREQUEST._serialized_start = 21356
-    _UPDATEWORKFLOWEXECUTIONREQUEST._serialized_end = 21617
-    _UPDATEWORKFLOWEXECUTIONRESPONSE._serialized_start = 21620
-    _UPDATEWORKFLOWEXECUTIONRESPONSE._serialized_end = 21758
-    _STARTBATCHOPERATIONREQUEST._serialized_start = 21761
-    _STARTBATCHOPERATIONREQUEST._serialized_end = 22260
-    _STARTBATCHOPERATIONRESPONSE._serialized_start = 22262
-    _STARTBATCHOPERATIONRESPONSE._serialized_end = 22291
-    _STOPBATCHOPERATIONREQUEST._serialized_start = 22293
-    _STOPBATCHOPERATIONREQUEST._serialized_end = 22389
-    _STOPBATCHOPERATIONRESPONSE._serialized_start = 22391
-    _STOPBATCHOPERATIONRESPONSE._serialized_end = 22419
-    _DESCRIBEBATCHOPERATIONREQUEST._serialized_start = 22421
-    _DESCRIBEBATCHOPERATIONREQUEST._serialized_end = 22487
-    _DESCRIBEBATCHOPERATIONRESPONSE._serialized_start = 22490
-    _DESCRIBEBATCHOPERATIONRESPONSE._serialized_end = 22904
-    _LISTBATCHOPERATIONSREQUEST._serialized_start = 22906
-    _LISTBATCHOPERATIONSREQUEST._serialized_end = 22997
-    _LISTBATCHOPERATIONSRESPONSE._serialized_start = 22999
-    _LISTBATCHOPERATIONSRESPONSE._serialized_end = 23120
-    _POLLWORKFLOWEXECUTIONUPDATEREQUEST._serialized_start = 23123
-    _POLLWORKFLOWEXECUTIONUPDATEREQUEST._serialized_end = 23308
-    _POLLWORKFLOWEXECUTIONUPDATERESPONSE._serialized_start = 23310
-    _POLLWORKFLOWEXECUTIONUPDATERESPONSE._serialized_end = 23397
+    _UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST_MERGESETS._serialized_start = 20842
+    _UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST_MERGESETS._serialized_end = 20915
+    _UPDATEWORKERBUILDIDCOMPATIBILITYRESPONSE._serialized_start = 20930
+    _UPDATEWORKERBUILDIDCOMPATIBILITYRESPONSE._serialized_end = 20996
+    _GETWORKERBUILDIDCOMPATIBILITYREQUEST._serialized_start = 20998
+    _GETWORKERBUILDIDCOMPATIBILITYREQUEST._serialized_end = 21093
+    _GETWORKERBUILDIDCOMPATIBILITYRESPONSE._serialized_start = 21095
+    _GETWORKERBUILDIDCOMPATIBILITYRESPONSE._serialized_end = 21211
+    _GETWORKERTASKREACHABILITYREQUEST._serialized_start = 21214
+    _GETWORKERTASKREACHABILITYREQUEST._serialized_end = 21370
+    _GETWORKERTASKREACHABILITYRESPONSE._serialized_start = 21372
+    _GETWORKERTASKREACHABILITYRESPONSE._serialized_end = 21486
+    _UPDATEWORKFLOWEXECUTIONREQUEST._serialized_start = 21489
+    _UPDATEWORKFLOWEXECUTIONREQUEST._serialized_end = 21750
+    _UPDATEWORKFLOWEXECUTIONRESPONSE._serialized_start = 21753
+    _UPDATEWORKFLOWEXECUTIONRESPONSE._serialized_end = 21891
+    _STARTBATCHOPERATIONREQUEST._serialized_start = 21894
+    _STARTBATCHOPERATIONREQUEST._serialized_end = 22464
+    _STARTBATCHOPERATIONRESPONSE._serialized_start = 22466
+    _STARTBATCHOPERATIONRESPONSE._serialized_end = 22495
+    _STOPBATCHOPERATIONREQUEST._serialized_start = 22497
+    _STOPBATCHOPERATIONREQUEST._serialized_end = 22593
+    _STOPBATCHOPERATIONRESPONSE._serialized_start = 22595
+    _STOPBATCHOPERATIONRESPONSE._serialized_end = 22623
+    _DESCRIBEBATCHOPERATIONREQUEST._serialized_start = 22625
+    _DESCRIBEBATCHOPERATIONREQUEST._serialized_end = 22691
+    _DESCRIBEBATCHOPERATIONRESPONSE._serialized_start = 22694
+    _DESCRIBEBATCHOPERATIONRESPONSE._serialized_end = 23108
+    _LISTBATCHOPERATIONSREQUEST._serialized_start = 23110
+    _LISTBATCHOPERATIONSREQUEST._serialized_end = 23201
+    _LISTBATCHOPERATIONSRESPONSE._serialized_start = 23203
+    _LISTBATCHOPERATIONSRESPONSE._serialized_end = 23324
+    _POLLWORKFLOWEXECUTIONUPDATEREQUEST._serialized_start = 23327
+    _POLLWORKFLOWEXECUTIONUPDATEREQUEST._serialized_end = 23512
+    _POLLWORKFLOWEXECUTIONUPDATERESPONSE._serialized_start = 23514
+    _POLLWORKFLOWEXECUTIONUPDATERESPONSE._serialized_end = 23601
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.2.0/temporalio/api/workflowservice/v1/request_response_pb2.pyi` & `temporalio-1.3.0/temporalio/api/workflowservice/v1/request_response_pb2.pyi`

 * *Files 2% similar despite different names*

```diff
@@ -944,26 +944,24 @@
     WORKER_VERSION_CAPABILITIES_FIELD_NUMBER: builtins.int
     namespace: builtins.str
     @property
     def task_queue(self) -> temporalio.api.taskqueue.v1.message_pb2.TaskQueue: ...
     identity: builtins.str
     """The identity of the worker/client who is polling this task queue"""
     binary_checksum: builtins.str
-    """Each worker process should provide an ID unique to the specific set of code it is running
+    """DEPRECATED since 1.21 - use `worker_version_capabilities` instead.
+    Each worker process should provide an ID unique to the specific set of code it is running
     "checksum" in this field name isn't very accurate, it should be though of as an id.
     """
     @property
     def worker_version_capabilities(
         self,
     ) -> temporalio.api.common.v1.message_pb2.WorkerVersionCapabilities:
-        """If set, the worker is opting in to versioning and wishes to only
-        receive tasks that are considered compatible with the version capabilities provided.
-        Doing so only makes sense in conjunction with the `UpdateWorkerBuildIdCompatibility` API.
-        When this field has a `worker_build_id`, and `binary_checksum` is not
-        set, that value should also be considered as the `binary_checksum`.
+        """Information about this worker's build identifier and if it is choosing to use the versioning
+        feature. See the `WorkerVersionCapabilities` docstring for more.
         """
     def __init__(
         self,
         *,
         namespace: builtins.str = ...,
         task_queue: temporalio.api.taskqueue.v1.message_pb2.TaskQueue | None = ...,
         identity: builtins.str = ...,
@@ -1253,32 +1251,32 @@
     force_create_new_workflow_task: builtins.bool
     """Can be used to *force* creation of a new workflow task, even if no commands have resolved or
     one would not otherwise have been generated. This is used when the worker knows it is doing
     something useful, but cannot complete it within the workflow task timeout. Local activities
     which run for longer than the task timeout being the prime example.
     """
     binary_checksum: builtins.str
-    """Worker process' unique binary id"""
+    """DEPRECATED since 1.21 - use `worker_version_stamp` instead.
+    Worker process' unique binary id
+    """
     @property
     def query_results(
         self,
     ) -> google.protobuf.internal.containers.MessageMap[
         builtins.str, temporalio.api.query.v1.message_pb2.WorkflowQueryResult
     ]:
         """Responses to the `queries` field in the task being responded to"""
     namespace: builtins.str
     @property
     def worker_version_stamp(
         self,
     ) -> temporalio.api.common.v1.message_pb2.WorkerVersionStamp:
-        """If using versioning, the worker uses this field to indicate what version(s) it used to
-        process the task. When this field has a `worker_build_id`, and `binary_checksum` is not set,
-        that value should also be considered as the `binary_checksum`. Leaving this field empty when
-        replying to a task has had this field previously populated in history in an error, and such
-        a completion will be rejected.
+        """Version info of the worker who processed this task. This message's `build_id` field should
+        always be set by SDKs. Workers opting into versioning will also set the `use_versioning`
+        field to true. See message docstrings for more.
         """
     @property
     def messages(
         self,
     ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
         temporalio.api.protocol.v1.message_pb2.Message
     ]:
@@ -1420,51 +1418,65 @@
     TASK_TOKEN_FIELD_NUMBER: builtins.int
     CAUSE_FIELD_NUMBER: builtins.int
     FAILURE_FIELD_NUMBER: builtins.int
     IDENTITY_FIELD_NUMBER: builtins.int
     BINARY_CHECKSUM_FIELD_NUMBER: builtins.int
     NAMESPACE_FIELD_NUMBER: builtins.int
     MESSAGES_FIELD_NUMBER: builtins.int
+    WORKER_VERSION_FIELD_NUMBER: builtins.int
     task_token: builtins.bytes
     """The task token as received in `PollWorkflowTaskQueueResponse`"""
     cause: temporalio.api.enums.v1.failed_cause_pb2.WorkflowTaskFailedCause.ValueType
     """Why did the task fail? It's important to note that many of the variants in this enum cannot
     apply to worker responses. See the type's doc for more.
     """
     @property
     def failure(self) -> temporalio.api.failure.v1.message_pb2.Failure:
         """Failure details"""
     identity: builtins.str
     """The identity of the worker/client"""
     binary_checksum: builtins.str
-    """Worker process' unique binary id"""
+    """DEPRECATED since 1.21 - use `worker_version_stamp` instead.
+    Worker process' unique binary id
+    """
     namespace: builtins.str
     @property
     def messages(
         self,
     ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
         temporalio.api.protocol.v1.message_pb2.Message
     ]:
         """Protocol messages piggybacking on a WFT as a transport"""
+    @property
+    def worker_version(self) -> temporalio.api.common.v1.message_pb2.WorkerVersionStamp:
+        """Version info of the worker who processed this task. This message's `build_id` field should
+        always be set by SDKs. Workers opting into versioning will also set the `use_versioning`
+        field to true. See message docstrings for more.
+        """
     def __init__(
         self,
         *,
         task_token: builtins.bytes = ...,
         cause: temporalio.api.enums.v1.failed_cause_pb2.WorkflowTaskFailedCause.ValueType = ...,
         failure: temporalio.api.failure.v1.message_pb2.Failure | None = ...,
         identity: builtins.str = ...,
         binary_checksum: builtins.str = ...,
         namespace: builtins.str = ...,
         messages: collections.abc.Iterable[
             temporalio.api.protocol.v1.message_pb2.Message
         ]
         | None = ...,
+        worker_version: temporalio.api.common.v1.message_pb2.WorkerVersionStamp
+        | None = ...,
     ) -> None: ...
     def HasField(
-        self, field_name: typing_extensions.Literal["failure", b"failure"]
+        self,
+        field_name: typing_extensions.Literal[
+            "failure", b"failure", "worker_version", b"worker_version"
+        ],
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
             "binary_checksum",
             b"binary_checksum",
             "cause",
@@ -1475,14 +1487,16 @@
             b"identity",
             "messages",
             b"messages",
             "namespace",
             b"namespace",
             "task_token",
             b"task_token",
+            "worker_version",
+            b"worker_version",
         ],
     ) -> None: ...
 
 global___RespondWorkflowTaskFailedRequest = RespondWorkflowTaskFailedRequest
 
 class RespondWorkflowTaskFailedResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -1510,17 +1524,16 @@
     def task_queue_metadata(
         self,
     ) -> temporalio.api.taskqueue.v1.message_pb2.TaskQueueMetadata: ...
     @property
     def worker_version_capabilities(
         self,
     ) -> temporalio.api.common.v1.message_pb2.WorkerVersionCapabilities:
-        """If set, the worker is opting in to versioning and wishes to only
-        receive tasks that are considered compatible with the capabilities provided.
-        Doing so only makes sense in conjunction with the `UpdateWorkerBuildIdCompatibility` API.
+        """Information about this worker's build identifier and if it is choosing to use the versioning
+        feature. See the `WorkerVersionCapabilities` docstring for more.
         """
     def __init__(
         self,
         *,
         namespace: builtins.str = ...,
         task_queue: temporalio.api.taskqueue.v1.message_pb2.TaskQueue | None = ...,
         identity: builtins.str = ...,
@@ -1882,44 +1895,58 @@
 class RespondActivityTaskCompletedRequest(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     TASK_TOKEN_FIELD_NUMBER: builtins.int
     RESULT_FIELD_NUMBER: builtins.int
     IDENTITY_FIELD_NUMBER: builtins.int
     NAMESPACE_FIELD_NUMBER: builtins.int
+    WORKER_VERSION_FIELD_NUMBER: builtins.int
     task_token: builtins.bytes
     """The task token as received in `PollActivityTaskQueueResponse`"""
     @property
     def result(self) -> temporalio.api.common.v1.message_pb2.Payloads:
         """The result of successfully executing the activity"""
     identity: builtins.str
     """The identity of the worker/client"""
     namespace: builtins.str
+    @property
+    def worker_version(self) -> temporalio.api.common.v1.message_pb2.WorkerVersionStamp:
+        """Version info of the worker who processed this task. This message's `build_id` field should
+        always be set by SDKs. Workers opting into versioning will also set the `use_versioning`
+        field to true. See message docstrings for more.
+        """
     def __init__(
         self,
         *,
         task_token: builtins.bytes = ...,
         result: temporalio.api.common.v1.message_pb2.Payloads | None = ...,
         identity: builtins.str = ...,
         namespace: builtins.str = ...,
+        worker_version: temporalio.api.common.v1.message_pb2.WorkerVersionStamp
+        | None = ...,
     ) -> None: ...
     def HasField(
-        self, field_name: typing_extensions.Literal["result", b"result"]
+        self,
+        field_name: typing_extensions.Literal[
+            "result", b"result", "worker_version", b"worker_version"
+        ],
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
             "identity",
             b"identity",
             "namespace",
             b"namespace",
             "result",
             b"result",
             "task_token",
             b"task_token",
+            "worker_version",
+            b"worker_version",
         ],
     ) -> None: ...
 
 global___RespondActivityTaskCompletedRequest = RespondActivityTaskCompletedRequest
 
 class RespondActivityTaskCompletedResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -2002,39 +2029,53 @@
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     TASK_TOKEN_FIELD_NUMBER: builtins.int
     FAILURE_FIELD_NUMBER: builtins.int
     IDENTITY_FIELD_NUMBER: builtins.int
     NAMESPACE_FIELD_NUMBER: builtins.int
     LAST_HEARTBEAT_DETAILS_FIELD_NUMBER: builtins.int
+    WORKER_VERSION_FIELD_NUMBER: builtins.int
     task_token: builtins.bytes
     """The task token as received in `PollActivityTaskQueueResponse`"""
     @property
     def failure(self) -> temporalio.api.failure.v1.message_pb2.Failure:
         """Detailed failure information"""
     identity: builtins.str
     """The identity of the worker/client"""
     namespace: builtins.str
     @property
     def last_heartbeat_details(self) -> temporalio.api.common.v1.message_pb2.Payloads:
         """Additional details to be stored as last activity heartbeat"""
+    @property
+    def worker_version(self) -> temporalio.api.common.v1.message_pb2.WorkerVersionStamp:
+        """Version info of the worker who processed this task. This message's `build_id` field should
+        always be set by SDKs. Workers opting into versioning will also set the `use_versioning`
+        field to true. See message docstrings for more.
+        """
     def __init__(
         self,
         *,
         task_token: builtins.bytes = ...,
         failure: temporalio.api.failure.v1.message_pb2.Failure | None = ...,
         identity: builtins.str = ...,
         namespace: builtins.str = ...,
         last_heartbeat_details: temporalio.api.common.v1.message_pb2.Payloads
         | None = ...,
+        worker_version: temporalio.api.common.v1.message_pb2.WorkerVersionStamp
+        | None = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
-            "failure", b"failure", "last_heartbeat_details", b"last_heartbeat_details"
+            "failure",
+            b"failure",
+            "last_heartbeat_details",
+            b"last_heartbeat_details",
+            "worker_version",
+            b"worker_version",
         ],
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
             "failure",
             b"failure",
@@ -2042,14 +2083,16 @@
             b"identity",
             "last_heartbeat_details",
             b"last_heartbeat_details",
             "namespace",
             b"namespace",
             "task_token",
             b"task_token",
+            "worker_version",
+            b"worker_version",
         ],
     ) -> None: ...
 
 global___RespondActivityTaskFailedRequest = RespondActivityTaskFailedRequest
 
 class RespondActivityTaskFailedResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -2174,44 +2217,58 @@
 class RespondActivityTaskCanceledRequest(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     TASK_TOKEN_FIELD_NUMBER: builtins.int
     DETAILS_FIELD_NUMBER: builtins.int
     IDENTITY_FIELD_NUMBER: builtins.int
     NAMESPACE_FIELD_NUMBER: builtins.int
+    WORKER_VERSION_FIELD_NUMBER: builtins.int
     task_token: builtins.bytes
     """The task token as received in `PollActivityTaskQueueResponse`"""
     @property
     def details(self) -> temporalio.api.common.v1.message_pb2.Payloads:
         """Serialized additional information to attach to the cancellation"""
     identity: builtins.str
     """The identity of the worker/client"""
     namespace: builtins.str
+    @property
+    def worker_version(self) -> temporalio.api.common.v1.message_pb2.WorkerVersionStamp:
+        """Version info of the worker who processed this task. This message's `build_id` field should
+        always be set by SDKs. Workers opting into versioning will also set the `use_versioning`
+        field to true. See message docstrings for more.
+        """
     def __init__(
         self,
         *,
         task_token: builtins.bytes = ...,
         details: temporalio.api.common.v1.message_pb2.Payloads | None = ...,
         identity: builtins.str = ...,
         namespace: builtins.str = ...,
+        worker_version: temporalio.api.common.v1.message_pb2.WorkerVersionStamp
+        | None = ...,
     ) -> None: ...
     def HasField(
-        self, field_name: typing_extensions.Literal["details", b"details"]
+        self,
+        field_name: typing_extensions.Literal[
+            "details", b"details", "worker_version", b"worker_version"
+        ],
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
             "details",
             b"details",
             "identity",
             b"identity",
             "namespace",
             b"namespace",
             "task_token",
             b"task_token",
+            "worker_version",
+            b"worker_version",
         ],
     ) -> None: ...
 
 global___RespondActivityTaskCanceledRequest = RespondActivityTaskCanceledRequest
 
 class RespondActivityTaskCanceledResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -4543,20 +4600,46 @@
                 "make_set_default",
                 b"make_set_default",
                 "new_build_id",
                 b"new_build_id",
             ],
         ) -> None: ...
 
+    class MergeSets(google.protobuf.message.Message):
+        DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+        PRIMARY_SET_BUILD_ID_FIELD_NUMBER: builtins.int
+        SECONDARY_SET_BUILD_ID_FIELD_NUMBER: builtins.int
+        primary_set_build_id: builtins.str
+        """A build ID in the set whose default will become the merged set default"""
+        secondary_set_build_id: builtins.str
+        """A build ID in the set which will be merged into the primary set"""
+        def __init__(
+            self,
+            *,
+            primary_set_build_id: builtins.str = ...,
+            secondary_set_build_id: builtins.str = ...,
+        ) -> None: ...
+        def ClearField(
+            self,
+            field_name: typing_extensions.Literal[
+                "primary_set_build_id",
+                b"primary_set_build_id",
+                "secondary_set_build_id",
+                b"secondary_set_build_id",
+            ],
+        ) -> None: ...
+
     NAMESPACE_FIELD_NUMBER: builtins.int
     TASK_QUEUE_FIELD_NUMBER: builtins.int
     ADD_NEW_BUILD_ID_IN_NEW_DEFAULT_SET_FIELD_NUMBER: builtins.int
     ADD_NEW_COMPATIBLE_BUILD_ID_FIELD_NUMBER: builtins.int
     PROMOTE_SET_BY_BUILD_ID_FIELD_NUMBER: builtins.int
     PROMOTE_BUILD_ID_WITHIN_SET_FIELD_NUMBER: builtins.int
+    MERGE_SETS_FIELD_NUMBER: builtins.int
     namespace: builtins.str
     task_queue: builtins.str
     """Must be set, the task queue to apply changes to. Because all workers on a given task queue
     must have the same set of workflow & activity implementations, there is no reason to specify
     a task queue type here.
     """
     add_new_build_id_in_new_default_set: builtins.str
@@ -4581,32 +4664,44 @@
     """
     promote_build_id_within_set: builtins.str
     """Promote an existing build id within some set to be the current default for that set.
 
     (-- api-linter: core::0140::prepositions=disabled
         aip.dev/not-precedent: Within makes perfect sense here. --)
     """
+    @property
+    def merge_sets(self) -> global___UpdateWorkerBuildIdCompatibilityRequest.MergeSets:
+        """Merge two existing sets together, thus declaring all build IDs in both sets compatible
+        with one another. The primary set's default will become the default for the merged set.
+        This is useful if you've accidentally declared a new ID as incompatible you meant to
+        declare as compatible. The unusual case of incomplete replication during failover could
+        also result in a split set, which this operation can repair.
+        """
     def __init__(
         self,
         *,
         namespace: builtins.str = ...,
         task_queue: builtins.str = ...,
         add_new_build_id_in_new_default_set: builtins.str = ...,
         add_new_compatible_build_id: global___UpdateWorkerBuildIdCompatibilityRequest.AddNewCompatibleVersion
         | None = ...,
         promote_set_by_build_id: builtins.str = ...,
         promote_build_id_within_set: builtins.str = ...,
+        merge_sets: global___UpdateWorkerBuildIdCompatibilityRequest.MergeSets
+        | None = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
             "add_new_build_id_in_new_default_set",
             b"add_new_build_id_in_new_default_set",
             "add_new_compatible_build_id",
             b"add_new_compatible_build_id",
+            "merge_sets",
+            b"merge_sets",
             "operation",
             b"operation",
             "promote_build_id_within_set",
             b"promote_build_id_within_set",
             "promote_set_by_build_id",
             b"promote_set_by_build_id",
         ],
@@ -4614,14 +4709,16 @@
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
             "add_new_build_id_in_new_default_set",
             b"add_new_build_id_in_new_default_set",
             "add_new_compatible_build_id",
             b"add_new_compatible_build_id",
+            "merge_sets",
+            b"merge_sets",
             "namespace",
             b"namespace",
             "operation",
             b"operation",
             "promote_build_id_within_set",
             b"promote_build_id_within_set",
             "promote_set_by_build_id",
@@ -4634,14 +4731,15 @@
         self, oneof_group: typing_extensions.Literal["operation", b"operation"]
     ) -> (
         typing_extensions.Literal[
             "add_new_build_id_in_new_default_set",
             "add_new_compatible_build_id",
             "promote_set_by_build_id",
             "promote_build_id_within_set",
+            "merge_sets",
         ]
         | None
     ): ...
 
 global___UpdateWorkerBuildIdCompatibilityRequest = (
     UpdateWorkerBuildIdCompatibilityRequest
 )
@@ -4673,195 +4771,170 @@
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAMESPACE_FIELD_NUMBER: builtins.int
     TASK_QUEUE_FIELD_NUMBER: builtins.int
     MAX_SETS_FIELD_NUMBER: builtins.int
-    INCLUDE_RETIREMENT_CANDIDATES_FIELD_NUMBER: builtins.int
-    INCLUDE_POLLER_COMPATIBILITY_FIELD_NUMBER: builtins.int
     namespace: builtins.str
     task_queue: builtins.str
     """Must be set, the task queue to interrogate about worker id compatibility."""
     max_sets: builtins.int
     """Limits how many compatible sets will be returned. Specify 1 to only return the current
     default major version set. 0 returns all sets.
     """
-    include_retirement_candidates: builtins.bool
-    """If set, the response will include information about worker versions which are ready to be
-    retired.
-    """
-    include_poller_compatibility: builtins.bool
-    """If set, the response will include information about which versions have open workflows, and
-    whether or not there are currently polling workers who are compatible with those versions.
-    """
     def __init__(
         self,
         *,
         namespace: builtins.str = ...,
         task_queue: builtins.str = ...,
         max_sets: builtins.int = ...,
-        include_retirement_candidates: builtins.bool = ...,
-        include_poller_compatibility: builtins.bool = ...,
     ) -> None: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
-            "include_poller_compatibility",
-            b"include_poller_compatibility",
-            "include_retirement_candidates",
-            b"include_retirement_candidates",
             "max_sets",
             b"max_sets",
             "namespace",
             b"namespace",
             "task_queue",
             b"task_queue",
         ],
     ) -> None: ...
 
 global___GetWorkerBuildIdCompatibilityRequest = GetWorkerBuildIdCompatibilityRequest
 
 class GetWorkerBuildIdCompatibilityResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    class RetirementCandidate(google.protobuf.message.Message):
-        DESCRIPTOR: google.protobuf.descriptor.Descriptor
-
-        BUILD_ID_FIELD_NUMBER: builtins.int
-        ALL_WORKFLOWS_ARE_ARCHIVED_FIELD_NUMBER: builtins.int
-        POLLERS_FIELD_NUMBER: builtins.int
-        build_id: builtins.str
-        """The worker build id which is ready for retirement"""
-        all_workflows_are_archived: builtins.bool
-        """If true, there are no open *or* closed workflows, meaning there is no reason at all
-        to keep the worker alive, not even to service queries on closed workflows. If not true,
-        then there are no open workflows, but some closed ones.
-        """
-        @property
-        def pollers(
-            self,
-        ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
-            temporalio.api.taskqueue.v1.message_pb2.PollerInfo
-        ]:
-            """Currently polling workers who match the build id ready for retirement"""
-        def __init__(
-            self,
-            *,
-            build_id: builtins.str = ...,
-            all_workflows_are_archived: builtins.bool = ...,
-            pollers: collections.abc.Iterable[
-                temporalio.api.taskqueue.v1.message_pb2.PollerInfo
-            ]
-            | None = ...,
-        ) -> None: ...
-        def ClearField(
-            self,
-            field_name: typing_extensions.Literal[
-                "all_workflows_are_archived",
-                b"all_workflows_are_archived",
-                "build_id",
-                b"build_id",
-                "pollers",
-                b"pollers",
-            ],
-        ) -> None: ...
-
-    class VersionsWithCompatiblePollers(google.protobuf.message.Message):
-        DESCRIPTOR: google.protobuf.descriptor.Descriptor
-
-        MOST_RECENT_BUILD_ID_FIELD_NUMBER: builtins.int
-        POLLERS_FIELD_NUMBER: builtins.int
-        most_recent_build_id: builtins.str
-        """The latest build id which completed a workflow task on some open workflow"""
-        @property
-        def pollers(
-            self,
-        ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
-            temporalio.api.taskqueue.v1.message_pb2.PollerInfo
-        ]:
-            """Currently polling workers who are compatible with `most_recent_build_id`."""
-        def __init__(
-            self,
-            *,
-            most_recent_build_id: builtins.str = ...,
-            pollers: collections.abc.Iterable[
-                temporalio.api.taskqueue.v1.message_pb2.PollerInfo
-            ]
-            | None = ...,
-        ) -> None: ...
-        def ClearField(
-            self,
-            field_name: typing_extensions.Literal[
-                "most_recent_build_id", b"most_recent_build_id", "pollers", b"pollers"
-            ],
-        ) -> None: ...
-
     MAJOR_VERSION_SETS_FIELD_NUMBER: builtins.int
-    RETIREMENT_CANDIDATES_FIELD_NUMBER: builtins.int
-    ACTIVE_VERSIONS_AND_POLLERS_FIELD_NUMBER: builtins.int
     @property
     def major_version_sets(
         self,
     ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
         temporalio.api.taskqueue.v1.message_pb2.CompatibleVersionSet
     ]:
         """Major version sets, in order from oldest to newest. The last element of the list will always
         be the current default major version. IE: New workflows will target the most recent version
         in that version set.
 
         There may be fewer sets returned than exist, if the request chose to limit this response.
         """
+    def __init__(
+        self,
+        *,
+        major_version_sets: collections.abc.Iterable[
+            temporalio.api.taskqueue.v1.message_pb2.CompatibleVersionSet
+        ]
+        | None = ...,
+    ) -> None: ...
+    def ClearField(
+        self,
+        field_name: typing_extensions.Literal[
+            "major_version_sets", b"major_version_sets"
+        ],
+    ) -> None: ...
+
+global___GetWorkerBuildIdCompatibilityResponse = GetWorkerBuildIdCompatibilityResponse
+
+class GetWorkerTaskReachabilityRequest(google.protobuf.message.Message):
+    DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+    NAMESPACE_FIELD_NUMBER: builtins.int
+    BUILD_IDS_FIELD_NUMBER: builtins.int
+    TASK_QUEUES_FIELD_NUMBER: builtins.int
+    REACHABILITY_FIELD_NUMBER: builtins.int
+    namespace: builtins.str
     @property
-    def retirement_candidates(
+    def build_ids(
+        self,
+    ) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
+        """Build ids to retrieve reachability for. An empty string will be interpreted as an unversioned worker.
+        The number of build ids that can be queried in a single API call is limited.
+        Open source users can adjust this limit by setting the server's dynamic config value for
+        `limit.reachabilityQueryBuildIds` with the caveat that this call can strain the visibility store.
+        """
+    @property
+    def task_queues(
         self,
-    ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
-        global___GetWorkerBuildIdCompatibilityResponse.RetirementCandidate
-    ]:
-        """A list of workers who are still live and polling the task queue, but may no longer be needed
-        to make progress on open workflows.
+    ) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
+        """Task queues to retrieve reachability for. Leave this empty to query for all task queues associated with given
+        build ids in the namespace.
+        Must specify at least one task queue if querying for an unversioned worker.
+        The number of task queues that the server will fetch reachability information for is limited.
+        See the `GetWorkerTaskReachabilityResponse` documentation for more information.
         """
+    reachability: temporalio.api.enums.v1.task_queue_pb2.TaskReachability.ValueType
+    """Type of reachability to query for.
+    `TASK_REACHABILITY_NEW_WORKFLOWS` is always returned in the response.
+    Use `TASK_REACHABILITY_EXISTING_WORKFLOWS` if your application needs to respond to queries on closed workflows.
+    Otherwise, use `TASK_REACHABILITY_OPEN_WORKFLOWS`. Default is `TASK_REACHABILITY_EXISTING_WORKFLOWS` if left
+    unspecified.
+    See the TaskReachability docstring for information about each enum variant.
+    """
+    def __init__(
+        self,
+        *,
+        namespace: builtins.str = ...,
+        build_ids: collections.abc.Iterable[builtins.str] | None = ...,
+        task_queues: collections.abc.Iterable[builtins.str] | None = ...,
+        reachability: temporalio.api.enums.v1.task_queue_pb2.TaskReachability.ValueType = ...,
+    ) -> None: ...
+    def ClearField(
+        self,
+        field_name: typing_extensions.Literal[
+            "build_ids",
+            b"build_ids",
+            "namespace",
+            b"namespace",
+            "reachability",
+            b"reachability",
+            "task_queues",
+            b"task_queues",
+        ],
+    ) -> None: ...
+
+global___GetWorkerTaskReachabilityRequest = GetWorkerTaskReachabilityRequest
+
+class GetWorkerTaskReachabilityResponse(google.protobuf.message.Message):
+    DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+    BUILD_ID_REACHABILITY_FIELD_NUMBER: builtins.int
     @property
-    def active_versions_and_pollers(
+    def build_id_reachability(
         self,
     ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
-        global___GetWorkerBuildIdCompatibilityResponse.VersionsWithCompatiblePollers
+        temporalio.api.taskqueue.v1.message_pb2.BuildIdReachability
     ]:
-        """A list of versions and pollers who are capable of processing tasks at that version (if any)
-        for which there are currently open workflows.
+        """Task reachability, broken down by build id and then task queue.
+        When requesting a large number of task queues or all task queues associated with the given build ids in a
+        namespace, all task queues will be listed in the response but some of them may not contain reachability
+        information due to a server enforced limit. When reaching the limit, task queues that reachability information
+        could not be retrieved for will be marked with a single TASK_REACHABILITY_UNSPECIFIED entry. The caller may issue
+        another call to get the reachability for those task queues.
+
+        Open source users can adjust this limit by setting the server's dynamic config value for
+        `limit.reachabilityTaskQueueScan` with the caveat that this call can strain the visibility store.
         """
     def __init__(
         self,
         *,
-        major_version_sets: collections.abc.Iterable[
-            temporalio.api.taskqueue.v1.message_pb2.CompatibleVersionSet
-        ]
-        | None = ...,
-        retirement_candidates: collections.abc.Iterable[
-            global___GetWorkerBuildIdCompatibilityResponse.RetirementCandidate
-        ]
-        | None = ...,
-        active_versions_and_pollers: collections.abc.Iterable[
-            global___GetWorkerBuildIdCompatibilityResponse.VersionsWithCompatiblePollers
+        build_id_reachability: collections.abc.Iterable[
+            temporalio.api.taskqueue.v1.message_pb2.BuildIdReachability
         ]
         | None = ...,
     ) -> None: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
-            "active_versions_and_pollers",
-            b"active_versions_and_pollers",
-            "major_version_sets",
-            b"major_version_sets",
-            "retirement_candidates",
-            b"retirement_candidates",
+            "build_id_reachability", b"build_id_reachability"
         ],
     ) -> None: ...
 
-global___GetWorkerBuildIdCompatibilityResponse = GetWorkerBuildIdCompatibilityResponse
+global___GetWorkerTaskReachabilityResponse = GetWorkerTaskReachabilityResponse
 
 class UpdateWorkflowExecutionRequest(google.protobuf.message.Message):
     """(-- api-linter: core::0134=disabled
     aip.dev/not-precedent: Update RPCs don't follow Google API format. --)
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -4978,14 +5051,15 @@
     JOB_ID_FIELD_NUMBER: builtins.int
     REASON_FIELD_NUMBER: builtins.int
     EXECUTIONS_FIELD_NUMBER: builtins.int
     TERMINATION_OPERATION_FIELD_NUMBER: builtins.int
     SIGNAL_OPERATION_FIELD_NUMBER: builtins.int
     CANCELLATION_OPERATION_FIELD_NUMBER: builtins.int
     DELETION_OPERATION_FIELD_NUMBER: builtins.int
+    RESET_OPERATION_FIELD_NUMBER: builtins.int
     namespace: builtins.str
     """Namespace that contains the batch operation"""
     visibility_query: builtins.str
     """Visibility query defines the the group of workflow to apply the batch operation
     This field and Executions are mutually exclusive
     """
     job_id: builtins.str
@@ -5013,14 +5087,18 @@
     def cancellation_operation(
         self,
     ) -> temporalio.api.batch.v1.message_pb2.BatchOperationCancellation: ...
     @property
     def deletion_operation(
         self,
     ) -> temporalio.api.batch.v1.message_pb2.BatchOperationDeletion: ...
+    @property
+    def reset_operation(
+        self,
+    ) -> temporalio.api.batch.v1.message_pb2.BatchOperationReset: ...
     def __init__(
         self,
         *,
         namespace: builtins.str = ...,
         visibility_query: builtins.str = ...,
         job_id: builtins.str = ...,
         reason: builtins.str = ...,
@@ -5032,24 +5110,28 @@
         | None = ...,
         signal_operation: temporalio.api.batch.v1.message_pb2.BatchOperationSignal
         | None = ...,
         cancellation_operation: temporalio.api.batch.v1.message_pb2.BatchOperationCancellation
         | None = ...,
         deletion_operation: temporalio.api.batch.v1.message_pb2.BatchOperationDeletion
         | None = ...,
+        reset_operation: temporalio.api.batch.v1.message_pb2.BatchOperationReset
+        | None = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
             "cancellation_operation",
             b"cancellation_operation",
             "deletion_operation",
             b"deletion_operation",
             "operation",
             b"operation",
+            "reset_operation",
+            b"reset_operation",
             "signal_operation",
             b"signal_operation",
             "termination_operation",
             b"termination_operation",
         ],
     ) -> builtins.bool: ...
     def ClearField(
@@ -5065,14 +5147,16 @@
             b"job_id",
             "namespace",
             b"namespace",
             "operation",
             b"operation",
             "reason",
             b"reason",
+            "reset_operation",
+            b"reset_operation",
             "signal_operation",
             b"signal_operation",
             "termination_operation",
             b"termination_operation",
             "visibility_query",
             b"visibility_query",
         ],
@@ -5081,14 +5165,15 @@
         self, oneof_group: typing_extensions.Literal["operation", b"operation"]
     ) -> (
         typing_extensions.Literal[
             "termination_operation",
             "signal_operation",
             "cancellation_operation",
             "deletion_operation",
+            "reset_operation",
         ]
         | None
     ): ...
 
 global___StartBatchOperationRequest = StartBatchOperationRequest
 
 class StartBatchOperationResponse(google.protobuf.message.Message):
```

### Comparing `temporalio-1.2.0/temporalio/api/workflowservice/v1/request_response_pb2_grpc.pyi` & `temporalio-1.3.0/temporalio/api/workflowservice/v1/request_response_pb2_grpc.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/workflowservice/v1/service_pb2.py` & `temporalio-1.3.0/temporalio/api/workflowservice/v1/service_pb2.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,18 +14,18 @@
 
 
 from temporalio.api.workflowservice.v1 import (
     request_response_pb2 as temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n-temporal/api/workflowservice/v1/service.proto\x12\x1ftemporal.api.workflowservice.v1\x1a\x36temporal/api/workflowservice/v1/request_response.proto2\xfe\x45\n\x0fWorkflowService\x12\x8c\x01\n\x11RegisterNamespace\x12\x39.temporal.api.workflowservice.v1.RegisterNamespaceRequest\x1a:.temporal.api.workflowservice.v1.RegisterNamespaceResponse"\x00\x12\x8c\x01\n\x11\x44\x65scribeNamespace\x12\x39.temporal.api.workflowservice.v1.DescribeNamespaceRequest\x1a:.temporal.api.workflowservice.v1.DescribeNamespaceResponse"\x00\x12\x83\x01\n\x0eListNamespaces\x12\x36.temporal.api.workflowservice.v1.ListNamespacesRequest\x1a\x37.temporal.api.workflowservice.v1.ListNamespacesResponse"\x00\x12\x86\x01\n\x0fUpdateNamespace\x12\x37.temporal.api.workflowservice.v1.UpdateNamespaceRequest\x1a\x38.temporal.api.workflowservice.v1.UpdateNamespaceResponse"\x00\x12\x8f\x01\n\x12\x44\x65precateNamespace\x12:.temporal.api.workflowservice.v1.DeprecateNamespaceRequest\x1a;.temporal.api.workflowservice.v1.DeprecateNamespaceResponse"\x00\x12\x9b\x01\n\x16StartWorkflowExecution\x12>.temporal.api.workflowservice.v1.StartWorkflowExecutionRequest\x1a?.temporal.api.workflowservice.v1.StartWorkflowExecutionResponse"\x00\x12\xaa\x01\n\x1bGetWorkflowExecutionHistory\x12\x43.temporal.api.workflowservice.v1.GetWorkflowExecutionHistoryRequest\x1a\x44.temporal.api.workflowservice.v1.GetWorkflowExecutionHistoryResponse"\x00\x12\xbf\x01\n"GetWorkflowExecutionHistoryReverse\x12J.temporal.api.workflowservice.v1.GetWorkflowExecutionHistoryReverseRequest\x1aK.temporal.api.workflowservice.v1.GetWorkflowExecutionHistoryReverseResponse"\x00\x12\x98\x01\n\x15PollWorkflowTaskQueue\x12=.temporal.api.workflowservice.v1.PollWorkflowTaskQueueRequest\x1a>.temporal.api.workflowservice.v1.PollWorkflowTaskQueueResponse"\x00\x12\xad\x01\n\x1cRespondWorkflowTaskCompleted\x12\x44.temporal.api.workflowservice.v1.RespondWorkflowTaskCompletedRequest\x1a\x45.temporal.api.workflowservice.v1.RespondWorkflowTaskCompletedResponse"\x00\x12\xa4\x01\n\x19RespondWorkflowTaskFailed\x12\x41.temporal.api.workflowservice.v1.RespondWorkflowTaskFailedRequest\x1a\x42.temporal.api.workflowservice.v1.RespondWorkflowTaskFailedResponse"\x00\x12\x98\x01\n\x15PollActivityTaskQueue\x12=.temporal.api.workflowservice.v1.PollActivityTaskQueueRequest\x1a>.temporal.api.workflowservice.v1.PollActivityTaskQueueResponse"\x00\x12\xaa\x01\n\x1bRecordActivityTaskHeartbeat\x12\x43.temporal.api.workflowservice.v1.RecordActivityTaskHeartbeatRequest\x1a\x44.temporal.api.workflowservice.v1.RecordActivityTaskHeartbeatResponse"\x00\x12\xb6\x01\n\x1fRecordActivityTaskHeartbeatById\x12G.temporal.api.workflowservice.v1.RecordActivityTaskHeartbeatByIdRequest\x1aH.temporal.api.workflowservice.v1.RecordActivityTaskHeartbeatByIdResponse"\x00\x12\xad\x01\n\x1cRespondActivityTaskCompleted\x12\x44.temporal.api.workflowservice.v1.RespondActivityTaskCompletedRequest\x1a\x45.temporal.api.workflowservice.v1.RespondActivityTaskCompletedResponse"\x00\x12\xb9\x01\n RespondActivityTaskCompletedById\x12H.temporal.api.workflowservice.v1.RespondActivityTaskCompletedByIdRequest\x1aI.temporal.api.workflowservice.v1.RespondActivityTaskCompletedByIdResponse"\x00\x12\xa4\x01\n\x19RespondActivityTaskFailed\x12\x41.temporal.api.workflowservice.v1.RespondActivityTaskFailedRequest\x1a\x42.temporal.api.workflowservice.v1.RespondActivityTaskFailedResponse"\x00\x12\xb0\x01\n\x1dRespondActivityTaskFailedById\x12\x45.temporal.api.workflowservice.v1.RespondActivityTaskFailedByIdRequest\x1a\x46.temporal.api.workflowservice.v1.RespondActivityTaskFailedByIdResponse"\x00\x12\xaa\x01\n\x1bRespondActivityTaskCanceled\x12\x43.temporal.api.workflowservice.v1.RespondActivityTaskCanceledRequest\x1a\x44.temporal.api.workflowservice.v1.RespondActivityTaskCanceledResponse"\x00\x12\xb6\x01\n\x1fRespondActivityTaskCanceledById\x12G.temporal.api.workflowservice.v1.RespondActivityTaskCanceledByIdRequest\x1aH.temporal.api.workflowservice.v1.RespondActivityTaskCanceledByIdResponse"\x00\x12\xb3\x01\n\x1eRequestCancelWorkflowExecution\x12\x46.temporal.api.workflowservice.v1.RequestCancelWorkflowExecutionRequest\x1aG.temporal.api.workflowservice.v1.RequestCancelWorkflowExecutionResponse"\x00\x12\x9e\x01\n\x17SignalWorkflowExecution\x12?.temporal.api.workflowservice.v1.SignalWorkflowExecutionRequest\x1a@.temporal.api.workflowservice.v1.SignalWorkflowExecutionResponse"\x00\x12\xb9\x01\n SignalWithStartWorkflowExecution\x12H.temporal.api.workflowservice.v1.SignalWithStartWorkflowExecutionRequest\x1aI.temporal.api.workflowservice.v1.SignalWithStartWorkflowExecutionResponse"\x00\x12\x9b\x01\n\x16ResetWorkflowExecution\x12>.temporal.api.workflowservice.v1.ResetWorkflowExecutionRequest\x1a?.temporal.api.workflowservice.v1.ResetWorkflowExecutionResponse"\x00\x12\xa7\x01\n\x1aTerminateWorkflowExecution\x12\x42.temporal.api.workflowservice.v1.TerminateWorkflowExecutionRequest\x1a\x43.temporal.api.workflowservice.v1.TerminateWorkflowExecutionResponse"\x00\x12\x9e\x01\n\x17\x44\x65leteWorkflowExecution\x12?.temporal.api.workflowservice.v1.DeleteWorkflowExecutionRequest\x1a@.temporal.api.workflowservice.v1.DeleteWorkflowExecutionResponse"\x00\x12\xa7\x01\n\x1aListOpenWorkflowExecutions\x12\x42.temporal.api.workflowservice.v1.ListOpenWorkflowExecutionsRequest\x1a\x43.temporal.api.workflowservice.v1.ListOpenWorkflowExecutionsResponse"\x00\x12\xad\x01\n\x1cListClosedWorkflowExecutions\x12\x44.temporal.api.workflowservice.v1.ListClosedWorkflowExecutionsRequest\x1a\x45.temporal.api.workflowservice.v1.ListClosedWorkflowExecutionsResponse"\x00\x12\x9b\x01\n\x16ListWorkflowExecutions\x12>.temporal.api.workflowservice.v1.ListWorkflowExecutionsRequest\x1a?.temporal.api.workflowservice.v1.ListWorkflowExecutionsResponse"\x00\x12\xb3\x01\n\x1eListArchivedWorkflowExecutions\x12\x46.temporal.api.workflowservice.v1.ListArchivedWorkflowExecutionsRequest\x1aG.temporal.api.workflowservice.v1.ListArchivedWorkflowExecutionsResponse"\x00\x12\x9b\x01\n\x16ScanWorkflowExecutions\x12>.temporal.api.workflowservice.v1.ScanWorkflowExecutionsRequest\x1a?.temporal.api.workflowservice.v1.ScanWorkflowExecutionsResponse"\x00\x12\x9e\x01\n\x17\x43ountWorkflowExecutions\x12?.temporal.api.workflowservice.v1.CountWorkflowExecutionsRequest\x1a@.temporal.api.workflowservice.v1.CountWorkflowExecutionsResponse"\x00\x12\x92\x01\n\x13GetSearchAttributes\x12;.temporal.api.workflowservice.v1.GetSearchAttributesRequest\x1a<.temporal.api.workflowservice.v1.GetSearchAttributesResponse"\x00\x12\xa4\x01\n\x19RespondQueryTaskCompleted\x12\x41.temporal.api.workflowservice.v1.RespondQueryTaskCompletedRequest\x1a\x42.temporal.api.workflowservice.v1.RespondQueryTaskCompletedResponse"\x00\x12\x95\x01\n\x14ResetStickyTaskQueue\x12<.temporal.api.workflowservice.v1.ResetStickyTaskQueueRequest\x1a=.temporal.api.workflowservice.v1.ResetStickyTaskQueueResponse"\x00\x12\x80\x01\n\rQueryWorkflow\x12\x35.temporal.api.workflowservice.v1.QueryWorkflowRequest\x1a\x36.temporal.api.workflowservice.v1.QueryWorkflowResponse"\x00\x12\xa4\x01\n\x19\x44\x65scribeWorkflowExecution\x12\x41.temporal.api.workflowservice.v1.DescribeWorkflowExecutionRequest\x1a\x42.temporal.api.workflowservice.v1.DescribeWorkflowExecutionResponse"\x00\x12\x8c\x01\n\x11\x44\x65scribeTaskQueue\x12\x39.temporal.api.workflowservice.v1.DescribeTaskQueueRequest\x1a:.temporal.api.workflowservice.v1.DescribeTaskQueueResponse"\x00\x12\x83\x01\n\x0eGetClusterInfo\x12\x36.temporal.api.workflowservice.v1.GetClusterInfoRequest\x1a\x37.temporal.api.workflowservice.v1.GetClusterInfoResponse"\x00\x12\x80\x01\n\rGetSystemInfo\x12\x35.temporal.api.workflowservice.v1.GetSystemInfoRequest\x1a\x36.temporal.api.workflowservice.v1.GetSystemInfoResponse"\x00\x12\x9e\x01\n\x17ListTaskQueuePartitions\x12?.temporal.api.workflowservice.v1.ListTaskQueuePartitionsRequest\x1a@.temporal.api.workflowservice.v1.ListTaskQueuePartitionsResponse"\x00\x12\x83\x01\n\x0e\x43reateSchedule\x12\x36.temporal.api.workflowservice.v1.CreateScheduleRequest\x1a\x37.temporal.api.workflowservice.v1.CreateScheduleResponse"\x00\x12\x89\x01\n\x10\x44\x65scribeSchedule\x12\x38.temporal.api.workflowservice.v1.DescribeScheduleRequest\x1a\x39.temporal.api.workflowservice.v1.DescribeScheduleResponse"\x00\x12\x83\x01\n\x0eUpdateSchedule\x12\x36.temporal.api.workflowservice.v1.UpdateScheduleRequest\x1a\x37.temporal.api.workflowservice.v1.UpdateScheduleResponse"\x00\x12\x80\x01\n\rPatchSchedule\x12\x35.temporal.api.workflowservice.v1.PatchScheduleRequest\x1a\x36.temporal.api.workflowservice.v1.PatchScheduleResponse"\x00\x12\xa4\x01\n\x19ListScheduleMatchingTimes\x12\x41.temporal.api.workflowservice.v1.ListScheduleMatchingTimesRequest\x1a\x42.temporal.api.workflowservice.v1.ListScheduleMatchingTimesResponse"\x00\x12\x83\x01\n\x0e\x44\x65leteSchedule\x12\x36.temporal.api.workflowservice.v1.DeleteScheduleRequest\x1a\x37.temporal.api.workflowservice.v1.DeleteScheduleResponse"\x00\x12\x80\x01\n\rListSchedules\x12\x35.temporal.api.workflowservice.v1.ListSchedulesRequest\x1a\x36.temporal.api.workflowservice.v1.ListSchedulesResponse"\x00\x12\xb9\x01\n UpdateWorkerBuildIdCompatibility\x12H.temporal.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest\x1aI.temporal.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityResponse"\x00\x12\xb0\x01\n\x1dGetWorkerBuildIdCompatibility\x12\x45.temporal.api.workflowservice.v1.GetWorkerBuildIdCompatibilityRequest\x1a\x46.temporal.api.workflowservice.v1.GetWorkerBuildIdCompatibilityResponse"\x00\x12\x9e\x01\n\x17UpdateWorkflowExecution\x12?.temporal.api.workflowservice.v1.UpdateWorkflowExecutionRequest\x1a@.temporal.api.workflowservice.v1.UpdateWorkflowExecutionResponse"\x00\x12\xaa\x01\n\x1bPollWorkflowExecutionUpdate\x12\x43.temporal.api.workflowservice.v1.PollWorkflowExecutionUpdateRequest\x1a\x44.temporal.api.workflowservice.v1.PollWorkflowExecutionUpdateResponse"\x00\x12\x92\x01\n\x13StartBatchOperation\x12;.temporal.api.workflowservice.v1.StartBatchOperationRequest\x1a<.temporal.api.workflowservice.v1.StartBatchOperationResponse"\x00\x12\x8f\x01\n\x12StopBatchOperation\x12:.temporal.api.workflowservice.v1.StopBatchOperationRequest\x1a;.temporal.api.workflowservice.v1.StopBatchOperationResponse"\x00\x12\x9b\x01\n\x16\x44\x65scribeBatchOperation\x12>.temporal.api.workflowservice.v1.DescribeBatchOperationRequest\x1a?.temporal.api.workflowservice.v1.DescribeBatchOperationResponse"\x00\x12\x92\x01\n\x13ListBatchOperations\x12;.temporal.api.workflowservice.v1.ListBatchOperationsRequest\x1a<.temporal.api.workflowservice.v1.ListBatchOperationsResponse"\x00\x42\xb6\x01\n"io.temporal.api.workflowservice.v1B\x0cServiceProtoP\x01Z5go.temporal.io/api/workflowservice/v1;workflowservice\xaa\x02!Temporalio.Api.WorkflowService.V1\xea\x02$Temporalio::Api::WorkflowService::V1b\x06proto3'
+    b'\n-temporal/api/workflowservice/v1/service.proto\x12\x1ftemporal.api.workflowservice.v1\x1a\x36temporal/api/workflowservice/v1/request_response.proto2\xa5G\n\x0fWorkflowService\x12\x8c\x01\n\x11RegisterNamespace\x12\x39.temporal.api.workflowservice.v1.RegisterNamespaceRequest\x1a:.temporal.api.workflowservice.v1.RegisterNamespaceResponse"\x00\x12\x8c\x01\n\x11\x44\x65scribeNamespace\x12\x39.temporal.api.workflowservice.v1.DescribeNamespaceRequest\x1a:.temporal.api.workflowservice.v1.DescribeNamespaceResponse"\x00\x12\x83\x01\n\x0eListNamespaces\x12\x36.temporal.api.workflowservice.v1.ListNamespacesRequest\x1a\x37.temporal.api.workflowservice.v1.ListNamespacesResponse"\x00\x12\x86\x01\n\x0fUpdateNamespace\x12\x37.temporal.api.workflowservice.v1.UpdateNamespaceRequest\x1a\x38.temporal.api.workflowservice.v1.UpdateNamespaceResponse"\x00\x12\x8f\x01\n\x12\x44\x65precateNamespace\x12:.temporal.api.workflowservice.v1.DeprecateNamespaceRequest\x1a;.temporal.api.workflowservice.v1.DeprecateNamespaceResponse"\x00\x12\x9b\x01\n\x16StartWorkflowExecution\x12>.temporal.api.workflowservice.v1.StartWorkflowExecutionRequest\x1a?.temporal.api.workflowservice.v1.StartWorkflowExecutionResponse"\x00\x12\xaa\x01\n\x1bGetWorkflowExecutionHistory\x12\x43.temporal.api.workflowservice.v1.GetWorkflowExecutionHistoryRequest\x1a\x44.temporal.api.workflowservice.v1.GetWorkflowExecutionHistoryResponse"\x00\x12\xbf\x01\n"GetWorkflowExecutionHistoryReverse\x12J.temporal.api.workflowservice.v1.GetWorkflowExecutionHistoryReverseRequest\x1aK.temporal.api.workflowservice.v1.GetWorkflowExecutionHistoryReverseResponse"\x00\x12\x98\x01\n\x15PollWorkflowTaskQueue\x12=.temporal.api.workflowservice.v1.PollWorkflowTaskQueueRequest\x1a>.temporal.api.workflowservice.v1.PollWorkflowTaskQueueResponse"\x00\x12\xad\x01\n\x1cRespondWorkflowTaskCompleted\x12\x44.temporal.api.workflowservice.v1.RespondWorkflowTaskCompletedRequest\x1a\x45.temporal.api.workflowservice.v1.RespondWorkflowTaskCompletedResponse"\x00\x12\xa4\x01\n\x19RespondWorkflowTaskFailed\x12\x41.temporal.api.workflowservice.v1.RespondWorkflowTaskFailedRequest\x1a\x42.temporal.api.workflowservice.v1.RespondWorkflowTaskFailedResponse"\x00\x12\x98\x01\n\x15PollActivityTaskQueue\x12=.temporal.api.workflowservice.v1.PollActivityTaskQueueRequest\x1a>.temporal.api.workflowservice.v1.PollActivityTaskQueueResponse"\x00\x12\xaa\x01\n\x1bRecordActivityTaskHeartbeat\x12\x43.temporal.api.workflowservice.v1.RecordActivityTaskHeartbeatRequest\x1a\x44.temporal.api.workflowservice.v1.RecordActivityTaskHeartbeatResponse"\x00\x12\xb6\x01\n\x1fRecordActivityTaskHeartbeatById\x12G.temporal.api.workflowservice.v1.RecordActivityTaskHeartbeatByIdRequest\x1aH.temporal.api.workflowservice.v1.RecordActivityTaskHeartbeatByIdResponse"\x00\x12\xad\x01\n\x1cRespondActivityTaskCompleted\x12\x44.temporal.api.workflowservice.v1.RespondActivityTaskCompletedRequest\x1a\x45.temporal.api.workflowservice.v1.RespondActivityTaskCompletedResponse"\x00\x12\xb9\x01\n RespondActivityTaskCompletedById\x12H.temporal.api.workflowservice.v1.RespondActivityTaskCompletedByIdRequest\x1aI.temporal.api.workflowservice.v1.RespondActivityTaskCompletedByIdResponse"\x00\x12\xa4\x01\n\x19RespondActivityTaskFailed\x12\x41.temporal.api.workflowservice.v1.RespondActivityTaskFailedRequest\x1a\x42.temporal.api.workflowservice.v1.RespondActivityTaskFailedResponse"\x00\x12\xb0\x01\n\x1dRespondActivityTaskFailedById\x12\x45.temporal.api.workflowservice.v1.RespondActivityTaskFailedByIdRequest\x1a\x46.temporal.api.workflowservice.v1.RespondActivityTaskFailedByIdResponse"\x00\x12\xaa\x01\n\x1bRespondActivityTaskCanceled\x12\x43.temporal.api.workflowservice.v1.RespondActivityTaskCanceledRequest\x1a\x44.temporal.api.workflowservice.v1.RespondActivityTaskCanceledResponse"\x00\x12\xb6\x01\n\x1fRespondActivityTaskCanceledById\x12G.temporal.api.workflowservice.v1.RespondActivityTaskCanceledByIdRequest\x1aH.temporal.api.workflowservice.v1.RespondActivityTaskCanceledByIdResponse"\x00\x12\xb3\x01\n\x1eRequestCancelWorkflowExecution\x12\x46.temporal.api.workflowservice.v1.RequestCancelWorkflowExecutionRequest\x1aG.temporal.api.workflowservice.v1.RequestCancelWorkflowExecutionResponse"\x00\x12\x9e\x01\n\x17SignalWorkflowExecution\x12?.temporal.api.workflowservice.v1.SignalWorkflowExecutionRequest\x1a@.temporal.api.workflowservice.v1.SignalWorkflowExecutionResponse"\x00\x12\xb9\x01\n SignalWithStartWorkflowExecution\x12H.temporal.api.workflowservice.v1.SignalWithStartWorkflowExecutionRequest\x1aI.temporal.api.workflowservice.v1.SignalWithStartWorkflowExecutionResponse"\x00\x12\x9b\x01\n\x16ResetWorkflowExecution\x12>.temporal.api.workflowservice.v1.ResetWorkflowExecutionRequest\x1a?.temporal.api.workflowservice.v1.ResetWorkflowExecutionResponse"\x00\x12\xa7\x01\n\x1aTerminateWorkflowExecution\x12\x42.temporal.api.workflowservice.v1.TerminateWorkflowExecutionRequest\x1a\x43.temporal.api.workflowservice.v1.TerminateWorkflowExecutionResponse"\x00\x12\x9e\x01\n\x17\x44\x65leteWorkflowExecution\x12?.temporal.api.workflowservice.v1.DeleteWorkflowExecutionRequest\x1a@.temporal.api.workflowservice.v1.DeleteWorkflowExecutionResponse"\x00\x12\xa7\x01\n\x1aListOpenWorkflowExecutions\x12\x42.temporal.api.workflowservice.v1.ListOpenWorkflowExecutionsRequest\x1a\x43.temporal.api.workflowservice.v1.ListOpenWorkflowExecutionsResponse"\x00\x12\xad\x01\n\x1cListClosedWorkflowExecutions\x12\x44.temporal.api.workflowservice.v1.ListClosedWorkflowExecutionsRequest\x1a\x45.temporal.api.workflowservice.v1.ListClosedWorkflowExecutionsResponse"\x00\x12\x9b\x01\n\x16ListWorkflowExecutions\x12>.temporal.api.workflowservice.v1.ListWorkflowExecutionsRequest\x1a?.temporal.api.workflowservice.v1.ListWorkflowExecutionsResponse"\x00\x12\xb3\x01\n\x1eListArchivedWorkflowExecutions\x12\x46.temporal.api.workflowservice.v1.ListArchivedWorkflowExecutionsRequest\x1aG.temporal.api.workflowservice.v1.ListArchivedWorkflowExecutionsResponse"\x00\x12\x9b\x01\n\x16ScanWorkflowExecutions\x12>.temporal.api.workflowservice.v1.ScanWorkflowExecutionsRequest\x1a?.temporal.api.workflowservice.v1.ScanWorkflowExecutionsResponse"\x00\x12\x9e\x01\n\x17\x43ountWorkflowExecutions\x12?.temporal.api.workflowservice.v1.CountWorkflowExecutionsRequest\x1a@.temporal.api.workflowservice.v1.CountWorkflowExecutionsResponse"\x00\x12\x92\x01\n\x13GetSearchAttributes\x12;.temporal.api.workflowservice.v1.GetSearchAttributesRequest\x1a<.temporal.api.workflowservice.v1.GetSearchAttributesResponse"\x00\x12\xa4\x01\n\x19RespondQueryTaskCompleted\x12\x41.temporal.api.workflowservice.v1.RespondQueryTaskCompletedRequest\x1a\x42.temporal.api.workflowservice.v1.RespondQueryTaskCompletedResponse"\x00\x12\x95\x01\n\x14ResetStickyTaskQueue\x12<.temporal.api.workflowservice.v1.ResetStickyTaskQueueRequest\x1a=.temporal.api.workflowservice.v1.ResetStickyTaskQueueResponse"\x00\x12\x80\x01\n\rQueryWorkflow\x12\x35.temporal.api.workflowservice.v1.QueryWorkflowRequest\x1a\x36.temporal.api.workflowservice.v1.QueryWorkflowResponse"\x00\x12\xa4\x01\n\x19\x44\x65scribeWorkflowExecution\x12\x41.temporal.api.workflowservice.v1.DescribeWorkflowExecutionRequest\x1a\x42.temporal.api.workflowservice.v1.DescribeWorkflowExecutionResponse"\x00\x12\x8c\x01\n\x11\x44\x65scribeTaskQueue\x12\x39.temporal.api.workflowservice.v1.DescribeTaskQueueRequest\x1a:.temporal.api.workflowservice.v1.DescribeTaskQueueResponse"\x00\x12\x83\x01\n\x0eGetClusterInfo\x12\x36.temporal.api.workflowservice.v1.GetClusterInfoRequest\x1a\x37.temporal.api.workflowservice.v1.GetClusterInfoResponse"\x00\x12\x80\x01\n\rGetSystemInfo\x12\x35.temporal.api.workflowservice.v1.GetSystemInfoRequest\x1a\x36.temporal.api.workflowservice.v1.GetSystemInfoResponse"\x00\x12\x9e\x01\n\x17ListTaskQueuePartitions\x12?.temporal.api.workflowservice.v1.ListTaskQueuePartitionsRequest\x1a@.temporal.api.workflowservice.v1.ListTaskQueuePartitionsResponse"\x00\x12\x83\x01\n\x0e\x43reateSchedule\x12\x36.temporal.api.workflowservice.v1.CreateScheduleRequest\x1a\x37.temporal.api.workflowservice.v1.CreateScheduleResponse"\x00\x12\x89\x01\n\x10\x44\x65scribeSchedule\x12\x38.temporal.api.workflowservice.v1.DescribeScheduleRequest\x1a\x39.temporal.api.workflowservice.v1.DescribeScheduleResponse"\x00\x12\x83\x01\n\x0eUpdateSchedule\x12\x36.temporal.api.workflowservice.v1.UpdateScheduleRequest\x1a\x37.temporal.api.workflowservice.v1.UpdateScheduleResponse"\x00\x12\x80\x01\n\rPatchSchedule\x12\x35.temporal.api.workflowservice.v1.PatchScheduleRequest\x1a\x36.temporal.api.workflowservice.v1.PatchScheduleResponse"\x00\x12\xa4\x01\n\x19ListScheduleMatchingTimes\x12\x41.temporal.api.workflowservice.v1.ListScheduleMatchingTimesRequest\x1a\x42.temporal.api.workflowservice.v1.ListScheduleMatchingTimesResponse"\x00\x12\x83\x01\n\x0e\x44\x65leteSchedule\x12\x36.temporal.api.workflowservice.v1.DeleteScheduleRequest\x1a\x37.temporal.api.workflowservice.v1.DeleteScheduleResponse"\x00\x12\x80\x01\n\rListSchedules\x12\x35.temporal.api.workflowservice.v1.ListSchedulesRequest\x1a\x36.temporal.api.workflowservice.v1.ListSchedulesResponse"\x00\x12\xb9\x01\n UpdateWorkerBuildIdCompatibility\x12H.temporal.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest\x1aI.temporal.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityResponse"\x00\x12\xb0\x01\n\x1dGetWorkerBuildIdCompatibility\x12\x45.temporal.api.workflowservice.v1.GetWorkerBuildIdCompatibilityRequest\x1a\x46.temporal.api.workflowservice.v1.GetWorkerBuildIdCompatibilityResponse"\x00\x12\xa4\x01\n\x19GetWorkerTaskReachability\x12\x41.temporal.api.workflowservice.v1.GetWorkerTaskReachabilityRequest\x1a\x42.temporal.api.workflowservice.v1.GetWorkerTaskReachabilityResponse"\x00\x12\x9e\x01\n\x17UpdateWorkflowExecution\x12?.temporal.api.workflowservice.v1.UpdateWorkflowExecutionRequest\x1a@.temporal.api.workflowservice.v1.UpdateWorkflowExecutionResponse"\x00\x12\xaa\x01\n\x1bPollWorkflowExecutionUpdate\x12\x43.temporal.api.workflowservice.v1.PollWorkflowExecutionUpdateRequest\x1a\x44.temporal.api.workflowservice.v1.PollWorkflowExecutionUpdateResponse"\x00\x12\x92\x01\n\x13StartBatchOperation\x12;.temporal.api.workflowservice.v1.StartBatchOperationRequest\x1a<.temporal.api.workflowservice.v1.StartBatchOperationResponse"\x00\x12\x8f\x01\n\x12StopBatchOperation\x12:.temporal.api.workflowservice.v1.StopBatchOperationRequest\x1a;.temporal.api.workflowservice.v1.StopBatchOperationResponse"\x00\x12\x9b\x01\n\x16\x44\x65scribeBatchOperation\x12>.temporal.api.workflowservice.v1.DescribeBatchOperationRequest\x1a?.temporal.api.workflowservice.v1.DescribeBatchOperationResponse"\x00\x12\x92\x01\n\x13ListBatchOperations\x12;.temporal.api.workflowservice.v1.ListBatchOperationsRequest\x1a<.temporal.api.workflowservice.v1.ListBatchOperationsResponse"\x00\x42\xb6\x01\n"io.temporal.api.workflowservice.v1B\x0cServiceProtoP\x01Z5go.temporal.io/api/workflowservice/v1;workflowservice\xaa\x02!Temporalio.Api.WorkflowService.V1\xea\x02$Temporalio::Api::WorkflowService::V1b\x06proto3'
 )
 
 
 _WORKFLOWSERVICE = DESCRIPTOR.services_by_name["WorkflowService"]
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
     DESCRIPTOR._serialized_options = b'\n"io.temporal.api.workflowservice.v1B\014ServiceProtoP\001Z5go.temporal.io/api/workflowservice/v1;workflowservice\252\002!Temporalio.Api.WorkflowService.V1\352\002$Temporalio::Api::WorkflowService::V1'
     _WORKFLOWSERVICE._serialized_start = 139
-    _WORKFLOWSERVICE._serialized_end = 9097
+    _WORKFLOWSERVICE._serialized_end = 9264
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.2.0/temporalio/api/workflowservice/v1/service_pb2.pyi` & `temporalio-1.3.0/temporalio/api/workflowservice/v1/service_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/api/workflowservice/v1/service_pb2_grpc.py` & `temporalio-1.3.0/temporalio/api/workflowservice/v1/service_pb2_grpc.py`

 * *Files 1% similar despite different names*

```diff
@@ -273,14 +273,19 @@
             response_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkerBuildIdCompatibilityResponse.FromString,
         )
         self.GetWorkerBuildIdCompatibility = channel.unary_unary(
             "/temporal.api.workflowservice.v1.WorkflowService/GetWorkerBuildIdCompatibility",
             request_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerBuildIdCompatibilityRequest.SerializeToString,
             response_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerBuildIdCompatibilityResponse.FromString,
         )
+        self.GetWorkerTaskReachability = channel.unary_unary(
+            "/temporal.api.workflowservice.v1.WorkflowService/GetWorkerTaskReachability",
+            request_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerTaskReachabilityRequest.SerializeToString,
+            response_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerTaskReachabilityResponse.FromString,
+        )
         self.UpdateWorkflowExecution = channel.unary_unary(
             "/temporal.api.workflowservice.v1.WorkflowService/UpdateWorkflowExecution",
             request_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkflowExecutionRequest.SerializeToString,
             response_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkflowExecutionResponse.FromString,
         )
         self.PollWorkflowExecutionUpdate = channel.unary_unary(
             "/temporal.api.workflowservice.v1.WorkflowService/PollWorkflowExecutionUpdate",
@@ -785,25 +790,51 @@
 
     def UpdateWorkerBuildIdCompatibility(self, request, context):
         """Allows users to specify sets of worker build id versions on a per task queue basis. Versions
         are ordered, and may be either compatible with some extant version, or a new incompatible
         version, forming sets of ids which are incompatible with each other, but whose contained
         members are compatible with one another.
 
+        A single build id may be mapped to multiple task queues using this API for cases where a single process hosts
+        multiple workers.
+
+        To query which workers can be retired, use the `GetWorkerTaskReachability` API.
+
+        NOTE: The number of task queues mapped to a single build id is limited by the `limit.taskQueuesPerBuildId`
+        (default is 20), if this limit is exceeded this API will error with a FailedPrecondition.
+
         (-- api-linter: core::0134::response-message-name=disabled
         aip.dev/not-precedent: UpdateWorkerBuildIdCompatibility RPC doesn't follow Google API format. --)
         (-- api-linter: core::0134::method-signature=disabled
         aip.dev/not-precedent: UpdateWorkerBuildIdCompatibility RPC doesn't follow Google API format. --)
         """
         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
         context.set_details("Method not implemented!")
         raise NotImplementedError("Method not implemented!")
 
     def GetWorkerBuildIdCompatibility(self, request, context):
-        """Fetches the worker build id versioning sets for some task queue and related metadata."""
+        """Fetches the worker build id versioning sets for a task queue."""
+        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
+        context.set_details("Method not implemented!")
+        raise NotImplementedError("Method not implemented!")
+
+    def GetWorkerTaskReachability(self, request, context):
+        """Fetches task reachability to determine whether a worker may be retired.
+        The request may specify task queues to query for or let the server fetch all task queues mapped to the given
+        build IDs.
+
+        When requesting a large number of task queues or all task queues associated with the given build ids in a
+        namespace, all task queues will be listed in the response but some of them may not contain reachability
+        information due to a server enforced limit. When reaching the limit, task queues that reachability information
+        could not be retrieved for will be marked with a single TASK_REACHABILITY_UNSPECIFIED entry. The caller may issue
+        another call to get the reachability for those task queues.
+
+        Open source users can adjust this limit by setting the server's dynamic config value for
+        `limit.reachabilityTaskQueueScan` with the caveat that this call can strain the visibility store.
+        """
         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
         context.set_details("Method not implemented!")
         raise NotImplementedError("Method not implemented!")
 
     def UpdateWorkflowExecution(self, request, context):
         """Invokes the specified update function on user workflow code.
         (-- api-linter: core::0134=disabled
@@ -1098,14 +1129,19 @@
             response_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkerBuildIdCompatibilityResponse.SerializeToString,
         ),
         "GetWorkerBuildIdCompatibility": grpc.unary_unary_rpc_method_handler(
             servicer.GetWorkerBuildIdCompatibility,
             request_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerBuildIdCompatibilityRequest.FromString,
             response_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerBuildIdCompatibilityResponse.SerializeToString,
         ),
+        "GetWorkerTaskReachability": grpc.unary_unary_rpc_method_handler(
+            servicer.GetWorkerTaskReachability,
+            request_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerTaskReachabilityRequest.FromString,
+            response_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerTaskReachabilityResponse.SerializeToString,
+        ),
         "UpdateWorkflowExecution": grpc.unary_unary_rpc_method_handler(
             servicer.UpdateWorkflowExecution,
             request_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkflowExecutionRequest.FromString,
             response_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkflowExecutionResponse.SerializeToString,
         ),
         "PollWorkflowExecutionUpdate": grpc.unary_unary_rpc_method_handler(
             servicer.PollWorkflowExecutionUpdate,
@@ -2597,14 +2633,43 @@
             options,
             channel_credentials,
             insecure,
             call_credentials,
             compression,
             wait_for_ready,
             timeout,
+            metadata,
+        )
+
+    @staticmethod
+    def GetWorkerTaskReachability(
+        request,
+        target,
+        options=(),
+        channel_credentials=None,
+        call_credentials=None,
+        insecure=False,
+        compression=None,
+        wait_for_ready=None,
+        timeout=None,
+        metadata=None,
+    ):
+        return grpc.experimental.unary_unary(
+            request,
+            target,
+            "/temporal.api.workflowservice.v1.WorkflowService/GetWorkerTaskReachability",
+            temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerTaskReachabilityRequest.SerializeToString,
+            temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerTaskReachabilityResponse.FromString,
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
             metadata,
         )
 
     @staticmethod
     def UpdateWorkflowExecution(
         request,
         target,
```

### Comparing `temporalio-1.2.0/temporalio/api/workflowservice/v1/service_pb2_grpc.pyi` & `temporalio-1.3.0/temporalio/api/workflowservice/v1/service_pb2_grpc.pyi`

 * *Files 2% similar despite different names*

```diff
@@ -458,24 +458,49 @@
         temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkerBuildIdCompatibilityResponse,
     ]
     """Allows users to specify sets of worker build id versions on a per task queue basis. Versions
     are ordered, and may be either compatible with some extant version, or a new incompatible
     version, forming sets of ids which are incompatible with each other, but whose contained
     members are compatible with one another.
 
+    A single build id may be mapped to multiple task queues using this API for cases where a single process hosts
+    multiple workers. 
+
+    To query which workers can be retired, use the `GetWorkerTaskReachability` API.
+
+    NOTE: The number of task queues mapped to a single build id is limited by the `limit.taskQueuesPerBuildId`
+    (default is 20), if this limit is exceeded this API will error with a FailedPrecondition.
+
     (-- api-linter: core::0134::response-message-name=disabled
         aip.dev/not-precedent: UpdateWorkerBuildIdCompatibility RPC doesn't follow Google API format. --)
     (-- api-linter: core::0134::method-signature=disabled
         aip.dev/not-precedent: UpdateWorkerBuildIdCompatibility RPC doesn't follow Google API format. --)
     """
     GetWorkerBuildIdCompatibility: grpc.UnaryUnaryMultiCallable[
         temporalio.api.workflowservice.v1.request_response_pb2.GetWorkerBuildIdCompatibilityRequest,
         temporalio.api.workflowservice.v1.request_response_pb2.GetWorkerBuildIdCompatibilityResponse,
     ]
-    """Fetches the worker build id versioning sets for some task queue and related metadata."""
+    """Fetches the worker build id versioning sets for a task queue."""
+    GetWorkerTaskReachability: grpc.UnaryUnaryMultiCallable[
+        temporalio.api.workflowservice.v1.request_response_pb2.GetWorkerTaskReachabilityRequest,
+        temporalio.api.workflowservice.v1.request_response_pb2.GetWorkerTaskReachabilityResponse,
+    ]
+    """Fetches task reachability to determine whether a worker may be retired.
+    The request may specify task queues to query for or let the server fetch all task queues mapped to the given
+    build IDs.
+
+    When requesting a large number of task queues or all task queues associated with the given build ids in a
+    namespace, all task queues will be listed in the response but some of them may not contain reachability
+    information due to a server enforced limit. When reaching the limit, task queues that reachability information
+    could not be retrieved for will be marked with a single TASK_REACHABILITY_UNSPECIFIED entry. The caller may issue
+    another call to get the reachability for those task queues.
+
+    Open source users can adjust this limit by setting the server's dynamic config value for
+    `limit.reachabilityTaskQueueScan` with the caveat that this call can strain the visibility store.
+    """
     UpdateWorkflowExecution: grpc.UnaryUnaryMultiCallable[
         temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkflowExecutionRequest,
         temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkflowExecutionResponse,
     ]
     """Invokes the specified update function on user workflow code.
     (-- api-linter: core::0134=disabled
         aip.dev/not-precedent: UpdateWorkflowExecution doesn't follow Google API format --)
@@ -1118,28 +1143,57 @@
         temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkerBuildIdCompatibilityResponse
     ):
         """Allows users to specify sets of worker build id versions on a per task queue basis. Versions
         are ordered, and may be either compatible with some extant version, or a new incompatible
         version, forming sets of ids which are incompatible with each other, but whose contained
         members are compatible with one another.
 
+        A single build id may be mapped to multiple task queues using this API for cases where a single process hosts
+        multiple workers.
+
+        To query which workers can be retired, use the `GetWorkerTaskReachability` API.
+
+        NOTE: The number of task queues mapped to a single build id is limited by the `limit.taskQueuesPerBuildId`
+        (default is 20), if this limit is exceeded this API will error with a FailedPrecondition.
+
         (-- api-linter: core::0134::response-message-name=disabled
             aip.dev/not-precedent: UpdateWorkerBuildIdCompatibility RPC doesn't follow Google API format. --)
         (-- api-linter: core::0134::method-signature=disabled
             aip.dev/not-precedent: UpdateWorkerBuildIdCompatibility RPC doesn't follow Google API format. --)
         """
     @abc.abstractmethod
     def GetWorkerBuildIdCompatibility(
         self,
         request: temporalio.api.workflowservice.v1.request_response_pb2.GetWorkerBuildIdCompatibilityRequest,
         context: grpc.ServicerContext,
     ) -> (
         temporalio.api.workflowservice.v1.request_response_pb2.GetWorkerBuildIdCompatibilityResponse
     ):
-        """Fetches the worker build id versioning sets for some task queue and related metadata."""
+        """Fetches the worker build id versioning sets for a task queue."""
+    @abc.abstractmethod
+    def GetWorkerTaskReachability(
+        self,
+        request: temporalio.api.workflowservice.v1.request_response_pb2.GetWorkerTaskReachabilityRequest,
+        context: grpc.ServicerContext,
+    ) -> (
+        temporalio.api.workflowservice.v1.request_response_pb2.GetWorkerTaskReachabilityResponse
+    ):
+        """Fetches task reachability to determine whether a worker may be retired.
+        The request may specify task queues to query for or let the server fetch all task queues mapped to the given
+        build IDs.
+
+        When requesting a large number of task queues or all task queues associated with the given build ids in a
+        namespace, all task queues will be listed in the response but some of them may not contain reachability
+        information due to a server enforced limit. When reaching the limit, task queues that reachability information
+        could not be retrieved for will be marked with a single TASK_REACHABILITY_UNSPECIFIED entry. The caller may issue
+        another call to get the reachability for those task queues.
+
+        Open source users can adjust this limit by setting the server's dynamic config value for
+        `limit.reachabilityTaskQueueScan` with the caveat that this call can strain the visibility store.
+        """
     @abc.abstractmethod
     def UpdateWorkflowExecution(
         self,
         request: temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkflowExecutionRequest,
         context: grpc.ServicerContext,
     ) -> (
         temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkflowExecutionResponse
```

### Comparing `temporalio-1.2.0/temporalio/bridge/Cargo.lock` & `temporalio-1.3.0/temporalio/bridge/Cargo.lock`

 * *Files 2% similar despite different names*

```diff
@@ -1,27 +1,35 @@
 # This file is automatically @generated by Cargo.
 # It is not intended for manual editing.
 version = 3
 
 [[package]]
+name = "addr2line"
+version = "0.20.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "f4fa78e18c64fce05e902adecd7a5eed15a5e0a3439f7b0e169f0252214865e3"
+dependencies = [
+ "gimli",
+]
+
+[[package]]
 name = "adler"
 version = "1.0.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "f26201604c87b1e01bd3d98f8d5d9a8fcbb815e8cedb41ffccbeb4bf593a35fe"
 
 [[package]]
 name = "aes"
-version = "0.7.5"
+version = "0.8.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "9e8b47f52ea9bae42228d07ec09eb676433d7c4ed1ebdf0f1d1c29ed446f1ab8"
+checksum = "ac1f845298e95f983ff1944b728ae08b8cebab80d684f0a832ed0fc74dfa27e2"
 dependencies = [
  "cfg-if",
  "cipher",
  "cpufeatures",
- "opaque-debug",
 ]
 
 [[package]]
 name = "ahash"
 version = "0.8.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "2c99f64d1e06488f620f932677e24bc6e2897582980441ae90a671415bd7ec2f"
@@ -29,77 +37,83 @@
  "cfg-if",
  "once_cell",
  "version_check",
 ]
 
 [[package]]
 name = "aho-corasick"
-version = "0.7.20"
+version = "1.0.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "cc936419f96fa211c1b9166887b38e5e40b19958e5b895be7c1f93adec7071ac"
+checksum = "43f6cb1bf222025340178f382c426f13757b2960e89779dfcb319c32542a5a41"
 dependencies = [
  "memchr",
 ]
 
 [[package]]
+name = "android-tzdata"
+version = "0.1.1"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "e999941b234f3131b00bc13c22d06e8c5ff726d1b6318ac7eb276997bbb4fef0"
+
+[[package]]
 name = "anyhow"
-version = "1.0.70"
+version = "1.0.71"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "7de8ce5e0f9f8d88245311066a578d72b7af3e7088f32783804676302df237e4"
+checksum = "9c7d0618f0e0b7e8ff11427422b64564d5fb0be1940354bfe2e0529b18a9d9b8"
 
 [[package]]
 name = "arc-swap"
 version = "1.6.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "bddcadddf5e9015d310179a59bb28c4d4b9920ad0f11e8e14dbadf654890c9a6"
 
 [[package]]
 name = "async-stream"
-version = "0.3.4"
+version = "0.3.5"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "ad445822218ce64be7a341abfb0b1ea43b5c23aa83902542a4542e78309d8e5e"
+checksum = "cd56dd203fef61ac097dd65721a419ddccb106b2d2b70ba60a6b529f03961a51"
 dependencies = [
  "async-stream-impl",
  "futures-core",
  "pin-project-lite",
 ]
 
 [[package]]
 name = "async-stream-impl"
-version = "0.3.4"
+version = "0.3.5"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e4655ae1a7b0cdf149156f780c5bf3f1352bc53cbd9e0a361a7ef7b22947e965"
+checksum = "16e62a023e7c117e27523144c5d2459f4397fcc3cab0085af8e2224f643a0193"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn 1.0.109",
+ "syn 2.0.23",
 ]
 
 [[package]]
 name = "async-trait"
-version = "0.1.67"
+version = "0.1.70"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "86ea188f25f0255d8f92797797c97ebf5631fa88178beb1a46fdf5622c9a00e4"
+checksum = "79fa67157abdfd688a259b6648808757db9347af834624f27ec646da976aee5d"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn 2.0.8",
+ "syn 2.0.23",
 ]
 
 [[package]]
 name = "autocfg"
 version = "1.1.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "d468802bab17cbc0cc575e9b053f41e72aa36bfa6b7f55e3529ffa43161b97fa"
 
 [[package]]
 name = "axum"
-version = "0.6.12"
+version = "0.6.18"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "349f8ccfd9221ee7d1f3d4b33e1f8319b3a81ed8f61f2ea40b37b859794b4491"
+checksum = "f8175979259124331c1d7bf6586ee7e0da434155e4b2d48ec2c8386281d8df39"
 dependencies = [
  "async-trait",
  "axum-core",
  "bitflags",
  "bytes",
  "futures-util",
  "http",
@@ -117,17 +131,17 @@
  "tower",
  "tower-layer",
  "tower-service",
 ]
 
 [[package]]
 name = "axum-core"
-version = "0.3.3"
+version = "0.3.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "b2f958c80c248b34b9a877a643811be8dbca03ca5ba827f2b63baf3a81e5fc4e"
+checksum = "759fa577a247914fd3f7f76d62972792636412fbfd634cd452f6a385a74d2d2c"
 dependencies = [
  "async-trait",
  "bytes",
  "futures-util",
  "http",
  "http-body",
  "mime",
@@ -144,24 +158,39 @@
 dependencies = [
  "getrandom",
  "instant",
  "rand",
 ]
 
 [[package]]
+name = "backtrace"
+version = "0.3.68"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "4319208da049c43661739c5fade2ba182f09d1dc2299b32298d3a31692b17e12"
+dependencies = [
+ "addr2line",
+ "cc",
+ "cfg-if",
+ "libc",
+ "miniz_oxide",
+ "object",
+ "rustc-demangle",
+]
+
+[[package]]
 name = "base64"
 version = "0.13.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "9e1b586273c5702936fe7b7d6896644d8be71e6314cfe09d3167c95f712589e8"
 
 [[package]]
 name = "base64"
-version = "0.21.0"
+version = "0.21.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "a4a4ddaa51a5bc52a6948f74c06d20aaaddb71924eab79b8c97a8c556e942d6a"
+checksum = "604178f6c5c21f02dc555784810edfb88d34ac2c73b2eae109655649ee73ce3d"
 
 [[package]]
 name = "base64ct"
 version = "1.6.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "8c3c1a368f70d6cf7302d78f8f7093da241fb8e8807c05cc9e51a125895a6d5b"
 
@@ -178,17 +207,17 @@
 checksum = "3078c7629b62d3f0439517fa394996acacc5cbc91c5a20d8c658e77abd503a71"
 dependencies = [
  "generic-array",
 ]
 
 [[package]]
 name = "bumpalo"
-version = "3.12.0"
+version = "3.13.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "0d261e256854913907f67ed06efbc3338dfe6179796deefc1ff763fc1aee5535"
+checksum = "a3e2c3daef883ecc1b5d58c15adae93470a91d425f3532ba1695849656af3fc1"
 
 [[package]]
 name = "byteorder"
 version = "1.4.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "14c189c53d098945499cdfa7ecc63567cf3886b3332b312a5b4585d8d3a6a610"
 
@@ -232,30 +261,31 @@
 name = "cfg-if"
 version = "1.0.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "baf1de4339761588bc0619e3cbc0120ee582ebb74b53b4efbf79117bd2da40fd"
 
 [[package]]
 name = "chrono"
-version = "0.4.24"
+version = "0.4.26"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "4e3c5919066adf22df73762e50cffcde3a758f2a848b113b586d1f86728b673b"
+checksum = "ec837a71355b28f6556dbd569b37b3f363091c0bd4b2e735674521b4c5fd9bc5"
 dependencies = [
- "num-integer",
+ "android-tzdata",
  "num-traits",
  "serde",
 ]
 
 [[package]]
 name = "cipher"
-version = "0.3.0"
+version = "0.4.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "7ee52072ec15386f770805afd189a01c8841be8696bed250fa2f13c4c0d6dfb7"
+checksum = "773f3b9af64447d2ce9850330c473515014aa235e6a783b02db81ff39e4a3dad"
 dependencies = [
- "generic-array",
+ "crypto-common",
+ "inout",
 ]
 
 [[package]]
 name = "constant_time_eq"
 version = "0.1.5"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "245097e9a4535ee1e3e3931fcfcd55a796a44c643e8596ff6566d68f09b87bbc"
@@ -274,23 +304,23 @@
 dependencies = [
  "core-foundation-sys",
  "libc",
 ]
 
 [[package]]
 name = "core-foundation-sys"
-version = "0.8.3"
+version = "0.8.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "5827cebf4670468b8772dd191856768aedcb1b0278a04f989f7766351917b9dc"
+checksum = "e496a50fda8aacccc86d7529e2c1e0892dbd0f898a6b5645b5561b89c3210efa"
 
 [[package]]
 name = "cpufeatures"
-version = "0.2.5"
+version = "0.2.9"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "28d997bd5e24a5928dd43e46dc529867e207907fe0b239c3477d924f7f2ca320"
+checksum = "a17b76ff3a4162b0b27f354a0c87015ddad39d35f9c0c36607a3bdd175dde1f1"
 dependencies = [
  "libc",
 ]
 
 [[package]]
 name = "crc32fast"
 version = "1.3.2"
@@ -312,17 +342,17 @@
  "crossbeam-epoch",
  "crossbeam-queue",
  "crossbeam-utils",
 ]
 
 [[package]]
 name = "crossbeam-channel"
-version = "0.5.7"
+version = "0.5.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "cf2b3e8478797446514c91ef04bafcb59faba183e621ad488df88983cc14128c"
+checksum = "a33c2bf77f2df06183c3aa30d1e96c0695a313d4f9c453cc3762a6db39f99200"
 dependencies = [
  "cfg-if",
  "crossbeam-utils",
 ]
 
 [[package]]
 name = "crossbeam-deque"
@@ -333,22 +363,22 @@
  "cfg-if",
  "crossbeam-epoch",
  "crossbeam-utils",
 ]
 
 [[package]]
 name = "crossbeam-epoch"
-version = "0.9.14"
+version = "0.9.15"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "46bd5f3f85273295a9d14aedfb86f6aadbff6d8f5295c4a9edb08e819dcf5695"
+checksum = "ae211234986c545741a7dc064309f67ee1e5ad243d0e48335adc0484d960bcc7"
 dependencies = [
  "autocfg",
  "cfg-if",
  "crossbeam-utils",
- "memoffset 0.8.0",
+ "memoffset 0.9.0",
  "scopeguard",
 ]
 
 [[package]]
 name = "crossbeam-queue"
 version = "0.3.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
@@ -356,17 +386,17 @@
 dependencies = [
  "cfg-if",
  "crossbeam-utils",
 ]
 
 [[package]]
 name = "crossbeam-utils"
-version = "0.8.15"
+version = "0.8.16"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "3c063cd8cc95f5c377ed0d4b49a4b21f632396ff690e8470c29b3359b346984b"
+checksum = "5a22b2d63d4d1dc0b7f1b6b2747dd0088008a9be28b6ddf0b1e7d335e3037294"
 dependencies = [
  "cfg-if",
 ]
 
 [[package]]
 name = "crypto-common"
 version = "0.1.6"
@@ -374,24 +404,14 @@
 checksum = "1bfb12502f3fc46cca1bb51ac28df9d618d813cdc3d2f25b9fe775a34af26bb3"
 dependencies = [
  "generic-array",
  "typenum",
 ]
 
 [[package]]
-name = "ctor"
-version = "0.1.26"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "6d2301688392eb071b0bf1a37be05c469d3cc4dbbd95df672fe28ab021e6a096"
-dependencies = [
- "quote",
- "syn 1.0.109",
-]
-
-[[package]]
 name = "darling"
 version = "0.14.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "7b750cb3417fd1b327431a470f388520309479ab0bf5e323505daf0290cd3850"
 dependencies = [
  "darling_core",
  "darling_macro",
@@ -483,17 +503,17 @@
 name = "difflib"
 version = "0.4.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "6184e33543162437515c2e2b48714794e37845ec9851711914eec9d308f6ebe8"
 
 [[package]]
 name = "digest"
-version = "0.10.6"
+version = "0.10.7"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "8168378f4e5023e7218c89c891c0fd8ecdb5e5e4f18cb78f38cf245dd021e76f"
+checksum = "9ed9a281f7bc9b7576e61468ba615a66a5c8cfdff42420a70aa82701a3b1e292"
 dependencies = [
  "block-buffer",
  "crypto-common",
  "subtle",
 ]
 
 [[package]]
@@ -515,30 +535,30 @@
 checksum = "071a31f4ee85403370b58aca746f01041ede6f0da2730960ad001edc2b71b394"
 dependencies = [
  "cfg-if",
 ]
 
 [[package]]
 name = "enum-iterator"
-version = "1.4.0"
+version = "1.4.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "706d9e7cf1c7664859d79cd524e4e53ea2b67ea03c98cc2870c5e539695d597e"
+checksum = "7add3873b5dd076766ee79c8e406ad1a472c385476b9e38849f8eec24f1be689"
 dependencies = [
  "enum-iterator-derive",
 ]
 
 [[package]]
 name = "enum-iterator-derive"
-version = "1.2.0"
+version = "1.2.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "355f93763ef7b0ae1c43c4d8eccc9d5848d84ad1a1d8ce61c421d1ac85a19d05"
+checksum = "eecf8589574ce9b895052fa12d69af7a233f99e6107f5cb8dd1044f2a17bfdcb"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn 1.0.109",
+ "syn 2.0.23",
 ]
 
 [[package]]
 name = "enum_dispatch"
 version = "0.3.11"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "11f36e95862220b211a6e2aa5eca09b4fa391b13cd52ceb8035a24bf65a79de2"
@@ -547,30 +567,30 @@
  "proc-macro2",
  "quote",
  "syn 1.0.109",
 ]
 
 [[package]]
 name = "erased-serde"
-version = "0.3.25"
+version = "0.3.27"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "4f2b0c2380453a92ea8b6c8e5f64ecaafccddde8ceab55ff7a8ac1029f894569"
+checksum = "f94c0e13118e7d7533271f754a168ae8400e6a1cc043f2bfd53cc7290f1a1de3"
 dependencies = [
  "serde",
 ]
 
 [[package]]
 name = "errno"
-version = "0.2.8"
+version = "0.3.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "f639046355ee4f37944e44f60642c6f3a7efa3cf6b78c78a0d989a8ce6c396a1"
+checksum = "4bcfec3a70f97c962c307b2d2c56e358cf1d00b558d74262b5f929ee8cc7e73a"
 dependencies = [
  "errno-dragonfly",
  "libc",
- "winapi",
+ "windows-sys",
 ]
 
 [[package]]
 name = "errno-dragonfly"
 version = "0.1.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "aa68f1b12764fab894d2755d2518754e71b4fd80ecfb822714a1206c2aab39bf"
@@ -586,35 +606,35 @@
 checksum = "e51093e27b0797c359783294ca4f0a911c270184cb10f85783b118614a1501be"
 dependencies = [
  "instant",
 ]
 
 [[package]]
 name = "filetime"
-version = "0.2.20"
+version = "0.2.21"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "8a3de6e8d11b22ff9edc6d916f890800597d60f8b2da1caf2955c274638d6412"
+checksum = "5cbc844cecaee9d4443931972e1289c8ff485cb4cc2767cb03ca139ed6885153"
 dependencies = [
  "cfg-if",
  "libc",
- "redox_syscall",
- "windows-sys 0.45.0",
+ "redox_syscall 0.2.16",
+ "windows-sys",
 ]
 
 [[package]]
 name = "fixedbitset"
 version = "0.4.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "0ce7134b9999ecaf8bcd65542e436736ef32ddca1b3e06094cb6ec5755203b80"
 
 [[package]]
 name = "flate2"
-version = "1.0.25"
+version = "1.0.26"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "a8a2db397cb1c8772f31494cb8917e48cd1e64f0fa7efac59fbd741a0a8ce841"
+checksum = "3b9429470923de8e8cbd4d2dc513535400b4b3fef0319fb5c4e1f520a7bef743"
 dependencies = [
  "crc32fast",
  "miniz_oxide",
 ]
 
 [[package]]
 name = "float-cmp"
@@ -629,84 +649,84 @@
 name = "fnv"
 version = "1.0.7"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "3f9eec918d3f24069decb9af1554cad7c880e2da24a9afd88aca000531ab82c1"
 
 [[package]]
 name = "form_urlencoded"
-version = "1.1.0"
+version = "1.2.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "a9c384f161156f5260c24a097c56119f9be8c798586aecc13afbcbe7b7e26bf8"
+checksum = "a62bc1cf6f830c2ec14a513a9fb124d0a213a629668a4186f329db21fe045652"
 dependencies = [
  "percent-encoding",
 ]
 
 [[package]]
 name = "fragile"
 version = "2.0.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "6c2141d6d6c8512188a7891b4b01590a45f6dac67afb4f255c4124dbb86d4eaa"
 
 [[package]]
 name = "futures"
-version = "0.3.27"
+version = "0.3.28"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "531ac96c6ff5fd7c62263c5e3c67a603af4fcaee2e1a0ae5565ba3a11e69e549"
+checksum = "23342abe12aba583913b2e62f22225ff9c950774065e4bfb61a19cd9770fec40"
 dependencies = [
  "futures-channel",
  "futures-core",
  "futures-executor",
  "futures-io",
  "futures-sink",
  "futures-task",
  "futures-util",
 ]
 
 [[package]]
 name = "futures-channel"
-version = "0.3.27"
+version = "0.3.28"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "164713a5a0dcc3e7b4b1ed7d3b433cabc18025386f9339346e8daf15963cf7ac"
+checksum = "955518d47e09b25bbebc7a18df10b81f0c766eaf4c4f1cccef2fca5f2a4fb5f2"
 dependencies = [
  "futures-core",
  "futures-sink",
 ]
 
 [[package]]
 name = "futures-core"
-version = "0.3.27"
+version = "0.3.28"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "86d7a0c1aa76363dac491de0ee99faf6941128376f1cf96f07db7603b7de69dd"
+checksum = "4bca583b7e26f571124fe5b7561d49cb2868d79116cfa0eefce955557c6fee8c"
 
 [[package]]
 name = "futures-executor"
-version = "0.3.27"
+version = "0.3.28"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "1997dd9df74cdac935c76252744c1ed5794fac083242ea4fe77ef3ed60ba0f83"
+checksum = "ccecee823288125bd88b4d7f565c9e58e41858e47ab72e8ea2d64e93624386e0"
 dependencies = [
  "futures-core",
  "futures-task",
  "futures-util",
 ]
 
 [[package]]
 name = "futures-io"
-version = "0.3.27"
+version = "0.3.28"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "89d422fa3cbe3b40dca574ab087abb5bc98258ea57eea3fd6f1fa7162c778b91"
+checksum = "4fff74096e71ed47f8e023204cfd0aa1289cd54ae5430a9523be060cdb849964"
 
 [[package]]
 name = "futures-macro"
-version = "0.3.27"
+version = "0.3.28"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "3eb14ed937631bd8b8b8977f2c198443447a8355b6e3ca599f38c975e5a963b6"
+checksum = "89ca545a94061b6365f2c7355b4b32bd20df3ff95f02da9329b34ccc3bd6ee72"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn 1.0.109",
+ "syn 2.0.23",
 ]
 
 [[package]]
 name = "futures-retry"
 version = "0.6.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "fde5a672a61f96552aa5ed9fd9c81c3fbdae4be9b1e205d6eaf17c83705adc0f"
@@ -714,35 +734,35 @@
  "futures",
  "pin-project-lite",
  "tokio",
 ]
 
 [[package]]
 name = "futures-sink"
-version = "0.3.27"
+version = "0.3.28"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "ec93083a4aecafb2a80a885c9de1f0ccae9dbd32c2bb54b0c3a65690e0b8d2f2"
+checksum = "f43be4fe21a13b9781a69afa4985b0f6ee0e1afab2c6f454a8cf30e2b2237b6e"
 
 [[package]]
 name = "futures-task"
-version = "0.3.27"
+version = "0.3.28"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "fd65540d33b37b16542a0438c12e6aeead10d4ac5d05bd3f805b8f35ab592879"
+checksum = "76d3d132be6c0e6aa1534069c705a74a5997a356c0dc2f86a47765e5617c5b65"
 
 [[package]]
 name = "futures-timer"
 version = "3.0.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "e64b03909df88034c26dc1547e8970b91f98bdb65165d6a4e9110d94263dbb2c"
 
 [[package]]
 name = "futures-util"
-version = "0.3.27"
+version = "0.3.28"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "3ef6b17e481503ec85211fed8f39d1970f128935ca1f814cd32ac4a6842e84ab"
+checksum = "26b01e40b772d54cf6c6d721c1d1abd0647a0106a12ecaa1c186273392a69533"
 dependencies = [
  "futures-channel",
  "futures-core",
  "futures-io",
  "futures-macro",
  "futures-sink",
  "futures-task",
@@ -750,43 +770,38 @@
  "pin-project-lite",
  "pin-utils",
  "slab",
 ]
 
 [[package]]
 name = "generic-array"
-version = "0.14.6"
+version = "0.14.7"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "bff49e947297f3312447abdca79f45f4738097cc82b06e72054d2223f601f1b9"
+checksum = "85649ca51fd72272d7821adaf274ad91c288277713d9c18820d8499a7ff69e9a"
 dependencies = [
  "typenum",
  "version_check",
 ]
 
 [[package]]
 name = "getrandom"
-version = "0.2.8"
+version = "0.2.10"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "c05aeb6a22b8f62540c194aac980f2115af067bfe15a0734d7277a768d396b31"
+checksum = "be4136b2a15dd319360be1c07d9933517ccf0be8f16bf62a3bee4f0d618df427"
 dependencies = [
  "cfg-if",
  "libc",
  "wasi 0.11.0+wasi-snapshot-preview1",
 ]
 
 [[package]]
-name = "ghost"
-version = "0.1.9"
+name = "gimli"
+version = "0.27.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e77ac7b51b8e6313251737fcef4b1c01a2ea102bde68415b62c0ee9268fec357"
-dependencies = [
- "proc-macro2",
- "quote",
- "syn 2.0.8",
-]
+checksum = "b6c80984affa11d98d1b88b66ac8853f143217b399d3c74116778ff8fdb4ed2e"
 
 [[package]]
 name = "governor"
 version = "0.5.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "c390a940a5d157878dd057c78680a33ce3415bcd05b4799509ea44210914b4d5"
 dependencies = [
@@ -800,17 +815,17 @@
  "quanta",
  "rand",
  "smallvec",
 ]
 
 [[package]]
 name = "h2"
-version = "0.3.16"
+version = "0.3.20"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "5be7b54589b581f624f566bf5d8eb2bab1db736c51528720b6bd36b96b55924d"
+checksum = "97ec8491ebaf99c8eaa73058b045fe58073cd6be7f596ac993ced0b0a0c01049"
 dependencies = [
  "bytes",
  "fnv",
  "futures-core",
  "futures-sink",
  "futures-util",
  "http",
@@ -840,26 +855,17 @@
 name = "heck"
 version = "0.4.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "95505c38b4572b2d910cecb0281560f54b440a19336cbbcb27bf6ce6adc6f5a8"
 
 [[package]]
 name = "hermit-abi"
-version = "0.2.6"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "ee512640fe35acbfb4bb779db6f0d80704c2cacfa2e39b601ef3e3f47d1ae4c7"
-dependencies = [
- "libc",
-]
-
-[[package]]
-name = "hermit-abi"
-version = "0.3.1"
+version = "0.3.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "fed44880c466736ef9a5c5b5facefb5ed0785676d0c02d612db14e54f0d84286"
+checksum = "443144c8cdadd93ebf52ddb4056d257f5b52c04d3c804e657d19eb73fc33668b"
 
 [[package]]
 name = "hmac"
 version = "0.12.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "6c49c37c09c17a53d937dfbb742eb3a961d65a994e6bcdcf37e7399d0cc8ab5e"
 dependencies = [
@@ -898,17 +904,17 @@
 name = "httpdate"
 version = "1.0.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "c4a1e36c821dbe04574f602848a19f742f4fb3c98d40449f11bcad18d6b17421"
 
 [[package]]
 name = "hyper"
-version = "0.14.25"
+version = "0.14.27"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "cc5e554ff619822309ffd57d8734d77cd5ce6238bc956f037ea06c58238c9899"
+checksum = "ffb1cfd654a8219eaef89881fdb3bb3b1cdc5fa75ded05d6933b2b382e395468"
 dependencies = [
  "bytes",
  "futures-channel",
  "futures-core",
  "futures-util",
  "h2",
  "http",
@@ -922,23 +928,24 @@
  "tower-service",
  "tracing",
  "want",
 ]
 
 [[package]]
 name = "hyper-rustls"
-version = "0.23.2"
+version = "0.24.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "1788965e61b367cd03a62950836d5cd41560c3577d90e40e0819373194d1661c"
+checksum = "8d78e1e73ec14cf7375674f74d7dde185c8206fd9dea6fb6295e8a98098aaa97"
 dependencies = [
+ "futures-util",
  "http",
  "hyper",
- "rustls",
+ "rustls 0.21.3",
  "tokio",
- "tokio-rustls",
+ "tokio-rustls 0.24.1",
 ]
 
 [[package]]
 name = "hyper-timeout"
 version = "0.4.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "bbb958482e8c7be4bc3cf272a766a2b0bf1a6755e7a6ae777f017a31d11b13b1"
@@ -953,149 +960,151 @@
 name = "ident_case"
 version = "1.0.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "b9e0384b61958566e926dc50660321d12159025e767c18e043daf26b70104c39"
 
 [[package]]
 name = "idna"
-version = "0.3.0"
+version = "0.4.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e14ddfc70884202db2244c223200c204c2bda1bc6e0998d11b5e024d657209e6"
+checksum = "7d20d6b07bfbc108882d88ed8e37d39636dcc260e15e30c45e6ba089610b917c"
 dependencies = [
  "unicode-bidi",
  "unicode-normalization",
 ]
 
 [[package]]
 name = "indexmap"
-version = "1.9.2"
+version = "1.9.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "1885e79c1fc4b10f0e172c475f458b7f7b93061064d98c3293e98c5ba0c8b399"
+checksum = "bd070e393353796e801d209ad339e89596eb4c8d430d18ede6a1cced8fafbd99"
 dependencies = [
  "autocfg",
  "hashbrown 0.12.3",
 ]
 
 [[package]]
 name = "indoc"
 version = "1.0.9"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "bfa799dd5ed20a7e349f3b4639aa80d74549c81716d9ec4f994c9b5815598306"
 
 [[package]]
+name = "inout"
+version = "0.1.3"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "a0c10553d664a4d0bcff9f4215d0aac67a639cc68ef660840afe309b807bc9f5"
+dependencies = [
+ "generic-array",
+]
+
+[[package]]
 name = "instant"
 version = "0.1.12"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "7a5bbe824c507c5da5956355e86a746d82e0e1464f65d862cc5e71da70e94b2c"
 dependencies = [
  "cfg-if",
 ]
 
 [[package]]
 name = "inventory"
-version = "0.3.4"
+version = "0.3.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "498ae1c9c329c7972b917506239b557a60386839192f1cf0ca034f345b65db99"
-dependencies = [
- "ctor",
- "ghost",
-]
+checksum = "c38a87a1e0e2752433cd4b26019a469112a25fb43b30f5ee9b3b898925c5a0f9"
 
 [[package]]
 name = "io-lifetimes"
-version = "1.0.9"
+version = "1.0.11"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "09270fd4fa1111bc614ed2246c7ef56239a3063d5be0d1ec3b589c505d400aeb"
+checksum = "eae7b9aee968036d54dce06cebaefd919e4472e753296daccd6d344e3e2df0c2"
 dependencies = [
- "hermit-abi 0.3.1",
+ "hermit-abi",
  "libc",
- "windows-sys 0.45.0",
+ "windows-sys",
 ]
 
 [[package]]
 name = "ipnet"
-version = "2.7.1"
+version = "2.8.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "30e22bd8629359895450b59ea7a776c850561b96a3b1d31321c1949d9e6c9146"
+checksum = "28b29a3cd74f0f4598934efe3aeba42bae0eb4680554128851ebbecb02af14e6"
 
 [[package]]
 name = "itertools"
 version = "0.10.5"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "b0fd2260e829bddf4cb6ea802289de2f86d6a7a690192fbe91b3f46e0f2c8473"
 dependencies = [
  "either",
 ]
 
 [[package]]
 name = "itoa"
-version = "1.0.6"
+version = "1.0.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "453ad9f582a441959e5f0d088b02ce04cfe8d51a8eaf077f12ac6d3e94164ca6"
+checksum = "62b02a5381cc465bd3041d84623d0fa3b66738b52b8e2fc3bab8ad63ab032f4a"
 
 [[package]]
 name = "jobserver"
 version = "0.1.26"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "936cfd212a0155903bcbc060e316fb6cc7cbf2e1907329391ebadc1fe0ce77c2"
 dependencies = [
  "libc",
 ]
 
 [[package]]
 name = "js-sys"
-version = "0.3.61"
+version = "0.3.64"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "445dde2150c55e483f3d8416706b97ec8e8237c307e5b7b4b8dd15e6af2a0730"
+checksum = "c5f195fe497f702db0f318b07fdd68edb16955aed830df8363d837542f8f935a"
 dependencies = [
  "wasm-bindgen",
 ]
 
 [[package]]
 name = "lazy_static"
 version = "1.4.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "e2abad23fbc42b3700f2f279844dc832adb2b2eb069b2df918f455c4e18cc646"
 
 [[package]]
 name = "libc"
-version = "0.2.140"
+version = "0.2.147"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "99227334921fae1a979cf0bfdfcc6b3e5ce376ef57e16fb6fb3ea2ed6095f80c"
+checksum = "b4668fb0ea861c1df094127ac5f1da3409a82116a4ba74fca2e58ef927159bb3"
 
 [[package]]
 name = "linux-raw-sys"
-version = "0.1.4"
+version = "0.3.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "f051f77a7c8e6957c0696eac88f26b0117e54f52d3fc682ab19397a8812846a4"
+checksum = "ef53942eb7bf7ff43a617b3e2c1c4a5ecf5944a7c1bc12d7ee39bbb15e5c1519"
 
 [[package]]
 name = "lock_api"
-version = "0.4.9"
+version = "0.4.10"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "435011366fe56583b16cf956f9df0095b405b82d76425bc8981c0e22e60ec4df"
+checksum = "c1cc9717a20b1bb222f333e6a92fd32f7d8a18ddc5a3191a11af45dcbf4dcd16"
 dependencies = [
  "autocfg",
  "scopeguard",
 ]
 
 [[package]]
 name = "log"
-version = "0.4.17"
+version = "0.4.19"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "abb12e687cfb44aa40f41fc3978ef76448f9b6038cad6aef4259d3c095a2382e"
-dependencies = [
- "cfg-if",
-]
+checksum = "b06a4cde4c0f271a446782e3eff8de789548ce57dbc8eca9292c27f4a42004b4"
 
 [[package]]
 name = "lru"
-version = "0.10.0"
+version = "0.10.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "03f1160296536f10c833a82dca22267d5486734230d47bf00bf435885814ba1e"
+checksum = "718e8fae447df0c7e1ba7f5189829e63fd536945c8988d61444c19039f16b670"
 dependencies = [
  "hashbrown 0.13.2",
 ]
 
 [[package]]
 name = "mach"
 version = "0.3.2"
@@ -1107,15 +1116,15 @@
 
 [[package]]
 name = "matchers"
 version = "0.1.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "8263075bb86c5a1b1427b5ae862e8889656f126e9f77c484496e8b47cf5c5558"
 dependencies = [
- "regex-automata",
+ "regex-automata 0.1.10",
 ]
 
 [[package]]
 name = "matchit"
 version = "0.7.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "b87248edafb776e59e6ee64a79086f65890d3510f2c656c000bf2a7e8a0aea40"
@@ -1141,60 +1150,68 @@
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "d61c719bcfbcf5d62b3a09efa6088de8c54bc0bfcd3ea7ae39fcc186108b8de1"
 dependencies = [
  "autocfg",
 ]
 
 [[package]]
+name = "memoffset"
+version = "0.9.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "5a634b1c61a95585bd15607c6ab0c4e5b226e695ff2800ba0cdccddf208c406c"
+dependencies = [
+ "autocfg",
+]
+
+[[package]]
 name = "mime"
 version = "0.3.17"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "6877bb514081ee2a7ff5ef9de3281f14a4dd4bceac4c09388074a6b5df8a139a"
 
 [[package]]
 name = "miniz_oxide"
-version = "0.6.2"
+version = "0.7.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "b275950c28b37e794e8c55d88aeb5e139d0ce23fdbbeda68f8d7174abdf9e8fa"
+checksum = "e7810e0be55b428ada41041c41f32c9f1a42817901b4ccf45fa3d4b6561e74c7"
 dependencies = [
  "adler",
 ]
 
 [[package]]
 name = "mio"
-version = "0.8.6"
+version = "0.8.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "5b9d9a46eff5b4ff64b45a9e316a6d1e0bc719ef429cbec4dc630684212bfdf9"
+checksum = "927a765cd3fc26206e66b296465fa9d3e5ab003e651c1b3c060e7956d96b19d2"
 dependencies = [
  "libc",
- "log",
  "wasi 0.11.0+wasi-snapshot-preview1",
- "windows-sys 0.45.0",
+ "windows-sys",
 ]
 
 [[package]]
 name = "mockall"
-version = "0.11.3"
+version = "0.11.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "50e4a1c770583dac7ab5e2f6c139153b783a53a1bbee9729613f193e59828326"
+checksum = "4c84490118f2ee2d74570d114f3d0493cbf02790df303d2707606c3e14e07c96"
 dependencies = [
  "cfg-if",
  "downcast",
  "fragile",
  "lazy_static",
  "mockall_derive",
  "predicates",
  "predicates-tree",
 ]
 
 [[package]]
 name = "mockall_derive"
-version = "0.11.3"
+version = "0.11.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "832663583d5fa284ca8810bf7015e46c9fff9622d3cf34bd1eea5003fec06dd0"
+checksum = "22ce75669015c4f47b289fd4d4f56e894e4c96003ffdf3ac51313126f94c6cbb"
 dependencies = [
  "cfg-if",
  "proc-macro2",
  "quote",
  "syn 1.0.109",
 ]
 
@@ -1243,53 +1260,46 @@
 checksum = "77a8165726e8236064dbb45459242600304b42a5ea24ee2948e18e023bf7ba84"
 dependencies = [
  "overload",
  "winapi",
 ]
 
 [[package]]
-name = "num-integer"
-version = "0.1.45"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "225d3389fb3509a24c93f5c29eb6bde2586b98d9f016636dff58d7c6f7569cd9"
-dependencies = [
- "autocfg",
- "num-traits",
-]
-
-[[package]]
 name = "num-traits"
 version = "0.2.15"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "578ede34cf02f8924ab9447f50c28075b4d3e5b269972345e7e0372b38c6cdcd"
 dependencies = [
  "autocfg",
 ]
 
 [[package]]
 name = "num_cpus"
-version = "1.15.0"
+version = "1.16.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "0fac9e2da13b5eb447a6ce3d392f23a29d8694bff781bf03a16cd9ac8697593b"
+checksum = "4161fcb6d602d4d2081af7c3a45852d875a03dd337a6bfdd6e06407b61342a43"
 dependencies = [
- "hermit-abi 0.2.6",
+ "hermit-abi",
  "libc",
 ]
 
 [[package]]
-name = "once_cell"
-version = "1.17.1"
+name = "object"
+version = "0.31.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "b7e5500299e16ebb147ae15a00a942af264cf3688f47923b8fc2cd5858f23ad3"
+checksum = "8bda667d9f2b5051b8833f59f3bf748b28ef54f850f4fcb389a252aa383866d1"
+dependencies = [
+ "memchr",
+]
 
 [[package]]
-name = "opaque-debug"
-version = "0.3.0"
+name = "once_cell"
+version = "1.18.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "624a8340c38c1b80fd549087862da4ba43e08858af025b236e509b6649fc13d5"
+checksum = "dd8b5dd2ae5ed71462c540258bedcb51965123ad7e7ccf4b9a8cafaa4a63576d"
 
 [[package]]
 name = "openssl-probe"
 version = "0.1.5"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "ff011a302c396a5197692431fc1948019154afc178baf7d8e37367442a4601cf"
 
@@ -1398,23 +1408,23 @@
 dependencies = [
  "lock_api",
  "parking_lot_core",
 ]
 
 [[package]]
 name = "parking_lot_core"
-version = "0.9.7"
+version = "0.9.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "9069cbb9f99e3a5083476ccb29ceb1de18b9118cafa53e90c9551235de2b9521"
+checksum = "93f00c865fe7cabf650081affecd3871070f26767e7b2070a3ffae14c654b447"
 dependencies = [
  "cfg-if",
  "libc",
- "redox_syscall",
+ "redox_syscall 0.3.5",
  "smallvec",
- "windows-sys 0.45.0",
+ "windows-targets",
 ]
 
 [[package]]
 name = "password-hash"
 version = "0.4.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "7676374caaee8a325c9e7a2ae557f216c5563a171d6997b0ef8a65af35147700"
@@ -1434,65 +1444,65 @@
  "hmac",
  "password-hash",
  "sha2",
 ]
 
 [[package]]
 name = "percent-encoding"
-version = "2.2.0"
+version = "2.3.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "478c572c3d73181ff3c2539045f6eb99e5491218eae919370993b890cdbdd98e"
+checksum = "9b2a4787296e9989611394c33f193f676704af1686e70b8f8033ab5ba9a35a94"
 
 [[package]]
 name = "petgraph"
 version = "0.6.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "4dd7d28ee937e54fe3080c91faa1c3a46c06de6252988a7f4592ba2310ef22a4"
 dependencies = [
  "fixedbitset",
  "indexmap",
 ]
 
 [[package]]
 name = "pin-project"
-version = "1.0.12"
+version = "1.1.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "ad29a609b6bcd67fee905812e544992d216af9d755757c05ed2d0e15a74c6ecc"
+checksum = "030ad2bc4db10a8944cb0d837f158bdfec4d4a4873ab701a95046770d11f8842"
 dependencies = [
  "pin-project-internal",
 ]
 
 [[package]]
 name = "pin-project-internal"
-version = "1.0.12"
+version = "1.1.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "069bdb1e05adc7a8990dce9cc75370895fbe4e3d58b9b73bf1aee56359344a55"
+checksum = "ec2e072ecce94ec471b13398d5402c188e76ac03cf74dd1a975161b23a3f6d9c"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn 1.0.109",
+ "syn 2.0.23",
 ]
 
 [[package]]
 name = "pin-project-lite"
-version = "0.2.9"
+version = "0.2.10"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e0a7ae3ac2f1173085d398531c705756c94a4c56843785df85a60c1a0afac116"
+checksum = "4c40d25201921e5ff0c862a505c6557ea88568a4e3ace775ab55e93f2f4f9d57"
 
 [[package]]
 name = "pin-utils"
 version = "0.1.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "8b870d8c151b6f2fb93e84a13146138f05d02ed11c7e7c54f8826aaaf7c9f184"
 
 [[package]]
 name = "pkg-config"
-version = "0.3.26"
+version = "0.3.27"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "6ac9a59f73473f1b8d852421e59e64809f025994837ef743615c6d0c5b305160"
+checksum = "26072860ba924cbfa98ea39c8c19b4dd6a4a25423dbdf219c1eca91aa0cf6964"
 
 [[package]]
 name = "ppv-lite86"
 version = "0.2.17"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "5b40af805b3121feab8a3c29f04d8ad262fa8e0561883e7653e024ae4479e6de"
 
@@ -1534,17 +1544,17 @@
 dependencies = [
  "proc-macro2",
  "syn 1.0.109",
 ]
 
 [[package]]
 name = "proc-macro2"
-version = "1.0.53"
+version = "1.0.63"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "ba466839c78239c09faf015484e5cc04860f88242cff4d03eb038f04b4699b73"
+checksum = "7b368fba921b0dce7e60f5e04ec15e565b3303972b42bcfde1d0713b881959eb"
 dependencies = [
  "unicode-ident",
 ]
 
 [[package]]
 name = "prometheus"
 version = "0.13.3"
@@ -1558,27 +1568,27 @@
  "parking_lot",
  "protobuf",
  "thiserror",
 ]
 
 [[package]]
 name = "prost"
-version = "0.11.8"
+version = "0.11.9"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e48e50df39172a3e7eb17e14642445da64996989bc212b583015435d39a58537"
+checksum = "0b82eaa1d779e9a4bc1c3217db8ffbeabaae1dca241bf70183242128d48681cd"
 dependencies = [
  "bytes",
  "prost-derive",
 ]
 
 [[package]]
 name = "prost-build"
-version = "0.11.8"
+version = "0.11.9"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "2c828f93f5ca4826f97fedcbd3f9a536c16b12cff3dbbb4a007f932bbad95b12"
+checksum = "119533552c9a7ffacc21e099c24a0ac8bb19c2a2a3f363de84cd9b844feab270"
 dependencies = [
  "bytes",
  "heck",
  "itertools",
  "lazy_static",
  "log",
  "multimap",
@@ -1590,67 +1600,67 @@
  "syn 1.0.109",
  "tempfile",
  "which",
 ]
 
 [[package]]
 name = "prost-derive"
-version = "0.11.8"
+version = "0.11.9"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "4ea9b0f8cbe5e15a8a042d030bd96668db28ecb567ec37d691971ff5731d2b1b"
+checksum = "e5d2d8d10f3c6ded6da8b05b5fb3b8a5082514344d56c9f871412d29b4e075b4"
 dependencies = [
  "anyhow",
  "itertools",
  "proc-macro2",
  "quote",
  "syn 1.0.109",
 ]
 
 [[package]]
 name = "prost-types"
-version = "0.11.8"
+version = "0.11.9"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "379119666929a1afd7a043aa6cf96fa67a6dce9af60c88095a4686dbce4c9c88"
+checksum = "213622a1460818959ac1181aaeb2dc9c7f63df720db7d788b3e24eacd1983e13"
 dependencies = [
  "prost",
 ]
 
 [[package]]
 name = "prost-wkt"
-version = "0.4.1"
+version = "0.4.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "9f82196110c6376d25bf155f6d3a55835151d4f8ad470f203d46ee04c040d2fb"
+checksum = "562788060bcf2bfabe055194bd991ed2442457661744c88e0a0828ff9a08c08b"
 dependencies = [
  "chrono",
  "inventory",
  "prost",
  "serde",
  "serde_derive",
  "serde_json",
  "typetag",
 ]
 
 [[package]]
 name = "prost-wkt-build"
-version = "0.4.1"
+version = "0.4.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "8958d27269aec14c99c134ebb2796ab4287478bde21453d76aa43d1683265759"
+checksum = "c4dca8bcead3b728a6a7da017cc95e7f4cb2320ec4f6896bc593a1c4700f7328"
 dependencies = [
  "heck",
  "prost",
  "prost-build",
  "prost-types",
  "quote",
 ]
 
 [[package]]
 name = "prost-wkt-types"
-version = "0.4.1"
+version = "0.4.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "0c174ca3ca389b401547913b2a92aa9c08d849499138f962a771aedc9d77b2ce"
+checksum = "2377c5680f2342871823045052e791b4487f7c90aae17e0feaee24cf59578a34"
 dependencies = [
  "chrono",
  "prost",
  "prost-build",
  "prost-types",
  "prost-wkt",
  "prost-wkt-build",
@@ -1664,17 +1674,17 @@
 name = "protobuf"
 version = "2.28.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "106dd99e98437432fed6519dedecfade6a06a73bb7b2a1e019fdd2bee5778d94"
 
 [[package]]
 name = "pyo3"
-version = "0.18.1"
+version = "0.18.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "06a3d8e8a46ab2738109347433cb7b96dffda2e4a218b03ef27090238886b147"
+checksum = "e3b1ac5b3731ba34fdaa9785f8d74d17448cd18f30cf19e0c7e7b1fdb5272109"
 dependencies = [
  "cfg-if",
  "indoc",
  "libc",
  "memoffset 0.8.0",
  "parking_lot",
  "pyo3-build-config",
@@ -1694,49 +1704,49 @@
  "pin-project-lite",
  "pyo3",
  "tokio",
 ]
 
 [[package]]
 name = "pyo3-build-config"
-version = "0.18.1"
+version = "0.18.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "75439f995d07ddfad42b192dfcf3bc66a7ecfd8b4a1f5f6f046aa5c2c5d7677d"
+checksum = "9cb946f5ac61bb61a5014924910d936ebd2b23b705f7a4a3c40b05c720b079a3"
 dependencies = [
  "once_cell",
  "target-lexicon",
 ]
 
 [[package]]
 name = "pyo3-ffi"
-version = "0.18.1"
+version = "0.18.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "839526a5c07a17ff44823679b68add4a58004de00512a95b6c1c98a6dcac0ee5"
+checksum = "fd4d7c5337821916ea2a1d21d1092e8443cf34879e53a0ac653fbb98f44ff65c"
 dependencies = [
  "libc",
  "pyo3-build-config",
 ]
 
 [[package]]
 name = "pyo3-macros"
-version = "0.18.1"
+version = "0.18.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "bd44cf207476c6a9760c4653559be4f206efafb924d3e4cbf2721475fc0d6cc5"
+checksum = "a9d39c55dab3fc5a4b25bbd1ac10a2da452c4aca13bb450f22818a002e29648d"
 dependencies = [
  "proc-macro2",
  "pyo3-macros-backend",
  "quote",
  "syn 1.0.109",
 ]
 
 [[package]]
 name = "pyo3-macros-backend"
-version = "0.18.1"
+version = "0.18.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "dc1f43d8e30460f36350d18631ccf85ded64c059829208fe680904c65bcd0a4c"
+checksum = "97daff08a4c48320587b5224cc98d609e3c27b6d437315bd40b605c98eeb5918"
 dependencies = [
  "proc-macro2",
  "quote",
  "syn 1.0.109",
 ]
 
 [[package]]
@@ -1753,17 +1763,17 @@
  "wasi 0.10.2+wasi-snapshot-preview1",
  "web-sys",
  "winapi",
 ]
 
 [[package]]
 name = "quote"
-version = "1.0.26"
+version = "1.0.29"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "4424af4bf778aae2051a77b60283332f386554255d722233d09fbfc7e30da2fc"
+checksum = "573015e8ab27661678357f27dc26460738fd2b6c86e46f386fde94cb5d913105"
 dependencies = [
  "proc-macro2",
 ]
 
 [[package]]
 name = "rand"
 version = "0.8.5"
@@ -1809,46 +1819,73 @@
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "fb5a58c1855b4b6819d59012155603f0b22ad30cad752600aadfcb695265519a"
 dependencies = [
  "bitflags",
 ]
 
 [[package]]
+name = "redox_syscall"
+version = "0.3.5"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "567664f262709473930a4bf9e51bf2ebf3348f2e748ccc50dea20646858f8f29"
+dependencies = [
+ "bitflags",
+]
+
+[[package]]
 name = "regex"
-version = "1.7.2"
+version = "1.9.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "cce168fea28d3e05f158bda4576cf0c844d5045bc2cc3620fa0292ed5bb5814c"
+checksum = "89089e897c013b3deb627116ae56a6955a72b8bed395c9526af31c9fe528b484"
 dependencies = [
  "aho-corasick",
  "memchr",
- "regex-syntax",
+ "regex-automata 0.3.0",
+ "regex-syntax 0.7.3",
 ]
 
 [[package]]
 name = "regex-automata"
 version = "0.1.10"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "6c230d73fb8d8c1b9c0b3135c5142a8acee3a0558fb8db5cf1cb65f8d7862132"
 dependencies = [
- "regex-syntax",
+ "regex-syntax 0.6.29",
+]
+
+[[package]]
+name = "regex-automata"
+version = "0.3.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "fa250384981ea14565685dea16a9ccc4d1c541a13f82b9c168572264d1df8c56"
+dependencies = [
+ "aho-corasick",
+ "memchr",
+ "regex-syntax 0.7.3",
 ]
 
 [[package]]
 name = "regex-syntax"
 version = "0.6.29"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "f162c6dd7b008981e4d40210aca20b4bd0f9b60ca9271061b07f78537722f2e1"
 
 [[package]]
+name = "regex-syntax"
+version = "0.7.3"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "2ab07dc67230e4a4718e70fd5c20055a4334b121f1f9db8fe63ef39ce9b8c846"
+
+[[package]]
 name = "reqwest"
-version = "0.11.15"
+version = "0.11.18"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "0ba30cc2c0cd02af1222ed216ba659cdb2f879dfe3181852fe7c50b1d0005949"
+checksum = "cde824a14b7c14f85caff81225f411faacc04a2013f41670f41443742b1c1c55"
 dependencies = [
- "base64 0.21.0",
+ "base64 0.21.2",
  "bytes",
  "encoding_rs",
  "futures-core",
  "futures-util",
  "h2",
  "http",
  "http-body",
@@ -1857,21 +1894,21 @@
  "ipnet",
  "js-sys",
  "log",
  "mime",
  "once_cell",
  "percent-encoding",
  "pin-project-lite",
- "rustls",
+ "rustls 0.21.3",
  "rustls-pemfile",
  "serde",
  "serde_json",
  "serde_urlencoded",
  "tokio",
- "tokio-rustls",
+ "tokio-rustls 0.24.1",
  "tokio-util",
  "tower-service",
  "url",
  "wasm-bindgen",
  "wasm-bindgen-futures",
  "wasm-streams",
  "web-sys",
@@ -1892,22 +1929,28 @@
  "untrusted",
  "web-sys",
  "winapi",
 ]
 
 [[package]]
 name = "ringbuf"
-version = "0.3.2"
+version = "0.3.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "93ca10b9c9e53ac855a2d6953bce34cef6edbac32c4b13047a4d59d67299420a"
+checksum = "79abed428d1fd2a128201cec72c5f6938e2da607c6f3745f769fabea399d950a"
 dependencies = [
  "crossbeam-utils",
 ]
 
 [[package]]
+name = "rustc-demangle"
+version = "0.1.23"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "d626bb9dae77e28219937af045c257c28bfd3f69333c512553507f5f9798cb76"
+
+[[package]]
 name = "rustc_version"
 version = "0.4.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "bfa0f585226d2e68097d4f95d113b15b83a82e819ab25717ec0590d9584ef366"
 dependencies = [
  "semver",
 ]
@@ -1933,24 +1976,24 @@
 
 [[package]]
 name = "rustfsm_trait"
 version = "0.1.0"
 
 [[package]]
 name = "rustix"
-version = "0.36.11"
+version = "0.37.23"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "db4165c9963ab29e422d6c26fbc1d37f15bace6b2810221f9d925023480fcf0e"
+checksum = "4d69718bf81c6127a49dc64e44a742e8bb9213c0ff8869a22c308f84c1d4ab06"
 dependencies = [
  "bitflags",
  "errno",
  "io-lifetimes",
  "libc",
  "linux-raw-sys",
- "windows-sys 0.45.0",
+ "windows-sys",
 ]
 
 [[package]]
 name = "rustls"
 version = "0.20.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "fff78fc74d175294f4e83b28343315ffcfb114b156f0185e9741cb5570f50e2f"
@@ -1958,53 +2001,75 @@
  "log",
  "ring",
  "sct",
  "webpki",
 ]
 
 [[package]]
+name = "rustls"
+version = "0.21.3"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "b19faa85ecb5197342b54f987b142fb3e30d0c90da40f80ef4fa9a726e6676ed"
+dependencies = [
+ "log",
+ "ring",
+ "rustls-webpki",
+ "sct",
+]
+
+[[package]]
 name = "rustls-native-certs"
-version = "0.6.2"
+version = "0.6.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "0167bac7a9f490495f3c33013e7722b53cb087ecbe082fb0c6387c96f634ea50"
+checksum = "a9aace74cb666635c918e9c12bc0d348266037aa8eb599b5cba565709a8dff00"
 dependencies = [
  "openssl-probe",
  "rustls-pemfile",
  "schannel",
  "security-framework",
 ]
 
 [[package]]
 name = "rustls-pemfile"
-version = "1.0.2"
+version = "1.0.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "d194b56d58803a43635bdc398cd17e383d6f71f9182b9a192c127ca42494a59b"
+checksum = "2d3987094b1d07b653b7dfdc3f70ce9a1da9c51ac18c1b06b662e4f9a0e9f4b2"
 dependencies = [
- "base64 0.21.0",
+ "base64 0.21.2",
+]
+
+[[package]]
+name = "rustls-webpki"
+version = "0.101.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "89efed4bd0af2a8de0feb22ba38030244c93db56112b8aa67d27022286852b1c"
+dependencies = [
+ "ring",
+ "untrusted",
 ]
 
 [[package]]
 name = "rustversion"
-version = "1.0.12"
+version = "1.0.13"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "4f3208ce4d8448b3f3e7d168a73f5e0c43a61e32930de3bceeccedb388b6bf06"
+checksum = "dc31bd9b61a32c31f9650d18add92aa83a49ba979c143eefd27fe7177b05bd5f"
 
 [[package]]
 name = "ryu"
-version = "1.0.13"
+version = "1.0.14"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "f91339c0467de62360649f8d3e185ca8de4224ff281f66000de5eb2a77a79041"
+checksum = "fe232bdf6be8c8de797b22184ee71118d63780ea42ac85b61d1baa6d3b782ae9"
 
 [[package]]
 name = "schannel"
-version = "0.1.21"
+version = "0.1.22"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "713cfb06c7059f3588fb8044c0fad1d09e3c01d225e25b9220dbfdcf16dbb1b3"
+checksum = "0c3733bf4cf7ea0880754e19cb5a462007c4a8c1914bff372ccc95b464f1df88"
 dependencies = [
- "windows-sys 0.42.0",
+ "windows-sys",
 ]
 
 [[package]]
 name = "scopeguard"
 version = "1.1.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "d29ab0c6d3fc0ee92fe66e2d99f700eab17a8d57d1c1d3b748380fb20baa78cd"
@@ -2017,66 +2082,66 @@
 dependencies = [
  "ring",
  "untrusted",
 ]
 
 [[package]]
 name = "security-framework"
-version = "2.8.2"
+version = "2.9.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "a332be01508d814fed64bf28f798a146d73792121129962fdf335bb3c49a4254"
+checksum = "1fc758eb7bffce5b308734e9b0c1468893cae9ff70ebf13e7090be8dcbcc83a8"
 dependencies = [
  "bitflags",
  "core-foundation",
  "core-foundation-sys",
  "libc",
  "security-framework-sys",
 ]
 
 [[package]]
 name = "security-framework-sys"
-version = "2.8.0"
+version = "2.9.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "31c9bb296072e961fcbd8853511dd39c2d8be2deb1e17c6860b1d30732b323b4"
+checksum = "f51d0c0d83bec45f16480d0ce0058397a69e48fcdc52d1dc8855fb68acbd31a7"
 dependencies = [
  "core-foundation-sys",
  "libc",
 ]
 
 [[package]]
 name = "semver"
 version = "1.0.17"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "bebd363326d05ec3e2f532ab7660680f3b02130d780c299bca73469d521bc0ed"
 
 [[package]]
 name = "serde"
-version = "1.0.158"
+version = "1.0.166"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "771d4d9c4163ee138805e12c710dd365e4f44be8be0503cb1bb9eb989425d9c9"
+checksum = "d01b7404f9d441d3ad40e6a636a7782c377d2abdbe4fa2440e2edcc2f4f10db8"
 dependencies = [
  "serde_derive",
 ]
 
 [[package]]
 name = "serde_derive"
-version = "1.0.158"
+version = "1.0.166"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e801c1712f48475582b7696ac71e0ca34ebb30e09338425384269d9717c62cad"
+checksum = "5dd83d6dde2b6b2d466e14d9d1acce8816dedee94f735eac6395808b3483c6d6"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn 2.0.8",
+ "syn 2.0.23",
 ]
 
 [[package]]
 name = "serde_json"
-version = "1.0.94"
+version = "1.0.100"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "1c533a59c9d8a93a09c6ab31f0fd5e5f4dd1b8fc9434804029839884765d04ea"
+checksum = "0f1e14e89be7aa4c4b78bdbdc9eb5bf8517829a600ae8eaa39a6e1d960b5185c"
 dependencies = [
  "itoa",
  "ryu",
  "serde",
 ]
 
 [[package]]
@@ -2100,17 +2165,17 @@
  "cfg-if",
  "cpufeatures",
  "digest",
 ]
 
 [[package]]
 name = "sha2"
-version = "0.10.6"
+version = "0.10.7"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "82e6b795fe2e3b1e845bafcb27aa35405c4d47cdfc92af5fc8d3002f76cebdc0"
+checksum = "479fb9d862239e610720565ca91403019f2f00410f1864c5aa7479b950a76ed8"
 dependencies = [
  "cfg-if",
  "cpufeatures",
  "digest",
 ]
 
 [[package]]
@@ -2187,34 +2252,34 @@
 name = "strsim"
 version = "0.10.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "73473c0e59e6d5812c5dfe2a064a6444949f089e20eec9a2e5506596494e4623"
 
 [[package]]
 name = "subtle"
-version = "2.4.1"
+version = "2.5.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "6bdef32e8150c2a081110b42772ffe7d7c9032b606bc226c8260fd97e0976601"
+checksum = "81cdd64d312baedb58e21336b31bc043b77e01cc99033ce76ef539f78e965ebc"
 
 [[package]]
 name = "syn"
 version = "1.0.109"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "72b64191b275b66ffe2469e8af2c1cfe3bafa67b529ead792a6d0160888b4237"
 dependencies = [
  "proc-macro2",
  "quote",
  "unicode-ident",
 ]
 
 [[package]]
 name = "syn"
-version = "2.0.8"
+version = "2.0.23"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "bcc02725fd69ab9f26eab07fad303e2497fad6fb9eba4f96c4d1687bdf704ad9"
+checksum = "59fb7d6d8281a51045d62b8eb3a7d1ce347b76f312af50cd3dc0af39c87c1737"
 dependencies = [
  "proc-macro2",
  "quote",
  "unicode-ident",
 ]
 
 [[package]]
@@ -2232,29 +2297,30 @@
  "filetime",
  "libc",
  "xattr",
 ]
 
 [[package]]
 name = "target-lexicon"
-version = "0.12.6"
+version = "0.12.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "8ae9980cab1db3fceee2f6c6f643d5d8de2997c58ee8d25fb0cc8a9e9e7348e5"
+checksum = "1b1c7f239eb94671427157bd93b3694320f3668d4e1eff08c7285366fd777fac"
 
 [[package]]
 name = "tempfile"
-version = "3.4.0"
+version = "3.6.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "af18f7ae1acd354b992402e9ec5864359d693cd8a79dcbef59f76891701c1e95"
+checksum = "31c0432476357e58790aaa47a8efb0c5138f137343f3b5f23bd36a27e3b0a6d6"
 dependencies = [
+ "autocfg",
  "cfg-if",
  "fastrand",
- "redox_syscall",
+ "redox_syscall 0.3.5",
  "rustix",
- "windows-sys 0.42.0",
+ "windows-sys",
 ]
 
 [[package]]
 name = "temporal-client"
 version = "0.1.0"
 dependencies = [
  "anyhow",
@@ -2304,15 +2370,15 @@
 [[package]]
 name = "temporal-sdk-core"
 version = "0.1.0"
 dependencies = [
  "anyhow",
  "arc-swap",
  "async-trait",
- "base64 0.21.0",
+ "base64 0.21.2",
  "crossbeam",
  "dashmap",
  "derive_builder",
  "derive_more",
  "enum-iterator",
  "enum_dispatch",
  "flate2",
@@ -2381,15 +2447,15 @@
 ]
 
 [[package]]
 name = "temporal-sdk-core-protos"
 version = "0.1.0"
 dependencies = [
  "anyhow",
- "base64 0.21.0",
+ "base64 0.21.2",
  "derive_more",
  "prost",
  "prost-wkt",
  "prost-wkt-build",
  "prost-wkt-types",
  "rand",
  "serde",
@@ -2404,57 +2470,57 @@
 name = "termtree"
 version = "0.4.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "3369f5ac52d5eb6ab48c6b4ffdc8efbcad6b89c765749064ba298f2c68a16a76"
 
 [[package]]
 name = "thiserror"
-version = "1.0.40"
+version = "1.0.41"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "978c9a314bd8dc99be594bc3c175faaa9794be04a5a5e153caba6915336cebac"
+checksum = "c16a64ba9387ef3fdae4f9c1a7f07a0997fce91985c0336f1ddc1822b3b37802"
 dependencies = [
  "thiserror-impl",
 ]
 
 [[package]]
 name = "thiserror-impl"
-version = "1.0.40"
+version = "1.0.41"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "f9456a42c5b0d803c8cd86e73dd7cc9edd429499f37a3550d286d5e86720569f"
+checksum = "d14928354b01c4d6a4f0e549069adef399a284e7995c7ccca94e8a07a5346c59"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn 2.0.8",
+ "syn 2.0.23",
 ]
 
 [[package]]
 name = "thread_local"
 version = "1.1.7"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "3fdd6f064ccff2d6567adcb3873ca630700f00b5ad3f060c25b5dcfd9a4ce152"
 dependencies = [
  "cfg-if",
  "once_cell",
 ]
 
 [[package]]
 name = "time"
-version = "0.3.20"
+version = "0.3.22"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "cd0cbfecb4d19b5ea75bb31ad904eb5b9fa13f21079c3b92017ebdf4999a5890"
+checksum = "ea9e1b3cf1243ae005d9e74085d4d542f3125458f3a81af210d901dcd7411efd"
 dependencies = [
  "serde",
  "time-core",
 ]
 
 [[package]]
 name = "time-core"
-version = "0.1.0"
+version = "0.1.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "2e153e1f1acaef8acc537e68b44906d2db6436e2b35ac2c6b42640fff91f00fd"
+checksum = "7300fbefb4dadc1af235a9cef3737cea692a9d97e1b9cbcd4ebdae6f8868e6fb"
 
 [[package]]
 name = "tinyvec"
 version = "1.6.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "87cc5ceb3875bb20c2890005a4e226a4651264a5c75edb2421b52861a0a0cb50"
 dependencies = [
@@ -2465,80 +2531,90 @@
 name = "tinyvec_macros"
 version = "0.1.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "1f3ccbac311fea05f86f61904b462b55fb3df8837a366dfc601a0161d0532f20"
 
 [[package]]
 name = "tokio"
-version = "1.26.0"
+version = "1.29.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "03201d01c3c27a29c8a5cee5b55a93ddae1ccf6f08f65365c2c918f8c1b76f64"
+checksum = "532826ff75199d5833b9d2c5fe410f29235e25704ee5f0ef599fb51c21f4a4da"
 dependencies = [
  "autocfg",
+ "backtrace",
  "bytes",
  "libc",
- "memchr",
  "mio",
  "num_cpus",
  "parking_lot",
  "pin-project-lite",
  "signal-hook-registry",
  "socket2",
  "tokio-macros",
- "windows-sys 0.45.0",
+ "windows-sys",
 ]
 
 [[package]]
 name = "tokio-io-timeout"
 version = "1.2.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "30b74022ada614a1b4834de765f9bb43877f910cc8ce4be40e89042c9223a8bf"
 dependencies = [
  "pin-project-lite",
  "tokio",
 ]
 
 [[package]]
 name = "tokio-macros"
-version = "1.8.2"
+version = "2.1.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "d266c00fde287f55d3f1c3e96c500c362a2b8c695076ec180f27918820bc6df8"
+checksum = "630bdcf245f78637c13ec01ffae6187cca34625e8c63150d424b59e55af2675e"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn 1.0.109",
+ "syn 2.0.23",
 ]
 
 [[package]]
 name = "tokio-rustls"
 version = "0.23.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "c43ee83903113e03984cb9e5cebe6c04a5116269e900e3ddba8f068a62adda59"
 dependencies = [
- "rustls",
+ "rustls 0.20.8",
  "tokio",
  "webpki",
 ]
 
 [[package]]
+name = "tokio-rustls"
+version = "0.24.1"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "c28327cf380ac148141087fbfb9de9d7bd4e84ab5d2c28fbc911d753de8a7081"
+dependencies = [
+ "rustls 0.21.3",
+ "tokio",
+]
+
+[[package]]
 name = "tokio-stream"
-version = "0.1.12"
+version = "0.1.14"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "8fb52b74f05dbf495a8fba459fdc331812b96aa086d9eb78101fa0d4569c3313"
+checksum = "397c988d37662c7dda6d2208364a706264bf3d6138b11d436cbac0ad38832842"
 dependencies = [
  "futures-core",
  "pin-project-lite",
  "tokio",
 ]
 
 [[package]]
 name = "tokio-util"
-version = "0.7.7"
+version = "0.7.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "5427d89453009325de0d8f342c9490009f76e999cb7672d77e46267448f7e6b2"
+checksum = "806fe8c2c87eccc8b3267cbae29ed3ab2d0bd37fca70ab622e46aaa9375ddb7d"
 dependencies = [
  "bytes",
  "futures-core",
  "futures-sink",
  "pin-project-lite",
  "tokio",
  "tracing",
@@ -2565,15 +2641,15 @@
  "percent-encoding",
  "pin-project",
  "prost",
  "prost-derive",
  "rustls-native-certs",
  "rustls-pemfile",
  "tokio",
- "tokio-rustls",
+ "tokio-rustls 0.23.4",
  "tokio-stream",
  "tokio-util",
  "tower",
  "tower-layer",
  "tower-service",
  "tracing",
  "tracing-futures",
@@ -2635,28 +2711,28 @@
  "pin-project-lite",
  "tracing-attributes",
  "tracing-core",
 ]
 
 [[package]]
 name = "tracing-attributes"
-version = "0.1.23"
+version = "0.1.26"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "4017f8f45139870ca7e672686113917c71c7a6e02d4924eda67186083c03081a"
+checksum = "5f4f31f56159e98206da9efd823404b79b6ef3143b4a7ab76e67b1751b25a4ab"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn 1.0.109",
+ "syn 2.0.23",
 ]
 
 [[package]]
 name = "tracing-core"
-version = "0.1.30"
+version = "0.1.31"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "24eb03ba0eab1fd845050058ce5e616558e8f8d8fca633e6b163fe25c797213a"
+checksum = "0955b8137a1df6f1a2e9a37d8a6656291ff0297c1a97c24e0d8425fe2312f79a"
 dependencies = [
  "once_cell",
  "valuable",
 ]
 
 [[package]]
 name = "tracing-futures"
@@ -2691,17 +2767,17 @@
  "tracing-core",
  "tracing-log",
  "tracing-subscriber",
 ]
 
 [[package]]
 name = "tracing-subscriber"
-version = "0.3.16"
+version = "0.3.17"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "a6176eae26dd70d0c919749377897b54a9276bd7061339665dd68777926b5a70"
+checksum = "30a651bc37f915e81f087d86e62a18eec5f79550c7faff886f7090b4ea757c77"
 dependencies = [
  "matchers",
  "nu-ansi-term",
  "once_cell",
  "parking_lot",
  "regex",
  "sharded-slab",
@@ -2722,47 +2798,47 @@
 name = "typenum"
 version = "1.16.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "497961ef93d974e23eb6f433eb5fe1b7930b659f06d12dec6fc44a8f554c0bba"
 
 [[package]]
 name = "typetag"
-version = "0.2.7"
+version = "0.2.9"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "edc3ebbaab23e6cc369cb48246769d031f5bd85f1b28141f32982e3c0c7b33cf"
+checksum = "092e9b66a97c5f12e64f2d9c08c27d80342ff1ecde1d92288f939f55f5f1bcb3"
 dependencies = [
  "erased-serde",
  "inventory",
  "once_cell",
  "serde",
  "typetag-impl",
 ]
 
 [[package]]
 name = "typetag-impl"
-version = "0.2.7"
+version = "0.2.9"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "bb01b60fcc3f5e17babb1a9956263f3ccd2cadc3e52908400231441683283c1d"
+checksum = "8ae02a82d555be0636f3157d90b6e0ccc6eda4cbc2af123187682143ce3035f1"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn 2.0.8",
+ "syn 2.0.23",
 ]
 
 [[package]]
 name = "unicode-bidi"
 version = "0.3.13"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "92888ba5573ff080736b3648696b70cafad7d250551175acbaa4e0385b3e1460"
 
 [[package]]
 name = "unicode-ident"
-version = "1.0.8"
+version = "1.0.10"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e5464a87b239f13a63a501f2701565754bae92d243d4bb7eb12f6d57d2269bf4"
+checksum = "22049a19f4a68748a168c0fc439f9516686aa045927ff767eca0a85101fb6e73"
 
 [[package]]
 name = "unicode-normalization"
 version = "0.1.22"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "5c5713f0fc4b5db668a2ac63cdb7bb4469d8c9fed047b1d0292cc7b0ce2ba921"
 dependencies = [
@@ -2779,28 +2855,28 @@
 name = "untrusted"
 version = "0.7.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "a156c684c91ea7d62626509bce3cb4e1d9ed5c4d978f7b4352658f96a4c26b4a"
 
 [[package]]
 name = "url"
-version = "2.3.1"
+version = "2.4.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "0d68c799ae75762b8c3fe375feb6600ef5602c883c5d21eb51c09f22b83c4643"
+checksum = "50bff7831e19200a85b17131d085c25d7811bc4e186efdaf54bbd132994a88cb"
 dependencies = [
  "form_urlencoded",
  "idna",
  "percent-encoding",
 ]
 
 [[package]]
 name = "uuid"
-version = "1.3.0"
+version = "1.4.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "1674845326ee10d37ca60470760d4288a6f80f304007d92e5c53bab78c9cfd79"
+checksum = "d023da39d1fde5a8a3fe1f3e01ca9632ada0a63e9797de55a879d6e2236277be"
 dependencies = [
  "getrandom",
 ]
 
 [[package]]
 name = "valuable"
 version = "0.1.0"
@@ -2811,19 +2887,18 @@
 name = "version_check"
 version = "0.9.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "49874b5167b65d7193b8aba1567f5c7d93d001cafc34600cee003eda787e483f"
 
 [[package]]
 name = "want"
-version = "0.3.0"
+version = "0.3.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "1ce8a968cb1cd110d136ff8b819a556d6fb6d919363c61534f6860c7eb172ba0"
+checksum = "bfa7760aed19e106de2c7c0b581b509f2f25d3dacaf737cb82ac61bc6d760b0e"
 dependencies = [
- "log",
  "try-lock",
 ]
 
 [[package]]
 name = "wasi"
 version = "0.10.2+wasi-snapshot-preview1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
@@ -2833,77 +2908,77 @@
 name = "wasi"
 version = "0.11.0+wasi-snapshot-preview1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "9c8d87e72b64a3b4db28d11ce29237c246188f4f51057d65a7eab63b7987e423"
 
 [[package]]
 name = "wasm-bindgen"
-version = "0.2.84"
+version = "0.2.87"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "31f8dcbc21f30d9b8f2ea926ecb58f6b91192c17e9d33594b3df58b2007ca53b"
+checksum = "7706a72ab36d8cb1f80ffbf0e071533974a60d0a308d01a5d0375bf60499a342"
 dependencies = [
  "cfg-if",
  "wasm-bindgen-macro",
 ]
 
 [[package]]
 name = "wasm-bindgen-backend"
-version = "0.2.84"
+version = "0.2.87"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "95ce90fd5bcc06af55a641a86428ee4229e44e07033963a2290a8e241607ccb9"
+checksum = "5ef2b6d3c510e9625e5fe6f509ab07d66a760f0885d858736483c32ed7809abd"
 dependencies = [
  "bumpalo",
  "log",
  "once_cell",
  "proc-macro2",
  "quote",
- "syn 1.0.109",
+ "syn 2.0.23",
  "wasm-bindgen-shared",
 ]
 
 [[package]]
 name = "wasm-bindgen-futures"
-version = "0.4.34"
+version = "0.4.37"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "f219e0d211ba40266969f6dbdd90636da12f75bee4fc9d6c23d1260dadb51454"
+checksum = "c02dbc21516f9f1f04f187958890d7e6026df8d16540b7ad9492bc34a67cea03"
 dependencies = [
  "cfg-if",
  "js-sys",
  "wasm-bindgen",
  "web-sys",
 ]
 
 [[package]]
 name = "wasm-bindgen-macro"
-version = "0.2.84"
+version = "0.2.87"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "4c21f77c0bedc37fd5dc21f897894a5ca01e7bb159884559461862ae90c0b4c5"
+checksum = "dee495e55982a3bd48105a7b947fd2a9b4a8ae3010041b9e0faab3f9cd028f1d"
 dependencies = [
  "quote",
  "wasm-bindgen-macro-support",
 ]
 
 [[package]]
 name = "wasm-bindgen-macro-support"
-version = "0.2.84"
+version = "0.2.87"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "2aff81306fcac3c7515ad4e177f521b5c9a15f2b08f4e32d823066102f35a5f6"
+checksum = "54681b18a46765f095758388f2d0cf16eb8d4169b639ab575a8f5693af210c7b"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn 1.0.109",
+ "syn 2.0.23",
  "wasm-bindgen-backend",
  "wasm-bindgen-shared",
 ]
 
 [[package]]
 name = "wasm-bindgen-shared"
-version = "0.2.84"
+version = "0.2.87"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "0046fef7e28c3804e5e38bfa31ea2a0f73905319b677e57ebe37e49358989b5d"
+checksum = "ca6ad05a4870b2bf5fe995117d3728437bd27d7cd5f06f13c17443ef369775a1"
 
 [[package]]
 name = "wasm-streams"
 version = "0.2.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "6bbae3363c08332cadccd13b67db371814cd214c2524020932f0804b8cf7c078"
 dependencies = [
@@ -2912,17 +2987,17 @@
  "wasm-bindgen",
  "wasm-bindgen-futures",
  "web-sys",
 ]
 
 [[package]]
 name = "web-sys"
-version = "0.3.61"
+version = "0.3.64"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e33b99f4b23ba3eec1a53ac264e35a755f00e966e0065077d6027c0f575b0b97"
+checksum = "9b85cbef8c220a6abc02aefd892dfc0fc23afb1c6a426316ec33253a3877249b"
 dependencies = [
  "js-sys",
  "wasm-bindgen",
 ]
 
 [[package]]
 name = "webpki"
@@ -2974,92 +3049,77 @@
 name = "winapi-x86_64-pc-windows-gnu"
 version = "0.4.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "712e227841d057c1ee1cd2fb22fa7e5a5461ae8e48fa2ca79ec42cfc1931183f"
 
 [[package]]
 name = "windows-sys"
-version = "0.42.0"
+version = "0.48.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "5a3e1820f08b8513f676f7ab6c1f99ff312fb97b553d30ff4dd86f9f15728aa7"
-dependencies = [
- "windows_aarch64_gnullvm",
- "windows_aarch64_msvc",
- "windows_i686_gnu",
- "windows_i686_msvc",
- "windows_x86_64_gnu",
- "windows_x86_64_gnullvm",
- "windows_x86_64_msvc",
-]
-
-[[package]]
-name = "windows-sys"
-version = "0.45.0"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "75283be5efb2831d37ea142365f009c02ec203cd29a3ebecbc093d52315b66d0"
+checksum = "677d2418bec65e3338edb076e806bc1ec15693c5d0104683f2efe857f61056a9"
 dependencies = [
  "windows-targets",
 ]
 
 [[package]]
 name = "windows-targets"
-version = "0.42.2"
+version = "0.48.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "8e5180c00cd44c9b1c88adb3693291f1cd93605ded80c250a75d472756b4d071"
+checksum = "05d4b17490f70499f20b9e791dcf6a299785ce8af4d709018206dc5b4953e95f"
 dependencies = [
  "windows_aarch64_gnullvm",
  "windows_aarch64_msvc",
  "windows_i686_gnu",
  "windows_i686_msvc",
  "windows_x86_64_gnu",
  "windows_x86_64_gnullvm",
  "windows_x86_64_msvc",
 ]
 
 [[package]]
 name = "windows_aarch64_gnullvm"
-version = "0.42.2"
+version = "0.48.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "597a5118570b68bc08d8d59125332c54f1ba9d9adeedeef5b99b02ba2b0698f8"
+checksum = "91ae572e1b79dba883e0d315474df7305d12f569b400fcf90581b06062f7e1bc"
 
 [[package]]
 name = "windows_aarch64_msvc"
-version = "0.42.2"
+version = "0.48.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e08e8864a60f06ef0d0ff4ba04124db8b0fb3be5776a5cd47641e942e58c4d43"
+checksum = "b2ef27e0d7bdfcfc7b868b317c1d32c641a6fe4629c171b8928c7b08d98d7cf3"
 
 [[package]]
 name = "windows_i686_gnu"
-version = "0.42.2"
+version = "0.48.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "c61d927d8da41da96a81f029489353e68739737d3beca43145c8afec9a31a84f"
+checksum = "622a1962a7db830d6fd0a69683c80a18fda201879f0f447f065a3b7467daa241"
 
 [[package]]
 name = "windows_i686_msvc"
-version = "0.42.2"
+version = "0.48.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "44d840b6ec649f480a41c8d80f9c65108b92d89345dd94027bfe06ac444d1060"
+checksum = "4542c6e364ce21bf45d69fdd2a8e455fa38d316158cfd43b3ac1c5b1b19f8e00"
 
 [[package]]
 name = "windows_x86_64_gnu"
-version = "0.42.2"
+version = "0.48.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "8de912b8b8feb55c064867cf047dda097f92d51efad5b491dfb98f6bbb70cb36"
+checksum = "ca2b8a661f7628cbd23440e50b05d705db3686f894fc9580820623656af974b1"
 
 [[package]]
 name = "windows_x86_64_gnullvm"
-version = "0.42.2"
+version = "0.48.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "26d41b46a36d453748aedef1486d5c7a85db22e56aff34643984ea85514e94a3"
+checksum = "7896dbc1f41e08872e9d5e8f8baa8fdd2677f29468c4e156210174edc7f7b953"
 
 [[package]]
 name = "windows_x86_64_msvc"
-version = "0.42.2"
+version = "0.48.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "9aec5da331524158c6d1a4ac0ab1541149c0b9505fde06423b02f5ef0106b9f0"
+checksum = "1a515f5799fe4961cb532f983ce2b23082366b898e52ffbce459c86f67c8378a"
 
 [[package]]
 name = "winreg"
 version = "0.10.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "80d0f4e272c85def139476380b12f9ac60926689dd2e01d4923222f40580869d"
 dependencies = [
@@ -3073,17 +3133,17 @@
 checksum = "6d1526bbe5aaeb5eb06885f4d987bcdfa5e23187055de9b83fe00156a821fabc"
 dependencies = [
  "libc",
 ]
 
 [[package]]
 name = "zip"
-version = "0.6.4"
+version = "0.6.6"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "0445d0fbc924bb93539b4316c11afb121ea39296f99a3c4c9edad09e3658cdef"
+checksum = "760394e246e4c28189f19d488c058bf16f564016aefac5d32bb1f3b51d5e9261"
 dependencies = [
  "aes",
  "byteorder",
  "bzip2",
  "constant_time_eq",
  "crc32fast",
  "crossbeam-utils",
@@ -3112,15 +3172,15 @@
 dependencies = [
  "libc",
  "zstd-sys",
 ]
 
 [[package]]
 name = "zstd-sys"
-version = "2.0.7+zstd.1.5.4"
+version = "2.0.8+zstd.1.5.5"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "94509c3ba2fe55294d752b79842c530ccfab760192521df74a081a78d2b3c7f5"
+checksum = "5556e6ee25d32df2586c098bbfa278803692a20d0ab9565e049480d52707ec8c"
 dependencies = [
  "cc",
  "libc",
  "pkg-config",
 ]
```

### Comparing `temporalio-1.2.0/temporalio/bridge/Cargo.toml` & `temporalio-1.3.0/temporalio/bridge/Cargo.toml`

 * *Files 8% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 once_cell = "1.16.0"
 parking_lot = "0.12"
 prost = "0.11"
 prost-types = "0.11"
 pyo3 = { version = "0.18", features = ["extension-module", "abi3-py37"] }
 pyo3-asyncio = { version = "0.18", features = ["tokio-runtime"] }
 temporal-client = { version = "0.1.0", path = "./sdk-core/client" }
-temporal-sdk-core = { version = "0.1.0", path = "./sdk-core/core" }
+temporal-sdk-core = { version = "0.1.0", path = "./sdk-core/core", features = ["ephemeral-server"] }
 temporal-sdk-core-api = { version = "0.1.0", path = "./sdk-core/core-api" }
 temporal-sdk-core-protos = { version = "0.1.0", path = "./sdk-core/sdk-core-protos" }
 tokio = "1.26"
 tokio-stream = "0.1"
 tonic = "0.8"
 tracing = "0.1"
 url = "2.2"
```

### Comparing `temporalio-1.2.0/temporalio/bridge/client.py` & `temporalio-1.3.0/temporalio/bridge/client.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/activity_result/activity_result_pb2.py` & `temporalio-1.3.0/temporalio/bridge/proto/activity_result/activity_result_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/activity_result/activity_result_pb2.pyi` & `temporalio-1.3.0/temporalio/bridge/proto/activity_result/activity_result_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/activity_task/activity_task_pb2.py` & `temporalio-1.3.0/temporalio/bridge/proto/activity_task/activity_task_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/activity_task/activity_task_pb2.pyi` & `temporalio-1.3.0/temporalio/bridge/proto/activity_task/activity_task_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/bridge/__init__.py` & `temporalio-1.3.0/temporalio/bridge/proto/bridge/__init__.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/bridge/bridge_pb2.py` & `temporalio-1.3.0/temporalio/bridge/proto/bridge/bridge_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/bridge/bridge_pb2.pyi` & `temporalio-1.3.0/temporalio/bridge/proto/bridge/bridge_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/child_workflow/child_workflow_pb2.py` & `temporalio-1.3.0/temporalio/bridge/proto/child_workflow/child_workflow_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/child_workflow/child_workflow_pb2.pyi` & `temporalio-1.3.0/temporalio/bridge/proto/child_workflow/child_workflow_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/core_interface_pb2.py` & `temporalio-1.3.0/temporalio/bridge/proto/core_interface_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/core_interface_pb2.pyi` & `temporalio-1.3.0/temporalio/bridge/proto/core_interface_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/external_data/external_data_pb2.py` & `temporalio-1.3.0/temporalio/bridge/proto/external_data/external_data_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/external_data/external_data_pb2.pyi` & `temporalio-1.3.0/temporalio/bridge/proto/external_data/external_data_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/health/v1/health_pb2.py` & `temporalio-1.3.0/temporalio/bridge/proto/health/v1/health_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/health/v1/health_pb2.pyi` & `temporalio-1.3.0/temporalio/bridge/proto/health/v1/health_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/workflow_activation/__init__.py` & `temporalio-1.3.0/temporalio/bridge/proto/workflow_activation/__init__.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/workflow_activation/workflow_activation_pb2.py` & `temporalio-1.3.0/temporalio/bridge/proto/workflow_activation/workflow_activation_pb2.py`

 * *Files 1% similar despite different names*

```diff
@@ -32,15 +32,15 @@
     child_workflow_pb2 as temporal_dot_sdk_dot_core_dot_child__workflow_dot_child__workflow__pb2,
 )
 from temporalio.bridge.proto.common import (
     common_pb2 as temporal_dot_sdk_dot_core_dot_common_dot_common__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n?temporal/sdk/core/workflow_activation/workflow_activation.proto\x12\x1b\x63oresdk.workflow_activation\x1a\x1fgoogle/protobuf/timestamp.proto\x1a\x1egoogle/protobuf/duration.proto\x1a%temporal/api/failure/v1/message.proto\x1a$temporal/api/common/v1/message.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a\x37temporal/sdk/core/activity_result/activity_result.proto\x1a\x35temporal/sdk/core/child_workflow/child_workflow.proto\x1a%temporal/sdk/core/common/common.proto"\xe5\x01\n\x12WorkflowActivation\x12\x0e\n\x06run_id\x18\x01 \x01(\t\x12-\n\ttimestamp\x18\x02 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x14\n\x0cis_replaying\x18\x03 \x01(\x08\x12\x16\n\x0ehistory_length\x18\x04 \x01(\r\x12@\n\x04jobs\x18\x05 \x03(\x0b\x32\x32.coresdk.workflow_activation.WorkflowActivationJob\x12 \n\x18\x61vailable_internal_flags\x18\x06 \x03(\r"\xe1\x08\n\x15WorkflowActivationJob\x12\x44\n\x0estart_workflow\x18\x01 \x01(\x0b\x32*.coresdk.workflow_activation.StartWorkflowH\x00\x12<\n\nfire_timer\x18\x02 \x01(\x0b\x32&.coresdk.workflow_activation.FireTimerH\x00\x12K\n\x12update_random_seed\x18\x04 \x01(\x0b\x32-.coresdk.workflow_activation.UpdateRandomSeedH\x00\x12\x44\n\x0equery_workflow\x18\x05 \x01(\x0b\x32*.coresdk.workflow_activation.QueryWorkflowH\x00\x12\x46\n\x0f\x63\x61ncel_workflow\x18\x06 \x01(\x0b\x32+.coresdk.workflow_activation.CancelWorkflowH\x00\x12\x46\n\x0fsignal_workflow\x18\x07 \x01(\x0b\x32+.coresdk.workflow_activation.SignalWorkflowH\x00\x12H\n\x10resolve_activity\x18\x08 \x01(\x0b\x32,.coresdk.workflow_activation.ResolveActivityH\x00\x12G\n\x10notify_has_patch\x18\t \x01(\x0b\x32+.coresdk.workflow_activation.NotifyHasPatchH\x00\x12q\n&resolve_child_workflow_execution_start\x18\n \x01(\x0b\x32?.coresdk.workflow_activation.ResolveChildWorkflowExecutionStartH\x00\x12\x66\n resolve_child_workflow_execution\x18\x0b \x01(\x0b\x32:.coresdk.workflow_activation.ResolveChildWorkflowExecutionH\x00\x12\x66\n resolve_signal_external_workflow\x18\x0c \x01(\x0b\x32:.coresdk.workflow_activation.ResolveSignalExternalWorkflowH\x00\x12u\n(resolve_request_cancel_external_workflow\x18\r \x01(\x0b\x32\x41.coresdk.workflow_activation.ResolveRequestCancelExternalWorkflowH\x00\x12I\n\x11remove_from_cache\x18\x32 \x01(\x0b\x32,.coresdk.workflow_activation.RemoveFromCacheH\x00\x42\t\n\x07variant"\xd9\t\n\rStartWorkflow\x12\x15\n\rworkflow_type\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x32\n\targuments\x18\x03 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12\x17\n\x0frandomness_seed\x18\x04 \x01(\x04\x12H\n\x07headers\x18\x05 \x03(\x0b\x32\x37.coresdk.workflow_activation.StartWorkflow.HeadersEntry\x12\x10\n\x08identity\x18\x06 \x01(\t\x12I\n\x14parent_workflow_info\x18\x07 \x01(\x0b\x32+.coresdk.common.NamespacedWorkflowExecution\x12=\n\x1aworkflow_execution_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x37\n\x14workflow_run_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x38\n\x15workflow_task_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.Duration\x12\'\n\x1f\x63ontinued_from_execution_run_id\x18\x0b \x01(\t\x12J\n\x13\x63ontinued_initiator\x18\x0c \x01(\x0e\x32-.temporal.api.enums.v1.ContinueAsNewInitiator\x12;\n\x11\x63ontinued_failure\x18\r \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12@\n\x16last_completion_result\x18\x0e \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x1e\n\x16\x66irst_execution_run_id\x18\x0f \x01(\t\x12\x39\n\x0cretry_policy\x18\x10 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x0f\n\x07\x61ttempt\x18\x11 \x01(\x05\x12\x15\n\rcron_schedule\x18\x12 \x01(\t\x12\x46\n"workflow_execution_expiration_time\x18\x13 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x45\n"cron_schedule_to_schedule_interval\x18\x14 \x01(\x0b\x32\x19.google.protobuf.Duration\x12*\n\x04memo\x18\x15 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x16 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12.\n\nstart_time\x18\x17 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"\x18\n\tFireTimer\x12\x0b\n\x03seq\x18\x01 \x01(\r"[\n\x0fResolveActivity\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12;\n\x06result\x18\x02 \x01(\x0b\x32+.coresdk.activity_result.ActivityResolution"\xd1\x02\n"ResolveChildWorkflowExecutionStart\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12[\n\tsucceeded\x18\x02 \x01(\x0b\x32\x46.coresdk.workflow_activation.ResolveChildWorkflowExecutionStartSuccessH\x00\x12X\n\x06\x66\x61iled\x18\x03 \x01(\x0b\x32\x46.coresdk.workflow_activation.ResolveChildWorkflowExecutionStartFailureH\x00\x12]\n\tcancelled\x18\x04 \x01(\x0b\x32H.coresdk.workflow_activation.ResolveChildWorkflowExecutionStartCancelledH\x00\x42\x08\n\x06status";\n)ResolveChildWorkflowExecutionStartSuccess\x12\x0e\n\x06run_id\x18\x01 \x01(\t"\xa6\x01\n)ResolveChildWorkflowExecutionStartFailure\x12\x13\n\x0bworkflow_id\x18\x01 \x01(\t\x12\x15\n\rworkflow_type\x18\x02 \x01(\t\x12M\n\x05\x63\x61use\x18\x03 \x01(\x0e\x32>.coresdk.child_workflow.StartChildWorkflowExecutionFailedCause"`\n+ResolveChildWorkflowExecutionStartCancelled\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"i\n\x1dResolveChildWorkflowExecution\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12;\n\x06result\x18\x02 \x01(\x0b\x32+.coresdk.child_workflow.ChildWorkflowResult"+\n\x10UpdateRandomSeed\x12\x17\n\x0frandomness_seed\x18\x01 \x01(\x04"\x84\x02\n\rQueryWorkflow\x12\x10\n\x08query_id\x18\x01 \x01(\t\x12\x12\n\nquery_type\x18\x02 \x01(\t\x12\x32\n\targuments\x18\x03 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12H\n\x07headers\x18\x05 \x03(\x0b\x32\x37.coresdk.workflow_activation.QueryWorkflow.HeadersEntry\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"B\n\x0e\x43\x61ncelWorkflow\x12\x30\n\x07\x64\x65tails\x18\x01 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload"\x83\x02\n\x0eSignalWorkflow\x12\x13\n\x0bsignal_name\x18\x01 \x01(\t\x12.\n\x05input\x18\x02 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12\x10\n\x08identity\x18\x03 \x01(\t\x12I\n\x07headers\x18\x05 \x03(\x0b\x32\x38.coresdk.workflow_activation.SignalWorkflow.HeadersEntry\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01""\n\x0eNotifyHasPatch\x12\x10\n\x08patch_id\x18\x01 \x01(\t"_\n\x1dResolveSignalExternalWorkflow\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x31\n\x07\x66\x61ilure\x18\x02 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"f\n$ResolveRequestCancelExternalWorkflow\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x31\n\x07\x66\x61ilure\x18\x02 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"\xc1\x02\n\x0fRemoveFromCache\x12\x0f\n\x07message\x18\x01 \x01(\t\x12K\n\x06reason\x18\x02 \x01(\x0e\x32;.coresdk.workflow_activation.RemoveFromCache.EvictionReason"\xcf\x01\n\x0e\x45victionReason\x12\x0f\n\x0bUNSPECIFIED\x10\x00\x12\x0e\n\nCACHE_FULL\x10\x01\x12\x0e\n\nCACHE_MISS\x10\x02\x12\x12\n\x0eNONDETERMINISM\x10\x03\x12\r\n\tLANG_FAIL\x10\x04\x12\x12\n\x0eLANG_REQUESTED\x10\x05\x12\x12\n\x0eTASK_NOT_FOUND\x10\x06\x12\x15\n\x11UNHANDLED_COMMAND\x10\x07\x12\t\n\x05\x46\x41TAL\x10\x08\x12\x1f\n\x1bPAGINATION_OR_HISTORY_FETCH\x10\tB.\xea\x02+Temporalio::Bridge::Api::WorkflowActivationb\x06proto3'
+    b'\n?temporal/sdk/core/workflow_activation/workflow_activation.proto\x12\x1b\x63oresdk.workflow_activation\x1a\x1fgoogle/protobuf/timestamp.proto\x1a\x1egoogle/protobuf/duration.proto\x1a%temporal/api/failure/v1/message.proto\x1a$temporal/api/common/v1/message.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a\x37temporal/sdk/core/activity_result/activity_result.proto\x1a\x35temporal/sdk/core/child_workflow/child_workflow.proto\x1a%temporal/sdk/core/common/common.proto"\xa4\x02\n\x12WorkflowActivation\x12\x0e\n\x06run_id\x18\x01 \x01(\t\x12-\n\ttimestamp\x18\x02 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x14\n\x0cis_replaying\x18\x03 \x01(\x08\x12\x16\n\x0ehistory_length\x18\x04 \x01(\r\x12@\n\x04jobs\x18\x05 \x03(\x0b\x32\x32.coresdk.workflow_activation.WorkflowActivationJob\x12 \n\x18\x61vailable_internal_flags\x18\x06 \x03(\r\x12\x1a\n\x12history_size_bytes\x18\x07 \x01(\x04\x12!\n\x19\x63ontinue_as_new_suggested\x18\x08 \x01(\x08"\xe1\x08\n\x15WorkflowActivationJob\x12\x44\n\x0estart_workflow\x18\x01 \x01(\x0b\x32*.coresdk.workflow_activation.StartWorkflowH\x00\x12<\n\nfire_timer\x18\x02 \x01(\x0b\x32&.coresdk.workflow_activation.FireTimerH\x00\x12K\n\x12update_random_seed\x18\x04 \x01(\x0b\x32-.coresdk.workflow_activation.UpdateRandomSeedH\x00\x12\x44\n\x0equery_workflow\x18\x05 \x01(\x0b\x32*.coresdk.workflow_activation.QueryWorkflowH\x00\x12\x46\n\x0f\x63\x61ncel_workflow\x18\x06 \x01(\x0b\x32+.coresdk.workflow_activation.CancelWorkflowH\x00\x12\x46\n\x0fsignal_workflow\x18\x07 \x01(\x0b\x32+.coresdk.workflow_activation.SignalWorkflowH\x00\x12H\n\x10resolve_activity\x18\x08 \x01(\x0b\x32,.coresdk.workflow_activation.ResolveActivityH\x00\x12G\n\x10notify_has_patch\x18\t \x01(\x0b\x32+.coresdk.workflow_activation.NotifyHasPatchH\x00\x12q\n&resolve_child_workflow_execution_start\x18\n \x01(\x0b\x32?.coresdk.workflow_activation.ResolveChildWorkflowExecutionStartH\x00\x12\x66\n resolve_child_workflow_execution\x18\x0b \x01(\x0b\x32:.coresdk.workflow_activation.ResolveChildWorkflowExecutionH\x00\x12\x66\n resolve_signal_external_workflow\x18\x0c \x01(\x0b\x32:.coresdk.workflow_activation.ResolveSignalExternalWorkflowH\x00\x12u\n(resolve_request_cancel_external_workflow\x18\r \x01(\x0b\x32\x41.coresdk.workflow_activation.ResolveRequestCancelExternalWorkflowH\x00\x12I\n\x11remove_from_cache\x18\x32 \x01(\x0b\x32,.coresdk.workflow_activation.RemoveFromCacheH\x00\x42\t\n\x07variant"\xd9\t\n\rStartWorkflow\x12\x15\n\rworkflow_type\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x32\n\targuments\x18\x03 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12\x17\n\x0frandomness_seed\x18\x04 \x01(\x04\x12H\n\x07headers\x18\x05 \x03(\x0b\x32\x37.coresdk.workflow_activation.StartWorkflow.HeadersEntry\x12\x10\n\x08identity\x18\x06 \x01(\t\x12I\n\x14parent_workflow_info\x18\x07 \x01(\x0b\x32+.coresdk.common.NamespacedWorkflowExecution\x12=\n\x1aworkflow_execution_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x37\n\x14workflow_run_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x38\n\x15workflow_task_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.Duration\x12\'\n\x1f\x63ontinued_from_execution_run_id\x18\x0b \x01(\t\x12J\n\x13\x63ontinued_initiator\x18\x0c \x01(\x0e\x32-.temporal.api.enums.v1.ContinueAsNewInitiator\x12;\n\x11\x63ontinued_failure\x18\r \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12@\n\x16last_completion_result\x18\x0e \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x1e\n\x16\x66irst_execution_run_id\x18\x0f \x01(\t\x12\x39\n\x0cretry_policy\x18\x10 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x0f\n\x07\x61ttempt\x18\x11 \x01(\x05\x12\x15\n\rcron_schedule\x18\x12 \x01(\t\x12\x46\n"workflow_execution_expiration_time\x18\x13 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x45\n"cron_schedule_to_schedule_interval\x18\x14 \x01(\x0b\x32\x19.google.protobuf.Duration\x12*\n\x04memo\x18\x15 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x16 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12.\n\nstart_time\x18\x17 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"\x18\n\tFireTimer\x12\x0b\n\x03seq\x18\x01 \x01(\r"[\n\x0fResolveActivity\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12;\n\x06result\x18\x02 \x01(\x0b\x32+.coresdk.activity_result.ActivityResolution"\xd1\x02\n"ResolveChildWorkflowExecutionStart\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12[\n\tsucceeded\x18\x02 \x01(\x0b\x32\x46.coresdk.workflow_activation.ResolveChildWorkflowExecutionStartSuccessH\x00\x12X\n\x06\x66\x61iled\x18\x03 \x01(\x0b\x32\x46.coresdk.workflow_activation.ResolveChildWorkflowExecutionStartFailureH\x00\x12]\n\tcancelled\x18\x04 \x01(\x0b\x32H.coresdk.workflow_activation.ResolveChildWorkflowExecutionStartCancelledH\x00\x42\x08\n\x06status";\n)ResolveChildWorkflowExecutionStartSuccess\x12\x0e\n\x06run_id\x18\x01 \x01(\t"\xa6\x01\n)ResolveChildWorkflowExecutionStartFailure\x12\x13\n\x0bworkflow_id\x18\x01 \x01(\t\x12\x15\n\rworkflow_type\x18\x02 \x01(\t\x12M\n\x05\x63\x61use\x18\x03 \x01(\x0e\x32>.coresdk.child_workflow.StartChildWorkflowExecutionFailedCause"`\n+ResolveChildWorkflowExecutionStartCancelled\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"i\n\x1dResolveChildWorkflowExecution\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12;\n\x06result\x18\x02 \x01(\x0b\x32+.coresdk.child_workflow.ChildWorkflowResult"+\n\x10UpdateRandomSeed\x12\x17\n\x0frandomness_seed\x18\x01 \x01(\x04"\x84\x02\n\rQueryWorkflow\x12\x10\n\x08query_id\x18\x01 \x01(\t\x12\x12\n\nquery_type\x18\x02 \x01(\t\x12\x32\n\targuments\x18\x03 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12H\n\x07headers\x18\x05 \x03(\x0b\x32\x37.coresdk.workflow_activation.QueryWorkflow.HeadersEntry\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"B\n\x0e\x43\x61ncelWorkflow\x12\x30\n\x07\x64\x65tails\x18\x01 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload"\x83\x02\n\x0eSignalWorkflow\x12\x13\n\x0bsignal_name\x18\x01 \x01(\t\x12.\n\x05input\x18\x02 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12\x10\n\x08identity\x18\x03 \x01(\t\x12I\n\x07headers\x18\x05 \x03(\x0b\x32\x38.coresdk.workflow_activation.SignalWorkflow.HeadersEntry\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01""\n\x0eNotifyHasPatch\x12\x10\n\x08patch_id\x18\x01 \x01(\t"_\n\x1dResolveSignalExternalWorkflow\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x31\n\x07\x66\x61ilure\x18\x02 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"f\n$ResolveRequestCancelExternalWorkflow\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x31\n\x07\x66\x61ilure\x18\x02 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"\xc1\x02\n\x0fRemoveFromCache\x12\x0f\n\x07message\x18\x01 \x01(\t\x12K\n\x06reason\x18\x02 \x01(\x0e\x32;.coresdk.workflow_activation.RemoveFromCache.EvictionReason"\xcf\x01\n\x0e\x45victionReason\x12\x0f\n\x0bUNSPECIFIED\x10\x00\x12\x0e\n\nCACHE_FULL\x10\x01\x12\x0e\n\nCACHE_MISS\x10\x02\x12\x12\n\x0eNONDETERMINISM\x10\x03\x12\r\n\tLANG_FAIL\x10\x04\x12\x12\n\x0eLANG_REQUESTED\x10\x05\x12\x12\n\x0eTASK_NOT_FOUND\x10\x06\x12\x15\n\x11UNHANDLED_COMMAND\x10\x07\x12\t\n\x05\x46\x41TAL\x10\x08\x12\x1f\n\x1bPAGINATION_OR_HISTORY_FETCH\x10\tB.\xea\x02+Temporalio::Bridge::Api::WorkflowActivationb\x06proto3'
 )
 
 
 _WORKFLOWACTIVATION = DESCRIPTOR.message_types_by_name["WorkflowActivation"]
 _WORKFLOWACTIVATIONJOB = DESCRIPTOR.message_types_by_name["WorkflowActivationJob"]
 _STARTWORKFLOW = DESCRIPTOR.message_types_by_name["StartWorkflow"]
 _STARTWORKFLOW_HEADERSENTRY = _STARTWORKFLOW.nested_types_by_name["HeadersEntry"]
@@ -312,51 +312,51 @@
     _STARTWORKFLOW_HEADERSENTRY._options = None
     _STARTWORKFLOW_HEADERSENTRY._serialized_options = b"8\001"
     _QUERYWORKFLOW_HEADERSENTRY._options = None
     _QUERYWORKFLOW_HEADERSENTRY._serialized_options = b"8\001"
     _SIGNALWORKFLOW_HEADERSENTRY._options = None
     _SIGNALWORKFLOW_HEADERSENTRY._serialized_options = b"8\001"
     _WORKFLOWACTIVATION._serialized_start = 428
-    _WORKFLOWACTIVATION._serialized_end = 657
-    _WORKFLOWACTIVATIONJOB._serialized_start = 660
-    _WORKFLOWACTIVATIONJOB._serialized_end = 1781
-    _STARTWORKFLOW._serialized_start = 1784
-    _STARTWORKFLOW._serialized_end = 3025
-    _STARTWORKFLOW_HEADERSENTRY._serialized_start = 2946
-    _STARTWORKFLOW_HEADERSENTRY._serialized_end = 3025
-    _FIRETIMER._serialized_start = 3027
-    _FIRETIMER._serialized_end = 3051
-    _RESOLVEACTIVITY._serialized_start = 3053
-    _RESOLVEACTIVITY._serialized_end = 3144
-    _RESOLVECHILDWORKFLOWEXECUTIONSTART._serialized_start = 3147
-    _RESOLVECHILDWORKFLOWEXECUTIONSTART._serialized_end = 3484
-    _RESOLVECHILDWORKFLOWEXECUTIONSTARTSUCCESS._serialized_start = 3486
-    _RESOLVECHILDWORKFLOWEXECUTIONSTARTSUCCESS._serialized_end = 3545
-    _RESOLVECHILDWORKFLOWEXECUTIONSTARTFAILURE._serialized_start = 3548
-    _RESOLVECHILDWORKFLOWEXECUTIONSTARTFAILURE._serialized_end = 3714
-    _RESOLVECHILDWORKFLOWEXECUTIONSTARTCANCELLED._serialized_start = 3716
-    _RESOLVECHILDWORKFLOWEXECUTIONSTARTCANCELLED._serialized_end = 3812
-    _RESOLVECHILDWORKFLOWEXECUTION._serialized_start = 3814
-    _RESOLVECHILDWORKFLOWEXECUTION._serialized_end = 3919
-    _UPDATERANDOMSEED._serialized_start = 3921
-    _UPDATERANDOMSEED._serialized_end = 3964
-    _QUERYWORKFLOW._serialized_start = 3967
-    _QUERYWORKFLOW._serialized_end = 4227
-    _QUERYWORKFLOW_HEADERSENTRY._serialized_start = 2946
-    _QUERYWORKFLOW_HEADERSENTRY._serialized_end = 3025
-    _CANCELWORKFLOW._serialized_start = 4229
-    _CANCELWORKFLOW._serialized_end = 4295
-    _SIGNALWORKFLOW._serialized_start = 4298
-    _SIGNALWORKFLOW._serialized_end = 4557
-    _SIGNALWORKFLOW_HEADERSENTRY._serialized_start = 2946
-    _SIGNALWORKFLOW_HEADERSENTRY._serialized_end = 3025
-    _NOTIFYHASPATCH._serialized_start = 4559
-    _NOTIFYHASPATCH._serialized_end = 4593
-    _RESOLVESIGNALEXTERNALWORKFLOW._serialized_start = 4595
-    _RESOLVESIGNALEXTERNALWORKFLOW._serialized_end = 4690
-    _RESOLVEREQUESTCANCELEXTERNALWORKFLOW._serialized_start = 4692
-    _RESOLVEREQUESTCANCELEXTERNALWORKFLOW._serialized_end = 4794
-    _REMOVEFROMCACHE._serialized_start = 4797
-    _REMOVEFROMCACHE._serialized_end = 5118
-    _REMOVEFROMCACHE_EVICTIONREASON._serialized_start = 4911
-    _REMOVEFROMCACHE_EVICTIONREASON._serialized_end = 5118
+    _WORKFLOWACTIVATION._serialized_end = 720
+    _WORKFLOWACTIVATIONJOB._serialized_start = 723
+    _WORKFLOWACTIVATIONJOB._serialized_end = 1844
+    _STARTWORKFLOW._serialized_start = 1847
+    _STARTWORKFLOW._serialized_end = 3088
+    _STARTWORKFLOW_HEADERSENTRY._serialized_start = 3009
+    _STARTWORKFLOW_HEADERSENTRY._serialized_end = 3088
+    _FIRETIMER._serialized_start = 3090
+    _FIRETIMER._serialized_end = 3114
+    _RESOLVEACTIVITY._serialized_start = 3116
+    _RESOLVEACTIVITY._serialized_end = 3207
+    _RESOLVECHILDWORKFLOWEXECUTIONSTART._serialized_start = 3210
+    _RESOLVECHILDWORKFLOWEXECUTIONSTART._serialized_end = 3547
+    _RESOLVECHILDWORKFLOWEXECUTIONSTARTSUCCESS._serialized_start = 3549
+    _RESOLVECHILDWORKFLOWEXECUTIONSTARTSUCCESS._serialized_end = 3608
+    _RESOLVECHILDWORKFLOWEXECUTIONSTARTFAILURE._serialized_start = 3611
+    _RESOLVECHILDWORKFLOWEXECUTIONSTARTFAILURE._serialized_end = 3777
+    _RESOLVECHILDWORKFLOWEXECUTIONSTARTCANCELLED._serialized_start = 3779
+    _RESOLVECHILDWORKFLOWEXECUTIONSTARTCANCELLED._serialized_end = 3875
+    _RESOLVECHILDWORKFLOWEXECUTION._serialized_start = 3877
+    _RESOLVECHILDWORKFLOWEXECUTION._serialized_end = 3982
+    _UPDATERANDOMSEED._serialized_start = 3984
+    _UPDATERANDOMSEED._serialized_end = 4027
+    _QUERYWORKFLOW._serialized_start = 4030
+    _QUERYWORKFLOW._serialized_end = 4290
+    _QUERYWORKFLOW_HEADERSENTRY._serialized_start = 3009
+    _QUERYWORKFLOW_HEADERSENTRY._serialized_end = 3088
+    _CANCELWORKFLOW._serialized_start = 4292
+    _CANCELWORKFLOW._serialized_end = 4358
+    _SIGNALWORKFLOW._serialized_start = 4361
+    _SIGNALWORKFLOW._serialized_end = 4620
+    _SIGNALWORKFLOW_HEADERSENTRY._serialized_start = 3009
+    _SIGNALWORKFLOW_HEADERSENTRY._serialized_end = 3088
+    _NOTIFYHASPATCH._serialized_start = 4622
+    _NOTIFYHASPATCH._serialized_end = 4656
+    _RESOLVESIGNALEXTERNALWORKFLOW._serialized_start = 4658
+    _RESOLVESIGNALEXTERNALWORKFLOW._serialized_end = 4753
+    _RESOLVEREQUESTCANCELEXTERNALWORKFLOW._serialized_start = 4755
+    _RESOLVEREQUESTCANCELEXTERNALWORKFLOW._serialized_end = 4857
+    _REMOVEFROMCACHE._serialized_start = 4860
+    _REMOVEFROMCACHE._serialized_end = 5181
+    _REMOVEFROMCACHE_EVICTIONREASON._serialized_start = 4974
+    _REMOVEFROMCACHE_EVICTIONREASON._serialized_end = 5181
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/workflow_activation/workflow_activation_pb2.pyi` & `temporalio-1.3.0/temporalio/bridge/proto/workflow_activation/workflow_activation_pb2.pyi`

 * *Files 1% similar despite different names*

```diff
@@ -38,14 +38,16 @@
 
     RUN_ID_FIELD_NUMBER: builtins.int
     TIMESTAMP_FIELD_NUMBER: builtins.int
     IS_REPLAYING_FIELD_NUMBER: builtins.int
     HISTORY_LENGTH_FIELD_NUMBER: builtins.int
     JOBS_FIELD_NUMBER: builtins.int
     AVAILABLE_INTERNAL_FLAGS_FIELD_NUMBER: builtins.int
+    HISTORY_SIZE_BYTES_FIELD_NUMBER: builtins.int
+    CONTINUE_AS_NEW_SUGGESTED_FIELD_NUMBER: builtins.int
     run_id: builtins.str
     """The id of the currently active run of the workflow. Also used as a cache key. There may
     only ever be one active workflow task (and hence activation) of a run at one time.
     """
     @property
     def timestamp(self) -> google.protobuf.timestamp_pb2.Timestamp:
         """The current time as understood by the workflow, which is set by workflow task started events"""
@@ -66,34 +68,44 @@
     def available_internal_flags(
         self,
     ) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.int]:
         """Internal flags which are available for use by lang. If `is_replaying` is false, all
         internal flags may be used. This is not a delta - all previously used flags always
         appear since this representation is cheap.
         """
+    history_size_bytes: builtins.int
+    """The history size in bytes as of the last WFT started event"""
+    continue_as_new_suggested: builtins.bool
+    """Set true if the most recent WFT started event had this suggestion"""
     def __init__(
         self,
         *,
         run_id: builtins.str = ...,
         timestamp: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         is_replaying: builtins.bool = ...,
         history_length: builtins.int = ...,
         jobs: collections.abc.Iterable[global___WorkflowActivationJob] | None = ...,
         available_internal_flags: collections.abc.Iterable[builtins.int] | None = ...,
+        history_size_bytes: builtins.int = ...,
+        continue_as_new_suggested: builtins.bool = ...,
     ) -> None: ...
     def HasField(
         self, field_name: typing_extensions.Literal["timestamp", b"timestamp"]
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
             "available_internal_flags",
             b"available_internal_flags",
+            "continue_as_new_suggested",
+            b"continue_as_new_suggested",
             "history_length",
             b"history_length",
+            "history_size_bytes",
+            b"history_size_bytes",
             "is_replaying",
             b"is_replaying",
             "jobs",
             b"jobs",
             "run_id",
             b"run_id",
             "timestamp",
```

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/workflow_commands/__init__.py` & `temporalio-1.3.0/temporalio/bridge/proto/workflow_commands/__init__.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/workflow_commands/workflow_commands_pb2.py` & `temporalio-1.3.0/temporalio/bridge/proto/workflow_commands/workflow_commands_pb2.py`

 * *Files 1% similar despite different names*

```diff
@@ -30,15 +30,15 @@
     child_workflow_pb2 as temporal_dot_sdk_dot_core_dot_child__workflow_dot_child__workflow__pb2,
 )
 from temporalio.bridge.proto.common import (
     common_pb2 as temporal_dot_sdk_dot_core_dot_common_dot_common__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n;temporal/sdk/core/workflow_commands/workflow_commands.proto\x12\x19\x63oresdk.workflow_commands\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a$temporal/api/common/v1/message.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a%temporal/api/failure/v1/message.proto\x1a\x35temporal/sdk/core/child_workflow/child_workflow.proto\x1a%temporal/sdk/core/common/common.proto"\xac\r\n\x0fWorkflowCommand\x12<\n\x0bstart_timer\x18\x01 \x01(\x0b\x32%.coresdk.workflow_commands.StartTimerH\x00\x12H\n\x11schedule_activity\x18\x02 \x01(\x0b\x32+.coresdk.workflow_commands.ScheduleActivityH\x00\x12\x42\n\x10respond_to_query\x18\x03 \x01(\x0b\x32&.coresdk.workflow_commands.QueryResultH\x00\x12S\n\x17request_cancel_activity\x18\x04 \x01(\x0b\x32\x30.coresdk.workflow_commands.RequestCancelActivityH\x00\x12>\n\x0c\x63\x61ncel_timer\x18\x05 \x01(\x0b\x32&.coresdk.workflow_commands.CancelTimerH\x00\x12[\n\x1b\x63omplete_workflow_execution\x18\x06 \x01(\x0b\x32\x34.coresdk.workflow_commands.CompleteWorkflowExecutionH\x00\x12S\n\x17\x66\x61il_workflow_execution\x18\x07 \x01(\x0b\x32\x30.coresdk.workflow_commands.FailWorkflowExecutionH\x00\x12g\n"continue_as_new_workflow_execution\x18\x08 \x01(\x0b\x32\x39.coresdk.workflow_commands.ContinueAsNewWorkflowExecutionH\x00\x12W\n\x19\x63\x61ncel_workflow_execution\x18\t \x01(\x0b\x32\x32.coresdk.workflow_commands.CancelWorkflowExecutionH\x00\x12\x45\n\x10set_patch_marker\x18\n \x01(\x0b\x32).coresdk.workflow_commands.SetPatchMarkerH\x00\x12`\n\x1estart_child_workflow_execution\x18\x0b \x01(\x0b\x32\x36.coresdk.workflow_commands.StartChildWorkflowExecutionH\x00\x12\x62\n\x1f\x63\x61ncel_child_workflow_execution\x18\x0c \x01(\x0b\x32\x37.coresdk.workflow_commands.CancelChildWorkflowExecutionH\x00\x12w\n*request_cancel_external_workflow_execution\x18\r \x01(\x0b\x32\x41.coresdk.workflow_commands.RequestCancelExternalWorkflowExecutionH\x00\x12h\n"signal_external_workflow_execution\x18\x0e \x01(\x0b\x32:.coresdk.workflow_commands.SignalExternalWorkflowExecutionH\x00\x12Q\n\x16\x63\x61ncel_signal_workflow\x18\x0f \x01(\x0b\x32/.coresdk.workflow_commands.CancelSignalWorkflowH\x00\x12S\n\x17schedule_local_activity\x18\x10 \x01(\x0b\x32\x30.coresdk.workflow_commands.ScheduleLocalActivityH\x00\x12^\n\x1drequest_cancel_local_activity\x18\x11 \x01(\x0b\x32\x35.coresdk.workflow_commands.RequestCancelLocalActivityH\x00\x12\x66\n!upsert_workflow_search_attributes\x18\x12 \x01(\x0b\x32\x39.coresdk.workflow_commands.UpsertWorkflowSearchAttributesH\x00\x12Y\n\x1amodify_workflow_properties\x18\x13 \x01(\x0b\x32\x33.coresdk.workflow_commands.ModifyWorkflowPropertiesH\x00\x42\t\n\x07variant"S\n\nStartTimer\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x38\n\x15start_to_fire_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.Duration"\x1a\n\x0b\x43\x61ncelTimer\x12\x0b\n\x03seq\x18\x01 \x01(\r"\xc7\x05\n\x10ScheduleActivity\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x13\n\x0b\x61\x63tivity_id\x18\x02 \x01(\t\x12\x15\n\ractivity_type\x18\x03 \x01(\t\x12\x12\n\ntask_queue\x18\x05 \x01(\t\x12I\n\x07headers\x18\x06 \x03(\x0b\x32\x38.coresdk.workflow_commands.ScheduleActivity.HeadersEntry\x12\x32\n\targuments\x18\x07 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12<\n\x19schedule_to_close_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.Duration\x12<\n\x19schedule_to_start_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x39\n\x16start_to_close_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x34\n\x11heartbeat_timeout\x18\x0b \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x39\n\x0cretry_policy\x18\x0c \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12N\n\x11\x63\x61ncellation_type\x18\r \x01(\x0e\x32\x33.coresdk.workflow_commands.ActivityCancellationType\x12\x1e\n\x16\x64o_not_eagerly_execute\x18\x0e \x01(\x08\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"\xee\x05\n\x15ScheduleLocalActivity\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x13\n\x0b\x61\x63tivity_id\x18\x02 \x01(\t\x12\x15\n\ractivity_type\x18\x03 \x01(\t\x12\x0f\n\x07\x61ttempt\x18\x04 \x01(\r\x12:\n\x16original_schedule_time\x18\x05 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12N\n\x07headers\x18\x06 \x03(\x0b\x32=.coresdk.workflow_commands.ScheduleLocalActivity.HeadersEntry\x12\x32\n\targuments\x18\x07 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12<\n\x19schedule_to_close_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.Duration\x12<\n\x19schedule_to_start_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x39\n\x16start_to_close_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x39\n\x0cretry_policy\x18\x0b \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x38\n\x15local_retry_threshold\x18\x0c \x01(\x0b\x32\x19.google.protobuf.Duration\x12N\n\x11\x63\x61ncellation_type\x18\r \x01(\x0e\x32\x33.coresdk.workflow_commands.ActivityCancellationType\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"$\n\x15RequestCancelActivity\x12\x0b\n\x03seq\x18\x01 \x01(\r")\n\x1aRequestCancelLocalActivity\x12\x0b\n\x03seq\x18\x01 \x01(\r"\x9c\x01\n\x0bQueryResult\x12\x10\n\x08query_id\x18\x01 \x01(\t\x12<\n\tsucceeded\x18\x02 \x01(\x0b\x32\'.coresdk.workflow_commands.QuerySuccessH\x00\x12\x32\n\x06\x66\x61iled\x18\x03 \x01(\x0b\x32 .temporal.api.failure.v1.FailureH\x00\x42\t\n\x07variant"A\n\x0cQuerySuccess\x12\x31\n\x08response\x18\x01 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload"L\n\x19\x43ompleteWorkflowExecution\x12/\n\x06result\x18\x01 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload"J\n\x15\x46\x61ilWorkflowExecution\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"\xbe\x06\n\x1e\x43ontinueAsNewWorkflowExecution\x12\x15\n\rworkflow_type\x18\x01 \x01(\t\x12\x12\n\ntask_queue\x18\x02 \x01(\t\x12\x32\n\targuments\x18\x03 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12\x37\n\x14workflow_run_timeout\x18\x04 \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x38\n\x15workflow_task_timeout\x18\x05 \x01(\x0b\x32\x19.google.protobuf.Duration\x12Q\n\x04memo\x18\x06 \x03(\x0b\x32\x43.coresdk.workflow_commands.ContinueAsNewWorkflowExecution.MemoEntry\x12W\n\x07headers\x18\x07 \x03(\x0b\x32\x46.coresdk.workflow_commands.ContinueAsNewWorkflowExecution.HeadersEntry\x12j\n\x11search_attributes\x18\x08 \x03(\x0b\x32O.coresdk.workflow_commands.ContinueAsNewWorkflowExecution.SearchAttributesEntry\x12\x39\n\x0cretry_policy\x18\t \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x1aL\n\tMemoEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01\x1aX\n\x15SearchAttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"\x19\n\x17\x43\x61ncelWorkflowExecution"6\n\x0eSetPatchMarker\x12\x10\n\x08patch_id\x18\x01 \x01(\t\x12\x12\n\ndeprecated\x18\x02 \x01(\x08"\xa3\t\n\x1bStartChildWorkflowExecution\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x03 \x01(\t\x12\x15\n\rworkflow_type\x18\x04 \x01(\t\x12\x12\n\ntask_queue\x18\x05 \x01(\t\x12.\n\x05input\x18\x06 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12=\n\x1aworkflow_execution_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x37\n\x14workflow_run_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x38\n\x15workflow_task_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x46\n\x13parent_close_policy\x18\n \x01(\x0e\x32).coresdk.child_workflow.ParentClosePolicy\x12N\n\x18workflow_id_reuse_policy\x18\x0c \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x39\n\x0cretry_policy\x18\r \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\x0e \x01(\t\x12T\n\x07headers\x18\x0f \x03(\x0b\x32\x43.coresdk.workflow_commands.StartChildWorkflowExecution.HeadersEntry\x12N\n\x04memo\x18\x10 \x03(\x0b\x32@.coresdk.workflow_commands.StartChildWorkflowExecution.MemoEntry\x12g\n\x11search_attributes\x18\x11 \x03(\x0b\x32L.coresdk.workflow_commands.StartChildWorkflowExecution.SearchAttributesEntry\x12P\n\x11\x63\x61ncellation_type\x18\x12 \x01(\x0e\x32\x35.coresdk.child_workflow.ChildWorkflowCancellationType\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01\x1aL\n\tMemoEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01\x1aX\n\x15SearchAttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01":\n\x1c\x43\x61ncelChildWorkflowExecution\x12\x1a\n\x12\x63hild_workflow_seq\x18\x01 \x01(\r"\xa7\x01\n&RequestCancelExternalWorkflowExecution\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12I\n\x12workflow_execution\x18\x02 \x01(\x0b\x32+.coresdk.common.NamespacedWorkflowExecutionH\x00\x12\x1b\n\x11\x63hild_workflow_id\x18\x03 \x01(\tH\x00\x42\x08\n\x06target"\x8f\x03\n\x1fSignalExternalWorkflowExecution\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12I\n\x12workflow_execution\x18\x02 \x01(\x0b\x32+.coresdk.common.NamespacedWorkflowExecutionH\x00\x12\x1b\n\x11\x63hild_workflow_id\x18\x03 \x01(\tH\x00\x12\x13\n\x0bsignal_name\x18\x04 \x01(\t\x12-\n\x04\x61rgs\x18\x05 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12X\n\x07headers\x18\x06 \x03(\x0b\x32G.coresdk.workflow_commands.SignalExternalWorkflowExecution.HeadersEntry\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01\x42\x08\n\x06target"#\n\x14\x43\x61ncelSignalWorkflow\x12\x0b\n\x03seq\x18\x01 \x01(\r"\xe6\x01\n\x1eUpsertWorkflowSearchAttributes\x12j\n\x11search_attributes\x18\x01 \x03(\x0b\x32O.coresdk.workflow_commands.UpsertWorkflowSearchAttributes.SearchAttributesEntry\x1aX\n\x15SearchAttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"O\n\x18ModifyWorkflowProperties\x12\x33\n\rupserted_memo\x18\x01 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo*X\n\x18\x41\x63tivityCancellationType\x12\x0e\n\nTRY_CANCEL\x10\x00\x12\x1f\n\x1bWAIT_CANCELLATION_COMPLETED\x10\x01\x12\x0b\n\x07\x41\x42\x41NDON\x10\x02\x42,\xea\x02)Temporalio::Bridge::Api::WorkflowCommandsb\x06proto3'
+    b'\n;temporal/sdk/core/workflow_commands/workflow_commands.proto\x12\x19\x63oresdk.workflow_commands\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a$temporal/api/common/v1/message.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a%temporal/api/failure/v1/message.proto\x1a\x35temporal/sdk/core/child_workflow/child_workflow.proto\x1a%temporal/sdk/core/common/common.proto"\xac\r\n\x0fWorkflowCommand\x12<\n\x0bstart_timer\x18\x01 \x01(\x0b\x32%.coresdk.workflow_commands.StartTimerH\x00\x12H\n\x11schedule_activity\x18\x02 \x01(\x0b\x32+.coresdk.workflow_commands.ScheduleActivityH\x00\x12\x42\n\x10respond_to_query\x18\x03 \x01(\x0b\x32&.coresdk.workflow_commands.QueryResultH\x00\x12S\n\x17request_cancel_activity\x18\x04 \x01(\x0b\x32\x30.coresdk.workflow_commands.RequestCancelActivityH\x00\x12>\n\x0c\x63\x61ncel_timer\x18\x05 \x01(\x0b\x32&.coresdk.workflow_commands.CancelTimerH\x00\x12[\n\x1b\x63omplete_workflow_execution\x18\x06 \x01(\x0b\x32\x34.coresdk.workflow_commands.CompleteWorkflowExecutionH\x00\x12S\n\x17\x66\x61il_workflow_execution\x18\x07 \x01(\x0b\x32\x30.coresdk.workflow_commands.FailWorkflowExecutionH\x00\x12g\n"continue_as_new_workflow_execution\x18\x08 \x01(\x0b\x32\x39.coresdk.workflow_commands.ContinueAsNewWorkflowExecutionH\x00\x12W\n\x19\x63\x61ncel_workflow_execution\x18\t \x01(\x0b\x32\x32.coresdk.workflow_commands.CancelWorkflowExecutionH\x00\x12\x45\n\x10set_patch_marker\x18\n \x01(\x0b\x32).coresdk.workflow_commands.SetPatchMarkerH\x00\x12`\n\x1estart_child_workflow_execution\x18\x0b \x01(\x0b\x32\x36.coresdk.workflow_commands.StartChildWorkflowExecutionH\x00\x12\x62\n\x1f\x63\x61ncel_child_workflow_execution\x18\x0c \x01(\x0b\x32\x37.coresdk.workflow_commands.CancelChildWorkflowExecutionH\x00\x12w\n*request_cancel_external_workflow_execution\x18\r \x01(\x0b\x32\x41.coresdk.workflow_commands.RequestCancelExternalWorkflowExecutionH\x00\x12h\n"signal_external_workflow_execution\x18\x0e \x01(\x0b\x32:.coresdk.workflow_commands.SignalExternalWorkflowExecutionH\x00\x12Q\n\x16\x63\x61ncel_signal_workflow\x18\x0f \x01(\x0b\x32/.coresdk.workflow_commands.CancelSignalWorkflowH\x00\x12S\n\x17schedule_local_activity\x18\x10 \x01(\x0b\x32\x30.coresdk.workflow_commands.ScheduleLocalActivityH\x00\x12^\n\x1drequest_cancel_local_activity\x18\x11 \x01(\x0b\x32\x35.coresdk.workflow_commands.RequestCancelLocalActivityH\x00\x12\x66\n!upsert_workflow_search_attributes\x18\x12 \x01(\x0b\x32\x39.coresdk.workflow_commands.UpsertWorkflowSearchAttributesH\x00\x12Y\n\x1amodify_workflow_properties\x18\x13 \x01(\x0b\x32\x33.coresdk.workflow_commands.ModifyWorkflowPropertiesH\x00\x42\t\n\x07variant"S\n\nStartTimer\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x38\n\x15start_to_fire_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.Duration"\x1a\n\x0b\x43\x61ncelTimer\x12\x0b\n\x03seq\x18\x01 \x01(\r"\x84\x06\n\x10ScheduleActivity\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x13\n\x0b\x61\x63tivity_id\x18\x02 \x01(\t\x12\x15\n\ractivity_type\x18\x03 \x01(\t\x12\x12\n\ntask_queue\x18\x05 \x01(\t\x12I\n\x07headers\x18\x06 \x03(\x0b\x32\x38.coresdk.workflow_commands.ScheduleActivity.HeadersEntry\x12\x32\n\targuments\x18\x07 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12<\n\x19schedule_to_close_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.Duration\x12<\n\x19schedule_to_start_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x39\n\x16start_to_close_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x34\n\x11heartbeat_timeout\x18\x0b \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x39\n\x0cretry_policy\x18\x0c \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12N\n\x11\x63\x61ncellation_type\x18\r \x01(\x0e\x32\x33.coresdk.workflow_commands.ActivityCancellationType\x12\x1e\n\x16\x64o_not_eagerly_execute\x18\x0e \x01(\x08\x12;\n\x11versioning_intent\x18\x0f \x01(\x0e\x32 .coresdk.common.VersioningIntent\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"\xee\x05\n\x15ScheduleLocalActivity\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x13\n\x0b\x61\x63tivity_id\x18\x02 \x01(\t\x12\x15\n\ractivity_type\x18\x03 \x01(\t\x12\x0f\n\x07\x61ttempt\x18\x04 \x01(\r\x12:\n\x16original_schedule_time\x18\x05 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12N\n\x07headers\x18\x06 \x03(\x0b\x32=.coresdk.workflow_commands.ScheduleLocalActivity.HeadersEntry\x12\x32\n\targuments\x18\x07 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12<\n\x19schedule_to_close_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.Duration\x12<\n\x19schedule_to_start_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x39\n\x16start_to_close_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x39\n\x0cretry_policy\x18\x0b \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x38\n\x15local_retry_threshold\x18\x0c \x01(\x0b\x32\x19.google.protobuf.Duration\x12N\n\x11\x63\x61ncellation_type\x18\r \x01(\x0e\x32\x33.coresdk.workflow_commands.ActivityCancellationType\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"$\n\x15RequestCancelActivity\x12\x0b\n\x03seq\x18\x01 \x01(\r")\n\x1aRequestCancelLocalActivity\x12\x0b\n\x03seq\x18\x01 \x01(\r"\x9c\x01\n\x0bQueryResult\x12\x10\n\x08query_id\x18\x01 \x01(\t\x12<\n\tsucceeded\x18\x02 \x01(\x0b\x32\'.coresdk.workflow_commands.QuerySuccessH\x00\x12\x32\n\x06\x66\x61iled\x18\x03 \x01(\x0b\x32 .temporal.api.failure.v1.FailureH\x00\x42\t\n\x07variant"A\n\x0cQuerySuccess\x12\x31\n\x08response\x18\x01 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload"L\n\x19\x43ompleteWorkflowExecution\x12/\n\x06result\x18\x01 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload"J\n\x15\x46\x61ilWorkflowExecution\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"\xfb\x06\n\x1e\x43ontinueAsNewWorkflowExecution\x12\x15\n\rworkflow_type\x18\x01 \x01(\t\x12\x12\n\ntask_queue\x18\x02 \x01(\t\x12\x32\n\targuments\x18\x03 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12\x37\n\x14workflow_run_timeout\x18\x04 \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x38\n\x15workflow_task_timeout\x18\x05 \x01(\x0b\x32\x19.google.protobuf.Duration\x12Q\n\x04memo\x18\x06 \x03(\x0b\x32\x43.coresdk.workflow_commands.ContinueAsNewWorkflowExecution.MemoEntry\x12W\n\x07headers\x18\x07 \x03(\x0b\x32\x46.coresdk.workflow_commands.ContinueAsNewWorkflowExecution.HeadersEntry\x12j\n\x11search_attributes\x18\x08 \x03(\x0b\x32O.coresdk.workflow_commands.ContinueAsNewWorkflowExecution.SearchAttributesEntry\x12\x39\n\x0cretry_policy\x18\t \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12;\n\x11versioning_intent\x18\n \x01(\x0e\x32 .coresdk.common.VersioningIntent\x1aL\n\tMemoEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01\x1aX\n\x15SearchAttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"\x19\n\x17\x43\x61ncelWorkflowExecution"6\n\x0eSetPatchMarker\x12\x10\n\x08patch_id\x18\x01 \x01(\t\x12\x12\n\ndeprecated\x18\x02 \x01(\x08"\xe0\t\n\x1bStartChildWorkflowExecution\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x03 \x01(\t\x12\x15\n\rworkflow_type\x18\x04 \x01(\t\x12\x12\n\ntask_queue\x18\x05 \x01(\t\x12.\n\x05input\x18\x06 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12=\n\x1aworkflow_execution_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x37\n\x14workflow_run_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x38\n\x15workflow_task_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x46\n\x13parent_close_policy\x18\n \x01(\x0e\x32).coresdk.child_workflow.ParentClosePolicy\x12N\n\x18workflow_id_reuse_policy\x18\x0c \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x39\n\x0cretry_policy\x18\r \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\x0e \x01(\t\x12T\n\x07headers\x18\x0f \x03(\x0b\x32\x43.coresdk.workflow_commands.StartChildWorkflowExecution.HeadersEntry\x12N\n\x04memo\x18\x10 \x03(\x0b\x32@.coresdk.workflow_commands.StartChildWorkflowExecution.MemoEntry\x12g\n\x11search_attributes\x18\x11 \x03(\x0b\x32L.coresdk.workflow_commands.StartChildWorkflowExecution.SearchAttributesEntry\x12P\n\x11\x63\x61ncellation_type\x18\x12 \x01(\x0e\x32\x35.coresdk.child_workflow.ChildWorkflowCancellationType\x12;\n\x11versioning_intent\x18\x13 \x01(\x0e\x32 .coresdk.common.VersioningIntent\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01\x1aL\n\tMemoEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01\x1aX\n\x15SearchAttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01":\n\x1c\x43\x61ncelChildWorkflowExecution\x12\x1a\n\x12\x63hild_workflow_seq\x18\x01 \x01(\r"\xa7\x01\n&RequestCancelExternalWorkflowExecution\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12I\n\x12workflow_execution\x18\x02 \x01(\x0b\x32+.coresdk.common.NamespacedWorkflowExecutionH\x00\x12\x1b\n\x11\x63hild_workflow_id\x18\x03 \x01(\tH\x00\x42\x08\n\x06target"\x8f\x03\n\x1fSignalExternalWorkflowExecution\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12I\n\x12workflow_execution\x18\x02 \x01(\x0b\x32+.coresdk.common.NamespacedWorkflowExecutionH\x00\x12\x1b\n\x11\x63hild_workflow_id\x18\x03 \x01(\tH\x00\x12\x13\n\x0bsignal_name\x18\x04 \x01(\t\x12-\n\x04\x61rgs\x18\x05 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12X\n\x07headers\x18\x06 \x03(\x0b\x32G.coresdk.workflow_commands.SignalExternalWorkflowExecution.HeadersEntry\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01\x42\x08\n\x06target"#\n\x14\x43\x61ncelSignalWorkflow\x12\x0b\n\x03seq\x18\x01 \x01(\r"\xe6\x01\n\x1eUpsertWorkflowSearchAttributes\x12j\n\x11search_attributes\x18\x01 \x03(\x0b\x32O.coresdk.workflow_commands.UpsertWorkflowSearchAttributes.SearchAttributesEntry\x1aX\n\x15SearchAttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"O\n\x18ModifyWorkflowProperties\x12\x33\n\rupserted_memo\x18\x01 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo*X\n\x18\x41\x63tivityCancellationType\x12\x0e\n\nTRY_CANCEL\x10\x00\x12\x1f\n\x1bWAIT_CANCELLATION_COMPLETED\x10\x01\x12\x0b\n\x07\x41\x42\x41NDON\x10\x02\x42,\xea\x02)Temporalio::Bridge::Api::WorkflowCommandsb\x06proto3'
 )
 
 _ACTIVITYCANCELLATIONTYPE = DESCRIPTOR.enum_types_by_name["ActivityCancellationType"]
 ActivityCancellationType = enum_type_wrapper.EnumTypeWrapper(_ACTIVITYCANCELLATIONTYPE)
 TRY_CANCEL = 0
 WAIT_CANCELLATION_COMPLETED = 1
 ABANDON = 2
@@ -461,72 +461,72 @@
     _STARTCHILDWORKFLOWEXECUTION_MEMOENTRY._serialized_options = b"8\001"
     _STARTCHILDWORKFLOWEXECUTION_SEARCHATTRIBUTESENTRY._options = None
     _STARTCHILDWORKFLOWEXECUTION_SEARCHATTRIBUTESENTRY._serialized_options = b"8\001"
     _SIGNALEXTERNALWORKFLOWEXECUTION_HEADERSENTRY._options = None
     _SIGNALEXTERNALWORKFLOWEXECUTION_HEADERSENTRY._serialized_options = b"8\001"
     _UPSERTWORKFLOWSEARCHATTRIBUTES_SEARCHATTRIBUTESENTRY._options = None
     _UPSERTWORKFLOWSEARCHATTRIBUTES_SEARCHATTRIBUTESENTRY._serialized_options = b"8\001"
-    _ACTIVITYCANCELLATIONTYPE._serialized_start = 7205
-    _ACTIVITYCANCELLATIONTYPE._serialized_end = 7293
+    _ACTIVITYCANCELLATIONTYPE._serialized_start = 7388
+    _ACTIVITYCANCELLATIONTYPE._serialized_end = 7476
     _WORKFLOWCOMMAND._serialized_start = 365
     _WORKFLOWCOMMAND._serialized_end = 2073
     _STARTTIMER._serialized_start = 2075
     _STARTTIMER._serialized_end = 2158
     _CANCELTIMER._serialized_start = 2160
     _CANCELTIMER._serialized_end = 2186
     _SCHEDULEACTIVITY._serialized_start = 2189
-    _SCHEDULEACTIVITY._serialized_end = 2900
-    _SCHEDULEACTIVITY_HEADERSENTRY._serialized_start = 2821
-    _SCHEDULEACTIVITY_HEADERSENTRY._serialized_end = 2900
-    _SCHEDULELOCALACTIVITY._serialized_start = 2903
-    _SCHEDULELOCALACTIVITY._serialized_end = 3653
-    _SCHEDULELOCALACTIVITY_HEADERSENTRY._serialized_start = 2821
-    _SCHEDULELOCALACTIVITY_HEADERSENTRY._serialized_end = 2900
-    _REQUESTCANCELACTIVITY._serialized_start = 3655
-    _REQUESTCANCELACTIVITY._serialized_end = 3691
-    _REQUESTCANCELLOCALACTIVITY._serialized_start = 3693
-    _REQUESTCANCELLOCALACTIVITY._serialized_end = 3734
-    _QUERYRESULT._serialized_start = 3737
-    _QUERYRESULT._serialized_end = 3893
-    _QUERYSUCCESS._serialized_start = 3895
-    _QUERYSUCCESS._serialized_end = 3960
-    _COMPLETEWORKFLOWEXECUTION._serialized_start = 3962
-    _COMPLETEWORKFLOWEXECUTION._serialized_end = 4038
-    _FAILWORKFLOWEXECUTION._serialized_start = 4040
-    _FAILWORKFLOWEXECUTION._serialized_end = 4114
-    _CONTINUEASNEWWORKFLOWEXECUTION._serialized_start = 4117
-    _CONTINUEASNEWWORKFLOWEXECUTION._serialized_end = 4947
-    _CONTINUEASNEWWORKFLOWEXECUTION_MEMOENTRY._serialized_start = 4700
-    _CONTINUEASNEWWORKFLOWEXECUTION_MEMOENTRY._serialized_end = 4776
-    _CONTINUEASNEWWORKFLOWEXECUTION_HEADERSENTRY._serialized_start = 2821
-    _CONTINUEASNEWWORKFLOWEXECUTION_HEADERSENTRY._serialized_end = 2900
-    _CONTINUEASNEWWORKFLOWEXECUTION_SEARCHATTRIBUTESENTRY._serialized_start = 4859
-    _CONTINUEASNEWWORKFLOWEXECUTION_SEARCHATTRIBUTESENTRY._serialized_end = 4947
-    _CANCELWORKFLOWEXECUTION._serialized_start = 4949
-    _CANCELWORKFLOWEXECUTION._serialized_end = 4974
-    _SETPATCHMARKER._serialized_start = 4976
-    _SETPATCHMARKER._serialized_end = 5030
-    _STARTCHILDWORKFLOWEXECUTION._serialized_start = 5033
-    _STARTCHILDWORKFLOWEXECUTION._serialized_end = 6220
-    _STARTCHILDWORKFLOWEXECUTION_HEADERSENTRY._serialized_start = 2821
-    _STARTCHILDWORKFLOWEXECUTION_HEADERSENTRY._serialized_end = 2900
-    _STARTCHILDWORKFLOWEXECUTION_MEMOENTRY._serialized_start = 4700
-    _STARTCHILDWORKFLOWEXECUTION_MEMOENTRY._serialized_end = 4776
-    _STARTCHILDWORKFLOWEXECUTION_SEARCHATTRIBUTESENTRY._serialized_start = 4859
-    _STARTCHILDWORKFLOWEXECUTION_SEARCHATTRIBUTESENTRY._serialized_end = 4947
-    _CANCELCHILDWORKFLOWEXECUTION._serialized_start = 6222
-    _CANCELCHILDWORKFLOWEXECUTION._serialized_end = 6280
-    _REQUESTCANCELEXTERNALWORKFLOWEXECUTION._serialized_start = 6283
-    _REQUESTCANCELEXTERNALWORKFLOWEXECUTION._serialized_end = 6450
-    _SIGNALEXTERNALWORKFLOWEXECUTION._serialized_start = 6453
-    _SIGNALEXTERNALWORKFLOWEXECUTION._serialized_end = 6852
-    _SIGNALEXTERNALWORKFLOWEXECUTION_HEADERSENTRY._serialized_start = 2821
-    _SIGNALEXTERNALWORKFLOWEXECUTION_HEADERSENTRY._serialized_end = 2900
-    _CANCELSIGNALWORKFLOW._serialized_start = 6854
-    _CANCELSIGNALWORKFLOW._serialized_end = 6889
-    _UPSERTWORKFLOWSEARCHATTRIBUTES._serialized_start = 6892
-    _UPSERTWORKFLOWSEARCHATTRIBUTES._serialized_end = 7122
-    _UPSERTWORKFLOWSEARCHATTRIBUTES_SEARCHATTRIBUTESENTRY._serialized_start = 4859
-    _UPSERTWORKFLOWSEARCHATTRIBUTES_SEARCHATTRIBUTESENTRY._serialized_end = 4947
-    _MODIFYWORKFLOWPROPERTIES._serialized_start = 7124
-    _MODIFYWORKFLOWPROPERTIES._serialized_end = 7203
+    _SCHEDULEACTIVITY._serialized_end = 2961
+    _SCHEDULEACTIVITY_HEADERSENTRY._serialized_start = 2882
+    _SCHEDULEACTIVITY_HEADERSENTRY._serialized_end = 2961
+    _SCHEDULELOCALACTIVITY._serialized_start = 2964
+    _SCHEDULELOCALACTIVITY._serialized_end = 3714
+    _SCHEDULELOCALACTIVITY_HEADERSENTRY._serialized_start = 2882
+    _SCHEDULELOCALACTIVITY_HEADERSENTRY._serialized_end = 2961
+    _REQUESTCANCELACTIVITY._serialized_start = 3716
+    _REQUESTCANCELACTIVITY._serialized_end = 3752
+    _REQUESTCANCELLOCALACTIVITY._serialized_start = 3754
+    _REQUESTCANCELLOCALACTIVITY._serialized_end = 3795
+    _QUERYRESULT._serialized_start = 3798
+    _QUERYRESULT._serialized_end = 3954
+    _QUERYSUCCESS._serialized_start = 3956
+    _QUERYSUCCESS._serialized_end = 4021
+    _COMPLETEWORKFLOWEXECUTION._serialized_start = 4023
+    _COMPLETEWORKFLOWEXECUTION._serialized_end = 4099
+    _FAILWORKFLOWEXECUTION._serialized_start = 4101
+    _FAILWORKFLOWEXECUTION._serialized_end = 4175
+    _CONTINUEASNEWWORKFLOWEXECUTION._serialized_start = 4178
+    _CONTINUEASNEWWORKFLOWEXECUTION._serialized_end = 5069
+    _CONTINUEASNEWWORKFLOWEXECUTION_MEMOENTRY._serialized_start = 4822
+    _CONTINUEASNEWWORKFLOWEXECUTION_MEMOENTRY._serialized_end = 4898
+    _CONTINUEASNEWWORKFLOWEXECUTION_HEADERSENTRY._serialized_start = 2882
+    _CONTINUEASNEWWORKFLOWEXECUTION_HEADERSENTRY._serialized_end = 2961
+    _CONTINUEASNEWWORKFLOWEXECUTION_SEARCHATTRIBUTESENTRY._serialized_start = 4981
+    _CONTINUEASNEWWORKFLOWEXECUTION_SEARCHATTRIBUTESENTRY._serialized_end = 5069
+    _CANCELWORKFLOWEXECUTION._serialized_start = 5071
+    _CANCELWORKFLOWEXECUTION._serialized_end = 5096
+    _SETPATCHMARKER._serialized_start = 5098
+    _SETPATCHMARKER._serialized_end = 5152
+    _STARTCHILDWORKFLOWEXECUTION._serialized_start = 5155
+    _STARTCHILDWORKFLOWEXECUTION._serialized_end = 6403
+    _STARTCHILDWORKFLOWEXECUTION_HEADERSENTRY._serialized_start = 2882
+    _STARTCHILDWORKFLOWEXECUTION_HEADERSENTRY._serialized_end = 2961
+    _STARTCHILDWORKFLOWEXECUTION_MEMOENTRY._serialized_start = 4822
+    _STARTCHILDWORKFLOWEXECUTION_MEMOENTRY._serialized_end = 4898
+    _STARTCHILDWORKFLOWEXECUTION_SEARCHATTRIBUTESENTRY._serialized_start = 4981
+    _STARTCHILDWORKFLOWEXECUTION_SEARCHATTRIBUTESENTRY._serialized_end = 5069
+    _CANCELCHILDWORKFLOWEXECUTION._serialized_start = 6405
+    _CANCELCHILDWORKFLOWEXECUTION._serialized_end = 6463
+    _REQUESTCANCELEXTERNALWORKFLOWEXECUTION._serialized_start = 6466
+    _REQUESTCANCELEXTERNALWORKFLOWEXECUTION._serialized_end = 6633
+    _SIGNALEXTERNALWORKFLOWEXECUTION._serialized_start = 6636
+    _SIGNALEXTERNALWORKFLOWEXECUTION._serialized_end = 7035
+    _SIGNALEXTERNALWORKFLOWEXECUTION_HEADERSENTRY._serialized_start = 2882
+    _SIGNALEXTERNALWORKFLOWEXECUTION_HEADERSENTRY._serialized_end = 2961
+    _CANCELSIGNALWORKFLOW._serialized_start = 7037
+    _CANCELSIGNALWORKFLOW._serialized_end = 7072
+    _UPSERTWORKFLOWSEARCHATTRIBUTES._serialized_start = 7075
+    _UPSERTWORKFLOWSEARCHATTRIBUTES._serialized_end = 7305
+    _UPSERTWORKFLOWSEARCHATTRIBUTES_SEARCHATTRIBUTESENTRY._serialized_start = 4981
+    _UPSERTWORKFLOWSEARCHATTRIBUTES_SEARCHATTRIBUTESENTRY._serialized_end = 5069
+    _MODIFYWORKFLOWPROPERTIES._serialized_start = 7307
+    _MODIFYWORKFLOWPROPERTIES._serialized_end = 7386
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/workflow_commands/workflow_commands_pb2.pyi` & `temporalio-1.3.0/temporalio/bridge/proto/workflow_commands/workflow_commands_pb2.pyi`

 * *Files 2% similar despite different names*

```diff
@@ -370,14 +370,15 @@
     SCHEDULE_TO_CLOSE_TIMEOUT_FIELD_NUMBER: builtins.int
     SCHEDULE_TO_START_TIMEOUT_FIELD_NUMBER: builtins.int
     START_TO_CLOSE_TIMEOUT_FIELD_NUMBER: builtins.int
     HEARTBEAT_TIMEOUT_FIELD_NUMBER: builtins.int
     RETRY_POLICY_FIELD_NUMBER: builtins.int
     CANCELLATION_TYPE_FIELD_NUMBER: builtins.int
     DO_NOT_EAGERLY_EXECUTE_FIELD_NUMBER: builtins.int
+    VERSIONING_INTENT_FIELD_NUMBER: builtins.int
     seq: builtins.int
     """Lang's incremental sequence number, used as the operation identifier"""
     activity_id: builtins.str
     activity_type: builtins.str
     task_queue: builtins.str
     """The name of the task queue to place this activity request in"""
     @property
@@ -422,14 +423,16 @@
     cancellation_type: global___ActivityCancellationType.ValueType
     """Defines how the workflow will wait (or not) for cancellation of the activity to be confirmed"""
     do_not_eagerly_execute: builtins.bool
     """If set, the worker will not tell the service that it can immediately start executing this
     activity. When unset/default, workers will always attempt to do so if activity execution
     slots are available.
     """
+    versioning_intent: temporalio.bridge.proto.common.common_pb2.VersioningIntent.ValueType
+    """Whether this activity should run on a worker with a compatible build id or not."""
     def __init__(
         self,
         *,
         seq: builtins.int = ...,
         activity_id: builtins.str = ...,
         activity_type: builtins.str = ...,
         task_queue: builtins.str = ...,
@@ -444,14 +447,15 @@
         schedule_to_close_timeout: google.protobuf.duration_pb2.Duration | None = ...,
         schedule_to_start_timeout: google.protobuf.duration_pb2.Duration | None = ...,
         start_to_close_timeout: google.protobuf.duration_pb2.Duration | None = ...,
         heartbeat_timeout: google.protobuf.duration_pb2.Duration | None = ...,
         retry_policy: temporalio.api.common.v1.message_pb2.RetryPolicy | None = ...,
         cancellation_type: global___ActivityCancellationType.ValueType = ...,
         do_not_eagerly_execute: builtins.bool = ...,
+        versioning_intent: temporalio.bridge.proto.common.common_pb2.VersioningIntent.ValueType = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
             "heartbeat_timeout",
             b"heartbeat_timeout",
             "retry_policy",
@@ -489,14 +493,16 @@
             b"schedule_to_start_timeout",
             "seq",
             b"seq",
             "start_to_close_timeout",
             b"start_to_close_timeout",
             "task_queue",
             b"task_queue",
+            "versioning_intent",
+            b"versioning_intent",
         ],
     ) -> None: ...
 
 global___ScheduleActivity = ScheduleActivity
 
 class ScheduleLocalActivity(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -892,14 +898,15 @@
     ARGUMENTS_FIELD_NUMBER: builtins.int
     WORKFLOW_RUN_TIMEOUT_FIELD_NUMBER: builtins.int
     WORKFLOW_TASK_TIMEOUT_FIELD_NUMBER: builtins.int
     MEMO_FIELD_NUMBER: builtins.int
     HEADERS_FIELD_NUMBER: builtins.int
     SEARCH_ATTRIBUTES_FIELD_NUMBER: builtins.int
     RETRY_POLICY_FIELD_NUMBER: builtins.int
+    VERSIONING_INTENT_FIELD_NUMBER: builtins.int
     workflow_type: builtins.str
     """The identifier the lang-specific sdk uses to execute workflow code"""
     task_queue: builtins.str
     """Task queue for the new workflow execution"""
     @property
     def arguments(
         self,
@@ -941,14 +948,16 @@
         workflow's search attributes.
         """
     @property
     def retry_policy(self) -> temporalio.api.common.v1.message_pb2.RetryPolicy:
         """If set, the new workflow will have this retry policy. If unset, re-uses the current
         workflow's retry policy.
         """
+    versioning_intent: temporalio.bridge.proto.common.common_pb2.VersioningIntent.ValueType
+    """Whether the continued workflow should run on a worker with a compatible build id or not."""
     def __init__(
         self,
         *,
         workflow_type: builtins.str = ...,
         task_queue: builtins.str = ...,
         arguments: collections.abc.Iterable[
             temporalio.api.common.v1.message_pb2.Payload
@@ -965,14 +974,15 @@
         ]
         | None = ...,
         search_attributes: collections.abc.Mapping[
             builtins.str, temporalio.api.common.v1.message_pb2.Payload
         ]
         | None = ...,
         retry_policy: temporalio.api.common.v1.message_pb2.RetryPolicy | None = ...,
+        versioning_intent: temporalio.bridge.proto.common.common_pb2.VersioningIntent.ValueType = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
             "retry_policy",
             b"retry_policy",
             "workflow_run_timeout",
@@ -992,14 +1002,16 @@
             b"memo",
             "retry_policy",
             b"retry_policy",
             "search_attributes",
             b"search_attributes",
             "task_queue",
             b"task_queue",
+            "versioning_intent",
+            b"versioning_intent",
             "workflow_run_timeout",
             b"workflow_run_timeout",
             "workflow_task_timeout",
             b"workflow_task_timeout",
             "workflow_type",
             b"workflow_type",
         ],
@@ -1135,14 +1147,15 @@
     WORKFLOW_ID_REUSE_POLICY_FIELD_NUMBER: builtins.int
     RETRY_POLICY_FIELD_NUMBER: builtins.int
     CRON_SCHEDULE_FIELD_NUMBER: builtins.int
     HEADERS_FIELD_NUMBER: builtins.int
     MEMO_FIELD_NUMBER: builtins.int
     SEARCH_ATTRIBUTES_FIELD_NUMBER: builtins.int
     CANCELLATION_TYPE_FIELD_NUMBER: builtins.int
+    VERSIONING_INTENT_FIELD_NUMBER: builtins.int
     seq: builtins.int
     """Lang's incremental sequence number, used as the operation identifier"""
     namespace: builtins.str
     workflow_id: builtins.str
     workflow_type: builtins.str
     task_queue: builtins.str
     @property
@@ -1188,14 +1201,16 @@
         self,
     ) -> google.protobuf.internal.containers.MessageMap[
         builtins.str, temporalio.api.common.v1.message_pb2.Payload
     ]:
         """Search attributes"""
     cancellation_type: temporalio.bridge.proto.child_workflow.child_workflow_pb2.ChildWorkflowCancellationType.ValueType
     """Defines behaviour of the underlying workflow when child workflow cancellation has been requested."""
+    versioning_intent: temporalio.bridge.proto.common.common_pb2.VersioningIntent.ValueType
+    """Whether this child should run on a worker with a compatible build id or not."""
     def __init__(
         self,
         *,
         seq: builtins.int = ...,
         namespace: builtins.str = ...,
         workflow_id: builtins.str = ...,
         workflow_type: builtins.str = ...,
@@ -1218,14 +1233,15 @@
         ]
         | None = ...,
         search_attributes: collections.abc.Mapping[
             builtins.str, temporalio.api.common.v1.message_pb2.Payload
         ]
         | None = ...,
         cancellation_type: temporalio.bridge.proto.child_workflow.child_workflow_pb2.ChildWorkflowCancellationType.ValueType = ...,
+        versioning_intent: temporalio.bridge.proto.common.common_pb2.VersioningIntent.ValueType = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
             "retry_policy",
             b"retry_policy",
             "workflow_execution_timeout",
@@ -1257,14 +1273,16 @@
             b"retry_policy",
             "search_attributes",
             b"search_attributes",
             "seq",
             b"seq",
             "task_queue",
             b"task_queue",
+            "versioning_intent",
+            b"versioning_intent",
             "workflow_execution_timeout",
             b"workflow_execution_timeout",
             "workflow_id",
             b"workflow_id",
             "workflow_id_reuse_policy",
             b"workflow_id_reuse_policy",
             "workflow_run_timeout",
```

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/workflow_completion/workflow_completion_pb2.py` & `temporalio-1.3.0/temporalio/bridge/proto/workflow_completion/workflow_completion_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/proto/workflow_completion/workflow_completion_pb2.pyi` & `temporalio-1.3.0/temporalio/bridge/proto/workflow_completion/workflow_completion_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/runtime.py` & `temporalio-1.3.0/temporalio/bridge/runtime.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose-ci.yaml` & `temporalio-1.3.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose-ci.yaml`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose-telem.yaml` & `temporalio-1.3.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose-telem.yaml`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose.yaml` & `temporalio-1.3.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose.yaml`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/.buildkite/pipeline.yml` & `temporalio-1.3.0/temporalio/bridge/sdk-core/.buildkite/pipeline.yml`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/.cargo/config.toml` & `temporalio-1.3.0/temporalio/bridge/sdk-core/.cargo/config.toml`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/.github/workflows/heavy.yml` & `temporalio-1.3.0/temporalio/bridge/sdk-core/.github/workflows/heavy.yml`

 * *Files 4% similar despite different names*

```diff
@@ -22,8 +22,8 @@
         with:
           version: '3.x'
           repo-token: ${{ secrets.GITHUB_TOKEN }}
 
       - uses: actions-rs/cargo@v1
         with:
           command: integ-test
-          args: -c "--release" -c "--all-features" -t heavy_tests -- --test-threads 1
+          args: -c "--release" -c "--features=save_wf_inputs" -t heavy_tests -- --test-threads 1
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/ARCHITECTURE.md` & `temporalio-1.3.0/temporalio/bridge/sdk-core/ARCHITECTURE.md`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/LICENSE.txt` & `temporalio-1.3.0/temporalio/bridge/sdk-core/LICENSE.txt`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/README.md` & `temporalio-1.3.0/temporalio/bridge/sdk-core/README.md`

 * *Files 2% similar despite different names*

```diff
@@ -38,14 +38,16 @@
 You can buld and test the project using cargo:
 `cargo build`
 `cargo test`
 
 Run integ tests with `cargo integ-test`. You will need to already be running the server:
 `docker-compose -f .buildkite/docker/docker-compose.yaml up`
 
+Run load tests with `cargo test --features=save_wf_inputs --test heavy_tests`.
+
 ## Formatting
 To format all code run:
 `cargo fmt --all`
 
 ## Linting
 We are using [clippy](https://github.com/rust-lang/rust-clippy) for linting.
 You can run it using:
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/arch_docs/diagrams/README.md` & `temporalio-1.3.0/temporalio/bridge/sdk-core/arch_docs/diagrams/README.md`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/arch_docs/diagrams/sticky_queues.puml` & `temporalio-1.3.0/temporalio/bridge/sdk-core/arch_docs/diagrams/sticky_queues.puml`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/arch_docs/diagrams/workflow_internals.svg` & `temporalio-1.3.0/temporalio/bridge/sdk-core/arch_docs/diagrams/workflow_internals.svg`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/arch_docs/sticky_queues.md` & `temporalio-1.3.0/temporalio/bridge/sdk-core/arch_docs/sticky_queues.md`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/client/Cargo.toml` & `temporalio-1.3.0/temporalio/bridge/sdk-core/client/Cargo.toml`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/client/LICENSE.txt` & `temporalio-1.3.0/temporalio/bridge/sdk-core/client/LICENSE.txt`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/client/src/lib.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/client/src/lib.rs`

 * *Files 2% similar despite different names*

```diff
@@ -45,15 +45,15 @@
     time::{Duration, Instant},
 };
 use temporal_sdk_core_protos::{
     coresdk::{workflow_commands::QueryResult, IntoPayloadsExt},
     grpc::health::v1::health_client::HealthClient,
     temporal::api::{
         common::v1::{Header, Payload, Payloads, WorkflowExecution, WorkflowType},
-        enums::v1::{TaskQueueKind, WorkflowIdReusePolicy, WorkflowTaskFailedCause},
+        enums::v1::{TaskQueueKind, WorkflowIdReusePolicy},
         failure::v1::Failure,
         operatorservice::v1::operator_service_client::OperatorServiceClient,
         query::v1::WorkflowQuery,
         replication::v1::ClusterReplicationConfig,
         taskqueue::v1::TaskQueue,
         testservice::v1::test_service_client::TestServiceClient,
         workflowservice::v1::{workflow_service_client::WorkflowServiceClient, *},
@@ -521,28 +521,25 @@
 /// Contains an instance of a namespace-bound client for interacting with the Temporal server
 #[derive(Debug, Clone)]
 pub struct Client {
     /// Client for interacting with workflow service
     inner: ConfiguredClient<TemporalServiceClientWithMetrics>,
     /// The namespace this client interacts with
     namespace: String,
-    /// If set, attach as the worker build id to relevant calls
-    bound_worker_build_id: Option<String>,
 }
 
 impl Client {
     /// Create a new client from an existing configured lower level client and a namespace
     pub fn new(
         client: ConfiguredClient<TemporalServiceClientWithMetrics>,
         namespace: String,
     ) -> Self {
         Client {
             inner: client,
             namespace,
-            bound_worker_build_id: None,
         }
     }
 
     /// Return an auto-retrying version of the underling grpc client (instrumented with metrics
     /// collection, if enabled).
     ///
     /// Note that it is reasonably cheap to clone the returned type if you need to own it. Such
@@ -568,20 +565,14 @@
     }
 
     /// Return the options this client was initialized with mutably
     pub fn options_mut(&mut self) -> &mut ClientOptions {
         Arc::make_mut(&mut self.inner.options)
     }
 
-    /// Set a worker build id to be attached to relevant requests. Unlikely to be useful outside
-    /// of core.
-    pub fn set_worker_build_id(&mut self, id: String) {
-        self.bound_worker_build_id = Some(id)
-    }
-
     /// Returns a reference to the underlying client
     pub fn inner(&self) -> &ConfiguredClient<TemporalServiceClientWithMetrics> {
         &self.inner
     }
 
     /// Consumes self and returns the underlying client
     pub fn into_inner(self) -> ConfiguredClient<TemporalServiceClientWithMetrics> {
@@ -796,23 +787,14 @@
     /// failure details, such as message, cause and stack trace.
     async fn fail_activity_task(
         &self,
         task_token: TaskToken,
         failure: Option<Failure>,
     ) -> Result<RespondActivityTaskFailedResponse>;
 
-    /// Fail task by sending the failure to the server. `task_token` is the task token that would've
-    /// been received from polling for a workflow activation.
-    async fn fail_workflow_task(
-        &self,
-        task_token: TaskToken,
-        cause: WorkflowTaskFailedCause,
-        failure: Option<Failure>,
-    ) -> Result<RespondWorkflowTaskFailedResponse>;
-
     /// Send a signal to a certain workflow instance
     async fn signal_workflow_execution(
         &self,
         workflow_id: String,
         run_id: String,
         signal_name: String,
         payloads: Option<Payloads>,
@@ -972,14 +954,15 @@
                 workflow_id,
                 workflow_type: Some(WorkflowType {
                     name: workflow_type,
                 }),
                 task_queue: Some(TaskQueue {
                     name: task_queue,
                     kind: TaskQueueKind::Unspecified as i32,
+                    normal_name: "".to_string(),
                 }),
                 request_id: request_id.unwrap_or_else(|| Uuid::new_v4().to_string()),
                 workflow_id_reuse_policy: options.id_reuse_policy as i32,
                 workflow_execution_timeout: options
                     .execution_timeout
                     .and_then(|d| d.try_into().ok()),
                 workflow_run_timeout: options.execution_timeout.and_then(|d| d.try_into().ok()),
@@ -1019,14 +1002,15 @@
         Ok(self
             .wf_svc()
             .respond_activity_task_completed(RespondActivityTaskCompletedRequest {
                 task_token: task_token.0,
                 result,
                 identity: self.inner.options.identity.clone(),
                 namespace: self.namespace.clone(),
+                worker_version: None,
             })
             .await?
             .into_inner())
     }
 
     async fn record_activity_heartbeat(
         &self,
@@ -1053,14 +1037,15 @@
         Ok(self
             .wf_svc()
             .respond_activity_task_canceled(RespondActivityTaskCanceledRequest {
                 task_token: task_token.0,
                 details,
                 identity: self.inner.options.identity.clone(),
                 namespace: self.namespace.clone(),
+                worker_version: None,
             })
             .await?
             .into_inner())
     }
 
     async fn fail_activity_task(
         &self,
@@ -1072,41 +1057,20 @@
             .respond_activity_task_failed(RespondActivityTaskFailedRequest {
                 task_token: task_token.0,
                 failure,
                 identity: self.inner.options.identity.clone(),
                 namespace: self.namespace.clone(),
                 // TODO: Implement - https://github.com/temporalio/sdk-core/issues/293
                 last_heartbeat_details: None,
+                worker_version: None,
             })
             .await?
             .into_inner())
     }
 
-    async fn fail_workflow_task(
-        &self,
-        task_token: TaskToken,
-        cause: WorkflowTaskFailedCause,
-        failure: Option<Failure>,
-    ) -> Result<RespondWorkflowTaskFailedResponse> {
-        let request = RespondWorkflowTaskFailedRequest {
-            task_token: task_token.0,
-            cause: cause as i32,
-            failure,
-            identity: self.inner.options.identity.clone(),
-            binary_checksum: self.bound_worker_build_id.clone().unwrap_or_default(),
-            namespace: self.namespace.clone(),
-            messages: vec![],
-        };
-        Ok(self
-            .wf_svc()
-            .respond_workflow_task_failed(request)
-            .await?
-            .into_inner())
-    }
-
     async fn signal_workflow_execution(
         &self,
         workflow_id: String,
         run_id: String,
         signal_name: String,
         payloads: Option<Payloads>,
         request_id: Option<String>,
@@ -1141,14 +1105,15 @@
                 workflow_id: options.workflow_id,
                 workflow_type: Some(WorkflowType {
                     name: options.workflow_type,
                 }),
                 task_queue: Some(TaskQueue {
                     name: options.task_queue,
                     kind: TaskQueueKind::Normal as i32,
+                    normal_name: "".to_string(),
                 }),
                 input: options.input,
                 signal_name: options.signal_name,
                 signal_input: options.signal_input,
                 identity: self.inner.options.identity.clone(),
                 request_id: options
                     .request_id
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/client/src/metrics.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/client/src/metrics.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/client/src/raw.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/client/src/raw.rs`

 * *Files 1% similar despite different names*

```diff
@@ -756,14 +756,23 @@
         |r| {
             let mut labels = AttachMetricLabels::namespace(r.get_ref().namespace.clone());
             labels.task_q_str(r.get_ref().task_queue.clone());
             r.extensions_mut().insert(labels);
         }
     );
     (
+        get_worker_task_reachability,
+        GetWorkerTaskReachabilityRequest,
+        GetWorkerTaskReachabilityResponse,
+        |r| {
+            let mut labels = AttachMetricLabels::namespace(r.get_ref().namespace.clone());
+            r.extensions_mut().insert(labels);
+        }
+    );
+    (
         update_workflow_execution,
         UpdateWorkflowExecutionRequest,
         UpdateWorkflowExecutionResponse,
         |r| {
             let labels = AttachMetricLabels::namespace(r.get_ref().namespace.clone());
             r.extensions_mut().insert(labels);
         }
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/client/src/retry.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/client/src/retry.rs`

 * *Files 2% similar despite different names*

```diff
@@ -5,15 +5,14 @@
 use backoff::{backoff::Backoff, exponential::ExponentialBackoff, Clock, SystemClock};
 use futures_retry::{ErrorHandler, FutureRetry, RetryPolicy};
 use std::{fmt::Debug, future::Future, sync::Arc, time::Duration};
 use temporal_sdk_core_protos::{
     coresdk::workflow_commands::QueryResult,
     temporal::api::{
         common::v1::{Payload, Payloads},
-        enums::v1::WorkflowTaskFailedCause,
         failure::v1::Failure,
         query::v1::WorkflowQuery,
         workflowservice::v1::*,
     },
     TaskToken,
 };
 use tonic::Code;
@@ -322,29 +321,14 @@
             self,
             fail_activity_task,
             task_token.clone(),
             failure.clone()
         )
     }
 
-    async fn fail_workflow_task(
-        &self,
-        task_token: TaskToken,
-        cause: WorkflowTaskFailedCause,
-        failure: Option<Failure>,
-    ) -> Result<RespondWorkflowTaskFailedResponse> {
-        retry_call!(
-            self,
-            fail_workflow_task,
-            task_token.clone(),
-            cause,
-            failure.clone()
-        )
-    }
-
     async fn signal_workflow_execution(
         &self,
         workflow_id: String,
         run_id: String,
         signal_name: String,
         payloads: Option<Payloads>,
         request_id: Option<String>,
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/client/src/workflow_handle/mod.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/client/src/workflow_handle/mod.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/Cargo.toml` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/Cargo.toml`

 * *Files 12% similar despite different names*

```diff
@@ -9,71 +9,75 @@
 repository = "https://github.com/temporalio/sdk-core"
 keywords = ["temporal", "workflow"]
 categories = ["development-tools"]
 
 [lib]
 
 [features]
+default = []
 # Do not enable this feature when building production SDKs. If we ever want a user in the field to
 # record WF input data, we can build them a custom SDK or they can build - it adds significant extra
 # code size in the form of [de]serializers.
 save_wf_inputs = ["rmp-serde", "temporal-sdk-core-protos/serde_serialize"]
+tokio-console = ["console-subscriber"]
+ephemeral-server = ["dep:flate2", "dep:nix", "dep:reqwest", "dep:tar", "dep:zip"]
 
 [dependencies]
 anyhow = "1.0"
 arc-swap = "1.3"
 async-trait = "0.1"
 base64 = "0.21"
+console-subscriber = { version = "0.1", optional = true }
 crossbeam = "0.8"
 dashmap = "5.0"
 derive_builder = "0.12"
 derive_more = "0.99"
 enum_dispatch = "0.3"
 enum-iterator = "1.4"
-flate2 = "1.0"
+flate2 = { version = "1.0", optional = true }
 futures = "0.3"
 futures-util = "0.3"
 governor = "0.5"
 http = "0.2"
 hyper = "0.14"
 itertools = "0.10"
 lazy_static = "1.4"
 lru = "0.10"
 mockall = "0.11"
-nix = "0.26"
+nix = { version = "0.26", optional = true }
 once_cell = "1.5"
 opentelemetry = { version = "0.18", features = ["rt-tokio"] }
 opentelemetry-otlp = { version = "0.11", features = ["tokio", "metrics"] }
 opentelemetry-prometheus = "0.11"
 parking_lot = { version = "0.12", features = ["send_guard"] }
 pin-project = "1.0"
 prometheus = "0.13"
 prost = "0.11"
 prost-types = { version = "0.4", package = "prost-wkt-types" }
 rand = "0.8.3"
-reqwest = { version = "0.11", features = ["json", "stream", "rustls-tls", "tokio-rustls"], default-features = false }
+reqwest = { version = "0.11", features = ["json", "stream", "rustls-tls", "tokio-rustls"], default-features = false, optional = true }
 ringbuf = "0.3"
 rmp-serde = { version = "1.1", optional = true }
 serde = "1.0"
 serde_json = "1.0"
 siphasher = "0.3"
 slotmap = "1.0"
-tar = "0.4"
+tar = { version = "0.4", optional = true }
 thiserror = "1.0"
 tokio = { version = "1.26", features = ["rt", "rt-multi-thread", "parking_lot", "time", "fs", "process"] }
 tokio-util = { version = "0.7", features = ["io", "io-util"] }
 tokio-stream = "0.1"
 tonic = { version = "0.8", features = ["tls", "tls-roots"] }
 tracing = "0.1"
 tracing-futures = "0.2"
 tracing-opentelemetry = "0.18"
 tracing-subscriber = { version = "0.3", features = ["parking_lot", "env-filter", "registry"] }
 url = "2.2"
 uuid = { version = "1.1", features = ["v4"] }
-zip = "0.6.3"
+zip = { version = "0.6.3", optional = true }
 
 # 1st party local deps
 [dependencies.temporal-sdk-core-api]
 path = "../core-api"
 version = "0.1"
 
 [dependencies.temporal-sdk-core-protos]
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/LICENSE.txt` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/LICENSE.txt`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/benches/workflow_replay.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/benches/workflow_replay.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/abstractions/take_cell.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/abstractions/take_cell.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/abstractions.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/abstractions.rs`

 * *Files 25% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 //! This module contains very generic helpers that can be used codebase-wide
 
 pub mod take_cell;
 
 use crate::MetricsContext;
 use derive_more::DebugCustom;
-use futures::{stream, Stream, StreamExt};
 use std::{
     fmt::{Debug, Formatter},
     sync::{
         atomic::{AtomicBool, AtomicUsize, Ordering},
         Arc,
     },
 };
@@ -43,14 +42,19 @@
         }
     }
 
     pub fn available_permits(&self) -> usize {
         self.sem.available_permits()
     }
 
+    #[cfg(test)]
+    pub fn unused_permits(&self) -> usize {
+        self.sem.available_permits() + self.unused_claimants.load(Ordering::Acquire)
+    }
+
     pub async fn acquire_owned(&self) -> Result<OwnedMeteredSemPermit, AcquireError> {
         let res = self.sem.clone().acquire_owned().await?;
         Ok(self.build_owned(res))
     }
 
     pub fn try_acquire_owned(&self) -> Result<OwnedMeteredSemPermit, TryAcquireError> {
         let res = self.sem.clone().try_acquire_owned()?;
@@ -110,16 +114,16 @@
             close_complete_token: CancellationToken::new(),
         })
     }
 }
 
 impl ClosableMeteredSemaphore {
     #[cfg(test)]
-    pub fn available_permits(&self) -> usize {
-        self.inner.available_permits()
+    pub fn unused_permits(&self) -> usize {
+        self.inner.unused_permits()
     }
 
     /// Request to close the semaphore and prevent new permits from being acquired.
     pub fn close(&self) {
         self.close_requested.store(true, Ordering::Release);
         if self.outstanding_permits.load(Ordering::Acquire) == 0 {
             self.close_complete_token.cancel();
@@ -227,97 +231,25 @@
             inner,
             unused_claimants: None,
             record_fn: Box::new(|_| {}),
         })
     }
 }
 
-/// From the input stream, create a new stream which only pulls from the input stream when allowed.
-/// When allowed is determined by the passed in `proceeder` emitting an item. The input stream is
-/// only pulled from when that future resolves.
-///
-/// This is *almost* identical to `zip`, but does not terminate early if the input stream closes.
-/// The proceeder must allow the poll before the returned stream closes. If the proceeder terminates
-/// the overall stream will terminate.
-pub(crate) fn stream_when_allowed<S, AS>(
-    input: S,
-    proceeder: AS,
-) -> impl Stream<Item = (S::Item, AS::Item)>
-where
-    S: Stream + Send + 'static,
-    AS: Stream + Send + 'static,
-{
-    let stream = stream::unfold(
-        (proceeder.boxed(), input.boxed()),
-        |(mut proceeder, mut input)| async {
-            let v = proceeder.next().await;
-            if let Some(v) = v {
-                input.next().await.map(|i| ((i, v), (proceeder, input)))
-            } else {
-                None
-            }
-        },
-    );
-    stream
-}
-
 macro_rules! dbg_panic {
   ($($arg:tt)*) => {
       error!($($arg)*);
       debug_assert!(false, $($arg)*);
   };
 }
 pub(crate) use dbg_panic;
 
 #[cfg(test)]
 mod tests {
     use super::*;
-    use futures::pin_mut;
-    use std::task::Poll;
-    use tokio::sync::mpsc::unbounded_channel;
-    use tokio_stream::wrappers::UnboundedReceiverStream;
-
-    #[test]
-    fn stream_when_allowed_works() {
-        let inputs = stream::iter([1, 2, 3]);
-        let (allow_tx, allow_rx) = unbounded_channel();
-        let when_allowed = stream_when_allowed(inputs, UnboundedReceiverStream::new(allow_rx));
-
-        let waker = futures::task::noop_waker_ref();
-        let mut cx = std::task::Context::from_waker(waker);
-        pin_mut!(when_allowed);
-
-        allow_tx.send(()).unwrap();
-        assert_eq!(
-            when_allowed.poll_next_unpin(&mut cx),
-            Poll::Ready(Some((1, ())))
-        );
-        // Now, it won't be ready
-        for _ in 1..10 {
-            assert_eq!(when_allowed.poll_next_unpin(&mut cx), Poll::Pending);
-        }
-        allow_tx.send(()).unwrap();
-        assert_eq!(
-            when_allowed.poll_next_unpin(&mut cx),
-            Poll::Ready(Some((2, ())))
-        );
-        for _ in 1..10 {
-            assert_eq!(when_allowed.poll_next_unpin(&mut cx), Poll::Pending);
-        }
-        allow_tx.send(()).unwrap();
-        assert_eq!(
-            when_allowed.poll_next_unpin(&mut cx),
-            Poll::Ready(Some((3, ())))
-        );
-        for _ in 1..10 {
-            assert_eq!(when_allowed.poll_next_unpin(&mut cx), Poll::Pending);
-        }
-        allow_tx.send(()).unwrap();
-        assert_eq!(when_allowed.poll_next_unpin(&mut cx), Poll::Ready(None));
-    }
 
     #[tokio::test]
     async fn closable_semaphore_permit_drop_returns_permit() {
         let inner = MeteredSemaphore::new(2, MetricsContext::no_op(), |_, _| {});
         let sem = ClosableMeteredSemaphore::new_arc(Arc::new(inner));
         let perm = sem.try_acquire_owned().unwrap();
         let permits = sem.outstanding_permits.load(Ordering::Acquire);
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/activity_tasks.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/core_tests/activity_tasks.rs`

 * *Files 0% similar despite different names*

```diff
@@ -1054,34 +1054,42 @@
 
 #[rstest::rstest]
 #[tokio::test]
 async fn graceful_shutdown(#[values(true, false)] at_max_outstanding: bool) {
     let _task_q = "q";
     let grace_period = Duration::from_millis(200);
     let mut tasks = three_tasks();
-    let mut mock_client = mock_workflow_client();
-    mock_client
-        .expect_poll_activity_task()
+    let mut mock_act_poller = mock_poller();
+    mock_act_poller
+        .expect_poll()
         .times(3)
-        .returning(move |_, _| Ok(tasks.pop_front().unwrap()));
+        .returning(move || Some(Ok(tasks.pop_front().unwrap())));
+    mock_act_poller
+        .expect_poll()
+        .times(1)
+        .returning(move || None);
     // They shall all be reported as failed
+    let mut mock_client = mock_workflow_client();
     mock_client
         .expect_fail_activity_task()
         .times(3)
         .returning(|_, _| Ok(Default::default()));
 
     let max_outstanding = if at_max_outstanding { 3_usize } else { 100 };
-    let worker = Worker::new_test(
-        test_worker_cfg()
+    let mw = MockWorkerInputs {
+        act_poller: Some(Box::from(mock_act_poller)),
+        config: test_worker_cfg()
             .graceful_shutdown_period(grace_period)
             .max_outstanding_activities(max_outstanding)
+            .max_concurrent_at_polls(1_usize) // Makes test logic simple
             .build()
             .unwrap(),
-        mock_client,
-    );
+        ..Default::default()
+    };
+    let worker = mock_worker(MocksHolder::from_mock_worker(mock_client, mw));
 
     let _1 = worker.poll_activity_task().await.unwrap();
 
     // Wait at least the grace period after one poll - ensuring it doesn't trigger prematurely
     tokio::time::sleep(grace_period.mul_f32(1.1)).await;
 
     let _2 = worker.poll_activity_task().await.unwrap();
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/child_workflows.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/core_tests/child_workflows.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/determinism.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/core_tests/determinism.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/local_activities.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/core_tests/local_activities.rs`

 * *Files 3% similar despite different names*

```diff
@@ -17,15 +17,16 @@
         atomic::{AtomicUsize, Ordering},
         Arc,
     },
     time::{Duration, SystemTime},
 };
 use temporal_client::WorkflowOptions;
 use temporal_sdk::{
-    ActContext, ActivityCancelledError, LocalActivityOptions, WfContext, WorkflowResult,
+    ActContext, ActivityCancelledError, LocalActivityOptions, WfContext, WorkflowFunction,
+    WorkflowResult,
 };
 use temporal_sdk_core_api::{
     errors::{PollActivityError, PollWfError},
     Worker,
 };
 use temporal_sdk_core_protos::{
     coresdk::{
@@ -44,15 +45,15 @@
         query::v1::WorkflowQuery,
     },
     DEFAULT_ACTIVITY_TYPE,
 };
 use temporal_sdk_core_test_utils::{
     schedule_local_activity_cmd, start_timer_cmd, WorkerTestHelpers,
 };
-use tokio::{join, sync::Barrier};
+use tokio::{join, select, sync::Barrier};
 
 async fn echo(_ctx: ActContext, e: String) -> anyhow::Result<String> {
     Ok(e)
 }
 
 /// This test verifies that when replaying we are able to resolve local activities whose data we
 /// don't see until after the workflow issues the command
@@ -879,14 +880,104 @@
             WorkflowOptions::default(),
         )
         .await
         .unwrap();
     worker.run_until_done().await.unwrap();
 }
 
+#[rstest::rstest]
+#[tokio::test]
+async fn start_to_close_timeout_allows_retries(#[values(true, false)] la_completes: bool) {
+    let mut t = TestHistoryBuilder::default();
+    t.add_by_type(EventType::WorkflowExecutionStarted);
+    t.add_full_wf_task();
+    if la_completes {
+        t.add_local_activity_marker(1, "1", Some("hi".into()), None, |_| {});
+    } else {
+        t.add_local_activity_marker(
+            1,
+            "1",
+            None,
+            Some(Failure::application_failure("la failed".to_string(), false)),
+            |_| {},
+        );
+    }
+    t.add_full_wf_task();
+    t.add_workflow_execution_completed();
+
+    let wf_id = "fakeid";
+    let mock = mock_workflow_client();
+    let mh = MockPollCfg::from_resp_batches(
+        wf_id,
+        t,
+        [ResponseType::ToTaskNum(1), ResponseType::AllHistory],
+        mock,
+    );
+    let mut worker = mock_sdk_cfg(mh, |w| w.max_cached_workflows = 1);
+
+    worker.register_wf(
+        DEFAULT_WORKFLOW_TYPE.to_owned(),
+        move |ctx: WfContext| async move {
+            let la_res = ctx
+                .local_activity(LocalActivityOptions {
+                    activity_type: DEFAULT_ACTIVITY_TYPE.to_string(),
+                    input: "hi".as_json_payload().expect("serializes fine"),
+                    retry_policy: RetryPolicy {
+                        initial_interval: Some(prost_dur!(from_millis(20))),
+                        backoff_coefficient: 1.0,
+                        maximum_interval: None,
+                        maximum_attempts: 5,
+                        non_retryable_error_types: vec![],
+                    },
+                    start_to_close_timeout: Some(prost_dur!(from_millis(25))),
+                    ..Default::default()
+                })
+                .await;
+            if la_completes {
+                assert!(la_res.completed_ok());
+            } else {
+                assert_eq!(la_res.timed_out(), Some(TimeoutType::StartToClose));
+            }
+            Ok(().into())
+        },
+    );
+    let attempts: &'static _ = Box::leak(Box::new(AtomicUsize::new(0)));
+    let cancels: &'static _ = Box::leak(Box::new(AtomicUsize::new(0)));
+    worker.register_activity(
+        DEFAULT_ACTIVITY_TYPE,
+        move |ctx: ActContext, _: String| async move {
+            // Timeout the first 4 attempts, or all of them if we intend to fail
+            if attempts.fetch_add(1, Ordering::AcqRel) < 4 || !la_completes {
+                select! {
+                    _ = tokio::time::sleep(Duration::from_millis(100)) => (),
+                    _ = ctx.cancelled() => {
+                        cancels.fetch_add(1, Ordering::AcqRel);
+                        return Err(anyhow!(ActivityCancelledError::default()));
+                    }
+                }
+            }
+            Ok(())
+        },
+    );
+    worker
+        .submit_wf(
+            wf_id.to_owned(),
+            DEFAULT_WORKFLOW_TYPE.to_owned(),
+            vec![],
+            WorkflowOptions::default(),
+        )
+        .await
+        .unwrap();
+    worker.run_until_done().await.unwrap();
+    // Activity should have been attempted all 5 times
+    assert_eq!(attempts.load(Ordering::Acquire), 5);
+    let num_cancels = if la_completes { 4 } else { 5 };
+    assert_eq!(cancels.load(Ordering::Acquire), num_cancels);
+}
+
 #[tokio::test]
 async fn wft_failure_cancels_running_las() {
     let mut t = TestHistoryBuilder::default();
     t.add_wfe_started_with_wft_timeout(Duration::from_millis(200));
     t.add_full_wf_task();
     let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
     t.add_timer_fired(timer_started_event_id, "1".to_string());
@@ -960,25 +1051,26 @@
         [1.into(), ResponseType::AllHistory, ResponseType::AllHistory],
         mock,
     );
     mh.num_expected_fails = 2;
     mh.num_expected_completions = Some(0.into());
     let mut worker = mock_sdk_cfg(mh, |w| w.max_cached_workflows = 1);
 
+    #[allow(unreachable_code)]
     worker.register_wf(
         DEFAULT_WORKFLOW_TYPE.to_owned(),
-        |ctx: WfContext| async move {
+        WorkflowFunction::new::<_, _, ()>(|ctx: WfContext| async move {
             ctx.local_activity(LocalActivityOptions {
                 activity_type: "echo".to_string(),
                 input: "hi".as_json_payload().expect("serializes fine"),
                 ..Default::default()
             })
             .await;
-            panic!("Oh nooooo")
-        },
+            panic!()
+        }),
     );
     worker.register_activity(
         "echo",
         move |_: ActContext, _: String| async move { Ok(()) },
     );
     worker
         .submit_wf(
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/mod.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/core_tests/mod.rs`

 * *Files 1% similar despite different names*

```diff
@@ -60,15 +60,15 @@
                 Ok(Default::default())
             }
             .boxed()
         });
     mock_client
         .expect_poll_workflow_task()
         .times(1)
-        .returning(move |_, _| {
+        .returning(move |_| {
             async move {
                 BARR.wait().await;
                 sleep(Duration::from_secs(1)).await;
                 Ok(Default::default())
             }
             .boxed()
         });
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/queries.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/core_tests/queries.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/replay_flag.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/core_tests/replay_flag.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/workers.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/core_tests/workers.rs`

 * *Files 6% similar despite different names*

```diff
@@ -1,26 +1,28 @@
 use crate::{
     prost_dur,
     test_help::{
-        build_fake_worker, build_mock_pollers, canned_histories, mock_manual_poller, mock_worker,
-        MockPollCfg, MockWorkerInputs, MocksHolder, ResponseType, WorkerExt,
+        build_fake_worker, build_mock_pollers, canned_histories, mock_worker, MockPollCfg,
+        MockWorkerInputs, MocksHolder, ResponseType, WorkerExt,
     },
     worker::client::mocks::mock_workflow_client,
     PollActivityError, PollWfError,
 };
-use futures::FutureExt;
+use futures_util::{stream, stream::StreamExt};
 use std::{cell::RefCell, time::Duration};
 use temporal_sdk_core_api::Worker;
 use temporal_sdk_core_protos::{
     coresdk::{
         workflow_activation::workflow_activation_job,
         workflow_commands::{workflow_command, CompleteWorkflowExecution, StartTimer},
         workflow_completion::WorkflowActivationCompletion,
     },
-    temporal::api::workflowservice::v1::RespondWorkflowTaskCompletedResponse,
+    temporal::api::workflowservice::v1::{
+        PollWorkflowTaskQueueResponse, RespondWorkflowTaskCompletedResponse,
+    },
 };
 use temporal_sdk_core_test_utils::start_timer_cmd;
 use tokio::sync::{watch, Barrier};
 
 #[tokio::test]
 async fn after_shutdown_of_worker_get_shutdown_err() {
     let t = canned_histories::single_timer("1");
@@ -83,28 +85,26 @@
         );
     });
 }
 
 #[tokio::test]
 async fn worker_shutdown_during_poll_doesnt_deadlock() {
     let (tx, rx) = watch::channel(false);
-    let mut mock_poller = mock_manual_poller();
     let rx = rx.clone();
-    mock_poller.expect_poll().returning(move || {
-        let mut rx = rx.clone();
-        async move {
-            // Don't resolve polls until worker shuts down
-            rx.changed().await.unwrap();
-            // We don't want to return a real response here because it would get buffered and
-            // then we'd have real work to do to be able to finish shutdown.
-            Some(Ok(Default::default()))
-        }
-        .boxed()
+    let stream = stream::unfold(rx, |mut rx| async move {
+        // Don't resolve polls until worker shuts down
+        rx.changed().await.unwrap();
+        // We don't want to return a real response here because it would get buffered and
+        // then we'd have real work to do to be able to finish shutdown.
+        Some((
+            Ok(PollWorkflowTaskQueueResponse::default().try_into().unwrap()),
+            rx,
+        ))
     });
-    let mw = MockWorkerInputs::new_from_poller(Box::new(mock_poller));
+    let mw = MockWorkerInputs::new(stream.boxed());
     let mut mock_client = mock_workflow_client();
     mock_client
         .expect_complete_workflow_task()
         .returning(|_| Ok(RespondWorkflowTaskCompletedResponse::default()));
     let worker = mock_worker(MocksHolder::from_mock_worker(mock_client, mw));
     let pollfut = worker.poll_workflow_activation();
     let shutdownfut = async {
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/workflow_cancels.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/core_tests/workflow_cancels.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/workflow_tasks.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/core_tests/workflow_tasks.rs`

 * *Files 1% similar despite different names*

```diff
@@ -3,44 +3,46 @@
     internal_flags::CoreInternalFlags,
     job_assert,
     replay::TestHistoryBuilder,
     test_help::{
         build_fake_worker, build_mock_pollers, build_multihist_mock_sg, canned_histories,
         gen_assert_and_fail, gen_assert_and_reply, hist_to_poll_resp, mock_sdk, mock_sdk_cfg,
         mock_worker, poll_and_reply, poll_and_reply_clears_outstanding_evicts, single_hist_mock_sg,
-        test_worker_cfg, FakeWfResponses, MockPollCfg, MocksHolder, ResponseType,
+        test_worker_cfg, FakeWfResponses, MockPollCfg, MocksHolder, ResponseType, WorkerExt,
         WorkflowCachingPolicy::{self, AfterEveryReply, NonSticky},
     },
     worker::client::mocks::{mock_manual_workflow_client, mock_workflow_client},
     Worker,
 };
 use futures::{stream, FutureExt};
 use rstest::{fixture, rstest};
 use std::{
     collections::{HashMap, HashSet, VecDeque},
     sync::{
-        atomic::{AtomicU64, Ordering},
+        atomic::{AtomicU64, AtomicUsize, Ordering},
+        mpsc::sync_channel,
         Arc,
     },
     time::Duration,
 };
 use temporal_client::WorkflowOptions;
 use temporal_sdk::{ActivityOptions, CancellableFuture, WfContext};
 use temporal_sdk_core_api::{errors::PollWfError, Worker as WorkerTrait};
 use temporal_sdk_core_protos::{
     coresdk::{
         activity_result::{self as ar, activity_resolution, ActivityResolution},
+        common::VersioningIntent,
         workflow_activation::{
             remove_from_cache::EvictionReason, workflow_activation_job, FireTimer, ResolveActivity,
             StartWorkflow, UpdateRandomSeed, WorkflowActivationJob,
         },
         workflow_commands::{
             ActivityCancellationType, CancelTimer, CompleteWorkflowExecution,
             ContinueAsNewWorkflowExecution, FailWorkflowExecution, RequestCancelActivity,
-            ScheduleActivity, SetPatchMarker,
+            ScheduleActivity, SetPatchMarker, StartChildWorkflowExecution,
         },
         workflow_completion::WorkflowActivationCompletion,
     },
     default_act_sched, default_wes_attribs,
     temporal::api::{
         command::v1::command::Attributes,
         common::v1::{Payload, RetryPolicy},
@@ -56,14 +58,15 @@
     },
     DEFAULT_ACTIVITY_TYPE, DEFAULT_WORKFLOW_TYPE,
 };
 use temporal_sdk_core_test_utils::{fanout_tasks, start_timer_cmd, WorkerTestHelpers};
 use tokio::{
     join,
     sync::{Barrier, Semaphore},
+    time,
 };
 
 #[fixture(hist_batches = &[])]
 fn single_timer_setup(hist_batches: &'static [usize]) -> Worker {
     let wfid = "fake_wf_id";
 
     let t = canned_histories::single_timer("1");
@@ -1531,34 +1534,32 @@
         run_id = activation.run_id.clone();
         worker
             .complete_workflow_activation(WorkflowActivationCompletion::empty(activation.run_id))
             .await
             .unwrap();
     }
     assert_eq!(worker.outstanding_workflow_tasks().await, 0);
-    // 1 permit is in use because the next task is buffered and has re-used the permit
-    assert_eq!(worker.available_wft_permits().await, 1);
     // We should be "out of work" because the mock service thinks we didn't complete the last task,
     // which we didn't, because we don't spam failures. The real server would eventually time out
     // the task. Mock doesn't understand that, so the WFT permit is released because eventually a
     // new one will be generated. We manually clear the mock's outstanding task list so the next
     // poll will work.
     outstanding_mock_tasks.unwrap().release_run(&run_id);
     let activation = worker.poll_workflow_activation().await.unwrap();
     // There should be no change in permits, since this just unbuffered the buffered task
-    assert_eq!(worker.available_wft_permits().await, 1);
+    assert_eq!(worker.available_wft_permits(), 1);
     worker
         .complete_workflow_activation(WorkflowActivationCompletion::from_cmd(
             activation.run_id,
             CompleteWorkflowExecution { result: None }.into(),
         ))
         .await
         .unwrap();
     worker.shutdown().await;
-    assert_eq!(worker.available_wft_permits().await, 2);
+    assert_eq!(worker.available_wft_permits(), 2);
 }
 
 #[tokio::test]
 async fn cache_miss_will_fetch_history() {
     let mut t = TestHistoryBuilder::default();
     t.add_by_type(EventType::WorkflowExecutionStarted);
     t.add_full_wf_task();
@@ -1643,14 +1644,53 @@
         ))
         .await
         .unwrap();
     assert_eq!(worker.outstanding_workflow_tasks().await, 0);
     worker.shutdown().await;
 }
 
+#[tokio::test]
+async fn history_byte_size_and_can_suggestion_in_activation() {
+    let mut t = TestHistoryBuilder::default();
+    t.add_by_type(EventType::WorkflowExecutionStarted);
+    t.add_full_wf_task();
+    t.add_we_signaled("sig", vec![]);
+    t.add_full_wf_task();
+    t.add_workflow_execution_completed();
+    t.modify_event(7, |he| {
+        if let Some(history_event::Attributes::WorkflowTaskStartedEventAttributes(ref mut attrs)) =
+            he.attributes
+        {
+            attrs.suggest_continue_as_new = true;
+        }
+    });
+
+    let mh = MockPollCfg::from_resp_batches(
+        "fake_wf_id",
+        t,
+        [ResponseType::ToTaskNum(1), ResponseType::OneTask(2)],
+        mock_workflow_client(),
+    );
+    let mut mock = build_mock_pollers(mh);
+    mock.worker_cfg(|cfg| cfg.max_cached_workflows = 1);
+    let worker = mock_worker(mock);
+
+    let activation = worker.poll_workflow_activation().await.unwrap();
+    // Test builder always does num events * 10
+    assert_eq!(activation.history_size_bytes, 30);
+    assert!(!activation.continue_as_new_suggested);
+    worker
+        .complete_workflow_activation(WorkflowActivationCompletion::empty(activation.run_id))
+        .await
+        .unwrap();
+    let activation = worker.poll_workflow_activation().await.unwrap();
+    assert_eq!(activation.history_size_bytes, 70);
+    assert!(activation.continue_as_new_suggested);
+}
+
 /// This test verifies that WFTs which come as replies to completing a WFT are properly delivered
 /// via activation polling.
 #[tokio::test]
 async fn tasks_from_completion_are_delivered() {
     let wfid = "fake_wf_id";
     let mut t = TestHistoryBuilder::default();
     t.add_by_type(EventType::WorkflowExecutionStarted);
@@ -1871,15 +1911,15 @@
             Some(workflow_activation_job::Variant::StartWorkflow(sw))
             if sw.workflow_id == "wf-5"
         );
     };
 
     join!(blocking_poll, complete_evict);
     // p5 outstanding and final poll outstanding -- hence one permit available
-    assert_eq!(core.available_wft_permits().await, 1);
+    assert_eq!(core.available_wft_permits(), 1);
     assert_eq!(core.cached_workflows().await, 3);
 }
 
 #[tokio::test]
 async fn eviction_waits_until_replay_finished() {
     let wfid = "fake_wf_id";
     let t = canned_histories::long_sequential_timers(3);
@@ -1998,33 +2038,31 @@
 #[tokio::test]
 async fn no_race_acquiring_permits() {
     let wfid = "fake_wf_id";
     let mut mock_client = mock_manual_workflow_client();
     // We need to allow two polls to happen by triggering two processing events in the workflow
     // stream, but then delivering the actual tasks after that
     let task_barr: &'static Barrier = Box::leak(Box::new(Barrier::new(2)));
-    mock_client
-        .expect_poll_workflow_task()
-        .returning(move |_, _| {
-            let t = canned_histories::single_timer("1");
-            let poll_resp = hist_to_poll_resp(&t, wfid.to_owned(), 2.into()).resp;
-            async move {
-                task_barr.wait().await;
-                Ok(poll_resp.clone())
-            }
-            .boxed()
-        });
+    mock_client.expect_poll_workflow_task().returning(move |_| {
+        let t = canned_histories::single_timer("1");
+        let poll_resp = hist_to_poll_resp(&t, wfid.to_owned(), 2.into()).resp;
+        async move {
+            task_barr.wait().await;
+            Ok(poll_resp.clone())
+        }
+        .boxed()
+    });
     mock_client
         .expect_complete_workflow_task()
         .returning(|_| async move { Ok(Default::default()) }.boxed());
 
     let worker = Worker::new_test(
         test_worker_cfg()
-            .max_outstanding_workflow_tasks(1_usize)
-            .max_cached_workflows(10_usize)
+            .max_outstanding_workflow_tasks(2_usize)
+            .max_cached_workflows(0_usize)
             .build()
             .unwrap(),
         mock_client,
     );
 
     // Two polls in a row, both of which will get stuck on the barrier and are only allowed to
     // proceed after a call which will cause the workflow stream to process an event. Without the
@@ -2053,14 +2091,15 @@
     let other_f = async {
         worker.cached_workflows().await;
         task_barr.wait().await;
         worker.cached_workflows().await;
         task_barr.wait().await;
     };
     join!(poll_1_f, poll_2_f, other_f);
+    worker.drain_pollers_and_shutdown().await;
 }
 
 #[tokio::test]
 async fn continue_as_new_preserves_some_values() {
     let wfid = "fake_wf_id";
     let memo = HashMap::<String, Payload>::from([("enchi".to_string(), b"cat".into())]).into();
     let search = HashMap::<String, Payload>::from([("noisy".to_string(), b"kitty".into())]).into();
@@ -2075,24 +2114,22 @@
     let mut mock_client = mock_workflow_client();
     let hist = {
         let mut t = TestHistoryBuilder::default();
         t.add(wes_attrs.clone());
         t.add_full_wf_task();
         t
     };
-    mock_client
-        .expect_poll_workflow_task()
-        .returning(move |_, _| {
-            Ok(hist_to_poll_resp(&hist, wfid.to_owned(), ResponseType::AllHistory).resp)
-        });
+    mock_client.expect_poll_workflow_task().returning(move |_| {
+        Ok(hist_to_poll_resp(&hist, wfid.to_owned(), ResponseType::AllHistory).resp)
+    });
     mock_client
         .expect_complete_workflow_task()
         .returning(move |mut c| {
-            let can_cmd = c.commands.pop().unwrap().attributes.unwrap();
-            if let Attributes::ContinueAsNewWorkflowExecutionCommandAttributes(a) = can_cmd {
+            let cmd = c.commands.pop().unwrap().attributes.unwrap();
+            if let Attributes::ContinueAsNewWorkflowExecutionCommandAttributes(a) = cmd {
                 assert_eq!(a.workflow_type.unwrap().name, "meow");
                 assert_eq!(a.memo, wes_attrs.memo);
                 assert_eq!(a.search_attributes, wes_attrs.search_attributes);
                 assert_eq!(a.retry_policy, wes_attrs.retry_policy);
             } else {
                 panic!("Wrong attributes type");
             }
@@ -2584,7 +2621,189 @@
             vec![],
             WorkflowOptions::default(),
         )
         .await
         .unwrap();
     worker.run_until_done().await.unwrap();
 }
+
+#[tokio::test]
+async fn poller_wont_run_ahead_of_task_slots() {
+    let popped_tasks = Arc::new(AtomicUsize::new(0));
+    let ptc = popped_tasks.clone();
+    let mut bunch_of_first_tasks = (1..50).map(move |i| {
+        ptc.fetch_add(1, Ordering::Relaxed);
+        hist_to_poll_resp(
+            &canned_histories::single_timer(&format!("{i}")),
+            format!("wf-{i}"),
+            1.into(),
+        )
+        .resp
+    });
+    let mut mock_client = mock_workflow_client();
+    mock_client
+        .expect_poll_workflow_task()
+        .returning(move |_| Ok(bunch_of_first_tasks.next().unwrap()));
+    mock_client
+        .expect_complete_workflow_task()
+        .returning(|_| Ok(Default::default()));
+
+    let worker = Worker::new_test(
+        test_worker_cfg()
+            .max_cached_workflows(10_usize)
+            .max_outstanding_workflow_tasks(10_usize)
+            .max_concurrent_wft_polls(10_usize)
+            .no_remote_activities(true)
+            .build()
+            .unwrap(),
+        mock_client,
+    );
+
+    // Should be able to get up to 10 tasks
+    let mut tasks = vec![];
+    for _ in 0..10 {
+        tasks.push(worker.poll_workflow_activation().await.unwrap());
+    }
+
+    assert_eq!(worker.outstanding_workflow_tasks().await, 10);
+    assert_eq!(worker.available_wft_permits(), 0);
+    assert_eq!(worker.unused_wft_permits(), 0);
+
+    // This one should hang until we complete some tasks since we're at the limit
+    let hung_poll = async {
+        // This should end up getting shut down after the other routine finishes tasks
+        assert_matches!(
+            worker.poll_workflow_activation().await.unwrap_err(),
+            PollWfError::ShutDown
+        );
+    };
+    // Wait for a bit concurrently with above, verify no extra tasks got taken, shutdown
+    let ender = async {
+        time::sleep(Duration::from_millis(300)).await;
+        // initiate shutdown, then complete open tasks
+        worker.initiate_shutdown();
+        for t in tasks {
+            worker
+                .complete_workflow_activation(WorkflowActivationCompletion::empty(t.run_id))
+                .await
+                .unwrap();
+        }
+        worker.shutdown().await;
+    };
+    join!(hung_poll, ender);
+    // We shouldn't have got more than the 10 tasks from the poller -- verifying that the concurrent
+    // polling is not exceeding the task limit
+    assert_eq!(popped_tasks.load(Ordering::Relaxed), 10);
+}
+
+#[tokio::test]
+async fn poller_wont_poll_until_lang_polls() {
+    let mut mock_client = mock_workflow_client();
+    let (tx, rx) = sync_channel(101);
+    // Normally you'd just not set any expectations, but the problem is since we never poll
+    // the WFT stream, we'll never join the tasks running the pollers and thus the error
+    // gets printed but doesn't bubble up to the test. So we set this explicit expectation
+    // in here to ensure it isn't called.
+    mock_client.expect_poll_workflow_task().returning(move |_| {
+        let _ = tx.send(());
+        Ok(Default::default())
+    });
+
+    let worker = Worker::new_test(
+        test_worker_cfg()
+            .no_remote_activities(true)
+            .build()
+            .unwrap(),
+        mock_client,
+    );
+
+    tokio::time::sleep(Duration::from_millis(100)).await;
+
+    worker.drain_pollers_and_shutdown().await;
+    // Nothing should've appeared here or we did poll
+    assert!(rx.recv().is_err());
+}
+
+#[rstest]
+#[tokio::test]
+async fn use_compatible_version_flag(
+    #[values(
+        VersioningIntent::Unspecified,
+        VersioningIntent::Compatible,
+        VersioningIntent::Default
+    )]
+    intent: VersioningIntent,
+    #[values(true, false)] different_tq: bool,
+    #[values("activity", "child_wf", "continue_as_new")] command_type: &'static str,
+) {
+    let wfid = "fake_wf_id";
+    let mut mock_client = mock_workflow_client();
+    let hist = {
+        let mut t = TestHistoryBuilder::default();
+        t.add_by_type(EventType::WorkflowExecutionStarted);
+        t.add_full_wf_task();
+        t
+    };
+    mock_client.expect_poll_workflow_task().returning(move |_| {
+        Ok(hist_to_poll_resp(&hist, wfid.to_owned(), ResponseType::AllHistory).resp)
+    });
+    let compat_flag_expected = match intent {
+        VersioningIntent::Unspecified => !different_tq,
+        VersioningIntent::Compatible => true,
+        VersioningIntent::Default => false,
+    };
+    mock_client
+        .expect_complete_workflow_task()
+        .returning(move |mut c| {
+            let can_cmd = c.commands.pop().unwrap().attributes.unwrap();
+            match can_cmd {
+                Attributes::ContinueAsNewWorkflowExecutionCommandAttributes(a) => {
+                    assert_eq!(a.use_compatible_version, compat_flag_expected);
+                }
+                Attributes::ScheduleActivityTaskCommandAttributes(a) => {
+                    assert_eq!(a.use_compatible_version, compat_flag_expected);
+                }
+                Attributes::StartChildWorkflowExecutionCommandAttributes(a) => {
+                    assert_eq!(a.use_compatible_version, compat_flag_expected);
+                }
+                _ => panic!("invalid attributes type"),
+            }
+            Ok(Default::default())
+        });
+
+    let worker = Worker::new_test(test_worker_cfg().build().unwrap(), mock_client);
+    let r = worker.poll_workflow_activation().await.unwrap();
+    let task_queue = if different_tq {
+        "enchi cat!".to_string()
+    } else {
+        "".to_string()
+    };
+    let cmd = match command_type {
+        "continue_as_new" => ContinueAsNewWorkflowExecution {
+            workflow_type: "meow".to_string(),
+            versioning_intent: intent as i32,
+            task_queue,
+            ..Default::default()
+        }
+        .into(),
+        "activity" => ScheduleActivity {
+            seq: 1,
+            activity_id: "1".to_string(),
+            versioning_intent: intent as i32,
+            task_queue,
+            ..default_act_sched()
+        }
+        .into(),
+        "child_wf" => StartChildWorkflowExecution {
+            seq: 1,
+            versioning_intent: intent as i32,
+            task_queue,
+            ..Default::default()
+        }
+        .into(),
+        _ => panic!("invalid command type"),
+    };
+    worker
+        .complete_workflow_activation(WorkflowActivationCompletion::from_cmd(r.run_id, cmd))
+        .await
+        .unwrap();
+}
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/ephemeral_server/mod.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/ephemeral_server/mod.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/internal_flags.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/internal_flags.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/lib.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/lib.rs`

 * *Files 2% similar despite different names*

```diff
@@ -8,14 +8,15 @@
 #[macro_use]
 pub extern crate assert_matches;
 #[macro_use]
 extern crate tracing;
 extern crate core;
 
 mod abstractions;
+#[cfg(feature = "ephemeral-server")]
 pub mod ephemeral_server;
 mod internal_flags;
 mod pollers;
 mod protosext;
 pub mod replay;
 pub(crate) mod retry_logic;
 pub mod telemetry;
@@ -78,15 +79,14 @@
 ) -> Result<Worker, anyhow::Error>
 where
     CT: Into<sealed::AnyClient>,
 {
     let client = {
         let ll = client.into().into_inner();
         let mut client = Client::new(*ll, worker_config.namespace.clone());
-        client.set_worker_build_id(worker_config.worker_build_id.clone());
         if let Some(ref id_override) = worker_config.client_identity_override {
             client.options_mut().identity = id_override.clone();
         }
         RetryClient::new(client, RetryConfig::default())
     };
     if client.namespace() != worker_config.namespace {
         panic!("Passed in client is not bound to the same namespace as the worker");
@@ -143,17 +143,16 @@
 /// workflows.
 pub(crate) fn sticky_q_name_for_worker(
     process_identity: &str,
     config: &WorkerConfig,
 ) -> Option<String> {
     if config.max_cached_workflows > 0 {
         Some(format!(
-            "{}-{}-{}",
+            "{}-{}",
             &process_identity,
-            &config.task_queue,
             uuid::Uuid::new_v4().simple()
         ))
     } else {
         None
     }
 }
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/pollers/poll_buffer.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/pollers/poll_buffer.rs`

 * *Files 19% similar despite different names*

```diff
@@ -1,158 +1,182 @@
 use crate::{
+    abstractions::{dbg_panic, MeteredSemaphore, OwnedMeteredSemPermit},
     pollers::{self, Poller},
     worker::client::WorkerClient,
 };
 use futures::{prelude::stream::FuturesUnordered, StreamExt};
+use futures_util::{future::BoxFuture, FutureExt};
+use governor::{Quota, RateLimiter};
 use std::{
     fmt::Debug,
     future::Future,
     sync::{
-        atomic::{AtomicUsize, Ordering},
+        atomic::{AtomicBool, AtomicUsize, Ordering},
         Arc,
     },
+    time::Duration,
 };
-use temporal_sdk_core_protos::temporal::api::workflowservice::v1::{
-    PollActivityTaskQueueResponse, PollWorkflowTaskQueueResponse,
+use temporal_sdk_core_protos::temporal::api::{
+    taskqueue::v1::TaskQueue,
+    workflowservice::v1::{PollActivityTaskQueueResponse, PollWorkflowTaskQueueResponse},
 };
 use tokio::{
     sync::{
-        mpsc::{channel, Receiver},
-        Mutex, Semaphore,
+        broadcast,
+        mpsc::{unbounded_channel, UnboundedReceiver},
+        Mutex,
     },
     task::JoinHandle,
 };
 use tokio_util::sync::CancellationToken;
 
 pub struct LongPollBuffer<T> {
-    buffered_polls: Mutex<Receiver<pollers::Result<T>>>,
+    buffered_polls: Mutex<UnboundedReceiver<pollers::Result<(T, OwnedMeteredSemPermit)>>>,
     shutdown: CancellationToken,
-    /// This semaphore exists to ensure that we only poll server as many times as core actually
-    /// *asked* it to be polled - otherwise we might spin and buffer polls constantly. This also
-    /// means unit tests can continue to function in a predictable manner when calling mocks.
-    polls_requested: Arc<Semaphore>,
     join_handles: FuturesUnordered<JoinHandle<()>>,
-    /// Called every time the number of pollers is changed
-    num_pollers_changed: Option<Box<dyn Fn(usize) + Send + Sync>>,
-    active_pollers: Arc<AtomicUsize>,
+    /// Pollers won't actually start polling until initialized & value is sent
+    starter: broadcast::Sender<()>,
+    did_start: AtomicBool,
 }
 
-struct ActiveCounter<'a>(&'a AtomicUsize);
-impl<'a> ActiveCounter<'a> {
-    fn new(a: &'a AtomicUsize) -> Self {
-        a.fetch_add(1, Ordering::Relaxed);
-        Self(a)
+struct ActiveCounter<'a, F: Fn(usize)>(&'a AtomicUsize, Option<F>);
+impl<'a, F> ActiveCounter<'a, F>
+where
+    F: Fn(usize),
+{
+    fn new(a: &'a AtomicUsize, change_fn: Option<F>) -> Self {
+        let v = a.fetch_add(1, Ordering::Relaxed) + 1;
+        if let Some(cfn) = change_fn.as_ref() {
+            cfn(v);
+        }
+        Self(a, change_fn)
     }
 }
-impl Drop for ActiveCounter<'_> {
+impl<F> Drop for ActiveCounter<'_, F>
+where
+    F: Fn(usize),
+{
     fn drop(&mut self) {
-        self.0.fetch_sub(1, Ordering::Relaxed);
+        let v = self.0.fetch_sub(1, Ordering::Relaxed) - 1;
+        if let Some(cfn) = self.1.as_ref() {
+            cfn(v)
+        }
     }
 }
 
 impl<T> LongPollBuffer<T>
 where
     T: Send + Debug + 'static,
 {
-    pub fn new<FT>(
+    pub(crate) fn new<FT, DelayFut>(
         poll_fn: impl Fn() -> FT + Send + Sync + 'static,
+        poll_semaphore: Arc<MeteredSemaphore>,
         max_pollers: usize,
-        buffer_size: usize,
         shutdown: CancellationToken,
+        num_pollers_handler: Option<impl Fn(usize) + Send + Sync + 'static>,
+        pre_permit_delay: Option<impl Fn() -> DelayFut + Send + Sync + 'static>,
     ) -> Self
     where
         FT: Future<Output = pollers::Result<T>> + Send,
+        DelayFut: Future<Output = ()> + Send,
     {
-        let (tx, rx) = channel(buffer_size);
-        let polls_requested = Arc::new(Semaphore::new(0));
+        let (tx, rx) = unbounded_channel();
+        let (starter, wait_for_start) = broadcast::channel(1);
         let active_pollers = Arc::new(AtomicUsize::new(0));
         let join_handles = FuturesUnordered::new();
         let pf = Arc::new(poll_fn);
+        let nph = num_pollers_handler.map(Arc::new);
+        let pre_permit_delay = pre_permit_delay.map(Arc::new);
         for _ in 0..max_pollers {
             let tx = tx.clone();
             let pf = pf.clone();
             let shutdown = shutdown.clone();
-            let polls_requested = polls_requested.clone();
             let ap = active_pollers.clone();
+            let poll_semaphore = poll_semaphore.clone();
+            let nph = nph.clone();
+            let pre_permit_delay = pre_permit_delay.clone();
+            let mut wait_for_start = wait_for_start.resubscribe();
             let jh = tokio::spawn(async move {
+                tokio::select! {
+                    _ = wait_for_start.recv() => (),
+                    _ = shutdown.cancelled() => return,
+                }
+                drop(wait_for_start);
+
+                let nph = nph.as_ref().map(|a| a.as_ref());
                 loop {
                     if shutdown.is_cancelled() {
                         break;
                     }
-                    let sp = tokio::select! {
-                        sp = polls_requested.acquire() => sp.expect("Polls semaphore not dropped"),
-                        _ = shutdown.cancelled() => continue,
+                    if let Some(ref ppd) = pre_permit_delay {
+                        tokio::select! {
+                            _ = ppd() => (),
+                            _ = shutdown.cancelled() => break,
+                        }
+                    }
+                    let permit = tokio::select! {
+                        p = poll_semaphore.acquire_owned() => p,
+                        _ = shutdown.cancelled() => break,
+                    };
+                    let permit = if let Ok(p) = permit {
+                        p
+                    } else {
+                        break;
                     };
-                    let _active_guard = ActiveCounter::new(ap.as_ref());
+                    let _active_guard = ActiveCounter::new(ap.as_ref(), nph);
                     let r = tokio::select! {
                         r = pf() => r,
-                        _ = shutdown.cancelled() => continue,
+                        _ = shutdown.cancelled() => break,
                     };
-                    sp.forget();
-                    let _ = tx.send(r).await;
+                    let _ = tx.send(r.map(|r| (r, permit)));
                 }
             });
             join_handles.push(jh);
         }
         Self {
             buffered_polls: Mutex::new(rx),
             shutdown,
-            polls_requested,
             join_handles,
-            num_pollers_changed: None,
-            active_pollers,
+            starter,
+            did_start: AtomicBool::new(false),
         }
     }
-
-    /// Set a function that will be called every time the number of pollers changes.
-    /// TODO: Currently a bit weird, will make more sense once we implement dynamic poller scaling.
-    pub fn set_num_pollers_handler(&mut self, handler: impl Fn(usize) + Send + Sync + 'static) {
-        self.num_pollers_changed = Some(Box::new(handler));
-    }
 }
 
 #[async_trait::async_trait]
-impl<T> Poller<T> for LongPollBuffer<T>
+impl<T> Poller<(T, OwnedMeteredSemPermit)> for LongPollBuffer<T>
 where
     T: Send + Sync + Debug + 'static,
 {
-    /// Poll the buffer. Adds one permit to the polling pool - the point of this being that the
-    /// buffer may support many concurrent pollers, but there is no reason to have them poll unless
-    /// enough polls have actually been requested. Calling this function adds a permit that any
-    /// concurrent poller may fulfill.
-    ///
-    /// EX: If this function is only ever called serially and always `await`ed, there will be no
-    /// concurrent polling. If it is called many times and the futures are awaited concurrently,
-    /// then polling will happen concurrently.
+    /// Poll for the next item from this poller
     ///
-    /// Returns `None` if the poll buffer has been shut down
+    /// Returns `None` if the poller has been shut down
     #[instrument(name = "long_poll", level = "trace", skip(self))]
-    async fn poll(&self) -> Option<pollers::Result<T>> {
-        self.polls_requested.add_permits(1);
-        if let Some(fun) = self.num_pollers_changed.as_ref() {
-            fun(self.active_pollers.load(Ordering::Relaxed));
+    async fn poll(&self) -> Option<pollers::Result<(T, OwnedMeteredSemPermit)>> {
+        if !self.did_start.fetch_or(true, Ordering::Relaxed) {
+            let _ = self.starter.send(());
         }
 
         let mut locked = self.buffered_polls.lock().await;
-        let res = (*locked).recv().await;
-
-        if let Some(fun) = self.num_pollers_changed.as_ref() {
-            fun(self.active_pollers.load(Ordering::Relaxed));
-        }
-
-        res
+        (*locked).recv().await
     }
 
     fn notify_shutdown(&self) {
         self.shutdown.cancel();
     }
 
     async fn shutdown(mut self) {
         self.notify_shutdown();
-        while self.join_handles.next().await.is_some() {}
+        while let Some(jh) = self.join_handles.next().await {
+            if let Err(e) = jh {
+                if !e.is_cancelled() {
+                    dbg_panic!("Poller task did not terminate cleanly: {:?}", e);
+                }
+            }
+        }
     }
 
     async fn shutdown_box(self: Box<Self>) {
         let this = *self;
         this.shutdown().await;
     }
 }
@@ -161,16 +185,18 @@
 #[derive(derive_more::Constructor)]
 pub struct WorkflowTaskPoller {
     normal_poller: PollWorkflowTaskBuffer,
     sticky_poller: Option<PollWorkflowTaskBuffer>,
 }
 
 #[async_trait::async_trait]
-impl Poller<PollWorkflowTaskQueueResponse> for WorkflowTaskPoller {
-    async fn poll(&self) -> Option<pollers::Result<PollWorkflowTaskQueueResponse>> {
+impl Poller<(PollWorkflowTaskQueueResponse, OwnedMeteredSemPermit)> for WorkflowTaskPoller {
+    async fn poll(
+        &self,
+    ) -> Option<pollers::Result<(PollWorkflowTaskQueueResponse, OwnedMeteredSemPermit)>> {
         if let Some(sq) = self.sticky_poller.as_ref() {
             tokio::select! {
                 r = self.normal_poller.poll() => r,
                 r = sq.poll() => r,
             }
         } else {
             self.normal_poller.poll().await
@@ -196,82 +222,145 @@
         this.shutdown().await;
     }
 }
 
 pub type PollWorkflowTaskBuffer = LongPollBuffer<PollWorkflowTaskQueueResponse>;
 pub(crate) fn new_workflow_task_buffer(
     client: Arc<dyn WorkerClient>,
-    task_queue: String,
-    is_sticky: bool,
+    task_queue: TaskQueue,
     concurrent_pollers: usize,
-    buffer_size: usize,
+    semaphore: Arc<MeteredSemaphore>,
     shutdown: CancellationToken,
+    num_pollers_handler: Option<impl Fn(usize) + Send + Sync + 'static>,
 ) -> PollWorkflowTaskBuffer {
     LongPollBuffer::new(
         move || {
             let client = client.clone();
             let task_queue = task_queue.clone();
-            async move { client.poll_workflow_task(task_queue, is_sticky).await }
+            async move { client.poll_workflow_task(task_queue).await }
         },
+        semaphore,
         concurrent_pollers,
-        buffer_size,
         shutdown,
+        num_pollers_handler,
+        None::<fn() -> BoxFuture<'static, ()>>,
     )
 }
 
 pub type PollActivityTaskBuffer = LongPollBuffer<PollActivityTaskQueueResponse>;
+#[allow(clippy::too_many_arguments)]
 pub(crate) fn new_activity_task_buffer(
     client: Arc<dyn WorkerClient>,
     task_queue: String,
     concurrent_pollers: usize,
-    buffer_size: usize,
+    semaphore: Arc<MeteredSemaphore>,
     max_tps: Option<f64>,
     shutdown: CancellationToken,
+    num_pollers_handler: Option<impl Fn(usize) + Send + Sync + 'static>,
+    max_worker_acts_per_sec: Option<f64>,
 ) -> PollActivityTaskBuffer {
+    let rate_limiter = max_worker_acts_per_sec.and_then(|ps| {
+        Quota::with_period(Duration::from_secs_f64(ps.recip()))
+            .map(|q| Arc::new(RateLimiter::direct(q)))
+    });
     LongPollBuffer::new(
         move || {
             let client = client.clone();
             let task_queue = task_queue.clone();
             async move { client.poll_activity_task(task_queue, max_tps).await }
         },
+        semaphore,
         concurrent_pollers,
-        buffer_size,
         shutdown,
+        num_pollers_handler,
+        rate_limiter.map(|rl| {
+            move || {
+                let rl = rl.clone();
+                async move { rl.until_ready().await }.boxed()
+            }
+        }),
     )
 }
 
 #[cfg(test)]
+#[derive(derive_more::Constructor)]
+pub(crate) struct MockPermittedPollBuffer<PT> {
+    sem: Arc<MeteredSemaphore>,
+    inner: PT,
+}
+
+#[cfg(test)]
+#[async_trait::async_trait]
+impl<T, PT> Poller<(T, OwnedMeteredSemPermit)> for MockPermittedPollBuffer<PT>
+where
+    T: Send + Sync + 'static,
+    PT: Poller<T> + Send + Sync + 'static,
+{
+    async fn poll(&self) -> Option<pollers::Result<(T, OwnedMeteredSemPermit)>> {
+        let p = self
+            .sem
+            .acquire_owned()
+            .await
+            .expect("Semaphore in poller not closed!");
+        self.inner.poll().await.map(|r| r.map(|r| (r, p)))
+    }
+
+    fn notify_shutdown(&self) {
+        self.inner.notify_shutdown();
+    }
+
+    async fn shutdown(self) {
+        self.inner.shutdown().await;
+    }
+
+    async fn shutdown_box(self: Box<Self>) {
+        self.inner.shutdown().await;
+    }
+}
+
+#[cfg(test)]
 mod tests {
     use super::*;
-    use crate::worker::client::mocks::mock_manual_workflow_client;
+    use crate::{
+        telemetry::metrics::MetricsContext, worker::client::mocks::mock_manual_workflow_client,
+    };
     use futures::FutureExt;
     use std::time::Duration;
+    use temporal_sdk_core_protos::temporal::api::enums::v1::TaskQueueKind;
     use tokio::{select, sync::mpsc::channel};
 
     #[tokio::test]
     async fn only_polls_once_with_1_poller() {
         let mut mock_client = mock_manual_workflow_client();
         mock_client
             .expect_poll_workflow_task()
             .times(2)
-            .returning(move |_, _| {
+            .returning(move |_| {
                 async {
                     tokio::time::sleep(Duration::from_millis(100)).await;
                     Ok(Default::default())
                 }
                 .boxed()
             });
 
         let pb = new_workflow_task_buffer(
             Arc::new(mock_client),
-            "someq".to_string(),
-            false,
-            1,
+            TaskQueue {
+                name: "sometq".to_string(),
+                kind: TaskQueueKind::Normal as i32,
+                normal_name: "".to_string(),
+            },
             1,
+            Arc::new(MeteredSemaphore::new(
+                10,
+                MetricsContext::no_op(),
+                |_, _| {},
+            )),
             CancellationToken::new(),
+            None::<fn(usize)>,
         );
 
         // Poll a bunch of times, "interrupting" it each time, we should only actually have polled
         // once since the poll takes a while
         let (interrupter_tx, mut interrupter_rx) = channel(50);
         for _ in 0..10 {
             interrupter_tx.send(()).await.unwrap();
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/protosext/mod.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/protosext/mod.rs`

 * *Files 1% similar despite different names*

```diff
@@ -333,34 +333,29 @@
 impl Default for LACloseTimeouts {
     fn default() -> Self {
         LACloseTimeouts::ScheduleOnly(Duration::from_secs(100))
     }
 }
 
 impl ValidScheduleLA {
-    pub fn from_schedule_la(
-        v: ScheduleLocalActivity,
-        wf_exe_timeout: Option<Duration>,
-    ) -> Result<Self, anyhow::Error> {
+    pub fn from_schedule_la(v: ScheduleLocalActivity) -> Result<Self, anyhow::Error> {
         let original_schedule_time = v
             .original_schedule_time
             .map(|x| {
                 x.try_into()
                     .map_err(|_| anyhow!("Could not convert original_schedule_time"))
             })
             .transpose()?;
         let sched_to_close = v
             .schedule_to_close_timeout
             .map(|x| {
                 x.try_into()
                     .map_err(|_| anyhow!("Could not convert schedule_to_close_timeout"))
             })
-            .transpose()?
-            // Default to execution timeout if unset
-            .or(wf_exe_timeout);
+            .transpose()?;
         let mut schedule_to_start_timeout = v
             .schedule_to_start_timeout
             .map(|x| {
                 x.try_into()
                     .map_err(|_| anyhow!("Could not convert schedule_to_start_timeout"))
             })
             .transpose()?;
@@ -388,15 +383,16 @@
                 if start > sched {
                     start = sched;
                 }
                 LACloseTimeouts::Both { sched, start }
             }
             (None, None) => {
                 return Err(anyhow!(
-                    "One of schedule_to_close or start_to_close timeouts must be set"
+                    "One or both of schedule_to_close or start_to_close timeouts must be set for \
+                     local activities"
                 ))
             }
         };
         let retry_policy = v.retry_policy.unwrap_or_default();
         let local_retry_threshold = v
             .local_retry_threshold
             .clone()
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/replay/mod.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/replay/mod.rs`

 * *Files 1% similar despite different names*

```diff
@@ -85,15 +85,15 @@
 /// Once it runs out of histories to return, it will serve up default responses after a 10s delay
 pub(crate) fn mock_client_from_histories(historator: Historator) -> impl WorkerClient {
     let mut mg = mock_manual_workflow_client();
 
     let hist_allow_tx = historator.replay_done_tx.clone();
     let historator = Arc::new(TokioMutex::new(historator));
 
-    mg.expect_poll_workflow_task().returning(move |_, _| {
+    mg.expect_poll_workflow_task().returning(move |_| {
         let historator = historator.clone();
         async move {
             let mut hlock = historator.lock().await;
             // Always wait for permission before dispatching the next task
             let _ = hlock.allow_stream.next().await;
 
             if let Some(history) = hlock.next().await {
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/retry_logic.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/retry_logic.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/telemetry/log_export.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/telemetry/log_export.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/telemetry/metrics.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/telemetry/metrics.rs`

 * *Files 2% similar despite different names*

```diff
@@ -83,14 +83,15 @@
     act_exec_latency: Histogram<u64>,
     worker_registered: Counter<u64>,
     num_pollers: Histogram<u64>,
     task_slots_available: Histogram<u64>,
     sticky_cache_hit: Counter<u64>,
     sticky_cache_miss: Counter<u64>,
     sticky_cache_size: Histogram<u64>,
+    sticky_cache_evictions: Counter<u64>,
 }
 
 impl MetricsContext {
     pub(crate) fn no_op() -> Self {
         Self {
             ctx: Default::default(),
             kvs: Default::default(),
@@ -284,14 +285,21 @@
 
     /// Record current cache size (in number of wfs, not bytes)
     pub(crate) fn cache_size(&self, size: u64) {
         self.instruments
             .sticky_cache_size
             .record(&self.ctx, size, &self.kvs);
     }
+
+    /// Count a workflow being evicted from the cache
+    pub(crate) fn cache_eviction(&self) {
+        self.instruments
+            .sticky_cache_evictions
+            .add(&self.ctx, 1, &self.kvs);
+    }
 }
 
 impl Instruments {
     fn new(telem: &TelemetryInstance) -> Self {
         let no_op_meter: Meter;
         let meter = if let Some(meter) = telem.get_metric_meter() {
             meter
@@ -323,14 +331,15 @@
             // name kept as worker start for compat with old sdk / what users expect
             worker_registered: meter.counter("worker_start"),
             num_pollers: meter.histogram(NUM_POLLERS_NAME),
             task_slots_available: meter.histogram(TASK_SLOTS_AVAILABLE_NAME),
             sticky_cache_hit: meter.counter("sticky_cache_hit"),
             sticky_cache_miss: meter.counter("sticky_cache_miss"),
             sticky_cache_size: meter.histogram(STICKY_CACHE_SIZE_NAME),
+            sticky_cache_evictions: meter.counter("sticky_cache_total_forced_eviction"),
         }
     }
 }
 
 const KEY_NAMESPACE: &str = "namespace";
 const KEY_WF_TYPE: &str = "workflow_type";
 const KEY_TASK_QUEUE: &str = "task_queue";
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/telemetry/mod.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/telemetry/mod.rs`

 * *Files 2% similar despite different names*

```diff
@@ -293,14 +293,17 @@
 
         let reg = tracing_subscriber::registry()
             .with(console_pretty_layer)
             .with(console_compact_layer)
             .with(forward_layer)
             .with(export_layer);
 
+        #[cfg(feature = "tokio-console")]
+        let reg = reg.with(console_subscriber::spawn());
+
         tx.send(TelemetryInstance::new(
             Arc::new(reg),
             logs_out,
             metric_prefix,
             meter_provider,
             prom_binding,
             keepalive_rx,
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/telemetry/prometheus_server.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/telemetry/prometheus_server.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/test_help/mod.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/test_help/mod.rs`

 * *Files 0% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 pub(crate) use temporal_sdk_core_test_utils::canned_histories;
 
 use crate::{
-    pollers::{BoxedActPoller, BoxedPoller, BoxedWFPoller, MockManualPoller, MockPoller},
+    pollers::{BoxedPoller, MockManualPoller, MockPoller},
     protosext::ValidPollWFTQResponse,
     replay::TestHistoryBuilder,
     sticky_q_name_for_worker,
     telemetry::metrics::MetricsContext,
     worker::{
         client::{
             mocks::mock_workflow_client, MockWorkerClient, WorkerClient, WorkflowTaskCompletion,
         },
-        new_wft_poller,
+        TaskPollers,
     },
     TaskToken, Worker, WorkerConfig, WorkerConfigBuilder,
 };
 use async_trait::async_trait;
 use bimap::BiMap;
 use futures::{future::BoxFuture, stream, stream::BoxStream, FutureExt, Stream, StreamExt};
 use mockall::TimesRange;
@@ -49,15 +49,14 @@
             RespondWorkflowTaskCompletedResponse,
         },
     },
 };
 use temporal_sdk_core_test_utils::TestWorker;
 use tokio::sync::{mpsc::unbounded_channel, Notify};
 use tokio_stream::wrappers::UnboundedReceiverStream;
-use tokio_util::sync::CancellationToken;
 
 pub const TEST_Q: &str = "q";
 
 pub fn test_worker_cfg() -> WorkerConfigBuilder {
     let mut wcb = WorkerConfigBuilder::default();
     wcb.namespace("default")
         .task_queue(TEST_Q)
@@ -144,19 +143,20 @@
     } else {
         mocks.inputs.act_poller
     };
     Worker::new_with_pollers(
         mocks.inputs.config,
         sticky_q,
         mocks.client,
-        mocks.inputs.wft_stream,
-        act_poller,
+        TaskPollers::Mocked {
+            wft_stream: mocks.inputs.wft_stream,
+            act_poller,
+        },
         MetricsContext::no_op(),
         None,
-        CancellationToken::new(),
     )
 }
 
 pub(crate) fn mock_sdk(poll_cfg: MockPollCfg) -> TestWorker {
     mock_sdk_cfg(poll_cfg, |_| {})
 }
 pub(crate) fn mock_sdk_cfg(
@@ -183,53 +183,46 @@
     pub outstanding_task_map: Option<OutstandingWFTMap>,
 }
 
 impl MocksHolder {
     pub fn worker_cfg(&mut self, mutator: impl FnOnce(&mut WorkerConfig)) {
         mutator(&mut self.inputs.config);
     }
-    pub fn set_act_poller(&mut self, poller: BoxedActPoller) {
+    pub fn set_act_poller(&mut self, poller: BoxedPoller<PollActivityTaskQueueResponse>) {
         self.inputs.act_poller = Some(poller);
     }
     /// Can be used for tests that need to avoid auto-shutdown due to running out of mock responses
     pub fn make_wft_stream_interminable(&mut self) {
         let old_stream = std::mem::replace(&mut self.inputs.wft_stream, stream::pending().boxed());
         self.inputs.wft_stream = old_stream.chain(stream::pending()).boxed();
     }
 }
 
 pub struct MockWorkerInputs {
     pub wft_stream: BoxStream<'static, Result<ValidPollWFTQResponse, tonic::Status>>,
-    pub act_poller: Option<BoxedActPoller>,
+    pub act_poller: Option<BoxedPoller<PollActivityTaskQueueResponse>>,
     pub config: WorkerConfig,
 }
 
 impl Default for MockWorkerInputs {
     fn default() -> Self {
-        Self::new_from_poller(Box::from(mock_poller()))
+        Self::new(stream::empty().boxed())
     }
 }
 
 impl MockWorkerInputs {
     pub fn new(
         wft_stream: BoxStream<'static, Result<ValidPollWFTQResponse, tonic::Status>>,
     ) -> Self {
         Self {
             wft_stream,
             act_poller: None,
             config: test_worker_cfg().build().unwrap(),
         }
     }
-    pub fn new_from_poller(wf_poller: BoxedWFPoller) -> Self {
-        Self {
-            wft_stream: new_wft_poller(wf_poller, MetricsContext::no_op()).boxed(),
-            act_poller: None,
-            config: test_worker_cfg().build().unwrap(),
-        }
-    }
 }
 
 impl MocksHolder {
     pub(crate) fn from_mock_worker(
         client: impl WorkerClient + 'static,
         mock_worker: MockWorkerInputs,
     ) -> Self {
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/activities/activity_heartbeat_manager.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/activities/activity_heartbeat_manager.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/activities/activity_task_poller_stream.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/activities/activity_task_poller_stream.rs`

 * *Files 17% similar despite different names*

```diff
@@ -1,77 +1,52 @@
-use crate::{
-    abstractions::MeteredSemaphore, pollers::BoxedActPoller, worker::activities::PermittedTqResp,
-    MetricsContext,
-};
+use crate::{pollers::BoxedActPoller, worker::activities::PermittedTqResp, MetricsContext};
 use futures::{stream, Stream};
-use governor::{
-    clock::DefaultClock,
-    middleware::NoOpMiddleware,
-    state::{InMemoryState, NotKeyed},
-    RateLimiter,
-};
-use std::sync::Arc;
 use temporal_sdk_core_protos::temporal::api::workflowservice::v1::PollActivityTaskQueueResponse;
 use tokio::select;
 use tokio_util::sync::CancellationToken;
 
 struct StreamState {
     poller: BoxedActPoller,
-    semaphore: Arc<MeteredSemaphore>,
-    rate_limiter: Option<RateLimiter<NotKeyed, InMemoryState, DefaultClock, NoOpMiddleware>>,
     metrics: MetricsContext,
     shutdown_token: CancellationToken,
     poller_was_shutdown: bool,
 }
 
 pub(crate) fn new_activity_task_poller(
     poller: BoxedActPoller,
-    semaphore: Arc<MeteredSemaphore>,
-    rate_limiter: Option<RateLimiter<NotKeyed, InMemoryState, DefaultClock, NoOpMiddleware>>,
     metrics: MetricsContext,
     shutdown_token: CancellationToken,
 ) -> impl Stream<Item = Result<PermittedTqResp, tonic::Status>> {
     let state = StreamState {
         poller,
-        semaphore,
-        rate_limiter,
         metrics,
         shutdown_token,
         poller_was_shutdown: false,
     };
     stream::unfold(state, |mut state| async move {
         loop {
             let poll = async {
-                let permit = state
-                    .semaphore
-                    .acquire_owned()
-                    .await
-                    .expect("outstanding activity semaphore not closed");
-                if !state.poller_was_shutdown {
-                    if let Some(ref rl) = state.rate_limiter {
-                        rl.until_ready().await;
-                    }
-                }
                 loop {
                     return match state.poller.poll().await {
-                        Some(Ok(resp)) => {
+                        Some(Ok((resp, permit))) => {
                             if resp == PollActivityTaskQueueResponse::default() {
-                                // We get the default proto in the event that the long poll times out.
+                                // We get the default proto in the event that the long poll times
+                                // out.
                                 debug!("Poll activity task timeout");
                                 state.metrics.act_poll_timeout();
                                 continue;
                             }
                             Some(Ok(PermittedTqResp { permit, resp }))
                         }
                         Some(Err(e)) => {
                             warn!(error=?e, "Error while polling for activity tasks");
                             Some(Err(e))
                         }
-                        // If poller returns None, it's dead, thus we also return None to terminate this
-                        // stream.
+                        // If poller returns None, it's dead, thus we also return None to terminate
+                        // this stream.
                         None => None,
                     };
                 }
             };
             if state.poller_was_shutdown {
                 return poll.await.map(|res| (res, state));
             }
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/activities/local_activities.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/activities/local_activities.rs`

 * *Files 4% similar despite different names*

```diff
@@ -35,23 +35,19 @@
     time::sleep,
 };
 use tokio_stream::wrappers::UnboundedReceiverStream;
 use tokio_util::sync::CancellationToken;
 
 #[allow(clippy::large_enum_variant)] // Timeouts are relatively rare
 #[derive(Debug)]
-pub(crate) enum DispatchOrTimeoutLA {
+pub(crate) enum NextPendingLAAction {
     /// Send the activity task to lang
     Dispatch(ActivityTask),
-    /// Notify the machines (and maybe lang) that this LA has timed out
-    Timeout {
-        run_id: String,
-        resolution: LocalActivityResolution,
-        task: Option<ActivityTask>,
-    },
+    /// The worker must re-feed this completion back through the machines. Includes timeouts.
+    Autocomplete(LACompleteAction),
 }
 
 #[derive(Debug)]
 pub(crate) struct LocalInFlightActInfo {
     pub la_info: NewLocalAct,
     pub dispatch_time: Instant,
     pub attempt: u32,
@@ -83,14 +79,32 @@
                         last_heartbeat_details: None,
                     },
                 )),
                 ..Default::default()
             }),
         })
     }
+
+    fn get_timeout_type(&self) -> Option<TimeoutType> {
+        match self {
+            Self::TimedOut(ActFail {
+                failure:
+                    Some(APIFailure {
+                        failure_info:
+                            Some(failure::FailureInfo::TimeoutFailureInfo(TimeoutFailureInfo {
+                                timeout_type,
+                                ..
+                            })),
+                        ..
+                    }),
+                ..
+            }) => TimeoutType::from_i32(*timeout_type),
+            _ => None,
+        }
+    }
 }
 
 #[derive(Debug, Clone)]
 #[cfg_attr(
     feature = "save_wf_inputs",
     derive(serde::Serialize, serde::Deserialize)
 )]
@@ -364,54 +378,38 @@
             }
         }
         immediate_resolutions
     }
 
     /// Returns the next pending local-activity related action, or None if shutdown has initiated
     /// and there are no more remaining actions to take.
-    pub(crate) async fn next_pending(&self) -> Option<DispatchOrTimeoutLA> {
+    pub(crate) async fn next_pending(&self) -> Option<NextPendingLAAction> {
         let (new_or_retry, permit) = match self.rcvs.lock().await.next().await? {
             NewOrCancel::Cancel(c) => {
                 return match c {
-                    CancelOrTimeout::Cancel(c) => Some(DispatchOrTimeoutLA::Dispatch(c)),
-                    CancelOrTimeout::Timeout {
-                        run_id,
-                        resolution,
-                        dispatch_cancel,
-                    } => {
-                        let task = if dispatch_cancel {
-                            let tt = self
-                                .dat
-                                .lock()
-                                .la_info
-                                .get(&ExecutingLAId {
-                                    run_id: run_id.clone(),
-                                    seq_num: resolution.seq,
-                                })
-                                .as_ref()
-                                .map(|lai| lai.task_token.clone());
-                            if let Some(task_token) = tt {
-                                self.complete(&task_token, &resolution.result);
-                                Some(ActivityTask {
-                                    task_token: task_token.0,
-                                    variant: Some(activity_task::Variant::Cancel(Cancel {
-                                        reason: ActivityCancelReason::TimedOut as i32,
-                                    })),
-                                })
-                            } else {
-                                None
-                            }
+                    CancelOrTimeout::Cancel(c) => Some(NextPendingLAAction::Dispatch(c)),
+                    CancelOrTimeout::Timeout { run_id, resolution } => {
+                        let tt = self
+                            .dat
+                            .lock()
+                            .la_info
+                            .get(&ExecutingLAId {
+                                run_id,
+                                seq_num: resolution.seq,
+                            })
+                            .as_ref()
+                            .map(|lai| lai.task_token.clone());
+                        if let Some(task_token) = tt {
+                            Some(NextPendingLAAction::Autocomplete(
+                                self.complete(&task_token, resolution.result),
+                            ))
                         } else {
+                            // This timeout is for a no-longer-tracked activity, so, whatever
                             None
-                        };
-                        Some(DispatchOrTimeoutLA::Timeout {
-                            run_id,
-                            resolution,
-                            task,
-                        })
+                        }
                     }
                 };
             }
             NewOrCancel::New(n, perm) => (n, perm),
         };
 
         // It is important that there are no await points after receiving from the channel, as
@@ -439,26 +437,30 @@
             .get_mut(&id)
             .map(|lai| lai.backing_off_task.take());
 
         // If this task sat in the queue for too long, return a timeout for it instead
         if let Some(s2s) = sa.schedule_to_start_timeout.as_ref() {
             let sat_for = new_la.schedule_time.elapsed().unwrap_or_default();
             if sat_for > *s2s {
-                return Some(DispatchOrTimeoutLA::Timeout {
-                    run_id: new_la.workflow_exec_info.run_id,
-                    resolution: LocalActivityResolution {
-                        seq: sa.seq,
-                        result: LocalActivityExecutionResult::timeout(TimeoutType::ScheduleToStart),
-                        runtime: sat_for,
-                        attempt,
-                        backoff: None,
-                        original_schedule_time: orig_sched_time,
+                return Some(NextPendingLAAction::Autocomplete(
+                    LACompleteAction::Report {
+                        run_id: new_la.workflow_exec_info.run_id,
+                        resolution: LocalActivityResolution {
+                            seq: sa.seq,
+                            result: LocalActivityExecutionResult::timeout(
+                                TimeoutType::ScheduleToStart,
+                            ),
+                            runtime: sat_for,
+                            attempt,
+                            backoff: None,
+                            original_schedule_time: orig_sched_time,
+                        },
+                        task: None,
                     },
-                    task: None,
-                });
+                ));
             }
         }
 
         let la_info = dat.la_info.get_mut(&id).expect("Activity must exist");
         let tt = la_info.task_token.clone();
         if let Some(to) = la_info.timeout_bag.as_mut() {
             to.mark_started();
@@ -470,43 +472,50 @@
                 dispatch_time: Instant::now(),
                 attempt,
                 _permit: permit.into_used(),
             },
         );
 
         let (schedule_to_close, start_to_close) = sa.close_timeouts.into_sched_and_start();
-        Some(DispatchOrTimeoutLA::Dispatch(ActivityTask {
+        Some(NextPendingLAAction::Dispatch(ActivityTask {
             task_token: tt.0,
             variant: Some(activity_task::Variant::Start(Start {
                 workflow_namespace: self.namespace.clone(),
                 workflow_type: new_la.workflow_type,
                 workflow_execution: Some(new_la.workflow_exec_info),
                 activity_id: sa.activity_id,
                 activity_type: sa.activity_type,
                 header_fields: sa.headers,
                 input: sa.arguments,
                 heartbeat_details: vec![],
                 scheduled_time: Some(new_la.schedule_time.into()),
                 current_attempt_scheduled_time: Some(new_la.schedule_time.into()),
                 started_time: Some(SystemTime::now().into()),
                 attempt,
-                schedule_to_close_timeout: schedule_to_close.and_then(|d| d.try_into().ok()),
-                start_to_close_timeout: start_to_close.and_then(|d| d.try_into().ok()),
+                schedule_to_close_timeout: schedule_to_close
+                    .unwrap_or(Duration::ZERO)
+                    .try_into()
+                    .ok(),
+                start_to_close_timeout: start_to_close
+                    .or(schedule_to_close)
+                    .unwrap()
+                    .try_into()
+                    .ok(),
                 heartbeat_timeout: None,
                 retry_policy: Some(sa.retry_policy),
                 is_local: true,
             })),
         }))
     }
 
-    /// Mark a local activity as having completed (pass, fail, or cancelled)
+    /// Mark a local activity as having completed
     pub(crate) fn complete(
         &self,
         task_token: &TaskToken,
-        status: &LocalActivityExecutionResult,
+        status: LocalActivityExecutionResult,
     ) -> LACompleteAction {
         let mut dlock = self.dat.lock();
         if let Some(info) = dlock.outstanding_activity_tasks.remove(task_token) {
             if self.workflows_have_shut_down.is_cancelled() {
                 // If workflows are already shut down, the results of all this don't matter.
                 // Just say we're done if there's nothing outstanding any more.
                 self.set_shutdown_complete_if_ready(&mut dlock);
@@ -520,45 +529,100 @@
             if let Some(ref oldlai) = maybe_old_lai {
                 if let Some(ref bot) = oldlai.backing_off_task {
                     dbg_panic!("Just-resolved LA should not have backoff task");
                     bot.abort();
                 }
             }
 
-            match status {
-                LocalActivityExecutionResult::Completed(_)
-                | LocalActivityExecutionResult::TimedOut(_)
-                | LocalActivityExecutionResult::Cancelled { .. } => {
-                    // Timeouts are included in this branch since they are not retried
-                    self.complete_notify.notify_one();
-                    LACompleteAction::Report(info)
-                }
-                LocalActivityExecutionResult::Failed(f) => {
-                    if let Some(backoff_dur) = info.la_info.schedule_cmd.retry_policy.should_retry(
+            enum Outcome {
+                FailurePath { backoff: Option<Duration> },
+                JustReport,
+            }
+            macro_rules! calc_backoff {
+                ($fail: ident) => {
+                    info.la_info.schedule_cmd.retry_policy.should_retry(
                         info.attempt as usize,
-                        f.failure
+                        $fail
+                            .failure
                             .as_ref()
                             .and_then(|f| f.maybe_application_failure()),
-                    ) {
+                    )
+                };
+            }
+
+            let mut is_timeout = false;
+            let outcome = match &status {
+                LocalActivityExecutionResult::Failed(fail) => Outcome::FailurePath {
+                    backoff: calc_backoff!(fail),
+                },
+                LocalActivityExecutionResult::TimedOut(fail)
+                    if matches!(status.get_timeout_type(), Some(TimeoutType::StartToClose)) =>
+                {
+                    // Start to close timeouts are retryable, other timeout types aren't.
+                    is_timeout = true;
+                    Outcome::FailurePath {
+                        backoff: calc_backoff!(fail),
+                    }
+                }
+                LocalActivityExecutionResult::TimedOut(_) => {
+                    is_timeout = true;
+                    Outcome::JustReport
+                }
+                LocalActivityExecutionResult::Completed(_)
+                | LocalActivityExecutionResult::Cancelled { .. } => Outcome::JustReport,
+            };
+
+            let mut resolution = LocalActivityResolution {
+                seq: info.la_info.schedule_cmd.seq,
+                result: status,
+                runtime: info.dispatch_time.elapsed(),
+                attempt: info.attempt,
+                backoff: None,
+                original_schedule_time: info.la_info.schedule_cmd.original_schedule_time,
+            };
+            // We want to generate a cancel task if the reason for failure was a timeout.
+            let task = if is_timeout {
+                Some(ActivityTask {
+                    task_token: task_token.clone().0,
+                    variant: Some(activity_task::Variant::Cancel(Cancel {
+                        reason: ActivityCancelReason::TimedOut as i32,
+                    })),
+                })
+            } else {
+                None
+            };
+
+            match outcome {
+                Outcome::FailurePath { backoff } => {
+                    if let Some(backoff_dur) = backoff {
+                        let fail_or_timeout = if is_timeout { "timed out" } else { "failed" };
                         let will_use_timer =
                             backoff_dur > info.la_info.schedule_cmd.local_retry_threshold;
                         debug!(run_id = %info.la_info.workflow_exec_info.run_id,
                                seq_num = %info.la_info.schedule_cmd.seq,
                                attempt = %info.attempt,
                                will_use_timer,
-                            "Local activity failed, will retry after backing off for {:?}",
-                             backoff_dur
+                            "Local activity {}, will retry after backing off for {:?}",
+                            fail_or_timeout,
+                            backoff_dur
                         );
                         if will_use_timer {
-                            // We want this to be reported, as the workflow will mark this
-                            // failure down, then start a timer for backoff.
-                            return LACompleteAction::LangDoesTimerBackoff(
-                                backoff_dur.try_into().expect("backoff fits into proto"),
-                                info,
-                            );
+                            // This la needs to write a failure marker, and then we will tell lang how
+                            // long of a timer to schedule to back off for. We do this because there are
+                            // no other situations where core generates "internal" commands so it is
+                            // much simpler for lang to reply with the timer / next LA command than to
+                            // do it internally. Plus, this backoff hack we'd like to eliminate
+                            // eventually.
+                            resolution.backoff =
+                                Some(backoff_dur.try_into().expect("backoff fits into proto"));
+                            return LACompleteAction::Report {
+                                run_id: info.la_info.workflow_exec_info.run_id,
+                                resolution,
+                                task,
+                            };
                         }
                         // Immediately create a new task token for the to-be-retried LA
                         let tt = dlock.gen_next_token();
                         // Send the retry request after waiting the backoff duration
                         let send_chan = self.act_req_tx.clone();
                         let jh = tokio::spawn(async move {
                             tokio::time::sleep(backoff_dur).await;
@@ -582,22 +646,40 @@
                                 attempts_in_wft: maybe_old_lai
                                     .as_ref()
                                     .map(|old| old.attempts_in_wft + 1)
                                     .unwrap_or(1),
                                 timeout_bag: maybe_old_lai.and_then(|old| old.timeout_bag),
                             },
                         );
-
-                        LACompleteAction::WillBeRetried
+                        LACompleteAction::WillBeRetried(task)
                     } else {
-                        LACompleteAction::Report(info)
+                        LACompleteAction::Report {
+                            run_id: info.la_info.workflow_exec_info.run_id,
+                            resolution,
+                            task,
+                        }
+                    }
+                }
+                Outcome::JustReport => {
+                    self.complete_notify.notify_one();
+                    LACompleteAction::Report {
+                        run_id: info.la_info.workflow_exec_info.run_id,
+                        resolution,
+                        task,
                     }
                 }
             }
         } else {
+            if !matches!(
+                status,
+                LocalActivityExecutionResult::TimedOut(_)
+                    | LocalActivityExecutionResult::Cancelled { .. }
+            ) {
+                warn!("Tried to complete untracked local activity");
+            }
             LACompleteAction::Untracked
         }
     }
 
     pub(crate) fn workflows_have_shutdown(&self) {
         self.workflows_have_shut_down.cancel();
         self.set_shutdown_complete_if_ready(&mut self.dat.lock());
@@ -664,21 +746,26 @@
         None
     }
 }
 
 #[derive(Debug)]
 #[allow(clippy::large_enum_variant)] // Most will be reported
 pub(crate) enum LACompleteAction {
-    /// Caller should report the status to the workflow
-    Report(LocalInFlightActInfo),
-    /// Lang needs to be told to do the schedule-a-timer-then-rerun hack
-    LangDoesTimerBackoff(prost_types::Duration, LocalInFlightActInfo),
+    /// Caller should report the status to the workflow machines - which may resolve the activity
+    /// or might result in scheduling a backoff timer.
+    Report {
+        run_id: String,
+        resolution: LocalActivityResolution,
+        /// May be set if a task also needs to be dispatched to lang. EX: Cancelling a timed-out
+        /// activity.
+        task: Option<ActivityTask>,
+    },
     /// The activity will be re-enqueued for another attempt (and so status should not be reported
     /// to the workflow)
-    WillBeRetried,
+    WillBeRetried(Option<ActivityTask>),
     /// The activity was unknown
     Untracked,
 }
 
 #[derive(Debug)]
 enum NewOrRetry {
     New(NewLocalAct),
@@ -691,15 +778,14 @@
 #[allow(clippy::large_enum_variant)]
 #[derive(Debug, Clone)]
 enum CancelOrTimeout {
     Cancel(ActivityTask),
     Timeout {
         run_id: String,
         resolution: LocalActivityResolution,
-        dispatch_cancel: bool,
     },
 }
 
 #[allow(clippy::large_enum_variant)]
 enum NewOrCancel {
     New(NewOrRetry, OwnedMeteredSemPermit),
     Cancel(CancelOrTimeout),
@@ -783,15 +869,14 @@
             if s2c.is_zero() {
                 return Err(resolution);
             }
         }
         let timeout_dat = CancelOrTimeout::Timeout {
             run_id: new_la.workflow_exec_info.run_id.clone(),
             resolution,
-            dispatch_cancel: true,
         };
         let start_to_close_dur_and_dat = start_to_close.map(|d| (d, timeout_dat.clone()));
         let fut_dat = schedule_to_close.map(|s2c| (s2c, timeout_dat));
 
         let cancel_chan_clone = cancel_chan.clone();
         let scheduling = tokio::spawn(async move {
             if let Some((timeout, dat)) = fut_dat {
@@ -807,15 +892,15 @@
             start_to_close_handle: None,
             cancel_chan,
         })
     }
 
     /// Must be called once the associated local activity has been started / dispatched to lang.
     fn mark_started(&mut self) {
-        if let Some((start_to_close, mut dat)) = self.start_to_close_dur_and_dat.take() {
+        if let Some((start_to_close, mut dat)) = self.start_to_close_dur_and_dat.as_ref().cloned() {
             let started_t = Instant::now();
             let cchan = self.cancel_chan.clone();
             self.start_to_close_handle = Some(tokio::spawn(async move {
                 sleep(start_to_close).await;
                 if let CancelOrTimeout::Timeout { resolution, .. } = &mut dat {
                     resolution.result =
                         LocalActivityExecutionResult::timeout(TimeoutType::StartToClose);
@@ -844,23 +929,32 @@
     use futures_util::FutureExt;
     use temporal_sdk_core_protos::temporal::api::{
         common::v1::RetryPolicy,
         failure::v1::{failure::FailureInfo, ApplicationFailureInfo, Failure},
     };
     use tokio::task::yield_now;
 
-    impl DispatchOrTimeoutLA {
+    impl NextPendingLAAction {
         fn unwrap(self) -> ActivityTask {
             match self {
-                DispatchOrTimeoutLA::Dispatch(t) => t,
+                NextPendingLAAction::Dispatch(t) => t,
                 _ => {
                     panic!("Non-dispatched action returned")
                 }
             }
         }
+
+        fn is_timeout(&self, with_task: bool) -> bool {
+            matches!(
+                self,
+                Self::Autocomplete(LACompleteAction::Report{task, resolution, ..})
+                if matches!(resolution.result, LocalActivityExecutionResult::TimedOut(_)) &&
+                   task.is_some() == with_task
+            )
+        }
     }
 
     #[tokio::test]
     async fn max_concurrent_respected() {
         let lam = LocalActivityManager::test(1);
         lam.enqueue((1..=50).map(|i| {
             NewLocalAct {
@@ -882,15 +976,15 @@
                 activity_task::Variant::Start(Start {activity_id, ..})
                     if activity_id == i.to_string()
             );
             let next_tt = TaskToken(next.task_token);
             let complete_branch = async {
                 lam.complete(
                     &next_tt,
-                    &LocalActivityExecutionResult::Completed(Default::default()),
+                    LocalActivityExecutionResult::Completed(Default::default()),
                 )
             };
             tokio::select! {
                 // Next call will not resolve until we complete the first
                 _ = lam.next_pending() => {
                     panic!("Branch must not be selected")
                 }
@@ -922,15 +1016,15 @@
             _ = lam.next_pending() => {
                 panic!("Complete branch must win")
             }
             _ = async {
                 // Spin until the receive lock has been grabbed by the call to pending, to ensure
                 // it's advanced enough
                 while lam.rcvs.try_lock().is_ok() { yield_now().await; }
-                lam.complete(&tt, &LocalActivityExecutionResult::Completed(Default::default()));
+                lam.complete(&tt, LocalActivityExecutionResult::Completed(Default::default()));
             } => (),
         };
     }
 
     #[tokio::test]
     async fn can_cancel_in_flight() {
         let lam = LocalActivityManager::test(5);
@@ -982,18 +1076,18 @@
         }
         .into()]);
 
         let next = lam.next_pending().await.unwrap().unwrap();
         let tt = TaskToken(next.task_token);
         let res = lam.complete(
             &tt,
-            &LocalActivityExecutionResult::Failed(Default::default()),
+            LocalActivityExecutionResult::Failed(Default::default()),
         );
-        assert_matches!(res, LACompleteAction::LangDoesTimerBackoff(dur, info)
-            if dur.seconds == 10 && info.attempt == 5
+        assert_matches!(res, LACompleteAction::Report{resolution, ..}
+            if resolution.backoff.as_ref().unwrap().seconds == 10 && resolution.attempt == 5
         )
     }
 
     #[tokio::test]
     async fn respects_non_retryable_error_types() {
         let lam = LocalActivityManager::test(1);
         lam.enqueue([NewLocalAct {
@@ -1017,28 +1111,28 @@
         }
         .into()]);
 
         let next = lam.next_pending().await.unwrap().unwrap();
         let tt = TaskToken(next.task_token);
         let res = lam.complete(
             &tt,
-            &LocalActivityExecutionResult::Failed(ActFail {
+            LocalActivityExecutionResult::Failed(ActFail {
                 failure: Some(Failure {
                     failure_info: Some(FailureInfo::ApplicationFailureInfo(
                         ApplicationFailureInfo {
                             r#type: "TestError".to_string(),
                             non_retryable: false,
                             ..Default::default()
                         },
                     )),
                     ..Default::default()
                 }),
             }),
         );
-        assert_matches!(res, LACompleteAction::Report(_));
+        assert_matches!(res, LACompleteAction::Report { .. });
     }
 
     #[tokio::test]
     async fn can_cancel_during_local_backoff() {
         let lam = LocalActivityManager::test(1);
         lam.enqueue([NewLocalAct {
             schedule_cmd: ValidScheduleLA {
@@ -1064,15 +1158,15 @@
         }
         .into()]);
 
         let next = lam.next_pending().await.unwrap().unwrap();
         let tt = TaskToken(next.task_token);
         lam.complete(
             &tt,
-            &LocalActivityExecutionResult::Failed(Default::default()),
+            LocalActivityExecutionResult::Failed(Default::default()),
         );
         // Cancel the activity, which is performing local backoff
         let immediate_res = lam.enqueue([LocalActRequest::Cancel(ExecutingLAId {
             run_id: "run_id".to_string(),
             seq_num: 1,
         })]);
         // It should not be present in the backoff tasks
@@ -1111,15 +1205,15 @@
         }
         .into()]);
 
         let next = lam.next_pending().await.unwrap().unwrap();
         let tt = TaskToken(next.task_token);
         lam.complete(
             &tt,
-            &LocalActivityExecutionResult::Failed(Default::default()),
+            LocalActivityExecutionResult::Failed(Default::default()),
         );
         lam.next_pending().await.unwrap().unwrap();
         assert_eq!(lam.num_in_backoff(), 0);
         assert_eq!(lam.num_outstanding(), 1);
     }
 
     #[tokio::test]
@@ -1148,18 +1242,15 @@
             schedule_time: SystemTime::now(),
         }
         .into()]);
 
         // Wait more than the timeout before grabbing the task
         sleep(timeout + Duration::from_millis(10)).await;
 
-        assert_matches!(
-            lam.next_pending().await.unwrap(),
-            DispatchOrTimeoutLA::Timeout { .. }
-        );
+        assert!(dbg!(lam.next_pending().await.unwrap()).is_timeout(false));
         assert_eq!(lam.num_in_backoff(), 0);
         assert_eq!(lam.num_outstanding(), 0);
     }
 
     #[rstest::rstest]
     #[case::schedule(true)]
     #[case::start(false)]
@@ -1176,14 +1267,15 @@
             schedule_cmd: ValidScheduleLA {
                 seq: 1,
                 activity_id: 1.to_string(),
                 attempt: 5,
                 retry_policy: RetryPolicy {
                     initial_interval: Some(prost_dur!(from_millis(10))),
                     backoff_coefficient: 1.0,
+                    maximum_attempts: 1,
                     ..Default::default()
                 },
                 local_retry_threshold: Duration::from_secs(500),
                 close_timeouts,
                 ..Default::default()
             },
             workflow_type: "".to_string(),
@@ -1191,23 +1283,35 @@
                 workflow_id: "".to_string(),
                 run_id: "run_id".to_string(),
             },
             schedule_time: SystemTime::now(),
         }
         .into()]);
 
-        lam.next_pending().await.unwrap().unwrap();
+        let next = lam.next_pending().await.unwrap().unwrap();
         assert_eq!(lam.num_in_backoff(), 0);
         assert_eq!(lam.num_outstanding(), 1);
 
+        if let Some(activity_task::Variant::Start(start)) = next.variant {
+            // Validate that timeouts reported to lang matches what server would have provided
+            // if this had been a normal activity with the same timeout configuration.
+            if is_schedule {
+                assert_eq!(start.schedule_to_close_timeout, timeout.try_into().ok());
+                assert_eq!(start.start_to_close_timeout, timeout.try_into().ok());
+            } else {
+                assert_eq!(
+                    start.schedule_to_close_timeout,
+                    Duration::ZERO.try_into().ok()
+                );
+                assert_eq!(start.start_to_close_timeout, timeout.try_into().ok());
+            }
+        };
+
         sleep(timeout + Duration::from_millis(10)).await;
-        assert_matches!(
-            lam.next_pending().await.unwrap(),
-            DispatchOrTimeoutLA::Timeout { .. }
-        );
+        assert!(lam.next_pending().await.unwrap().is_timeout(true));
         assert_eq!(lam.num_outstanding(), 0);
     }
 
     #[tokio::test]
     async fn idempotency_enforced() {
         let lam = LocalActivityManager::test(10);
         let new_la = NewLocalAct {
@@ -1263,15 +1367,15 @@
         lam.enqueue([new_la.clone().into()]);
         let spinfail = || async {
             for _ in 1..=10 {
                 let next = lam.next_pending().await.unwrap().unwrap();
                 let tt = TaskToken(next.task_token);
                 lam.complete(
                     &tt,
-                    &LocalActivityExecutionResult::Failed(Default::default()),
+                    LocalActivityExecutionResult::Failed(Default::default()),
                 );
             }
         };
 
         // Fail a bunch of times
         spinfail().await;
         // Nonfirst attempt count should still be zero
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/activities.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/activities.rs`

 * *Files 3% similar despite different names*

```diff
@@ -1,26 +1,23 @@
 mod activity_heartbeat_manager;
 mod activity_task_poller_stream;
 mod local_activities;
 
 pub(crate) use local_activities::{
-    DispatchOrTimeoutLA, ExecutingLAId, LACompleteAction, LocalActRequest,
-    LocalActivityExecutionResult, LocalActivityManager, LocalActivityResolution,
-    LocalInFlightActInfo, NewLocalAct,
+    ExecutingLAId, LACompleteAction, LocalActRequest, LocalActivityExecutionResult,
+    LocalActivityManager, LocalActivityResolution, NewLocalAct, NextPendingLAAction,
 };
 
 use crate::{
     abstractions::{
         ClosableMeteredSemaphore, MeteredSemaphore, OwnedMeteredSemPermit,
         TrackedOwnedMeteredSemPermit, UsedMeteredSemPermit,
     },
     pollers::BoxedActPoller,
-    telemetry::metrics::{
-        activity_type, activity_worker_type, eager, workflow_type, MetricsContext,
-    },
+    telemetry::metrics::{activity_type, eager, workflow_type, MetricsContext},
     worker::{
         activities::{
             activity_heartbeat_manager::ActivityHeartbeatError,
             activity_task_poller_stream::new_activity_task_poller,
         },
         client::WorkerClient,
     },
@@ -29,15 +26,14 @@
 use activity_heartbeat_manager::ActivityHeartbeatManager;
 use dashmap::DashMap;
 use futures::{
     stream,
     stream::{BoxStream, PollNext},
     Stream, StreamExt,
 };
-use governor::{Quota, RateLimiter};
 use std::{
     convert::TryInto,
     future,
     sync::{
         atomic::{AtomicBool, Ordering},
         Arc,
     },
@@ -154,40 +150,26 @@
     PendingCancel(PendingActivityCancel),
     PendingStart(Result<(PermittedTqResp, bool), PollActivityError>),
 }
 
 impl WorkerActivityTasks {
     #[allow(clippy::too_many_arguments)]
     pub(crate) fn new(
-        max_activity_tasks: usize,
-        max_worker_act_per_sec: Option<f64>,
+        semaphore: Arc<MeteredSemaphore>,
         poller: BoxedActPoller,
         client: Arc<dyn WorkerClient>,
         metrics: MetricsContext,
         max_heartbeat_throttle_interval: Duration,
         default_heartbeat_throttle_interval: Duration,
         graceful_shutdown: Option<Duration>,
     ) -> Self {
-        let semaphore = Arc::new(MeteredSemaphore::new(
-            max_activity_tasks,
-            metrics.with_new_attrs([activity_worker_type()]),
-            MetricsContext::available_task_slots,
-        ));
         let shutdown_initiated_token = CancellationToken::new();
-        let rate_limiter = max_worker_act_per_sec.and_then(|ps| {
-            Quota::with_period(Duration::from_secs_f64(ps.recip())).map(RateLimiter::direct)
-        });
         let outstanding_activity_tasks = Arc::new(DashMap::new());
-        let server_poller_stream = new_activity_task_poller(
-            poller,
-            semaphore.clone(),
-            rate_limiter,
-            metrics.clone(),
-            shutdown_initiated_token.clone(),
-        );
+        let server_poller_stream =
+            new_activity_task_poller(poller, metrics.clone(), shutdown_initiated_token.clone());
         let (eager_activities_tx, eager_activities_rx) = unbounded_channel();
         let eager_activities_semaphore = ClosableMeteredSemaphore::new_arc(semaphore);
 
         let start_tasks_stream_complete = CancellationToken::new();
         let starts_stream = Self::merge_start_task_sources(
             eager_activities_rx,
             server_poller_stream,
@@ -426,15 +408,15 @@
             sem: self.eager_activities_semaphore.clone(),
             tx: self.eager_activities_tx.clone(),
         }
     }
 
     #[cfg(test)]
     pub(crate) fn remaining_activity_capacity(&self) -> usize {
-        self.eager_activities_semaphore.available_permits()
+        self.eager_activities_semaphore.unused_permits()
     }
 }
 
 struct ActivityTaskStream<SrcStrm> {
     source_stream: SrcStrm,
     outstanding_tasks: Arc<DashMap<TaskToken, RemoteInFlightActInfo>>,
     start_tasks_stream_complete: CancellationToken,
@@ -621,46 +603,89 @@
         )),
     }
 }
 
 #[cfg(test)]
 mod tests {
     use super::*;
-    use crate::{
-        test_help::mock_poller_from_resps, worker::client::mocks::mock_manual_workflow_client,
-    };
+    use crate::{pollers::new_activity_task_buffer, worker::client::mocks::mock_workflow_client};
+    use temporal_sdk_core_protos::coresdk::activity_result::ActivityExecutionResult;
 
     #[tokio::test]
     async fn per_worker_ratelimit() {
-        let poller = mock_poller_from_resps([
-            PollActivityTaskQueueResponse {
-                task_token: vec![1],
-                activity_id: "act1".to_string(),
-                ..Default::default()
-            }
-            .into(),
-            PollActivityTaskQueueResponse {
-                task_token: vec![2],
-                activity_id: "act2".to_string(),
-                ..Default::default()
-            }
-            .into(),
-        ]);
-        let atm = WorkerActivityTasks::new(
+        let mut mock_client = mock_workflow_client();
+        mock_client
+            .expect_poll_activity_task()
+            .times(1)
+            .returning(move |_, _| {
+                Ok(PollActivityTaskQueueResponse {
+                    task_token: vec![1],
+                    activity_id: "act1".to_string(),
+                    ..Default::default()
+                })
+            });
+        mock_client
+            .expect_poll_activity_task()
+            .times(1)
+            .returning(move |_, _| {
+                Ok(PollActivityTaskQueueResponse {
+                    task_token: vec![2],
+                    activity_id: "act2".to_string(),
+                    ..Default::default()
+                })
+            });
+        mock_client
+            .expect_complete_activity_task()
+            .times(2)
+            .returning(|_, _| Ok(Default::default()));
+        let mock_client = Arc::new(mock_client);
+        let sem = Arc::new(MeteredSemaphore::new(
             10,
+            MetricsContext::no_op(),
+            MetricsContext::available_task_slots,
+        ));
+        let shutdown_token = CancellationToken::new();
+        let ap = new_activity_task_buffer(
+            mock_client.clone(),
+            "tq".to_string(),
+            5, // Lots of concurrent pollers, to ensure we don't poll to much when that's the case
+            sem.clone(),
+            None,
+            shutdown_token.clone(),
+            None::<fn(usize)>,
             Some(2.0),
-            poller,
-            Arc::new(mock_manual_workflow_client()),
+        );
+        let atm = WorkerActivityTasks::new(
+            sem.clone(),
+            Box::new(ap),
+            mock_client.clone(),
             MetricsContext::no_op(),
             Duration::from_secs(1),
             Duration::from_secs(1),
             None,
         );
         let start = Instant::now();
-        atm.poll().await.unwrap();
-        atm.poll().await.unwrap();
+        let t1 = atm.poll().await.unwrap();
+        let t2 = atm.poll().await.unwrap();
         // At least half a second will have elapsed since we only allow 2 tasks per second.
         // With no ratelimit, even on a slow CI server with lots of load, this would typically take
         // low single digit ms or less.
         assert!(start.elapsed() > Duration::from_secs_f64(0.5));
+        shutdown_token.cancel();
+        // Need to complete the tasks so shutdown will resolve
+        atm.complete(
+            TaskToken(t1.task_token),
+            ActivityExecutionResult::ok(vec![1].into()).status.unwrap(),
+            mock_client.as_ref(),
+        )
+        .await;
+        atm.complete(
+            TaskToken(t2.task_token),
+            ActivityExecutionResult::ok(vec![1].into()).status.unwrap(),
+            mock_client.as_ref(),
+        )
+        .await;
+        atm.initiate_shutdown();
+        assert_matches!(atm.poll().await.unwrap_err(), PollActivityError::ShutDown);
+        atm.shutdown().await;
     }
 }
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/client/mocks.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/client/mocks.rs`

 * *Files 2% similar despite different names*

```diff
@@ -33,15 +33,15 @@
 // Need a version of the mock that can return futures so we can return potentially pending
 // results. This is really annoying b/c of the async trait stuff. Need
 // https://github.com/asomers/mockall/issues/189 to be fixed for it to go away.
 mockall::mock! {
     pub(crate) ManualWorkerClient {}
     #[allow(unused)]
     impl WorkerClient for ManualWorkerClient {
-        fn poll_workflow_task<'a, 'b>(&'a self, task_queue: String, is_sticky: bool)
+        fn poll_workflow_task<'a, 'b>(&'a self, task_queue: TaskQueue)
             -> impl Future<Output = Result<PollWorkflowTaskQueueResponse>> + Send + 'b
             where 'a: 'b, Self: 'b;
 
         fn poll_activity_task<'a, 'b>(&self, task_queue: String, max_tasks_per_sec: Option<f64>)
             -> impl Future<Output = Result<PollActivityTaskQueueResponse>> + Send + 'b
             where 'a: 'b, Self: 'b;
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/client.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/client.rs`

 * *Files 5% similar despite different names*

```diff
@@ -44,32 +44,59 @@
             client,
             namespace,
             identity,
             worker_build_id,
             use_versioning,
         }
     }
-    fn versioning_build_id(&self) -> String {
-        if self.use_versioning {
+
+    fn default_capabilities(&self) -> Capabilities {
+        self.capabilities().cloned().unwrap_or_default()
+    }
+
+    fn binary_checksum(&self) -> String {
+        if self.default_capabilities().build_id_based_versioning {
+            "".to_string()
+        } else {
             self.worker_build_id.clone()
+        }
+    }
+
+    fn worker_version_capabilities(&self) -> Option<WorkerVersionCapabilities> {
+        if self.default_capabilities().build_id_based_versioning {
+            Some(WorkerVersionCapabilities {
+                build_id: self.worker_build_id.clone(),
+                use_versioning: self.use_versioning,
+            })
         } else {
-            "".to_string()
+            None
+        }
+    }
+
+    fn worker_version_stamp(&self) -> Option<WorkerVersionStamp> {
+        if self.default_capabilities().build_id_based_versioning {
+            Some(WorkerVersionStamp {
+                build_id: self.worker_build_id.clone(),
+                bundle_id: "".to_string(),
+                use_versioning: self.use_versioning,
+            })
+        } else {
+            None
         }
     }
 }
 
 /// This trait contains everything workers need to interact with Temporal, and hence provides a
 /// minimal mocking surface. Delegates to [WorkflowClientTrait] so see that for details.
 #[cfg_attr(test, mockall::automock)]
 #[async_trait::async_trait]
 pub(crate) trait WorkerClient: Sync + Send {
     async fn poll_workflow_task(
         &self,
-        task_queue: String,
-        is_sticky: bool,
+        task_queue: TaskQueue,
     ) -> Result<PollWorkflowTaskQueueResponse>;
     async fn poll_activity_task(
         &self,
         task_queue: String,
         max_tasks_per_sec: Option<f64>,
     ) -> Result<PollActivityTaskQueueResponse>;
     async fn complete_workflow_task(
@@ -118,36 +145,22 @@
     fn capabilities<'a>(&'a self) -> Option<&'a get_system_info_response::Capabilities>;
 }
 
 #[async_trait::async_trait]
 impl WorkerClient for WorkerClientBag {
     async fn poll_workflow_task(
         &self,
-        task_queue: String,
-        is_sticky: bool,
+        task_queue: TaskQueue,
     ) -> Result<PollWorkflowTaskQueueResponse> {
         let request = PollWorkflowTaskQueueRequest {
             namespace: self.namespace.clone(),
-            task_queue: Some(TaskQueue {
-                name: task_queue,
-                kind: if is_sticky {
-                    TaskQueueKind::Sticky
-                } else {
-                    TaskQueueKind::Normal
-                } as i32,
-            }),
+            task_queue: Some(task_queue),
             identity: self.identity.clone(),
-            binary_checksum: if self.use_versioning {
-                "".to_string()
-            } else {
-                self.worker_build_id.clone()
-            },
-            worker_version_capabilities: Some(WorkerVersionCapabilities {
-                build_id: self.versioning_build_id(),
-            }),
+            binary_checksum: self.binary_checksum(),
+            worker_version_capabilities: self.worker_version_capabilities(),
         };
 
         Ok(self
             .client
             .clone()
             .poll_workflow_task_queue(request)
             .await?
@@ -160,22 +173,21 @@
         max_tasks_per_sec: Option<f64>,
     ) -> Result<PollActivityTaskQueueResponse> {
         let request = PollActivityTaskQueueRequest {
             namespace: self.namespace.clone(),
             task_queue: Some(TaskQueue {
                 name: task_queue,
                 kind: TaskQueueKind::Normal as i32,
+                normal_name: "".to_string(),
             }),
             identity: self.identity.clone(),
             task_queue_metadata: max_tasks_per_sec.map(|tps| TaskQueueMetadata {
                 max_tasks_per_second: Some(tps),
             }),
-            worker_version_capabilities: Some(WorkerVersionCapabilities {
-                build_id: self.versioning_build_id(),
-            }),
+            worker_version_capabilities: self.worker_version_capabilities(),
         };
 
         Ok(self
             .client
             .clone()
             .poll_activity_task_queue(request)
             .await?
@@ -189,20 +201,17 @@
         let request = RespondWorkflowTaskCompletedRequest {
             task_token: request.task_token.into(),
             commands: request.commands,
             identity: self.identity.clone(),
             sticky_attributes: request.sticky_attributes,
             return_new_workflow_task: request.return_new_workflow_task,
             force_create_new_workflow_task: request.force_create_new_workflow_task,
-            worker_version_stamp: Some(WorkerVersionStamp {
-                build_id: self.versioning_build_id(),
-                bundle_id: "".to_string(),
-            }),
+            worker_version_stamp: self.worker_version_stamp(),
             messages: vec![],
-            binary_checksum: self.worker_build_id.clone(),
+            binary_checksum: self.binary_checksum(),
             query_results: request
                 .query_responses
                 .into_iter()
                 .map(|qr| {
                     let (id, completed_type, query_result, error_message) = qr.into_components();
                     (
                         id,
@@ -235,14 +244,15 @@
             .client
             .clone()
             .respond_activity_task_completed(RespondActivityTaskCompletedRequest {
                 task_token: task_token.0,
                 result,
                 identity: self.identity.clone(),
                 namespace: self.namespace.clone(),
+                worker_version: self.worker_version_stamp(),
             })
             .await?
             .into_inner())
     }
 
     async fn record_activity_heartbeat(
         &self,
@@ -271,14 +281,15 @@
             .client
             .clone()
             .respond_activity_task_canceled(RespondActivityTaskCanceledRequest {
                 task_token: task_token.0,
                 details,
                 identity: self.identity.clone(),
                 namespace: self.namespace.clone(),
+                worker_version: self.worker_version_stamp(),
             })
             .await?
             .into_inner())
     }
 
     async fn fail_activity_task(
         &self,
@@ -291,14 +302,15 @@
             .respond_activity_task_failed(RespondActivityTaskFailedRequest {
                 task_token: task_token.0,
                 failure,
                 identity: self.identity.clone(),
                 namespace: self.namespace.clone(),
                 // TODO: Implement - https://github.com/temporalio/sdk-core/issues/293
                 last_heartbeat_details: None,
+                worker_version: self.worker_version_stamp(),
             })
             .await?
             .into_inner())
     }
 
     async fn fail_workflow_task(
         &self,
@@ -307,17 +319,18 @@
         failure: Option<Failure>,
     ) -> Result<RespondWorkflowTaskFailedResponse> {
         let request = RespondWorkflowTaskFailedRequest {
             task_token: task_token.0,
             cause: cause as i32,
             failure,
             identity: self.identity.clone(),
-            binary_checksum: self.worker_build_id.clone(),
+            binary_checksum: self.binary_checksum(),
             namespace: self.namespace.clone(),
             messages: vec![],
+            worker_version: self.worker_version_stamp(),
         };
         Ok(self
             .client
             .clone()
             .respond_workflow_task_failed(request)
             .await?
             .into_inner())
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/mod.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/mod.rs`

 * *Files 7% similar despite different names*

```diff
@@ -6,41 +6,39 @@
 #[cfg(feature = "save_wf_inputs")]
 pub use workflow::replay_wf_state_inputs;
 
 pub(crate) use activities::{
     ExecutingLAId, LocalActRequest, LocalActivityExecutionResult, LocalActivityResolution,
     NewLocalAct,
 };
+pub(crate) use workflow::{wft_poller::new_wft_poller, LEGACY_QUERY_ID};
+
 #[cfg(test)]
 pub(crate) use workflow::ManagedWFFunc;
-pub(crate) use workflow::{wft_poller::new_wft_poller, LEGACY_QUERY_ID};
 
 use crate::{
+    abstractions::MeteredSemaphore,
     errors::CompleteWfError,
-    pollers::{
-        new_activity_task_buffer, new_workflow_task_buffer, BoxedActPoller, Poller,
-        WorkflowTaskPoller,
-    },
-    protosext::{validate_activity_completion, ValidPollWFTQResponse},
+    pollers::{new_activity_task_buffer, new_workflow_task_buffer, WorkflowTaskPoller},
+    protosext::validate_activity_completion,
     telemetry::{
         metrics::{
-            activity_poller, local_activity_worker_type, workflow_poller, workflow_sticky_poller,
-            MetricsContext,
+            activity_poller, activity_worker_type, local_activity_worker_type, workflow_poller,
+            workflow_sticky_poller, workflow_worker_type, MetricsContext,
         },
         TelemetryInstance,
     },
     worker::{
-        activities::{DispatchOrTimeoutLA, LACompleteAction, LocalActivityManager},
+        activities::{LACompleteAction, LocalActivityManager, NextPendingLAAction},
         client::WorkerClient,
         workflow::{LAReqSink, LocalResolution, WorkflowBasics, Workflows},
     },
     ActivityHeartbeat, CompleteActivityError, PollActivityError, PollWfError, WorkerTrait,
 };
-use activities::{LocalInFlightActInfo, WorkerActivityTasks};
-use futures::Stream;
+use activities::WorkerActivityTasks;
 use std::{
     convert::TryInto,
     future,
     sync::{
         atomic::{AtomicBool, Ordering},
         Arc,
     },
@@ -52,21 +50,33 @@
         workflow_activation::{remove_from_cache::EvictionReason, WorkflowActivation},
         workflow_completion::WorkflowActivationCompletion,
         ActivityTaskCompletion,
     },
     temporal::api::{
         enums::v1::TaskQueueKind,
         taskqueue::v1::{StickyExecutionAttributes, TaskQueue},
-        workflowservice::v1::{get_system_info_response, PollActivityTaskQueueResponse},
+        workflowservice::v1::get_system_info_response,
     },
     TaskToken,
 };
 use tokio::sync::mpsc::unbounded_channel;
 use tokio_util::sync::CancellationToken;
 
+use crate::{abstractions::dbg_panic, pollers::BoxedActPoller};
+#[cfg(test)]
+use {
+    crate::{
+        pollers::{BoxedPoller, MockPermittedPollBuffer},
+        protosext::ValidPollWFTQResponse,
+    },
+    futures::stream::BoxStream,
+    futures_util::StreamExt,
+    temporal_sdk_core_protos::temporal::api::workflowservice::v1::PollActivityTaskQueueResponse,
+};
+
 /// A worker polls on a certain task queue
 pub struct Worker {
     config: WorkerConfig,
     wf_client: Arc<dyn WorkerClient>,
 
     /// Manages all workflows and WFT processing
     workflows: Workflows,
@@ -179,117 +189,157 @@
 impl Worker {
     pub(crate) fn new(
         config: WorkerConfig,
         sticky_queue_name: Option<String>,
         client: Arc<dyn WorkerClient>,
         telem_instance: Option<&TelemetryInstance>,
     ) -> Self {
-        info!(task_queue=%config.task_queue,
-              namespace=%config.namespace,
-              "Initializing worker");
+        info!(task_queue=%config.task_queue, namespace=%config.namespace, "Initializing worker");
         let metrics = if let Some(ti) = telem_instance {
             MetricsContext::top_level(config.namespace.clone(), ti)
                 .with_task_q(config.task_queue.clone())
         } else {
             MetricsContext::no_op()
         };
         metrics.worker_registered();
 
-        let shutdown_token = CancellationToken::new();
-        let max_nonsticky_polls = if sticky_queue_name.is_some() {
-            config.max_nonsticky_polls()
-        } else {
-            config.max_concurrent_wft_polls
-        };
-        let max_sticky_polls = config.max_sticky_polls();
-        let wft_metrics = metrics.with_new_attrs([workflow_poller()]);
-        let mut wf_task_poll_buffer = new_workflow_task_buffer(
-            client.clone(),
-            config.task_queue.clone(),
-            false,
-            max_nonsticky_polls,
-            max_nonsticky_polls * 2,
-            shutdown_token.child_token(),
-        );
-        wf_task_poll_buffer.set_num_pollers_handler(move |np| wft_metrics.record_num_pollers(np));
-        let sticky_queue_poller = sticky_queue_name.as_ref().map(|sqn| {
-            let sticky_metrics = metrics.with_new_attrs([workflow_sticky_poller()]);
-            let mut sp = new_workflow_task_buffer(
-                client.clone(),
-                sqn.clone(),
-                true,
-                max_sticky_polls,
-                max_sticky_polls * 2,
-                shutdown_token.child_token(),
-            );
-            sp.set_num_pollers_handler(move |np| sticky_metrics.record_num_pollers(np));
-            sp
-        });
-        let act_poll_buffer = if config.no_remote_activities {
-            None
-        } else {
-            let mut ap = new_activity_task_buffer(
-                client.clone(),
-                config.task_queue.clone(),
-                config.max_concurrent_at_polls,
-                config.max_concurrent_at_polls * 2,
-                config.max_task_queue_activities_per_second,
-                shutdown_token.child_token(),
-            );
-            let act_metrics = metrics.with_new_attrs([activity_poller()]);
-            ap.set_num_pollers_handler(move |np| act_metrics.record_num_pollers(np));
-            Some(Box::from(ap)
-                as Box<
-                    dyn Poller<PollActivityTaskQueueResponse> + Send + Sync,
-                >)
-        };
-        let wf_task_poll_buffer = Box::new(WorkflowTaskPoller::new(
-            wf_task_poll_buffer,
-            sticky_queue_poller,
-        ));
-        let wft_stream = new_wft_poller(wf_task_poll_buffer, metrics.clone());
         Self::new_with_pollers(
             config,
             sticky_queue_name,
             client,
-            wft_stream,
-            act_poll_buffer,
+            TaskPollers::Real,
             metrics,
             telem_instance,
-            shutdown_token,
         )
     }
 
     #[cfg(test)]
     pub(crate) fn new_test(config: WorkerConfig, client: impl WorkerClient + 'static) -> Self {
         Self::new(config, None, Arc::new(client), None)
     }
 
     #[allow(clippy::too_many_arguments)] // Not much worth combining here
     pub(crate) fn new_with_pollers(
         mut config: WorkerConfig,
         sticky_queue_name: Option<String>,
         client: Arc<dyn WorkerClient>,
-        wft_stream: impl Stream<Item = Result<ValidPollWFTQResponse, tonic::Status>> + Send + 'static,
-        act_poller: Option<BoxedActPoller>,
+        task_pollers: TaskPollers,
         metrics: MetricsContext,
         telem_instance: Option<&TelemetryInstance>,
-        shutdown_token: CancellationToken,
     ) -> Self {
+        let shutdown_token = CancellationToken::new();
+        let wft_semaphore = Arc::new(MeteredSemaphore::new(
+            config.max_outstanding_workflow_tasks,
+            metrics.with_new_attrs([workflow_worker_type()]),
+            MetricsContext::available_task_slots,
+        ));
+        let act_semaphore = Arc::new(MeteredSemaphore::new(
+            config.max_outstanding_activities,
+            metrics.with_new_attrs([activity_worker_type()]),
+            MetricsContext::available_task_slots,
+        ));
+
+        let (wft_stream, act_poller) = match task_pollers {
+            TaskPollers::Real => {
+                let max_nonsticky_polls = if sticky_queue_name.is_some() {
+                    config.max_nonsticky_polls()
+                } else {
+                    config.max_concurrent_wft_polls
+                };
+                let max_sticky_polls = config.max_sticky_polls();
+                let wft_metrics = metrics.with_new_attrs([workflow_poller()]);
+                let wf_task_poll_buffer = new_workflow_task_buffer(
+                    client.clone(),
+                    TaskQueue {
+                        name: config.task_queue.clone(),
+                        kind: TaskQueueKind::Normal as i32,
+                        normal_name: "".to_string(),
+                    },
+                    max_nonsticky_polls,
+                    wft_semaphore.clone(),
+                    shutdown_token.child_token(),
+                    Some(move |np| {
+                        wft_metrics.record_num_pollers(np);
+                    }),
+                );
+                let sticky_queue_poller = sticky_queue_name.as_ref().map(|sqn| {
+                    let sticky_metrics = metrics.with_new_attrs([workflow_sticky_poller()]);
+                    new_workflow_task_buffer(
+                        client.clone(),
+                        TaskQueue {
+                            name: sqn.clone(),
+                            kind: TaskQueueKind::Sticky as i32,
+                            normal_name: config.task_queue.clone(),
+                        },
+                        max_sticky_polls,
+                        wft_semaphore.clone(),
+                        shutdown_token.child_token(),
+                        Some(move |np| {
+                            sticky_metrics.record_num_pollers(np);
+                        }),
+                    )
+                });
+                let act_poll_buffer = if config.no_remote_activities {
+                    None
+                } else {
+                    let act_metrics = metrics.with_new_attrs([activity_poller()]);
+                    let ap = new_activity_task_buffer(
+                        client.clone(),
+                        config.task_queue.clone(),
+                        config.max_concurrent_at_polls,
+                        act_semaphore.clone(),
+                        config.max_task_queue_activities_per_second,
+                        shutdown_token.child_token(),
+                        Some(move |np| act_metrics.record_num_pollers(np)),
+                        config.max_worker_activities_per_second,
+                    );
+                    Some(Box::from(ap) as BoxedActPoller)
+                };
+                let wf_task_poll_buffer = Box::new(WorkflowTaskPoller::new(
+                    wf_task_poll_buffer,
+                    sticky_queue_poller,
+                ));
+                let wft_stream = new_wft_poller(wf_task_poll_buffer, metrics.clone());
+                #[cfg(test)]
+                let wft_stream = wft_stream.left_stream();
+                (wft_stream, act_poll_buffer)
+            }
+            #[cfg(test)]
+            TaskPollers::Mocked {
+                wft_stream,
+                act_poller,
+            } => {
+                let ap =
+                    act_poller.map(|ap| MockPermittedPollBuffer::new(act_semaphore.clone(), ap));
+                let wft_semaphore = wft_semaphore.clone();
+                let wfs = wft_stream.then(move |s| {
+                    let wft_semaphore = wft_semaphore.clone();
+                    async move {
+                        let permit = wft_semaphore
+                            .acquire_owned()
+                            .await
+                            .expect("Mock WFT stream should not see closed semaphore");
+                        s.map(|s| (s, permit))
+                    }
+                });
+                let wfs = wfs.right_stream();
+                (wfs, ap.map(|ap| Box::new(ap) as BoxedActPoller))
+            }
+        };
+
         let (hb_tx, hb_rx) = unbounded_channel();
         let local_act_mgr = Arc::new(LocalActivityManager::new(
             config.max_outstanding_local_activities,
             config.namespace.clone(),
             hb_tx,
             metrics.with_new_attrs([local_activity_worker_type()]),
         ));
         let at_task_mgr = act_poller.map(|ap| {
             WorkerActivityTasks::new(
-                config.max_outstanding_activities,
-                config.max_worker_activities_per_second,
+                act_semaphore,
                 ap,
                 client.clone(),
                 metrics.clone(),
                 config.max_heartbeat_throttle_interval,
                 config.default_heartbeat_throttle_interval,
                 config.graceful_shutdown_period,
             )
@@ -308,38 +358,40 @@
                     shutdown_token.child_token(),
                     client.capabilities().cloned().unwrap_or_default(),
                 ),
                 sticky_queue_name.map(|sq| StickyExecutionAttributes {
                     worker_task_queue: Some(TaskQueue {
                         name: sq,
                         kind: TaskQueueKind::Sticky as i32,
+                        normal_name: config.task_queue.clone(),
                     }),
                     schedule_to_start_timeout: Some(
                         config
                             .sticky_queue_schedule_to_start_timeout
                             .try_into()
                             .expect("timeout fits into proto"),
                     ),
                 }),
                 client,
+                wft_semaphore,
                 wft_stream,
                 la_sink,
                 local_act_mgr.clone(),
                 hb_rx,
                 at_task_mgr
                     .as_ref()
                     .map(|mgr| mgr.get_handle_for_workflows()),
                 telem_instance,
             ),
             at_task_mgr,
             local_act_mgr,
             config,
             shutdown_token,
             post_activate_hook: None,
-            // Complete if there configured not to poll on non-local activities.
+            // Non-local activities are already complete if configured not to poll for them.
             non_local_activities_complete: Arc::new(AtomicBool::new(!poll_on_non_local_activities)),
             local_activities_complete: Default::default(),
         }
     }
 
     /// Will shutdown the worker. Does not resolve until all outstanding workflow tasks have been
     /// completed
@@ -389,17 +441,21 @@
             .get_state_info()
             .await
             .map(|r| r.outstanding_wft)
             .unwrap_or_default()
     }
 
     #[allow(unused)]
-    pub(crate) async fn available_wft_permits(&self) -> usize {
+    pub(crate) fn available_wft_permits(&self) -> usize {
         self.workflows.available_wft_permits()
     }
+    #[cfg(test)]
+    pub(crate) fn unused_wft_permits(&self) -> usize {
+        self.workflows.unused_wft_permits()
+    }
 
     /// Get new activity tasks (may be local or nonlocal). Local activities are returned first
     /// before polling the server if there are any.
     ///
     /// Returns `Ok(None)` in the event of a poll timeout or if the polling loop should otherwise
     /// be restarted
     async fn activity_poll(&self) -> Result<Option<ActivityTask>, PollActivityError> {
@@ -433,22 +489,17 @@
         };
         let local_activities_poll = async {
             if local_activities_complete {
                 future::pending::<()>().await;
                 unreachable!()
             }
             match self.local_act_mgr.next_pending().await {
-                Some(DispatchOrTimeoutLA::Dispatch(r)) => Ok(Some(r)),
-                Some(DispatchOrTimeoutLA::Timeout {
-                    run_id,
-                    resolution,
-                    task,
-                }) => {
-                    self.notify_local_result(&run_id, LocalResolution::LocalActivity(resolution));
-                    Ok(task)
+                Some(NextPendingLAAction::Dispatch(r)) => Ok(Some(r)),
+                Some(NextPendingLAAction::Autocomplete(action)) => {
+                    Ok(self.handle_la_complete_action(action))
                 }
                 None => {
                     if self.shutdown_token.is_cancelled() {
                         self.local_activities_complete
                             .store(true, Ordering::Relaxed);
                     }
                     Ok(None)
@@ -481,31 +532,15 @@
         &self,
         task_token: TaskToken,
         status: activity_execution_result::Status,
     ) -> Result<(), CompleteActivityError> {
         validate_activity_completion(&status)?;
         if task_token.is_local_activity_task() {
             let as_la_res: LocalActivityExecutionResult = status.try_into()?;
-            match self.local_act_mgr.complete(&task_token, &as_la_res) {
-                LACompleteAction::Report(info) => self.complete_local_act(as_la_res, info, None),
-                LACompleteAction::LangDoesTimerBackoff(backoff, info) => {
-                    // This la needs to write a failure marker, and then we will tell lang how
-                    // long of a timer to schedule to back off for. We do this because there are
-                    // no other situations where core generates "internal" commands so it is much
-                    // simpler for lang to reply with the timer / next LA command than to do it
-                    // internally. Plus, this backoff hack we'd like to eliminate eventually.
-                    self.complete_local_act(as_la_res, info, Some(backoff));
-                }
-                LACompleteAction::WillBeRetried => {
-                    // Nothing to do here
-                }
-                LACompleteAction::Untracked => {
-                    warn!("Tried to complete untracked local activity {}", task_token);
-                }
-            }
+            self.complete_local_act(task_token, as_la_res);
             return Ok(());
         }
 
         if let Some(atm) = &self.at_task_mgr {
             atm.complete(task_token, status, &*self.wf_client).await;
         } else {
             error!(
@@ -563,31 +598,36 @@
     pub(crate) fn set_post_activate_hook(
         &mut self,
         callback: impl Fn(&Self, PostActivateHookData) + Send + Sync + 'static,
     ) {
         self.post_activate_hook = Some(Box::new(callback))
     }
 
-    fn complete_local_act(
-        &self,
-        la_res: LocalActivityExecutionResult,
-        info: LocalInFlightActInfo,
-        backoff: Option<prost_types::Duration>,
-    ) {
-        self.notify_local_result(
-            &info.la_info.workflow_exec_info.run_id,
-            LocalResolution::LocalActivity(LocalActivityResolution {
-                seq: info.la_info.schedule_cmd.seq,
-                result: la_res,
-                runtime: info.dispatch_time.elapsed(),
-                attempt: info.attempt,
-                backoff,
-                original_schedule_time: info.la_info.schedule_cmd.original_schedule_time,
-            }),
-        )
+    fn complete_local_act(&self, task_token: TaskToken, la_res: LocalActivityExecutionResult) {
+        if self
+            .handle_la_complete_action(self.local_act_mgr.complete(&task_token, la_res))
+            .is_some()
+        {
+            dbg_panic!("Should never be a task from direct completion");
+        }
+    }
+
+    fn handle_la_complete_action(&self, action: LACompleteAction) -> Option<ActivityTask> {
+        match action {
+            LACompleteAction::Report {
+                run_id,
+                resolution,
+                task,
+            } => {
+                self.notify_local_result(&run_id, LocalResolution::LocalActivity(resolution));
+                task
+            }
+            LACompleteAction::WillBeRetried(task) => task,
+            LACompleteAction::Untracked => None,
+        }
     }
 
     fn notify_local_result(&self, run_id: &str, res: LocalResolution) {
         self.workflows.notify_of_local_result(run_id, res);
     }
 }
 
@@ -601,27 +641,35 @@
     config: &mut WorkerConfig,
     metrics: MetricsContext,
     shutdown_token: CancellationToken,
     server_capabilities: get_system_info_response::Capabilities,
 ) -> WorkflowBasics {
     WorkflowBasics {
         max_cached_workflows: config.max_cached_workflows,
-        max_outstanding_wfts: config.max_outstanding_workflow_tasks,
         shutdown_token,
         metrics,
         namespace: config.namespace.clone(),
         task_queue: config.task_queue.clone(),
         ignore_evicts_on_shutdown: config.ignore_evicts_on_shutdown,
         fetching_concurrency: config.fetching_concurrency,
         server_capabilities,
         #[cfg(feature = "save_wf_inputs")]
         wf_state_inputs: config.wf_state_inputs.take(),
     }
 }
 
+pub(crate) enum TaskPollers {
+    Real,
+    #[cfg(test)]
+    Mocked {
+        wft_stream: BoxStream<'static, Result<ValidPollWFTQResponse, tonic::Status>>,
+        act_poller: Option<BoxedPoller<PollActivityTaskQueueResponse>>,
+    },
+}
+
 #[cfg(test)]
 mod tests {
     use super::*;
     use crate::{
         advance_fut, test_help::test_worker_cfg, worker::client::mocks::mock_workflow_client,
     };
     use futures::FutureExt;
@@ -644,15 +692,15 @@
         advance_fut!(fut);
         assert_eq!(
             worker
                 .at_task_mgr
                 .as_ref()
                 .unwrap()
                 .remaining_activity_capacity(),
-            4
+            5
         );
     }
 
     #[tokio::test]
     async fn activity_errs_dont_eat_permits() {
         let mut mock_client = mock_workflow_client();
         mock_client
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/bridge.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/bridge.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/driven_workflow.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/driven_workflow.rs`

 * *Files 5% similar despite different names*

```diff
@@ -36,18 +36,14 @@
         randomness_seed: u64,
         start_time: Timestamp,
         attribs: WorkflowExecutionStartedEventAttributes,
     ) {
         debug!(run_id = %attribs.original_execution_run_id, "Driven WF start");
         let started_info = WorkflowStartedInfo {
             workflow_task_timeout: attribs.workflow_task_timeout.clone().try_into_or_none(),
-            workflow_execution_timeout: attribs
-                .workflow_execution_timeout
-                .clone()
-                .try_into_or_none(),
             memo: attribs.memo.clone(),
             search_attrs: attribs.search_attributes.clone(),
             retry_policy: attribs.retry_policy.clone(),
         };
         self.send_job(
             start_workflow_from_attribs(attribs, workflow_id, randomness_seed, start_time).into(),
         );
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/history_update.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/history_update.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/activity_state_machine.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/activity_state_machine.rs`

 * *Files 2% similar despite different names*

```diff
@@ -13,15 +13,18 @@
 use temporal_sdk_core_protos::{
     coresdk::{
         activity_result::{self as ar, activity_resolution, ActivityResolution, Cancellation},
         workflow_activation::ResolveActivity,
         workflow_commands::{ActivityCancellationType, ScheduleActivity},
     },
     temporal::api::{
-        command::v1::{command, Command, RequestCancelActivityTaskCommandAttributes},
+        command::v1::{
+            command, schedule_activity_cmd_to_api, Command,
+            RequestCancelActivityTaskCommandAttributes,
+        },
         common::v1::{ActivityType, Payload, Payloads},
         enums::v1::{CommandType, EventType, RetryState},
         failure::v1::{failure::FailureInfo, ActivityFailureInfo, CanceledFailureInfo, Failure},
         history::v1::{
             history_event, ActivityTaskCanceledEventAttributes,
             ActivityTaskCompletedEventAttributes, ActivityTaskFailedEventAttributes,
             ActivityTaskTimedOutEventAttributes, HistoryEvent,
@@ -103,14 +106,15 @@
 }
 
 impl ActivityMachine {
     /// Create a new activity and immediately schedule it.
     pub(super) fn new_scheduled(
         attrs: ScheduleActivity,
         internal_flags: InternalFlagsRef,
+        use_compatible_version: bool,
     ) -> NewMachineWithCommand {
         let mut s = Self::from_parts(
             Created {}.into(),
             SharedState {
                 cancellation_type: ActivityCancellationType::from_i32(attrs.cancellation_type)
                     .unwrap(),
                 attrs,
@@ -120,15 +124,18 @@
                 cancelled_before_sent: false,
             },
         );
         OnEventWrapper::on_event_mut(&mut s, ActivityMachineEvents::Schedule)
             .expect("Scheduling activities doesn't fail");
         let command = Command {
             command_type: CommandType::ScheduleActivityTask as i32,
-            attributes: Some(s.shared_state().attrs.clone().into()),
+            attributes: Some(schedule_activity_cmd_to_api(
+                s.shared_state().attrs.clone(),
+                use_compatible_version,
+            )),
         };
         NewMachineWithCommand {
             command,
             machine: s.into(),
         }
     }
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/cancel_external_state_machine.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/cancel_external_state_machine.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/cancel_workflow_state_machine.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/cancel_workflow_state_machine.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/child_workflow_state_machine.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/child_workflow_state_machine.rs`

 * *Files 0% similar despite different names*

```diff
@@ -18,15 +18,18 @@
             resolve_child_workflow_execution_start, ResolveChildWorkflowExecution,
             ResolveChildWorkflowExecutionStart, ResolveChildWorkflowExecutionStartCancelled,
             ResolveChildWorkflowExecutionStartFailure, ResolveChildWorkflowExecutionStartSuccess,
         },
         workflow_commands::StartChildWorkflowExecution,
     },
     temporal::api::{
-        command::v1::{Command, RequestCancelExternalWorkflowExecutionCommandAttributes},
+        command::v1::{
+            start_child_workflow_cmd_to_api, Command,
+            RequestCancelExternalWorkflowExecutionCommandAttributes,
+        },
         common::v1::{Payload, Payloads, WorkflowExecution, WorkflowType},
         enums::v1::{
             CommandType, EventType, RetryState, StartChildWorkflowExecutionFailedCause, TimeoutType,
         },
         failure::v1::{self as failure, failure::FailureInfo, Failure},
         history::v1::{
             history_event, ChildWorkflowExecutionCompletedEventAttributes,
@@ -355,14 +358,15 @@
 }
 
 impl ChildWorkflowMachine {
     /// Create a new child workflow and immediately schedule it.
     pub(super) fn new_scheduled(
         attribs: StartChildWorkflowExecution,
         internal_flags: InternalFlagsRef,
+        use_compatible_version: bool,
     ) -> NewMachineWithCommand {
         let mut s = Self::from_parts(
             Created {}.into(),
             SharedState {
                 lang_sequence_number: attribs.seq,
                 workflow_id: attribs.workflow_id.clone(),
                 workflow_type: attribs.workflow_type.clone(),
@@ -375,15 +379,18 @@
                 cancelled_before_sent: false,
             },
         );
         OnEventWrapper::on_event_mut(&mut s, ChildWorkflowMachineEvents::Schedule)
             .expect("Scheduling child workflows doesn't fail");
         let cmd = Command {
             command_type: CommandType::StartChildWorkflowExecution as i32,
-            attributes: Some(attribs.into()),
+            attributes: Some(start_child_workflow_cmd_to_api(
+                attribs,
+                use_compatible_version,
+            )),
         };
         NewMachineWithCommand {
             command: cmd,
             machine: s.into(),
         }
     }
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/complete_workflow_state_machine.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/complete_workflow_state_machine.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/continue_as_new_workflow_state_machine.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/continue_as_new_workflow_state_machine.rs`

 * *Files 3% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 };
 use crate::worker::workflow::machines::HistEventData;
 use rustfsm::{fsm, StateMachine, TransitionResult};
 use std::convert::TryFrom;
 use temporal_sdk_core_protos::{
     coresdk::workflow_commands::ContinueAsNewWorkflowExecution,
     temporal::api::{
-        command::v1::Command,
+        command::v1::{continue_as_new_cmd_to_api, Command},
         enums::v1::{CommandType, EventType},
     },
 };
 
 fsm! {
     pub(super)
     name ContinueAsNewWorkflowMachine;
@@ -26,21 +26,24 @@
     ContinueAsNewWorkflowCommandCreated --(WorkflowExecutionContinuedAsNew)
         --> ContinueAsNewWorkflowCommandRecorded;
 }
 
 #[derive(Debug, derive_more::Display)]
 pub(super) enum ContinueAsNewWorkflowCommand {}
 
-pub(super) fn continue_as_new(attribs: ContinueAsNewWorkflowExecution) -> NewMachineWithCommand {
+pub(super) fn continue_as_new(
+    attribs: ContinueAsNewWorkflowExecution,
+    use_compatible_version: bool,
+) -> NewMachineWithCommand {
     let mut machine = ContinueAsNewWorkflowMachine::from_parts(Created {}.into(), ());
     OnEventWrapper::on_event_mut(&mut machine, ContinueAsNewWorkflowMachineEvents::Schedule)
         .expect("Scheduling continue as new machine doesn't fail");
     let command = Command {
         command_type: CommandType::ContinueAsNewWorkflowExecution as i32,
-        attributes: Some(attribs.into()),
+        attributes: Some(continue_as_new_cmd_to_api(attribs, use_compatible_version)),
     };
     NewMachineWithCommand {
         command,
         machine: machine.into(),
     }
 }
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/fail_workflow_state_machine.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/fail_workflow_state_machine.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/local_activity_state_machine.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/local_activity_state_machine.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/mod.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/mod.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/modify_workflow_properties_state_machine.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/modify_workflow_properties_state_machine.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/patch_state_machine.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/patch_state_machine.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/signal_external_state_machine.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/signal_external_state_machine.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/timer_state_machine.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/timer_state_machine.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/transition_coverage.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/transition_coverage.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/upsert_search_attributes_state_machine.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/upsert_search_attributes_state_machine.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_machines/local_acts.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_machines/local_acts.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_machines.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_machines.rs`

 * *Files 3% similar despite different names*

```diff
@@ -43,15 +43,15 @@
     convert::TryInto,
     hash::{Hash, Hasher},
     rc::Rc,
     time::{Duration, Instant, SystemTime},
 };
 use temporal_sdk_core_protos::{
     coresdk::{
-        common::NamespacedWorkflowExecution,
+        common::{NamespacedWorkflowExecution, VersioningIntent},
         workflow_activation,
         workflow_activation::{
             workflow_activation_job, NotifyHasPatch, UpdateRandomSeed, WorkflowActivation,
         },
         workflow_commands::{
             request_cancel_external_workflow_execution as cancel_we, ContinueAsNewWorkflowExecution,
         },
@@ -91,27 +91,36 @@
     pub namespace: String,
     /// Workflow identifier
     pub workflow_id: String,
     /// Workflow type identifier. (Function name, class, etc)
     pub workflow_type: String,
     /// Identifies the current run
     pub run_id: String,
+    /// The task queue this workflow is operating within
+    pub task_queue: String,
+    /// Is set to true once we've seen the final event in workflow history, to avoid accidentally
+    /// re-applying the final workflow task.
+    pub have_seen_terminal_event: bool,
     /// The time the workflow execution began, as told by the WEStarted event
     workflow_start_time: Option<SystemTime>,
     /// The time the workflow execution finished, as determined by when the machines handled
     /// a terminal workflow command. If this is `Some`, you know the workflow is ended.
     workflow_end_time: Option<SystemTime>,
     /// The WFT start time if it has been established
     wft_start_time: Option<SystemTime>,
     /// The current workflow time if it has been established. This may differ from the WFT start
     /// time since local activities may advance the clock
     current_wf_time: Option<SystemTime>,
     /// The internal flags which have been seen so far during this run's execution and thus are
     /// usable during replay.
     observed_internal_flags: InternalFlagsRef,
+    /// Set on each WFT started event, the most recent size of history in bytes
+    history_size_bytes: u64,
+    /// Set on each WFT started event
+    continue_as_new_suggested: bool,
 
     all_machines: SlotMap<MachineKey, Machines>,
     /// If a machine key is in this map, that machine was created internally by core, not as a
     /// command from lang.
     machine_is_core_created: SparseSecondaryMap<MachineKey, ()>,
 
     /// A mapping for accessing machines associated to a particular event, where the key is the id
@@ -133,18 +142,14 @@
 
     /// Contains extra local-activity related data
     local_activity_data: LocalActivityData,
 
     /// The workflow that is being driven by this instance of the machines
     drive_me: DrivenWorkflow,
 
-    /// Is set to true once we've seen the final event in workflow history, to avoid accidentally
-    /// re-applying the final workflow task.
-    pub have_seen_terminal_event: bool,
-
     /// Metrics context
     pub metrics: MetricsContext,
 }
 
 #[derive(Debug, derive_more::Display)]
 #[display(fmt = "Cmd&Machine({command})")]
 struct CommandAndMachine {
@@ -225,26 +230,29 @@
         };
         Self {
             last_history_from_server: basics.history,
             namespace: basics.namespace,
             workflow_id: basics.workflow_id,
             workflow_type: basics.workflow_type,
             run_id: basics.run_id,
+            task_queue: basics.task_queue,
             drive_me: driven_wf,
             replaying,
             metrics: basics.metrics,
             // In an ideal world one could say ..Default::default() here and it'd still work.
             current_started_event_id: 0,
             next_started_event_id: 0,
             last_processed_event: 0,
             workflow_start_time: None,
             workflow_end_time: None,
             wft_start_time: None,
             current_wf_time: None,
             observed_internal_flags: Rc::new(RefCell::new(observed_internal_flags)),
+            history_size_bytes: 0,
+            continue_as_new_suggested: false,
             all_machines: Default::default(),
             machine_is_core_created: Default::default(),
             machines_by_event_id: Default::default(),
             id_to_machine: Default::default(),
             commands: Default::default(),
             current_wf_task_commands: Default::default(),
             encountered_change_markers: Default::default(),
@@ -365,14 +373,16 @@
             run_id: self.run_id.clone(),
             history_length: self.last_processed_event as u32,
             jobs,
             available_internal_flags: (*self.observed_internal_flags)
                 .borrow()
                 .all_lang()
                 .collect(),
+            history_size_bytes: self.history_size_bytes,
+            continue_as_new_suggested: self.continue_as_new_suggested,
         }
     }
 
     pub(crate) fn has_pending_jobs(&self) -> bool {
         !self.drive_me.peek_pending_jobs().is_empty()
     }
 
@@ -631,14 +641,21 @@
             };
         }
 
         if event.is_command_event() {
             return self.handle_command_event(event_dat, next_event);
         }
 
+        if let Some(history_event::Attributes::WorkflowTaskStartedEventAttributes(ref attrs)) =
+            event.attributes
+        {
+            self.history_size_bytes = u64::try_from(attrs.history_size_bytes).unwrap_or_default();
+            self.continue_as_new_suggested = attrs.suggest_continue_as_new;
+        }
+
         if let Some(initial_cmd_id) = event.get_initial_command_event_id() {
             // We remove the machine while we it handles events, then return it, to avoid
             // borrowing from ourself mutably.
             let maybe_machine = self.machines_by_event_id.remove(&initial_cmd_id);
             match maybe_machine {
                 Some(sm) => {
                     self.submachine_handle_event(sm, event_dat)?;
@@ -1046,32 +1063,35 @@
                     );
                 }
                 WFCommand::CancelTimer(attrs) => {
                     self.process_cancellation(CommandID::Timer(attrs.seq))?;
                 }
                 WFCommand::AddActivity(attrs) => {
                     let seq = attrs.seq;
+                    let use_compat = self.determine_use_compatible_flag(
+                        attrs.versioning_intent(),
+                        &attrs.task_queue,
+                    );
                     self.add_cmd_to_wf_task(
-                        ActivityMachine::new_scheduled(attrs, self.observed_internal_flags.clone()),
+                        ActivityMachine::new_scheduled(
+                            attrs,
+                            self.observed_internal_flags.clone(),
+                            use_compat,
+                        ),
                         CommandID::Activity(seq).into(),
                     );
                 }
                 WFCommand::AddLocalActivity(attrs) => {
                     let seq = attrs.seq;
-                    let attrs: ValidScheduleLA = ValidScheduleLA::from_schedule_la(
-                        attrs,
-                        self.get_started_info()
-                            .as_ref()
-                            .and_then(|x| x.workflow_execution_timeout),
-                    )
-                    .map_err(|e| {
-                        WFMachinesError::Fatal(format!(
-                            "Invalid schedule local activity request (seq {seq}): {e}"
-                        ))
-                    })?;
+                    let attrs: ValidScheduleLA =
+                        ValidScheduleLA::from_schedule_la(attrs).map_err(|e| {
+                            WFMachinesError::Fatal(format!(
+                                "Invalid schedule local activity request (seq {seq}): {e}"
+                            ))
+                        })?;
                     let (la, mach_resp) = new_local_activity(
                         attrs,
                         self.replaying,
                         self.local_activity_data.take_preresolution(seq),
                         self.current_wf_time,
                         self.observed_internal_flags.clone(),
                     )?;
@@ -1083,28 +1103,40 @@
                 WFCommand::RequestCancelActivity(attrs) => {
                     self.process_cancellation(CommandID::Activity(attrs.seq))?;
                 }
                 WFCommand::RequestCancelLocalActivity(attrs) => {
                     self.process_cancellation(CommandID::LocalActivity(attrs.seq))?;
                 }
                 WFCommand::CompleteWorkflow(attrs) => {
-                    self.metrics.wf_completed();
+                    if !self.replaying {
+                        self.metrics.wf_completed();
+                    }
                     self.add_terminal_command(complete_workflow(attrs));
                 }
                 WFCommand::FailWorkflow(attrs) => {
-                    self.metrics.wf_failed();
+                    if !self.replaying {
+                        self.metrics.wf_failed();
+                    }
                     self.add_terminal_command(fail_workflow(attrs));
                 }
                 WFCommand::ContinueAsNew(attrs) => {
-                    self.metrics.wf_continued_as_new();
+                    if !self.replaying {
+                        self.metrics.wf_continued_as_new();
+                    }
                     let attrs = self.augment_continue_as_new_with_current_values(attrs);
-                    self.add_terminal_command(continue_as_new(attrs));
+                    let use_compat = self.determine_use_compatible_flag(
+                        attrs.versioning_intent(),
+                        &attrs.task_queue,
+                    );
+                    self.add_terminal_command(continue_as_new(attrs, use_compat));
                 }
                 WFCommand::CancelWorkflow(attrs) => {
-                    self.metrics.wf_canceled();
+                    if !self.replaying {
+                        self.metrics.wf_canceled();
+                    }
                     self.add_terminal_command(cancel_workflow(attrs));
                 }
                 WFCommand::SetPatchMarker(attrs) => {
                     // Do not create commands for change IDs that we have already created commands
                     // for.
                     let encountered_entry = self.encountered_change_markers.get(&attrs.patch_id);
                     if !matches!(encountered_entry,
@@ -1132,18 +1164,23 @@
                                 },
                             );
                         }
                     }
                 }
                 WFCommand::AddChildWorkflow(attrs) => {
                     let seq = attrs.seq;
+                    let use_compat = self.determine_use_compatible_flag(
+                        attrs.versioning_intent(),
+                        &attrs.task_queue,
+                    );
                     self.add_cmd_to_wf_task(
                         ChildWorkflowMachine::new_scheduled(
                             attrs,
                             self.observed_internal_flags.clone(),
+                            use_compat,
                         ),
                         CommandID::ChildWorkflowStart(seq).into(),
                     );
                 }
                 WFCommand::CancelChild(attrs) => self.process_cancellation(
                     CommandID::ChildWorkflowStart(attrs.child_workflow_seq),
                 )?,
@@ -1285,14 +1322,29 @@
             }
             if attrs.retry_policy.is_none() {
                 attrs.retry_policy = started_info.retry_policy.clone();
             }
         }
         attrs
     }
+
+    /// Given a user's versioning intent for a command and that command's target task queue,
+    /// returns whether or not the command should set the flag for attempting to stick within the
+    /// compatible version set
+    fn determine_use_compatible_flag(&self, intent: VersioningIntent, target_tq: &str) -> bool {
+        match intent {
+            VersioningIntent::Compatible => true,
+            VersioningIntent::Default => false,
+            VersioningIntent::Unspecified => {
+                // If the target TQ is empty, that means use same TQ.
+                // When TQs match, use compat by default
+                target_tq.is_empty() || target_tq == self.task_queue
+            }
+        }
+    }
 }
 
 fn str_to_randomness_seed(run_id: &str) -> u64 {
     // This was originally `DefaultHasher` but that is potentially unstable across Rust releases.
     // This must forever be `SipHasher13` now or we risk breaking history compat.
     let mut s = SipHasher13::new();
     run_id.hash(&mut s);
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_task_state_machine.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_task_state_machine.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/managed_run/managed_wf_test.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/managed_run/managed_wf_test.rs`

 * *Files 2% similar despite different names*

```diff
@@ -57,15 +57,15 @@
 
 #[must_use]
 pub struct ManagedWFFunc {
     mgr: WorkflowManager,
     activation_tx: UnboundedSender<WorkflowActivation>,
     completions_rx: UnboundedReceiver<WorkflowActivationCompletion>,
     completions_sync_tx: crossbeam::channel::Sender<WorkflowActivationCompletion>,
-    future_handle: Option<JoinHandle<WorkflowResult<()>>>,
+    future_handle: Option<JoinHandle<WorkflowResult<Payload>>>,
     was_shutdown: bool,
 }
 
 impl ManagedWFFunc {
     pub fn new(hist: TestHistoryBuilder, func: WorkflowFunction, args: Vec<Payload>) -> Self {
         Self::new_from_update(hist.as_history_update(), func, args)
     }
@@ -89,14 +89,15 @@
         };
         let state_machines = WorkflowMachines::new(
             RunBasics {
                 namespace: "test_namespace".to_string(),
                 workflow_id: "wfid".to_string(),
                 workflow_type: "wftype".to_string(),
                 run_id: "runid".to_string(),
+                task_queue: TEST_Q.to_string(),
                 history: hist,
                 metrics: MetricsContext::no_op(),
                 capabilities: DEFAULT_TEST_CAPABILITIES,
             },
             Box::new(driver).into(),
         );
         let mgr = WorkflowManager::new_from_machines(state_machines);
@@ -171,15 +172,15 @@
         while !next_act.jobs.is_empty() {
             last_act = next_act;
             next_act = self.get_next_activation().await?;
         }
         Ok(last_act)
     }
 
-    pub async fn shutdown(&mut self) -> WorkflowResult<()> {
+    pub async fn shutdown(&mut self) -> WorkflowResult<Payload> {
         self.was_shutdown = true;
         // Send an eviction to ensure wf exits if it has not finished (ex: feeding partial hist)
         let _ = self.activation_tx.send(create_evict_activation(
             "not actually important".to_string(),
             "force shutdown".to_string(),
             EvictionReason::Unspecified,
         ));
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/managed_run.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/managed_run.rs`

 * *Files 1% similar despite different names*

```diff
@@ -1035,21 +1035,34 @@
             self.wfm
                 .notify_of_local_result(LocalResolution::LocalActivity(resolution))?;
         }
         Ok(())
     }
 
     fn reply_to_complete(
-        &self,
+        &mut self,
         outcome: ActivationCompleteOutcome,
         chan: Option<oneshot::Sender<ActivationCompleteResult>>,
     ) {
         if let Some(chan) = chan {
-            chan.send(self.build_activation_complete_result(outcome))
-                .expect("Rcv half of activation reply not dropped");
+            if chan
+                .send(self.build_activation_complete_result(outcome))
+                .is_err()
+            {
+                let warnstr = "The workflow task completer went missing! This likely indicates an \
+                               SDK bug, please report."
+                    .to_string();
+                warn!(run_id=%self.run_id(), "{}", warnstr);
+                self.request_eviction(RequestEvictMsg {
+                    run_id: self.run_id().to_string(),
+                    message: warnstr,
+                    reason: EvictionReason::Fatal,
+                    auto_reply_fail_tt: None,
+                });
+            }
         }
     }
 
     fn build_activation_complete_result(
         &self,
         outcome: ActivationCompleteOutcome,
     ) -> ActivationCompleteResult {
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/mod.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/mod.rs`

 * *Files 2% similar despite different names*

```diff
@@ -19,30 +19,27 @@
 pub(crate) use driven_workflow::{DrivenWorkflow, WorkflowFetcher};
 pub(crate) use history_update::HistoryUpdate;
 #[cfg(test)]
 pub(crate) use managed_run::ManagedWFFunc;
 
 use crate::{
     abstractions::{
-        dbg_panic, stream_when_allowed, take_cell::TakeCell, MeteredSemaphore,
-        TrackedOwnedMeteredSemPermit, UsedMeteredSemPermit,
+        dbg_panic, take_cell::TakeCell, MeteredSemaphore, TrackedOwnedMeteredSemPermit,
+        UsedMeteredSemPermit,
     },
     internal_flags::InternalFlags,
-    protosext::{legacy_query_failure, ValidPollWFTQResponse},
-    telemetry::{
-        metrics::workflow_worker_type, set_trace_subscriber_for_current_thread, TelemetryInstance,
-        VecDisplayer,
-    },
+    protosext::legacy_query_failure,
+    telemetry::{set_trace_subscriber_for_current_thread, TelemetryInstance, VecDisplayer},
     worker::{
         activities::{ActivitiesFromWFTsHandle, LocalActivityManager, TrackedPermittedTqResp},
         client::{WorkerClient, WorkflowTaskCompletion},
         workflow::{
             history_update::HistoryPaginator,
             managed_run::RunUpdateAct,
-            wft_extraction::{HistoryFetchReq, WFTExtractor},
+            wft_extraction::{HistoryFetchReq, WFTExtractor, WFTStreamIn},
             wft_poller::validate_wft,
             workflow_stream::{LocalInput, LocalInputs, WFStream},
         },
         LocalActRequest, LocalActivityExecutionResult, LocalActivityResolution,
         PostActivateHookData,
     },
     MetricsContext,
@@ -123,22 +120,21 @@
     client: Arc<dyn WorkerClient>,
     /// Will be populated when this worker is using a cache and should complete WFTs with a sticky
     /// queue.
     sticky_attrs: Option<StickyExecutionAttributes>,
     /// If set, can be used to reserve activity task slots for eager-return of new activity tasks.
     activity_tasks_handle: Option<ActivitiesFromWFTsHandle>,
     /// Ensures we stay at or below this worker's maximum concurrent workflow task limit
-    wft_semaphore: MeteredSemaphore,
+    wft_semaphore: Arc<MeteredSemaphore>,
     local_act_mgr: Arc<LocalActivityManager>,
     ever_polled: AtomicBool,
 }
 
 pub(crate) struct WorkflowBasics {
     pub max_cached_workflows: usize,
-    pub max_outstanding_wfts: usize,
     pub shutdown_token: CancellationToken,
     pub metrics: MetricsContext,
     pub namespace: String,
     pub task_queue: String,
     pub ignore_evicts_on_shutdown: bool,
     pub fetching_concurrency: usize,
     pub server_capabilities: get_system_info_response::Capabilities,
@@ -147,46 +143,38 @@
 }
 
 pub(crate) struct RunBasics<'a> {
     pub namespace: String,
     pub workflow_id: String,
     pub workflow_type: String,
     pub run_id: String,
+    pub task_queue: String,
     pub history: HistoryUpdate,
     pub metrics: MetricsContext,
     pub capabilities: &'a get_system_info_response::Capabilities,
 }
 
 impl Workflows {
     #[allow(clippy::too_many_arguments)] // Not much worth combining here
     pub(super) fn new(
         basics: WorkflowBasics,
         sticky_attrs: Option<StickyExecutionAttributes>,
         client: Arc<dyn WorkerClient>,
-        wft_stream: impl Stream<Item = Result<ValidPollWFTQResponse, tonic::Status>> + Send + 'static,
+        wft_semaphore: Arc<MeteredSemaphore>,
+        wft_stream: impl Stream<Item = WFTStreamIn> + Send + 'static,
         local_activity_request_sink: impl LocalActivityRequestSink,
         local_act_mgr: Arc<LocalActivityManager>,
         heartbeat_timeout_rx: UnboundedReceiver<HeartbeatTimeoutMsg>,
         activity_tasks_handle: Option<ActivitiesFromWFTsHandle>,
         telem_instance: Option<&TelemetryInstance>,
     ) -> Self {
         let (local_tx, local_rx) = unbounded_channel();
         let (fetch_tx, fetch_rx) = unbounded_channel();
         let shutdown_tok = basics.shutdown_token.clone();
         let task_queue = basics.task_queue.clone();
-        let wft_semaphore = MeteredSemaphore::new(
-            basics.max_outstanding_wfts,
-            basics.metrics.with_new_attrs([workflow_worker_type()]),
-            MetricsContext::available_task_slots,
-        );
-        // Only allow polling of the new WFT stream if there are available task slots
-        let proceeder = stream::unfold(wft_semaphore.clone(), |sem| async move {
-            Some((sem.acquire_owned().await.unwrap(), sem))
-        });
-        let wft_stream = stream_when_allowed(wft_stream, proceeder);
         let extracted_wft_stream = WFTExtractor::build(
             client.clone(),
             basics.fetching_concurrency,
             wft_stream,
             UnboundedReceiverStream::new(fetch_rx),
         );
         let locals_stream = stream::select(
@@ -511,14 +499,18 @@
         self.send_local(GetStateInfoMsg { response_tx: tx });
         async move { rx.await.ok() }
     }
 
     pub(super) fn available_wft_permits(&self) -> usize {
         self.wft_semaphore.available_permits()
     }
+    #[cfg(test)]
+    pub(super) fn unused_wft_permits(&self) -> usize {
+        self.wft_semaphore.unused_permits()
+    }
 
     pub(super) async fn shutdown(&self) -> Result<(), anyhow::Error> {
         if let Some(jh) = self.processing_task.take_once() {
             // This serves to drive the stream if it is still alive and wouldn't otherwise receive
             // another message. It allows it to shut itself down.
             let (waker, stop_waker) = abortable(async {
                 let mut interval = tokio::time::interval(Duration::from_millis(10));
@@ -1231,15 +1223,14 @@
 }
 
 /// Details remembered from the workflow execution started event that we may need to recall later.
 /// Is a subset of `WorkflowExecutionStartedEventAttributes`, but avoids holding on to huge fields.
 #[derive(Debug, Clone)]
 pub struct WorkflowStartedInfo {
     workflow_task_timeout: Option<Duration>,
-    workflow_execution_timeout: Option<Duration>,
     memo: Option<Memo>,
     search_attrs: Option<SearchAttributes>,
     retry_policy: Option<RetryPolicy>,
 }
 
 /// Wraps outgoing activation job protos with some internal details core might care about
 #[derive(Debug, derive_more::Display)]
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/run_cache.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/run_cache.rs`

 * *Files 6% similar despite different names*

```diff
@@ -9,40 +9,43 @@
 use lru::LruCache;
 use std::{mem, num::NonZeroUsize, rc::Rc};
 use temporal_sdk_core_protos::temporal::api::workflowservice::v1::get_system_info_response;
 
 pub(super) struct RunCache {
     max: usize,
     namespace: String,
+    task_queue: String,
     server_capabilities: get_system_info_response::Capabilities,
     /// Run id -> Data
     runs: LruCache<String, ManagedRun>,
     local_activity_request_sink: Rc<dyn LocalActivityRequestSink>,
 
     metrics: MetricsContext,
 }
 
 impl RunCache {
     pub fn new(
         max_cache_size: usize,
         namespace: String,
+        task_queue: String,
         server_capabilities: get_system_info_response::Capabilities,
         local_activity_request_sink: impl LocalActivityRequestSink,
         metrics: MetricsContext,
     ) -> Self {
         // The cache needs room for at least one run, otherwise we couldn't do anything. In
         // "0" size mode, the run is evicted once the workflow task is complete.
         let lru_size = if max_cache_size > 0 {
             max_cache_size
         } else {
             1
         };
         Self {
             max: max_cache_size,
             namespace,
+            task_queue,
             server_capabilities,
             runs: LruCache::new(
                 NonZeroUsize::new(lru_size).expect("LRU size is guaranteed positive"),
             ),
             local_activity_request_sink: Rc::new(local_activity_request_sink),
             metrics,
         }
@@ -68,14 +71,15 @@
         let history_update = mem::replace(&mut pwft.work.update, HistoryUpdate::dummy());
         let mut mrh = ManagedRun::new(
             RunBasics {
                 namespace: self.namespace.clone(),
                 workflow_id: pwft.work.execution.workflow_id.clone(),
                 workflow_type: pwft.work.workflow_type.clone(),
                 run_id: pwft.work.execution.run_id.clone(),
+                task_queue: self.task_queue.clone(),
                 history: history_update,
                 metrics,
                 capabilities: &self.server_capabilities,
             },
             self.local_activity_request_sink.clone(),
         );
         let run_id = run_id.to_string();
@@ -85,14 +89,15 @@
         }
         self.metrics.cache_size(cur_num_cached_runs as u64 + 1);
         rur
     }
     pub fn remove(&mut self, k: &str) -> Option<ManagedRun> {
         let r = self.runs.pop(k);
         self.metrics.cache_size(self.len() as u64);
+        self.metrics.cache_eviction();
         r
     }
 
     pub fn get_mut(&mut self, k: &str) -> Option<&mut ManagedRun> {
         self.runs.get_mut(k)
     }
     pub fn get(&mut self, k: &str) -> Option<&ManagedRun> {
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/wft_extraction.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/wft_extraction.rs`

 * *Files 2% similar despite different names*

```diff
@@ -32,18 +32,15 @@
         run_id: String,
         err: tonic::Status,
         auto_reply_fail_tt: Option<TaskToken>,
     },
     PollerDead,
 }
 
-type WFTStreamIn = (
-    Result<ValidPollWFTQResponse, tonic::Status>,
-    OwnedMeteredSemPermit,
-);
+pub(crate) type WFTStreamIn = Result<(ValidPollWFTQResponse, OwnedMeteredSemPermit), tonic::Status>;
 #[derive(derive_more::From, Debug)]
 pub(super) enum HistoryFetchReq {
     Full(CacheMissFetchReq, Arc<HistfetchRC>),
     NextPage(NextPageReq, Arc<HistfetchRC>),
 }
 /// Used inside of `Arc`s to ensure we don't shutdown while there are outstanding fetches.
 #[derive(Debug)]
@@ -54,19 +51,19 @@
         client: Arc<dyn WorkerClient>,
         max_fetch_concurrency: usize,
         wft_stream: impl Stream<Item = WFTStreamIn> + Send + 'static,
         fetch_stream: impl Stream<Item = HistoryFetchReq> + Send + 'static,
     ) -> impl Stream<Item = Result<WFTExtractorOutput, tonic::Status>> + Send + 'static {
         let fetch_client = client.clone();
         let wft_stream = wft_stream
-            .map(move |(wft, permit)| {
+            .map(move |stream_in| {
                 let client = client.clone();
                 async move {
-                    match wft {
-                        Ok(wft) => {
+                    match stream_in {
+                        Ok((wft, permit)) => {
                             let run_id = wft.workflow_execution.run_id.clone();
                             let tt = wft.task_token.clone();
                             Ok(match HistoryPaginator::from_poll(wft, client).await {
                                 Ok((pag, prep)) => WFTExtractorOutput::NewWFT(PermittedWFT {
                                     work: prep,
                                     permit: permit.into_used(),
                                     paginator: pag,
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/wft_poller.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/wft_poller.rs`

 * *Files 23% similar despite different names*

```diff
@@ -1,19 +1,24 @@
-use crate::{pollers::BoxedWFPoller, protosext::ValidPollWFTQResponse, MetricsContext};
+use crate::{
+    abstractions::OwnedMeteredSemPermit,
+    pollers::{BoxedWFPoller, Poller},
+    protosext::ValidPollWFTQResponse,
+    MetricsContext,
+};
 use futures::{stream, Stream};
 use temporal_sdk_core_protos::temporal::api::workflowservice::v1::PollWorkflowTaskQueueResponse;
 
 pub(crate) fn new_wft_poller(
     poller: BoxedWFPoller,
     metrics: MetricsContext,
-) -> impl Stream<Item = Result<ValidPollWFTQResponse, tonic::Status>> {
+) -> impl Stream<Item = Result<(ValidPollWFTQResponse, OwnedMeteredSemPermit), tonic::Status>> {
     stream::unfold((poller, metrics), |(poller, metrics)| async move {
         loop {
             return match poller.poll().await {
-                Some(Ok(wft)) => {
+                Some(Ok((wft, permit))) => {
                     if wft == PollWorkflowTaskQueueResponse::default() {
                         // We get the default proto in the event that the long poll times out.
                         debug!("Poll wft timeout");
                         metrics.wf_tq_poll_empty();
                         continue;
                     }
                     if let Some(dur) = wft.sched_to_start() {
@@ -23,23 +28,28 @@
                         Ok(w) => w,
                         Err(e) => {
                             error!(error=?e, "Server returned an unparseable workflow task");
                             continue;
                         }
                     };
                     metrics.wf_tq_poll_ok();
-                    Some((Ok(work), (poller, metrics)))
+                    Some((Ok((work, permit)), (poller, metrics)))
                 }
                 Some(Err(e)) => {
                     warn!(error=?e, "Error while polling for workflow tasks");
                     Some((Err(e), (poller, metrics)))
                 }
                 // If poller returns None, it's dead, thus we also return None to terminate this
                 // stream.
-                None => None,
+                None => {
+                    // Make sure we call the actual shutdown function here to propagate any panics
+                    // inside the polling tasks as errors.
+                    poller.shutdown_box().await;
+                    None
+                }
             };
         }
     })
 }
 
 pub(crate) fn validate_wft(
     wft: PollWorkflowTaskQueueResponse,
@@ -51,35 +61,55 @@
         )
     })
 }
 
 #[cfg(test)]
 mod tests {
     use super::*;
-    use crate::test_help::mock_poller;
+    use crate::{
+        abstractions::MeteredSemaphore, pollers::MockPermittedPollBuffer, test_help::mock_poller,
+    };
     use futures::{pin_mut, StreamExt};
+    use std::sync::Arc;
 
     #[tokio::test]
     async fn poll_timeouts_do_not_produce_responses() {
         let mut mock_poller = mock_poller();
         mock_poller
             .expect_poll()
             .times(1)
             .returning(|| Some(Ok(PollWorkflowTaskQueueResponse::default())));
         mock_poller.expect_poll().times(1).returning(|| None);
-        let stream = new_wft_poller(Box::new(mock_poller), MetricsContext::no_op());
+        mock_poller.expect_shutdown().times(1).returning(|| ());
+        let sem = Arc::new(MeteredSemaphore::new(
+            10,
+            MetricsContext::no_op(),
+            MetricsContext::available_task_slots,
+        ));
+        let stream = new_wft_poller(
+            Box::new(MockPermittedPollBuffer::new(sem, mock_poller)),
+            MetricsContext::no_op(),
+        );
         pin_mut!(stream);
         assert_matches!(stream.next().await, None);
     }
 
     #[tokio::test]
     async fn poll_errors_do_produce_responses() {
         let mut mock_poller = mock_poller();
         mock_poller
             .expect_poll()
             .times(1)
             .returning(|| Some(Err(tonic::Status::internal("ahhh"))));
-        let stream = new_wft_poller(Box::new(mock_poller), MetricsContext::no_op());
+        let sem = Arc::new(MeteredSemaphore::new(
+            10,
+            MetricsContext::no_op(),
+            MetricsContext::available_task_slots,
+        ));
+        let stream = new_wft_poller(
+            Box::new(MockPermittedPollBuffer::new(sem, mock_poller)),
+            MetricsContext::no_op(),
+        );
         pin_mut!(stream);
         assert_matches!(stream.next().await, Some(Err(_)));
     }
 }
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/workflow_stream/saved_wf_inputs.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/workflow_stream/saved_wf_inputs.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/workflow_stream.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core/src/worker/workflow/workflow_stream.rs`

 * *Files 0% similar despite different names*

```diff
@@ -93,14 +93,15 @@
         local_activity_request_sink: impl LocalActivityRequestSink,
     ) -> impl Stream<Item = Result<WFStreamOutput, PollWfError>> {
         let mut state = WFStream {
             buffered_polls_need_cache_slot: Default::default(),
             runs: RunCache::new(
                 basics.max_cached_workflows,
                 basics.namespace.clone(),
+                basics.task_queue.clone(),
                 basics.server_capabilities.clone(),
                 local_activity_request_sink,
                 basics.metrics.clone(),
             ),
             shutdown_token: basics.shutdown_token,
             ignore_evicts_on_shutdown: basics.ignore_evicts_on_shutdown,
             metrics: basics.metrics,
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/Cargo.toml` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core-api/Cargo.toml`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/LICENSE.txt` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core-api/LICENSE.txt`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/src/errors.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core-api/src/errors.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/src/lib.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core-api/src/lib.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/src/telemetry.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core-api/src/telemetry.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/src/worker.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/core-api/src/worker.rs`

 * *Files 17% similar despite different names*

```diff
@@ -1,10 +1,13 @@
 use std::time::Duration;
 use tokio::sync::mpsc::UnboundedSender;
 
+const MAX_OUTSTANDING_WFT_DEFAULT: usize = 100;
+const MAX_CONCURRENT_WFT_POLLS_DEFAULT: usize = 5;
+
 /// Defines per-worker configuration options
 #[derive(Debug, Clone, derive_builder::Builder, serde::Serialize, serde::Deserialize)]
 #[builder(setter(into), build_fn(validate = "Self::validate"))]
 #[non_exhaustive]
 pub struct WorkerConfig {
     /// The Temporal service namespace this worker is bound to
     pub namespace: String,
@@ -27,27 +30,27 @@
     #[builder(default = "0")]
     pub max_cached_workflows: usize,
     /// The maximum allowed number of workflow tasks that will ever be given to this worker at one
     /// time. Note that one workflow task may require multiple activations - so the WFT counts as
     /// "outstanding" until all activations it requires have been completed.
     ///
     /// Cannot be larger than `max_cached_workflows`.
-    #[builder(default = "100")]
+    #[builder(default = "MAX_OUTSTANDING_WFT_DEFAULT")]
     pub max_outstanding_workflow_tasks: usize,
     /// The maximum number of activity tasks that will ever be given to this worker concurrently
     #[builder(default = "100")]
     pub max_outstanding_activities: usize,
     /// The maximum number of local activity tasks that will ever be given to this worker
     /// concurrently
     #[builder(default = "100")]
     pub max_outstanding_local_activities: usize,
     /// Maximum number of concurrent poll workflow task requests we will perform at a time on this
     /// worker's task queue. See also [WorkerConfig::nonsticky_to_sticky_poll_ratio]. Must be at
     /// least 1.
-    #[builder(default = "5")]
+    #[builder(default = "MAX_CONCURRENT_WFT_POLLS_DEFAULT")]
     pub max_concurrent_wft_polls: usize,
     /// [WorkerConfig::max_concurrent_wft_polls] * this number = the number of max pollers that will
     /// be allowed for the nonsticky queue when sticky tasks are enabled. If both defaults are used,
     /// the sticky queue will allow 4 max pollers while the nonsticky queue will allow one. The
     /// minimum for either poller is 1, so if `max_concurrent_wft_polls` is 1 and sticky queues are
     /// enabled, there will be 2 concurrent polls.
     #[builder(default = "0.2")]
@@ -157,10 +160,48 @@
         if let Some(Some(ref x)) = self.max_worker_activities_per_second {
             if !x.is_normal() || x.is_sign_negative() {
                 return Err(
                     "`max_worker_activities_per_second` must be positive and nonzero".to_owned(),
                 );
             }
         }
+        if matches!(self.max_concurrent_wft_polls, Some(1))
+            && self.max_cached_workflows > Some(0)
+            && self
+                .max_outstanding_workflow_tasks
+                .unwrap_or(MAX_OUTSTANDING_WFT_DEFAULT)
+                <= 1
+        {
+            return Err(
+                "`max_outstanding_workflow_tasks` must be at at least 2 when \
+                 `max_cached_workflows` is nonzero"
+                    .to_owned(),
+            );
+        }
+        if self
+            .max_concurrent_wft_polls
+            .unwrap_or(MAX_CONCURRENT_WFT_POLLS_DEFAULT)
+            > self
+                .max_outstanding_workflow_tasks
+                .unwrap_or(MAX_OUTSTANDING_WFT_DEFAULT)
+        {
+            return Err(
+                "`max_concurrent_wft_polls` cannot exceed `max_outstanding_workflow_tasks`"
+                    .to_owned(),
+            );
+        }
+
+        if self.use_worker_versioning.unwrap_or_default()
+            && self
+                .worker_build_id
+                .as_ref()
+                .map(|s| s.is_empty())
+                .unwrap_or_default()
+        {
+            return Err(
+                "`worker_build_id` must be non-empty when `use_worker_versioning` is true"
+                    .to_owned(),
+            );
+        }
         Ok(())
     }
 }
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/etc/deps.svg` & `temporalio-1.3.0/temporalio/bridge/sdk-core/etc/deps.svg`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/etc/otel-collector-config.yaml` & `temporalio-1.3.0/temporalio/bridge/sdk-core/etc/otel-collector-config.yaml`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/Cargo.toml` & `temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/Cargo.toml`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/LICENSE.txt` & `temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/LICENSE.txt`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/Cargo.toml` & `temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/Cargo.toml`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/LICENSE.txt` & `temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/LICENSE.txt`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/src/lib.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/src/lib.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/dynamic_dest_pass.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/dynamic_dest_pass.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/handler_arg_pass.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/handler_arg_pass.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/handler_pass.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/handler_pass.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/medium_complex_pass.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/medium_complex_pass.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/no_handle_conversions_require_into_fail.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/no_handle_conversions_require_into_fail.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/no_handle_conversions_require_into_fail.stderr` & `temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/no_handle_conversions_require_into_fail.stderr`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/simple_pass.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/simple_pass.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_trait/LICENSE.txt` & `temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_trait/LICENSE.txt`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_trait/src/lib.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/fsm/rustfsm_trait/src/lib.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/histories/ends_empty_wft_complete.bin` & `temporalio-1.3.0/temporalio/bridge/sdk-core/histories/ends_empty_wft_complete.bin`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/histories/evict_while_la_running_no_interference-16_history.bin` & `temporalio-1.3.0/temporalio/bridge/sdk-core/histories/evict_while_la_running_no_interference-16_history.bin`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/histories/evict_while_la_running_no_interference-23_history.bin` & `temporalio-1.3.0/temporalio/bridge/sdk-core/histories/evict_while_la_running_no_interference-23_history.bin`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/histories/evict_while_la_running_no_interference-85_history.bin` & `temporalio-1.3.0/temporalio/bridge/sdk-core/histories/evict_while_la_running_no_interference-85_history.bin`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/histories/fail_wf_task.bin` & `temporalio-1.3.0/temporalio/bridge/sdk-core/histories/fail_wf_task.bin`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/histories/old_change_marker_format.bin` & `temporalio-1.3.0/temporalio/bridge/sdk-core/histories/old_change_marker_format.bin`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/histories/timer_workflow_history.bin` & `temporalio-1.3.0/temporalio/bridge/sdk-core/histories/timer_workflow_history.bin`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/.github/workflows/publish-docs.yml` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/.github/workflows/publish-docs.yml`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/.github/workflows/trigger-api-go-update.yml` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/.github/workflows/trigger-api-go-update.yml`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/LICENSE` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/LICENSE`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/Makefile` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/Makefile`

 * *Files 1% similar despite different names*

```diff
@@ -25,15 +25,15 @@
 PROTO_OUT := .gen
 PROTO_IMPORTS = -I=$(PROTO_ROOT) -I=$(shell go list -modfile build/go.mod -m -f '{{.Dir}}' github.com/temporalio/gogo-protobuf)/protobuf
 
 $(PROTO_OUT):
 	mkdir $(PROTO_OUT)
 
 ##### Compile proto files for go #####
-grpc: buf-lint api-linter gogo-grpc fix-path
+grpc: buf-lint api-linter buf-breaking gogo-grpc fix-path
 
 go-grpc: clean $(PROTO_OUT)
 	printf $(COLOR) "Compile for go-gRPC..."
 	$(foreach PROTO_DIR,$(PROTO_DIRS),protoc --fatal_warnings $(PROTO_IMPORTS) --go_out=plugins=grpc,paths=source_relative:$(PROTO_OUT) $(PROTO_DIR)*.proto;)
 
 gogo-grpc: clean $(PROTO_OUT)
 	printf $(COLOR) "Compile for gogo-gRPC..."
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/api-linter.yaml` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/api-linter.yaml`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/build/tools.go` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/build/tools.go`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/dependencies/gogoproto/gogo.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/dependencies/gogoproto/gogo.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/batch/v1/message.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/batch/v1/message.proto`

 * *Files 14% similar despite different names*

```diff
@@ -33,14 +33,15 @@
 
 import "dependencies/gogoproto/gogo.proto";
 import "google/protobuf/timestamp.proto";
 
 
 import "temporal/api/common/v1/message.proto";
 import "temporal/api/enums/v1/batch_operation.proto";
+import "temporal/api/enums/v1/reset.proto";
 
 message BatchOperationInfo {
   // Batch job ID
   string job_id = 1;
   // Batch operation state
   temporal.api.enums.v1.BatchOperationState state = 2;
   // Batch operation start time
@@ -82,8 +83,19 @@
 }
 
 // BatchOperationDeletion sends deletion requests to batch workflows.
 // Keep the parameter in sync with temporal.api.workflowservice.v1.DeleteWorkflowExecutionRequest.
 message BatchOperationDeletion {
   // The identity of the worker/client
   string identity = 1;
+}
+
+// BatchOperationReset sends reset requests to batch workflows.
+// Keep the parameter in sync with temporal.api.workflowservice.v1.ResetWorkflowExecutionRequest.
+message BatchOperationReset {
+  // Reset type.
+  temporal.api.enums.v1.ResetType reset_type = 1; 
+  // History event reapply options.
+  temporal.api.enums.v1.ResetReapplyType reset_reapply_type = 2; 
+  // The identity of the worker/client.
+  string identity = 3;
 }
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/command/v1/message.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/command/v1/message.proto`

 * *Files 3% similar despite different names*

```diff
@@ -79,14 +79,18 @@
     // Activities are provided by a default retry policy which is controlled through the service's
     // dynamic configuration. Retries will be attempted until `schedule_to_close_timeout` has
     // elapsed. To disable retries set retry_policy.maximum_attempts to 1.
     temporal.api.common.v1.RetryPolicy retry_policy = 11;
     // Request to start the activity directly bypassing matching service and worker polling
     // The slot for executing the activity should be reserved when setting this field to true.
     bool request_eager_execution = 12;
+    // If this is set, the workflow executing this command wishes to start the activity using
+    // a version compatible with the version that this workflow most recently ran on, if such
+    // behavior is possible.
+    bool use_compatible_version = 13;
 }
 
 message RequestCancelActivityTaskCommandAttributes {
     // The `ACTIVITY_TASK_SCHEDULED` event id for the activity being cancelled.
     int64 scheduled_event_id = 1;
 }
 
@@ -187,14 +191,17 @@
     // Should be removed
     temporal.api.common.v1.Payloads last_completion_result = 10;
     // Should be removed. Not necessarily unused but unclear and not exposed by SDKs.
     string cron_schedule = 11;
     temporal.api.common.v1.Header header = 12;
     temporal.api.common.v1.Memo memo = 13;
     temporal.api.common.v1.SearchAttributes search_attributes = 14;
+    // If this is set, the workflow executing this command wishes to continue as new using a version
+    // compatible with the version that this workflow most recently ran on.
+    bool use_compatible_version = 15;
 
     // `workflow_execution_timeout` is omitted as it shouldn't be overridden from within a workflow.
 }
 
 message StartChildWorkflowExecutionCommandAttributes {
     string namespace = 1;
     string workflow_id = 2;
@@ -214,14 +221,18 @@
     temporal.api.enums.v1.WorkflowIdReusePolicy workflow_id_reuse_policy = 11;
     temporal.api.common.v1.RetryPolicy retry_policy = 12;
     // Establish a cron schedule for the child workflow.
     string cron_schedule = 13;
     temporal.api.common.v1.Header header = 14;
     temporal.api.common.v1.Memo memo = 15;
     temporal.api.common.v1.SearchAttributes search_attributes = 16;
+    // If this is set, the workflow executing this command wishes to start the child workflow using
+    // a version compatible with the version that this workflow most recently ran on, if such
+    // behavior is possible.
+    bool use_compatible_version = 17;
 }
 
 message ProtocolMessageCommandAttributes {
     // The message ID of the message to which this command is a pointer.
     string message_id = 1;
 }
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/common/v1/message.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/common/v1/message.proto`

 * *Files 5% similar despite different names*

```diff
@@ -120,21 +120,32 @@
     // (-- api-linter: core::0141::forbidden-types=disabled
     //     aip.dev/not-precedent: Negative values make no sense to represent. --)
     uint32 nonfirst_local_activity_execution_attempts = 13;
 }
 
 // Identifies the version(s) of a worker that processed a task
 message WorkerVersionStamp {
-    // An opaque whole-worker identifier
+    // An opaque whole-worker identifier. Replaces the deprecated `binary_checksum` field when this
+    // message is included in requests which previously used that.
     string build_id = 1;
     // Set if the worker used a dynamically loadable bundle to process
     // the task. The bundle could be a WASM blob, JS bundle, etc.
     string bundle_id = 2;
+
+    // If set, the worker is opting in to worker versioning. Otherwise, this is used only as a
+    // marker for workflow reset points and the BuildIDs search attribute.
+    bool use_versioning = 3;
 }
 
-// Identifies the version(s) that a worker is compatible with when polling or identifying itself
+// Identifies the version(s) that a worker is compatible with when polling or identifying itself,
+// and whether or not this worker is opting into the build-id based versioning feature. This is
+// used by matching to determine which workers ought to receive what tasks.
 message WorkerVersionCapabilities {
     // An opaque whole-worker identifier
     string build_id = 1;
 
+    // If set, the worker is opting in to worker versioning, and wishes to only receive appropriate
+    // tasks.
+    bool use_versioning = 2;
+
     // Later, may include info like "I can process WASM and/or JS bundles"
 }
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/batch_operation.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/batch_operation.proto`

 * *Files 4% similar despite different names*

```diff
@@ -33,14 +33,15 @@
 
 enum BatchOperationType {
   BATCH_OPERATION_TYPE_UNSPECIFIED = 0;
   BATCH_OPERATION_TYPE_TERMINATE = 1;
   BATCH_OPERATION_TYPE_CANCEL = 2;
   BATCH_OPERATION_TYPE_SIGNAL = 3;
   BATCH_OPERATION_TYPE_DELETE = 4;
+  BATCH_OPERATION_TYPE_RESET = 5;
 }
 
 enum BatchOperationState {
   BATCH_OPERATION_STATE_UNSPECIFIED = 0;
   BATCH_OPERATION_STATE_RUNNING = 1;
   BATCH_OPERATION_STATE_COMPLETED = 2;
   BATCH_OPERATION_STATE_FAILED = 3;
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/command_type.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/command_type.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/common.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/common.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/event_type.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/event_type.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/failed_cause.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/failed_cause.proto`

 * *Files 1% similar despite different names*

```diff
@@ -118,8 +118,10 @@
     RESOURCE_EXHAUSTED_CAUSE_RPS_LIMIT = 1;
     // Caller exceeds max concurrent request limit.
     RESOURCE_EXHAUSTED_CAUSE_CONCURRENT_LIMIT = 2;
     // System overloaded.
     RESOURCE_EXHAUSTED_CAUSE_SYSTEM_OVERLOADED = 3;
     // Namespace exceeds persistence rate limit.
     RESOURCE_EXHAUSTED_CAUSE_PERSISTENCE_LIMIT = 4;
+    // Workflow is busy
+    RESOURCE_EXHAUSTED_CAUSE_BUSY_WORKFLOW = 5;
 }
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/namespace.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/namespace.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/query.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/query.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/reset.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/reset.proto`

 * *Files 14% similar despite different names*

```diff
@@ -35,7 +35,16 @@
 // * RESET_REAPPLY_TYPE_SIGNAL (default) - Signals are reapplied when workflow is reset
 // * RESET_REAPPLY_TYPE_NONE - nothing is reapplied
 enum ResetReapplyType {
     RESET_REAPPLY_TYPE_UNSPECIFIED = 0;
     RESET_REAPPLY_TYPE_SIGNAL = 1;
     RESET_REAPPLY_TYPE_NONE = 2;
 }
+
+// Reset type options
+enum ResetType { 
+    RESET_TYPE_UNSPECIFIED = 0;
+    // Resets to event of the first workflow task completed, or if it does not exist, the event after task scheduled.
+    RESET_TYPE_FIRST_WORKFLOW_TASK = 1;
+    // Resets to event of the last workflow task completed, or if it does not exist, the event after task scheduled.
+    RESET_TYPE_LAST_WORKFLOW_TASK = 2;
+}
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/schedule.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/schedule.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/task_queue.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/query/v1/message.proto`

 * *Files 27% similar despite different names*

```diff
@@ -18,42 +18,44 @@
 // AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 // LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 // OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 // THE SOFTWARE.
 
 syntax = "proto3";
 
-package temporal.api.enums.v1;
+package temporal.api.query.v1;
 
-option go_package = "go.temporal.io/api/enums/v1;enums";
-option java_package = "io.temporal.api.enums.v1";
+option go_package = "go.temporal.io/api/query/v1;query";
+option java_package = "io.temporal.api.query.v1";
 option java_multiple_files = true;
-option java_outer_classname = "TaskQueueProto";
-option ruby_package = "Temporalio::Api::Enums::V1";
-option csharp_namespace = "Temporalio.Api.Enums.V1";
-
-enum TaskQueueKind {
-    TASK_QUEUE_KIND_UNSPECIFIED = 0;
-    // Tasks from a normal workflow task queue always include complete workflow history
-    //
-    // The task queue specified by the user is always a normal task queue. There can be as many
-    // workers as desired for a single normal task queue. All those workers may pick up tasks from
-    // that queue.
-    TASK_QUEUE_KIND_NORMAL = 1;
-    // A sticky queue only includes new history since the last workflow task, and they are
-    // per-worker.
-    //
-    // Sticky queues are created dynamically by each worker during their start up. They only exist
-    // for the lifetime of the worker process. Tasks in a sticky task queue are only available to
-    // the worker that created the sticky queue.
-    //
-    // Sticky queues are only for workflow tasks. There are no sticky task queues for activities.
-    TASK_QUEUE_KIND_STICKY = 2;
+option java_outer_classname = "MessageProto";
+option ruby_package = "Temporalio::Api::Query::V1";
+option csharp_namespace = "Temporalio.Api.Query.V1";
+
+import "temporal/api/enums/v1/query.proto";
+import "temporal/api/enums/v1/workflow.proto";
+import "temporal/api/common/v1/message.proto";
+
+// See https://docs.temporal.io/docs/concepts/queries/
+message WorkflowQuery {
+    // The workflow-author-defined identifier of the query. Typically a function name.
+    string query_type = 1;
+    // Serialized arguments that will be provided to the query handler.
+    temporal.api.common.v1.Payloads query_args = 2;
+    // Headers that were passed by the caller of the query and copied by temporal 
+    // server into the workflow task.
+    temporal.api.common.v1.Header header = 3;
+}
+
+// Answer to a `WorkflowQuery`
+message WorkflowQueryResult {
+    // Did the query succeed or fail?
+    temporal.api.enums.v1.QueryResultType result_type = 1;
+    // Set when the query succeeds with the results
+    temporal.api.common.v1.Payloads answer = 2;
+    // Mutually exclusive with `answer`. Set when the query fails.
+    string error_message = 3;
 }
 
-enum TaskQueueType {
-    TASK_QUEUE_TYPE_UNSPECIFIED = 0;
-    // Workflow type of task queue.
-    TASK_QUEUE_TYPE_WORKFLOW = 1;
-    // Activity type of task queue.
-    TASK_QUEUE_TYPE_ACTIVITY = 2;
+message QueryRejected {
+    temporal.api.enums.v1.WorkflowExecutionStatus status = 1;
 }
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/update.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/update.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/workflow.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/workflow.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/errordetails/v1/message.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/errordetails/v1/message.proto`

 * *Files 2% similar despite different names*

```diff
@@ -102,7 +102,12 @@
     temporal.api.common.v1.WorkflowExecution workflow_execution = 1;
     // Serialized error returned by the system workflow performing the underlying operation.
     string workflow_error = 2;
 }
 
 message WorkflowNotReadyFailure {
 }
+
+message NewerBuildExistsFailure {
+    // The current default compatible build ID which will receive tasks
+    string default_build_id = 1;
+}
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/failure/v1/message.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/failure/v1/message.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/filter/v1/message.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/filter/v1/message.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/history/v1/message.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/history/v1/message.proto`

 * *Files 2% similar despite different names*

```diff
@@ -96,14 +96,19 @@
     temporal.api.common.v1.SearchAttributes search_attributes = 23;
     temporal.api.workflow.v1.ResetPoints prev_auto_reset_points = 24;
     temporal.api.common.v1.Header header = 25;
     // Version of the child execution initiated event in parent workflow
     // It should be used together with parent_initiated_event_id to identify
     // a child initiated event for global namespace
     int64 parent_initiated_event_version = 26;
+    // This field is new in 1.21.
+    string workflow_id = 28;
+    // If this workflow intends to use anything other than the current overall default version for
+    // the queue, then we include it here.
+    temporal.api.common.v1.WorkerVersionStamp source_version_stamp = 29;
 }
 
 message WorkflowExecutionCompletedEventAttributes {
     // Serialized result of workflow completion (ie: The return value of the workflow function)
     temporal.api.common.v1.Payloads result = 1;
     // The `WORKFLOW_TASK_COMPLETED` event which this command was reported with
     int64 workflow_task_completed_event_id = 2;
@@ -148,14 +153,17 @@
     // and sdk) the final event will be `WORKFLOW_EXECUTION_FAILED` with `new_execution_run_id` set.
     temporal.api.failure.v1.Failure failure = 10;
     // TODO: Is this the result of *this* workflow as it continued-as-new?
     temporal.api.common.v1.Payloads last_completion_result = 11;
     temporal.api.common.v1.Header header = 12;
     temporal.api.common.v1.Memo memo = 13;
     temporal.api.common.v1.SearchAttributes search_attributes = 14;
+    // If this is set, the workflow executing this command wishes to continue as new using a version
+    // compatible with the version that this workflow most recently ran on.
+    bool use_compatible_version = 15;
 
     // workflow_execution_timeout is omitted as it shouldn't be overridden from within a workflow.
 }
 
 message WorkflowTaskScheduledEventAttributes {
     // The task queue this workflow task was enqueued in, which could be a normal or sticky queue
     temporal.api.taskqueue.v1.TaskQueue task_queue = 1;
@@ -189,21 +197,22 @@
     int64 scheduled_event_id = 1;
     // The id of the `WORKFLOW_TASK_STARTED` event this task corresponds to
     int64 started_event_id = 2;
     // Identity of the worker who completed this task
     string identity = 3;
     // Binary ID of the worker who completed this task
     string binary_checksum = 4;
-    // Version info of the worker who processed this workflow task, or missing if worker is not
-    // using versioning. If present, the `build_id` field within is also used as `binary_checksum`,
-    // which may be omitted in that case (it may also be populated to preserve compatibility).
+    // Version info of the worker who processed this workflow task. If present, the `build_id` field
+    // within is also used as `binary_checksum`, which may be omitted in that case (it may also be
+    // populated to preserve compatibility).
     temporal.api.common.v1.WorkerVersionStamp worker_version = 5;
     // Data the SDK wishes to record for itself, but server need not interpret, and does not
     // directly impact workflow state.
     temporal.api.sdk.v1.WorkflowTaskCompletedMetadata sdk_metadata = 6;
+
     // Local usage data sent during workflow task completion and recorded here for posterity
     temporal.api.common.v1.MeteringMetadata metering_metadata = 13;
 }
 
 message WorkflowTaskTimedOutEventAttributes {
     // The id of the `WORKFLOW_TASK_SCHEDULED` event this task corresponds to
     int64 scheduled_event_id = 1;
@@ -224,16 +233,21 @@
     string identity = 5;
     // The original run id of the workflow. For reset workflow.
     string base_run_id = 6;
     // If the workflow is being reset, the new run id.
     string new_run_id = 7;
     // TODO: ?
     int64 fork_event_version = 8;
-    // If a worker explicitly failed this task, it's binary id
+    // DEPRECATED since 1.21 - use `worker_version` instead.
+    // If a worker explicitly failed this task, its binary id
     string binary_checksum = 9;
+    // Version info of the worker who processed this workflow task. If present, the `build_id` field
+    // within is also used as `binary_checksum`, which may be omitted in that case (it may also be
+    // populated to preserve compatibility).
+    temporal.api.common.v1.WorkerVersionStamp worker_version = 10;
 }
 
 message ActivityTaskScheduledEventAttributes {
     // The worker/user assigned identifier for the activity
     string activity_id = 1;
     temporal.api.common.v1.ActivityType activity_type = 2;
     // This used to be a `namespace` field which allowed to schedule activity in another namespace.
@@ -266,14 +280,18 @@
     google.protobuf.Duration heartbeat_timeout = 10 [(gogoproto.stdduration) = true];
     // The `WORKFLOW_TASK_COMPLETED` event which this command was reported with
     int64 workflow_task_completed_event_id = 11;
     // Activities are assigned a default retry policy controlled by the service's dynamic
     // configuration. Retries will happen up to `schedule_to_close_timeout`. To disable retries set
     // retry_policy.maximum_attempts to 1.
     temporal.api.common.v1.RetryPolicy retry_policy = 12;
+    // If this is set, the workflow executing this command wishes to start the activity using
+    // a version compatible with the version that this workflow most recently ran on, if such
+    // behavior is possible.
+    bool use_compatible_version = 13;
 }
 
 message ActivityTaskStartedEventAttributes {
     // The id of the `ACTIVITY_TASK_SCHEDULED` event this task corresponds to
     int64 scheduled_event_id = 1;
     // id of the worker that picked up this task
     string identity = 2;
@@ -291,26 +309,30 @@
     temporal.api.common.v1.Payloads result = 1;
     // The id of the `ACTIVITY_TASK_SCHEDULED` event this completion corresponds to
     int64 scheduled_event_id = 2;
     // The id of the `ACTIVITY_TASK_STARTED` event this completion corresponds to
     int64 started_event_id = 3;
     // id of the worker that completed this task
     string identity = 4;
+    // Version info of the worker who processed this workflow task.
+    temporal.api.common.v1.WorkerVersionStamp worker_version = 5;
 }
 
 message ActivityTaskFailedEventAttributes {
     // Failure details
     temporal.api.failure.v1.Failure failure = 1;
     // The id of the `ACTIVITY_TASK_SCHEDULED` event this failure corresponds to
     int64 scheduled_event_id = 2;
     // The id of the `ACTIVITY_TASK_STARTED` event this failure corresponds to
     int64 started_event_id = 3;
     // id of the worker that failed this task
     string identity = 4;
     temporal.api.enums.v1.RetryState retry_state = 5;
+    // Version info of the worker who processed this workflow task.
+    temporal.api.common.v1.WorkerVersionStamp worker_version = 6;
 }
 
 message ActivityTaskTimedOutEventAttributes {
     // If this activity had failed, was retried, and then timed out, that failure is stored as the
     // `cause` in here.
     temporal.api.failure.v1.Failure failure = 1;
     // The id of the `ACTIVITY_TASK_SCHEDULED` event this timeout corresponds to
@@ -335,14 +357,16 @@
     int64 latest_cancel_requested_event_id = 2;
     // The id of the `ACTIVITY_TASK_SCHEDULED` event this cancel confirmation corresponds to
     int64 scheduled_event_id = 3;
     // The id of the `ACTIVITY_TASK_STARTED` event this cancel confirmation corresponds to
     int64 started_event_id = 4;
     // id of the worker who canceled this activity
     string identity = 5;
+    // Version info of the worker who processed this workflow task.
+    temporal.api.common.v1.WorkerVersionStamp worker_version = 6;
 }
 
 message TimerStartedEventAttributes {
     // The worker/user assigned id for this timer
     string timer_id = 1;
     // How long until this timer fires
     //
@@ -552,14 +576,18 @@
     temporal.api.enums.v1.WorkflowIdReusePolicy workflow_id_reuse_policy = 12;
     temporal.api.common.v1.RetryPolicy retry_policy = 13;
     // If this child runs on a cron schedule, it will appear here
     string cron_schedule = 14;
     temporal.api.common.v1.Header header = 15;
     temporal.api.common.v1.Memo memo = 16;
     temporal.api.common.v1.SearchAttributes search_attributes = 17;
+    // If this is set, the workflow executing this command wishes to start the child workflow using
+    // a version compatible with the version that this workflow most recently ran on, if such
+    // behavior is possible.
+    bool use_compatible_version = 19;
 }
 
 message StartChildWorkflowExecutionFailedEventAttributes {
     // Namespace of the child workflow.
     // SDKs and UI tools should use `namespace` field but server must use `namespace_id` only.
     string namespace = 1;
     string namespace_id = 8;
@@ -693,14 +721,18 @@
     // update.
     temporal.api.update.v1.Request accepted_request = 4;
 }
 
 message WorkflowExecutionUpdateCompletedEventAttributes {
     // The metadata about this update.
     temporal.api.update.v1.Meta meta = 1;
+
+    // The event ID indicating the acceptance of this update.
+    int64 accepted_event_id = 3;
+
     // The outcome of executing the workflow update function.
     temporal.api.update.v1.Outcome outcome = 2;
 }
 
 message WorkflowExecutionUpdateRejectedEventAttributes {
     // The instance ID of the update protocol that generated this event.
     string protocol_instance_id = 1;
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/namespace/v1/message.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/namespace/v1/message.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/operatorservice/v1/request_response.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/operatorservice/v1/request_response.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/operatorservice/v1/service.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/operatorservice/v1/service.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/protocol/v1/message.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/protocol/v1/message.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/query/v1/message.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/replication/v1/message.proto`

 * *Files 22% similar despite different names*

```diff
@@ -18,44 +18,38 @@
 // AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 // LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 // OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 // THE SOFTWARE.
 
 syntax = "proto3";
 
-package temporal.api.query.v1;
+package temporal.api.replication.v1;
 
-option go_package = "go.temporal.io/api/query/v1;query";
-option java_package = "io.temporal.api.query.v1";
+option go_package = "go.temporal.io/api/replication/v1;replication";
+option java_package = "io.temporal.api.replication.v1";
 option java_multiple_files = true;
 option java_outer_classname = "MessageProto";
-option ruby_package = "Temporalio::Api::Query::V1";
-option csharp_namespace = "Temporalio.Api.Query.V1";
+option ruby_package = "Temporalio::Api::Replication::V1";
+option csharp_namespace = "Temporalio.Api.Replication.V1";
 
-import "temporal/api/enums/v1/query.proto";
-import "temporal/api/enums/v1/workflow.proto";
-import "temporal/api/common/v1/message.proto";
-
-// See https://docs.temporal.io/docs/concepts/queries/
-message WorkflowQuery {
-    // The workflow-author-defined identifier of the query. Typically a function name.
-    string query_type = 1;
-    // Serialized arguments that will be provided to the query handler.
-    temporal.api.common.v1.Payloads query_args = 2;
-    // Headers that were passed by the caller of the query and copied by temporal 
-    // server into the workflow task.
-    temporal.api.common.v1.Header header = 3;
+import "google/protobuf/timestamp.proto";
+
+import "dependencies/gogoproto/gogo.proto";
+
+import "temporal/api/enums/v1/namespace.proto";
+
+message ClusterReplicationConfig {
+    string cluster_name = 1;
 }
 
-// Answer to a `WorkflowQuery`
-message WorkflowQueryResult {
-    // Did the query succeed or fail?
-    temporal.api.enums.v1.QueryResultType result_type = 1;
-    // Set when the query succeeds with the results
-    temporal.api.common.v1.Payloads answer = 2;
-    // Mutually exclusive with `answer`. Set when the query fails.
-    string error_message = 3;
+message NamespaceReplicationConfig {
+    string active_cluster_name = 1;
+    repeated ClusterReplicationConfig clusters = 2;
+    temporal.api.enums.v1.ReplicationState state = 3;
 }
 
-message QueryRejected {
-    temporal.api.enums.v1.WorkflowExecutionStatus status = 1;
+// Represents a historical replication status of a Namespace
+message FailoverStatus {
+    // Timestamp when the Cluster switched to the following failover_version
+    google.protobuf.Timestamp failover_time = 1 [(gogoproto.stdtime) = true];
+    int64 failover_version = 2;
 }
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/replication/v1/message.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/temporal/api/testservice/v1/request_response.proto`

 * *Files 23% similar despite different names*

```diff
@@ -18,38 +18,46 @@
 // AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 // LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 // OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 // THE SOFTWARE.
 
 syntax = "proto3";
 
-package temporal.api.replication.v1;
+package temporal.api.testservice.v1;
 
-option go_package = "go.temporal.io/api/replication/v1;replication";
-option java_package = "io.temporal.api.replication.v1";
+option go_package = "go.temporal.io/api/testservice/v1;testservice";
+option java_package = "io.temporal.api.testservice.v1";
 option java_multiple_files = true;
-option java_outer_classname = "MessageProto";
-option ruby_package = "Temporalio::Api::Replication::V1";
-option csharp_namespace = "Temporalio.Api.Replication.V1";
+option java_outer_classname = "RequestResponseProto";
+option ruby_package = "Temporalio::Api::TestService::V1";
+option csharp_namespace = "Temporalio.Api.TestService.V1";
 
+import "google/protobuf/duration.proto";
 import "google/protobuf/timestamp.proto";
-
 import "dependencies/gogoproto/gogo.proto";
 
-import "temporal/api/enums/v1/namespace.proto";
+message LockTimeSkippingRequest {
+}
 
-message ClusterReplicationConfig {
-    string cluster_name = 1;
+message LockTimeSkippingResponse {
 }
 
-message NamespaceReplicationConfig {
-    string active_cluster_name = 1;
-    repeated ClusterReplicationConfig clusters = 2;
-    temporal.api.enums.v1.ReplicationState state = 3;
+message UnlockTimeSkippingRequest {
 }
 
-// Represents a historical replication status of a Namespace
-message FailoverStatus {
-    // Timestamp when the Cluster switched to the following failover_version
-    google.protobuf.Timestamp failover_time = 1 [(gogoproto.stdtime) = true];
-    int64 failover_version = 2;
+message UnlockTimeSkippingResponse {
 }
+
+message SleepUntilRequest {
+    google.protobuf.Timestamp timestamp = 1 [(gogoproto.stdtime) = true];
+}
+
+message SleepRequest {
+    google.protobuf.Duration duration = 1 [(gogoproto.stdduration) = true];
+}
+
+message SleepResponse {
+}
+
+message GetCurrentTimeResponse {
+    google.protobuf.Timestamp time = 1 [(gogoproto.stdtime) = true];
+}
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/schedule/v1/message.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/schedule/v1/message.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/sdk/v1/task_complete_metadata.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/sdk/v1/task_complete_metadata.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/taskqueue/v1/message.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/taskqueue/v1/message.proto`

 * *Files 18% similar despite different names*

```diff
@@ -41,14 +41,17 @@
 import "temporal/api/common/v1/message.proto";
 
 // See https://docs.temporal.io/docs/concepts/task-queues/
 message TaskQueue {
     string name = 1;
     // Default: TASK_QUEUE_KIND_NORMAL.
     temporal.api.enums.v1.TaskQueueKind kind = 2;
+    // Iff kind == TASK_QUEUE_KIND_STICKY, then this field contains the name of
+    // the normal task queue that the sticky worker is running on.
+    string normal_name = 3;
 }
 
 // Only applies to activity task queues
 message TaskQueueMetadata {
     // Allows throttling dispatch of tasks from this queue
     google.protobuf.DoubleValue max_tasks_per_second = 1;
 }
@@ -83,16 +86,30 @@
 message StickyExecutionAttributes {
     TaskQueue worker_task_queue = 1;
     // (-- api-linter: core::0140::prepositions=disabled
     //     aip.dev/not-precedent: "to" is used to indicate interval. --)
     google.protobuf.Duration schedule_to_start_timeout = 2 [(gogoproto.stdduration) = true];
 }
 
-// Used by the worker versioning APIs, represents an ordering of one or more versions which are
-// considered to be compatible with each other. Currently the versions are always worker build ids.
+// Used by the worker versioning APIs, represents an unordered set of one or more versions which are
+// considered to be compatible with each other. Currently the versions are always worker build IDs.
 message CompatibleVersionSet {
-    // A unique identifier for this version set. Users don't need to understand or care about this
-    // value, but it has value for debugging purposes.
-    string version_set_id = 1;
-    // All the compatible versions, ordered from oldest to newest
-    repeated string build_ids = 2;
+    // All the compatible versions, unordered, except for the last element, which is considered the set "default".
+    repeated string build_ids = 1;
+}
+
+// Reachability of tasks for a worker on a single task queue.
+message TaskQueueReachability {
+    string task_queue = 1;
+    // Task reachability for a worker in a single task queue.
+    // See the TaskReachability docstring for information about each enum variant.
+    // If reachability is empty, this worker is considered unreachable in this task queue.
+    repeated temporal.api.enums.v1.TaskReachability reachability = 2;
+}
+
+// Reachability of tasks for a worker by build id, in one or more task queues.
+message BuildIdReachability {
+    // A build id or empty if unversioned.
+    string build_id = 1;
+    // Reachability per task queue.
+    repeated TaskQueueReachability task_queue_reachability = 2;
 }
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/update/v1/message.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/update/v1/message.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/version/v1/message.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/version/v1/message.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflow/v1/message.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflow/v1/message.proto`

 * *Files 2% similar despite different names*

```diff
@@ -105,16 +105,20 @@
 }
 
 message ResetPoints {
     repeated ResetPointInfo points = 1;
 }
 
 message ResetPointInfo {
+    // A worker binary version identifier, will be deprecated and superseded by a newer concept of
+    // build_id.
     string binary_checksum = 1;
+    // The first run ID in the execution chain that was touched by this worker build.
     string run_id = 2;
+    // Event ID of the first WorkflowTaskCompleted event processed by this worker build.
     int64 first_workflow_task_completed_id = 3;
     google.protobuf.Timestamp create_time = 4 [(gogoproto.stdtime) = true];
     // (-- api-linter: core::0214::resource-expiry=disabled
     //     aip.dev/not-precedent: TTL is not defined for ResetPointInfo. --)
     // The time that the run is deleted due to retention.
     google.protobuf.Timestamp expire_time = 5 [(gogoproto.stdtime) = true];
     // false if the reset point has pending childWFs/reqCancels/signalExternals.
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflowservice/v1/request_response.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflowservice/v1/request_response.proto`

 * *Files 4% similar despite different names*

```diff
@@ -234,22 +234,20 @@
 }
 
 message PollWorkflowTaskQueueRequest {
     string namespace = 1;
     temporal.api.taskqueue.v1.TaskQueue task_queue = 2;
     // The identity of the worker/client who is polling this task queue
     string identity = 3;
+    // DEPRECATED since 1.21 - use `worker_version_capabilities` instead.
     // Each worker process should provide an ID unique to the specific set of code it is running
     // "checksum" in this field name isn't very accurate, it should be though of as an id.
     string binary_checksum = 4;
-    // If set, the worker is opting in to versioning and wishes to only
-    // receive tasks that are considered compatible with the version capabilities provided.
-    // Doing so only makes sense in conjunction with the `UpdateWorkerBuildIdCompatibility` API.
-    // When this field has a `worker_build_id`, and `binary_checksum` is not
-    // set, that value should also be considered as the `binary_checksum`.
+    // Information about this worker's build identifier and if it is choosing to use the versioning
+    // feature. See the `WorkerVersionCapabilities` docstring for more.
     temporal.api.common.v1.WorkerVersionCapabilities worker_version_capabilities = 5;
 }
 
 message PollWorkflowTaskQueueResponse {
     // A unique identifier for this task
     bytes task_token = 1;
     temporal.api.common.v1.WorkflowExecution workflow_execution = 2;
@@ -305,24 +303,23 @@
     // this completion. This can save on polling round-trips.
     bool return_new_workflow_task = 5;
     // Can be used to *force* creation of a new workflow task, even if no commands have resolved or
     // one would not otherwise have been generated. This is used when the worker knows it is doing
     // something useful, but cannot complete it within the workflow task timeout. Local activities
     // which run for longer than the task timeout being the prime example.
     bool force_create_new_workflow_task = 6;
+    // DEPRECATED since 1.21 - use `worker_version_stamp` instead.
     // Worker process' unique binary id
     string binary_checksum = 7;
     // Responses to the `queries` field in the task being responded to
     map<string, temporal.api.query.v1.WorkflowQueryResult> query_results = 8;
     string namespace = 9;
-    // If using versioning, the worker uses this field to indicate what version(s) it used to
-    // process the task. When this field has a `worker_build_id`, and `binary_checksum` is not set,
-    // that value should also be considered as the `binary_checksum`. Leaving this field empty when
-    // replying to a task has had this field previously populated in history in an error, and such
-    // a completion will be rejected.
+    // Version info of the worker who processed this task. This message's `build_id` field should
+    // always be set by SDKs. Workers opting into versioning will also set the `use_versioning`
+    // field to true. See message docstrings for more.
     temporal.api.common.v1.WorkerVersionStamp worker_version_stamp = 10;
     // Protocol messages piggybacking on a WFT as a transport
     repeated temporal.api.protocol.v1.Message messages = 11;
     // Data the SDK wishes to record for itself, but server need not interpret, and does not
     // directly impact workflow state.
     temporal.api.sdk.v1.WorkflowTaskCompletedMetadata sdk_metadata = 12;
     // Local usage data collected for metering
@@ -344,33 +341,37 @@
     // Why did the task fail? It's important to note that many of the variants in this enum cannot
     // apply to worker responses. See the type's doc for more.
     temporal.api.enums.v1.WorkflowTaskFailedCause cause = 2;
     // Failure details
     temporal.api.failure.v1.Failure failure = 3;
     // The identity of the worker/client
     string identity = 4;
+    // DEPRECATED since 1.21 - use `worker_version_stamp` instead.
     // Worker process' unique binary id
     string binary_checksum = 5;
     string namespace = 6;
     // Protocol messages piggybacking on a WFT as a transport
     repeated temporal.api.protocol.v1.Message messages = 7;
+    // Version info of the worker who processed this task. This message's `build_id` field should
+    // always be set by SDKs. Workers opting into versioning will also set the `use_versioning`
+    // field to true. See message docstrings for more.
+    temporal.api.common.v1.WorkerVersionStamp worker_version = 8;
 }
 
 message RespondWorkflowTaskFailedResponse {
 }
 
 message PollActivityTaskQueueRequest {
     string namespace = 1;
     temporal.api.taskqueue.v1.TaskQueue task_queue = 2;
     // The identity of the worker/client
     string identity = 3;
     temporal.api.taskqueue.v1.TaskQueueMetadata task_queue_metadata = 4;
-    // If set, the worker is opting in to versioning and wishes to only
-    // receive tasks that are considered compatible with the capabilities provided.
-    // Doing so only makes sense in conjunction with the `UpdateWorkerBuildIdCompatibility` API.
+    // Information about this worker's build identifier and if it is choosing to use the versioning
+    // feature. See the `WorkerVersionCapabilities` docstring for more.
     temporal.api.common.v1.WorkerVersionCapabilities worker_version_capabilities = 5;
 }
 
 message PollActivityTaskQueueResponse {
     // A unique identifier for this task
     bytes task_token = 1;
     // The namespace the workflow which requested this activity lives in
@@ -459,14 +460,18 @@
     // The task token as received in `PollActivityTaskQueueResponse`
     bytes task_token = 1;
     // The result of successfully executing the activity
     temporal.api.common.v1.Payloads result = 2;
     // The identity of the worker/client
     string identity = 3;
     string namespace = 4;
+    // Version info of the worker who processed this task. This message's `build_id` field should
+    // always be set by SDKs. Workers opting into versioning will also set the `use_versioning`
+    // field to true. See message docstrings for more.
+    temporal.api.common.v1.WorkerVersionStamp worker_version = 5;
 }
 
 message RespondActivityTaskCompletedResponse {
 }
 
 message RespondActivityTaskCompletedByIdRequest {
     // Namespace of the workflow which scheduled this activity
@@ -492,14 +497,18 @@
     // Detailed failure information
     temporal.api.failure.v1.Failure failure = 2;
     // The identity of the worker/client
     string identity = 3;
     string namespace = 4;
     // Additional details to be stored as last activity heartbeat
     temporal.api.common.v1.Payloads last_heartbeat_details = 5;
+    // Version info of the worker who processed this task. This message's `build_id` field should
+    // always be set by SDKs. Workers opting into versioning will also set the `use_versioning`
+    // field to true. See message docstrings for more.
+    temporal.api.common.v1.WorkerVersionStamp worker_version = 6;
 }
 
 message RespondActivityTaskFailedResponse {
     // Server validation failures could include
     // last_heartbeat_details payload is too large, request failure is too large
     repeated temporal.api.failure.v1.Failure failures = 1;
 }
@@ -531,14 +540,18 @@
     // The task token as received in `PollActivityTaskQueueResponse`
     bytes task_token = 1;
     // Serialized additional information to attach to the cancellation
     temporal.api.common.v1.Payloads details = 2;
     // The identity of the worker/client
     string identity = 3;
     string namespace = 4;
+    // Version info of the worker who processed this task. This message's `build_id` field should
+    // always be set by SDKs. Workers opting into versioning will also set the `use_versioning`
+    // field to true. See message docstrings for more.
+    temporal.api.common.v1.WorkerVersionStamp worker_version = 5;
 }
 
 message RespondActivityTaskCanceledResponse {
 }
 
 message RespondActivityTaskCanceledByIdRequest {
     // Namespace of the workflow which scheduled this activity
@@ -1067,14 +1080,21 @@
         string existing_compatible_build_id = 2;
         // When set, establishes the compatible set being targeted as the overall default for the
         // queue. If a different set was the current default, the targeted set will replace it as
         // the new default.
         bool make_set_default = 3;
     }
 
+    message MergeSets {
+        // A build ID in the set whose default will become the merged set default
+        string primary_set_build_id = 1;
+        // A build ID in the set which will be merged into the primary set
+        string secondary_set_build_id = 2;
+    }
+
     string namespace = 1;
     // Must be set, the task queue to apply changes to. Because all workers on a given task queue
     // must have the same set of workflow & activity implementations, there is no reason to specify
     // a task queue type here.
     string task_queue = 2;
     oneof operation {
         // A new build id. This operation will create a new set which will be the new overall
@@ -1093,14 +1113,20 @@
         //     aip.dev/not-precedent: Names are hard. --)
         string promote_set_by_build_id = 5;
         // Promote an existing build id within some set to be the current default for that set.
         //
         // (-- api-linter: core::0140::prepositions=disabled
         //     aip.dev/not-precedent: Within makes perfect sense here. --)
         string promote_build_id_within_set = 6;
+        // Merge two existing sets together, thus declaring all build IDs in both sets compatible
+        // with one another. The primary set's default will become the default for the merged set.
+        // This is useful if you've accidentally declared a new ID as incompatible you meant to
+        // declare as compatible. The unusual case of incomplete replication during failover could
+        // also result in a split set, which this operation can repair.
+        MergeSets merge_sets = 7;
     }
 }
 message UpdateWorkerBuildIdCompatibilityResponse {
     // The id of the compatible set that the updated version was added to, or exists in. Users don't
     // need to understand or care about this value, but it has value for debugging purposes.
     string version_set_id = 1;
 }
@@ -1110,54 +1136,59 @@
 message GetWorkerBuildIdCompatibilityRequest {
     string namespace = 1;
     // Must be set, the task queue to interrogate about worker id compatibility.
     string task_queue = 2;
     // Limits how many compatible sets will be returned. Specify 1 to only return the current
     // default major version set. 0 returns all sets.
     int32 max_sets = 3;
-    // If set, the response will include information about worker versions which are ready to be
-    // retired.
-    bool include_retirement_candidates = 4;
-    // If set, the response will include information about which versions have open workflows, and
-    // whether or not there are currently polling workers who are compatible with those versions.
-    bool include_poller_compatibility = 5;
 }
 message GetWorkerBuildIdCompatibilityResponse {
     // Major version sets, in order from oldest to newest. The last element of the list will always
     // be the current default major version. IE: New workflows will target the most recent version
     // in that version set.
     //
     // There may be fewer sets returned than exist, if the request chose to limit this response.
     repeated temporal.api.taskqueue.v1.CompatibleVersionSet major_version_sets = 1;
+}
 
-    message RetirementCandidate {
-        // The worker build id which is ready for retirement
-        string build_id = 1;
-        // If true, there are no open *or* closed workflows, meaning there is no reason at all
-        // to keep the worker alive, not even to service queries on closed workflows. If not true,
-        // then there are no open workflows, but some closed ones.
-        bool all_workflows_are_archived = 2;
-        // Currently polling workers who match the build id ready for retirement
-        repeated temporal.api.taskqueue.v1.PollerInfo pollers = 3;
-    }
-
-    // A list of workers who are still live and polling the task queue, but may no longer be needed
-    // to make progress on open workflows.
-    repeated RetirementCandidate retirement_candidates = 2;
-
-    message VersionsWithCompatiblePollers {
-        // The latest build id which completed a workflow task on some open workflow
-        string most_recent_build_id = 1;
-        // Currently polling workers who are compatible with `most_recent_build_id`.
-        repeated temporal.api.taskqueue.v1.PollerInfo pollers = 2;
-    }
-
-    // A list of versions and pollers who are capable of processing tasks at that version (if any)
-    // for which there are currently open workflows.
-    repeated VersionsWithCompatiblePollers active_versions_and_pollers = 3;
+message GetWorkerTaskReachabilityRequest {
+    string namespace = 1;
+    // Build ids to retrieve reachability for. An empty string will be interpreted as an unversioned worker.
+    // The number of build ids that can be queried in a single API call is limited.
+    // Open source users can adjust this limit by setting the server's dynamic config value for
+    // `limit.reachabilityQueryBuildIds` with the caveat that this call can strain the visibility store.
+    repeated string build_ids = 2;
+
+    // Task queues to retrieve reachability for. Leave this empty to query for all task queues associated with given
+    // build ids in the namespace.
+    // Must specify at least one task queue if querying for an unversioned worker.
+    // The number of task queues that the server will fetch reachability information for is limited.
+    // See the `GetWorkerTaskReachabilityResponse` documentation for more information.
+    repeated string task_queues = 3;
+
+    // Type of reachability to query for.
+    // `TASK_REACHABILITY_NEW_WORKFLOWS` is always returned in the response.
+    // Use `TASK_REACHABILITY_EXISTING_WORKFLOWS` if your application needs to respond to queries on closed workflows.
+    // Otherwise, use `TASK_REACHABILITY_OPEN_WORKFLOWS`. Default is `TASK_REACHABILITY_EXISTING_WORKFLOWS` if left
+    // unspecified.
+    // See the TaskReachability docstring for information about each enum variant.
+    temporal.api.enums.v1.TaskReachability reachability = 4;
+}
+
+message GetWorkerTaskReachabilityResponse {
+    // Task reachability, broken down by build id and then task queue.
+    // When requesting a large number of task queues or all task queues associated with the given build ids in a
+    // namespace, all task queues will be listed in the response but some of them may not contain reachability
+    // information due to a server enforced limit. When reaching the limit, task queues that reachability information
+    // could not be retrieved for will be marked with a single TASK_REACHABILITY_UNSPECIFIED entry. The caller may issue
+    // another call to get the reachability for those task queues.
+    //
+    // Open source users can adjust this limit by setting the server's dynamic config value for
+    // `limit.reachabilityTaskQueueScan` with the caveat that this call can strain the visibility store.
+    repeated temporal.api.taskqueue.v1.BuildIdReachability build_id_reachability = 1;
 }
 
 // (-- api-linter: core::0134=disabled
 //     aip.dev/not-precedent: Update RPCs don't follow Google API format. --)
 message UpdateWorkflowExecutionRequest {
     // The namespace name of the target workflow
     string namespace = 1;
@@ -1204,14 +1235,15 @@
     repeated temporal.api.common.v1.WorkflowExecution executions = 5;
     // Operation input
     oneof operation {
         temporal.api.batch.v1.BatchOperationTermination termination_operation = 10;
         temporal.api.batch.v1.BatchOperationSignal signal_operation = 11;
         temporal.api.batch.v1.BatchOperationCancellation cancellation_operation = 12;
         temporal.api.batch.v1.BatchOperationDeletion deletion_operation = 13;
+        temporal.api.batch.v1.BatchOperationReset reset_operation = 14;
     }
 }
 
 message StartBatchOperationResponse {
 }
 
 message StopBatchOperationRequest {
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflowservice/v1/service.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflowservice/v1/service.proto`

 * *Files 5% similar despite different names*

```diff
@@ -381,22 +381,44 @@
     }
 
     // Allows users to specify sets of worker build id versions on a per task queue basis. Versions
     // are ordered, and may be either compatible with some extant version, or a new incompatible
     // version, forming sets of ids which are incompatible with each other, but whose contained
     // members are compatible with one another.
     //
+    // A single build id may be mapped to multiple task queues using this API for cases where a single process hosts
+    // multiple workers. 
+    // 
+    // To query which workers can be retired, use the `GetWorkerTaskReachability` API.
+    //
+    // NOTE: The number of task queues mapped to a single build id is limited by the `limit.taskQueuesPerBuildId`
+    // (default is 20), if this limit is exceeded this API will error with a FailedPrecondition.
+    //
     // (-- api-linter: core::0134::response-message-name=disabled
     //     aip.dev/not-precedent: UpdateWorkerBuildIdCompatibility RPC doesn't follow Google API format. --)
     // (-- api-linter: core::0134::method-signature=disabled
     //     aip.dev/not-precedent: UpdateWorkerBuildIdCompatibility RPC doesn't follow Google API format. --)
     rpc UpdateWorkerBuildIdCompatibility (UpdateWorkerBuildIdCompatibilityRequest) returns (UpdateWorkerBuildIdCompatibilityResponse) {}
-    // Fetches the worker build id versioning sets for some task queue and related metadata.
+    // Fetches the worker build id versioning sets for a task queue.
     rpc GetWorkerBuildIdCompatibility (GetWorkerBuildIdCompatibilityRequest) returns (GetWorkerBuildIdCompatibilityResponse) {}
 
+    // Fetches task reachability to determine whether a worker may be retired.
+    // The request may specify task queues to query for or let the server fetch all task queues mapped to the given
+    // build IDs.
+    //
+    // When requesting a large number of task queues or all task queues associated with the given build ids in a
+    // namespace, all task queues will be listed in the response but some of them may not contain reachability
+    // information due to a server enforced limit. When reaching the limit, task queues that reachability information
+    // could not be retrieved for will be marked with a single TASK_REACHABILITY_UNSPECIFIED entry. The caller may issue
+    // another call to get the reachability for those task queues.
+    //
+    // Open source users can adjust this limit by setting the server's dynamic config value for
+    // `limit.reachabilityTaskQueueScan` with the caveat that this call can strain the visibility store.
+    rpc GetWorkerTaskReachability (GetWorkerTaskReachabilityRequest) returns (GetWorkerTaskReachabilityResponse) {}
+
     // Invokes the specified update function on user workflow code.
     // (-- api-linter: core::0134=disabled
     //     aip.dev/not-precedent: UpdateWorkflowExecution doesn't follow Google API format --)
     rpc UpdateWorkflowExecution(UpdateWorkflowExecutionRequest) returns (UpdateWorkflowExecutionResponse) {
     }
 
     // Polls a workflow execution for the outcome of a workflow execution update
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/grpc/health/v1/health.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/grpc/health/v1/health.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/activity_result/activity_result.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/activity_result/activity_result.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/activity_task/activity_task.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/activity_task/activity_task.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/child_workflow/child_workflow.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/child_workflow/child_workflow.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/core_interface.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/core_interface.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/external_data/external_data.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/external_data/external_data.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_activation/workflow_activation.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_activation/workflow_activation.proto`

 * *Files 2% similar despite different names*

```diff
@@ -31,14 +31,18 @@
     uint32 history_length = 4;
     // The things to do upon activating the workflow
     repeated WorkflowActivationJob jobs = 5;
     // Internal flags which are available for use by lang. If `is_replaying` is false, all
     // internal flags may be used. This is not a delta - all previously used flags always
     // appear since this representation is cheap.
     repeated uint32 available_internal_flags = 6;
+    // The history size in bytes as of the last WFT started event
+    uint64 history_size_bytes = 7;
+    // Set true if the most recent WFT started event had this suggestion
+    bool continue_as_new_suggested = 8;
 }
 
 message WorkflowActivationJob {
     oneof variant {
         // Begin a workflow for the first time
         StartWorkflow start_workflow = 1;
         // A timer has fired, allowing whatever was waiting on it (if anything) to proceed
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_commands/workflow_commands.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_commands/workflow_commands.proto`

 * *Files 2% similar despite different names*

```diff
@@ -80,14 +80,16 @@
     temporal.api.common.v1.RetryPolicy retry_policy = 12;
     // Defines how the workflow will wait (or not) for cancellation of the activity to be confirmed
     ActivityCancellationType cancellation_type = 13;
     // If set, the worker will not tell the service that it can immediately start executing this
     // activity. When unset/default, workers will always attempt to do so if activity execution
     // slots are available.
     bool do_not_eagerly_execute = 14;
+    // Whether this activity should run on a worker with a compatible build id or not.
+    coresdk.common.VersioningIntent versioning_intent = 15;
 }
 
 message ScheduleLocalActivity {
     // Lang's incremental sequence number, used as the operation identifier
     uint32 seq = 1;
     string activity_id = 2;
     string activity_type = 3;
@@ -194,14 +196,16 @@
     map<string, temporal.api.common.v1.Payload> headers = 7;
     // If set, the new workflow will have these search attributes. If unset, re-uses the current
     // workflow's search attributes.
     map<string, temporal.api.common.v1.Payload> search_attributes = 8;
     // If set, the new workflow will have this retry policy. If unset, re-uses the current
     // workflow's retry policy.
     temporal.api.common.v1.RetryPolicy retry_policy = 9;
+    // Whether the continued workflow should run on a worker with a compatible build id or not.
+    coresdk.common.VersioningIntent versioning_intent = 10;
 }
 
 // Indicate a workflow has completed as cancelled. Generally sent as a response to an activation
 // containing a cancellation job.
 message CancelWorkflowExecution {}
 
 // A request to set/check if a certain patch is present or not
@@ -241,14 +245,16 @@
     map<string, temporal.api.common.v1.Payload> headers = 15;
     // Memo fields
     map<string, temporal.api.common.v1.Payload> memo = 16;
     // Search attributes
     map<string, temporal.api.common.v1.Payload> search_attributes = 17;
     // Defines behaviour of the underlying workflow when child workflow cancellation has been requested.
     child_workflow.ChildWorkflowCancellationType cancellation_type = 18;
+    // Whether this child should run on a worker with a compatible build id or not.
+    coresdk.common.VersioningIntent versioning_intent = 19;
 }
 
 // Cancel a child workflow
 message CancelChildWorkflowExecution {
     // Sequence number as given to the `StartChildWorkflowExecution` command
     uint32 child_workflow_seq = 1;
 }
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_completion/workflow_completion.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_completion/workflow_completion.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/Makefile` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/Makefile`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/api-linter.yaml` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/api-linter.yaml`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/dependencies/gogoproto/gogo.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/dependencies/gogoproto/gogo.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/temporal/api/testservice/v1/service.proto` & `temporalio-1.3.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/temporal/api/testservice/v1/service.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/Cargo.toml` & `temporalio-1.3.0/temporalio/bridge/sdk-core/sdk/Cargo.toml`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/LICENSE.txt` & `temporalio-1.3.0/temporalio/bridge/sdk-core/sdk/LICENSE.txt`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/activity_context.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/sdk/src/activity_context.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/app_data.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/sdk/src/app_data.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/interceptors.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/sdk/src/interceptors.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/lib.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/sdk/src/lib.rs`

 * *Files 2% similar despite different names*

```diff
@@ -61,14 +61,15 @@
 use crate::{
     interceptors::WorkerInterceptor,
     workflow_context::{ChildWfCommon, PendingChildWorkflow},
 };
 use anyhow::{anyhow, bail, Context};
 use app_data::AppData;
 use futures::{future::BoxFuture, FutureExt, StreamExt, TryFutureExt, TryStreamExt};
+use serde::Serialize;
 use std::{
     any::{Any, TypeId},
     cell::RefCell,
     collections::HashMap,
     fmt::{Debug, Display, Formatter},
     future::Future,
     panic::AssertUnwindSafe,
@@ -143,15 +144,15 @@
     workflow_fns: RefCell<HashMap<String, WorkflowFunction>>,
 }
 struct WorkflowData {
     /// Channel used to send the workflow activations
     activation_chan: UnboundedSender<WorkflowActivation>,
 }
 
-struct WorkflowFutureHandle<F: Future<Output = Result<WorkflowResult<()>, JoinError>>> {
+struct WorkflowFutureHandle<F: Future<Output = Result<WorkflowResult<Payload>, JoinError>>> {
     join_handle: F,
     run_id: String,
 }
 
 struct ActivityHalf {
     /// Maps activity type to the function for executing activities of that type
     activity_fns: HashMap<String, ActivityFunction>,
@@ -189,18 +190,18 @@
     pub fn shutdown_handle(&self) -> impl Fn() {
         let w = self.common.worker.clone();
         move || w.initiate_shutdown()
     }
 
     /// Register a Workflow function to invoke when the Worker is asked to run a workflow of
     /// `workflow_type`
-    pub fn register_wf<F: Into<WorkflowFunction>>(
+    pub fn register_wf(
         &mut self,
         workflow_type: impl Into<String>,
-        wf_function: F,
+        wf_function: impl Into<WorkflowFunction>,
     ) {
         self.workflow_half
             .workflow_fns
             .get_mut()
             .insert(workflow_type.into(), wf_function.into());
     }
 
@@ -379,15 +380,17 @@
     fn workflow_activation_handler(
         &self,
         common: &CommonWorker,
         shutdown_token: CancellationToken,
         activation: WorkflowActivation,
         completions_tx: &UnboundedSender<WorkflowActivationCompletion>,
     ) -> Result<
-        Option<WorkflowFutureHandle<impl Future<Output = Result<WorkflowResult<()>, JoinError>>>>,
+        Option<
+            WorkflowFutureHandle<impl Future<Output = Result<WorkflowResult<Payload>, JoinError>>>,
+        >,
         anyhow::Error,
     > {
         let mut res = None;
         let run_id = activation.run_id.clone();
 
         // If the activation is to start a workflow, create a new workflow driver for it,
         // using the function associated with that workflow id
@@ -690,40 +693,58 @@
 }
 
 struct CommandSubscribeChildWorkflowCompletion {
     seq: u32,
     unblocker: oneshot::Sender<UnblockEvent>,
 }
 
-type WfFunc = dyn Fn(WfContext) -> BoxFuture<'static, WorkflowResult<()>> + Send + Sync + 'static;
+type WfFunc = dyn Fn(WfContext) -> BoxFuture<'static, Result<WfExitValue<Payload>, anyhow::Error>>
+    + Send
+    + Sync
+    + 'static;
 
 /// The user's async function / workflow code
 pub struct WorkflowFunction {
     wf_func: Box<WfFunc>,
 }
 
-impl<F, Fut> From<F> for WorkflowFunction
+impl<F, Fut, O> From<F> for WorkflowFunction
 where
     F: Fn(WfContext) -> Fut + Send + Sync + 'static,
-    Fut: Future<Output = WorkflowResult<()>> + Send + 'static,
+    Fut: Future<Output = Result<WfExitValue<O>, anyhow::Error>> + Send + 'static,
+    O: Serialize + Debug,
 {
     fn from(wf_func: F) -> Self {
         Self::new(wf_func)
     }
 }
 
 impl WorkflowFunction {
     /// Build a workflow function from a closure or function pointer which accepts a [WfContext]
-    pub fn new<F, Fut>(wf_func: F) -> Self
+    pub fn new<F, Fut, O>(f: F) -> Self
     where
         F: Fn(WfContext) -> Fut + Send + Sync + 'static,
-        Fut: Future<Output = WorkflowResult<()>> + Send + 'static,
+        Fut: Future<Output = Result<WfExitValue<O>, anyhow::Error>> + Send + 'static,
+        O: Serialize + Debug,
     {
         Self {
-            wf_func: Box::new(move |ctx: WfContext| wf_func(ctx).boxed()),
+            wf_func: Box::new(move |ctx: WfContext| {
+                (f)(ctx)
+                    .map(|r| {
+                        r.and_then(|r| {
+                            Ok(match r {
+                                WfExitValue::ContinueAsNew(b) => WfExitValue::ContinueAsNew(b),
+                                WfExitValue::Cancelled => WfExitValue::Cancelled,
+                                WfExitValue::Evicted => WfExitValue::Evicted,
+                                WfExitValue::Normal(o) => WfExitValue::Normal(o.as_json_payload()?),
+                            })
+                        })
+                    })
+                    .boxed()
+            }),
         }
     }
 }
 
 /// The result of running a workflow
 pub type WorkflowResult<T> = Result<WfExitValue<T>, anyhow::Error>;
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/payload_converter.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/sdk/src/payload_converter.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/workflow_context/options.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/sdk/src/workflow_context/options.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/workflow_context.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/sdk/src/workflow_context.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/workflow_future.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/sdk/src/workflow_future.rs`

 * *Files 1% similar despite different names*

```diff
@@ -46,15 +46,15 @@
     pub fn start_workflow(
         &self,
         namespace: String,
         task_queue: String,
         args: Vec<Payload>,
         outgoing_completions: UnboundedSender<WorkflowActivationCompletion>,
     ) -> (
-        impl Future<Output = WorkflowResult<()>>,
+        impl Future<Output = WorkflowResult<Payload>>,
         UnboundedSender<WorkflowActivation>,
     ) {
         let (cancel_tx, cancel_rx) = watch::channel(false);
         let (wf_context, cmd_receiver) = WfContext::new(namespace, task_queue, args, cancel_rx);
         let (tx, incoming_activations) = unbounded_channel();
         (
             WorkflowFuture {
@@ -89,15 +89,15 @@
 enum SigChanOrBuffer {
     Chan(UnboundedSender<SignalData>),
     Buffer(Vec<SignalData>),
 }
 
 pub struct WorkflowFuture {
     /// Future produced by calling the workflow function
-    inner: BoxFuture<'static, WorkflowResult<()>>,
+    inner: BoxFuture<'static, WorkflowResult<Payload>>,
     /// Commands produced inside user's wf code
     incoming_commands: Receiver<RustWfCmd>,
     /// Once blocked or the workflow has finished or errored out, the result is sent here
     outgoing_completions: UnboundedSender<WorkflowActivationCompletion>,
     /// Activations from core
     incoming_activations: UnboundedReceiver<WorkflowActivation>,
     /// Commands by ID -> blocked status
@@ -230,15 +230,15 @@
         }
 
         Ok(false)
     }
 }
 
 impl Future for WorkflowFuture {
-    type Output = WorkflowResult<()>;
+    type Output = WorkflowResult<Payload>;
 
     fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
         'activations: loop {
             // WF must always receive an activation first before responding with commands
             let activation = match self.incoming_activations.poll_recv(cx) {
                 Poll::Ready(a) => match a {
                     Some(act) => act,
@@ -439,18 +439,20 @@
             }
 
             if let Poll::Ready(res) = res {
                 // TODO: Auto reply with cancel when cancelled (instead of normal exit value)
                 match res {
                     Ok(exit_val) => match exit_val {
                         // TODO: Generic values
-                        WfExitValue::Normal(_) => {
+                        WfExitValue::Normal(result) => {
                             activation_cmds.push(
                                 workflow_command::Variant::CompleteWorkflowExecution(
-                                    CompleteWorkflowExecution { result: None },
+                                    CompleteWorkflowExecution {
+                                        result: Some(result),
+                                    },
                                 ),
                             );
                         }
                         WfExitValue::ContinueAsNew(cmd) => activation_cmds.push((*cmd).into()),
                         WfExitValue::Cancelled => {
                             activation_cmds.push(
                                 workflow_command::Variant::CancelWorkflowExecution(
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/Cargo.toml` & `temporalio-1.3.0/temporalio/bridge/sdk-core/sdk-core-protos/Cargo.toml`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/LICENSE.txt` & `temporalio-1.3.0/temporalio/bridge/sdk-core/sdk-core-protos/LICENSE.txt`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/build.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/sdk-core-protos/build.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/src/history_builder.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/sdk-core-protos/src/history_builder.rs`

 * *Files 1% similar despite different names*

```diff
@@ -102,14 +102,15 @@
     pub fn add_workflow_task_scheduled(&mut self) {
         self.workflow_task_scheduled_event_id = self.add_by_type(EventType::WorkflowTaskScheduled);
     }
 
     pub fn add_workflow_task_started(&mut self) {
         self.final_workflow_task_started_event_id = self.add(WorkflowTaskStartedEventAttributes {
             scheduled_event_id: self.workflow_task_scheduled_event_id,
+            history_size_bytes: ((self.events.len() + 1) * 10) as i64,
             ..Default::default()
         });
     }
 
     pub fn add_workflow_task_completed(&mut self) {
         let id = self.add(WorkflowTaskCompletedEventAttributes {
             scheduled_event_id: self.workflow_task_scheduled_event_id,
@@ -558,14 +559,15 @@
             Duration::from_secs(5)
                 .try_into()
                 .expect("5 secs is a valid duration"),
         ),
         task_queue: Some(TaskQueue {
             name: "q".to_string(),
             kind: TaskQueueKind::Normal as i32,
+            normal_name: "".to_string(),
         }),
         ..Default::default()
     }
 }
 
 pub fn default_act_sched() -> ScheduleActivity {
     ScheduleActivity {
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/src/history_info.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/sdk-core-protos/src/history_info.rs`

 * *Files 0% similar despite different names*

```diff
@@ -168,14 +168,15 @@
                     .wf_exe_started_attrs
                     .task_queue
                     .as_ref()
                     .unwrap()
                     .name
                     .clone(),
                 kind: TaskQueueKind::Normal as i32,
+                normal_name: "".to_string(),
             }),
             previous_started_event_id: self.previous_started_event_id,
             started_event_id: self.workflow_task_started_event_id,
             ..Default::default()
         }
     }
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/src/lib.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/sdk-core-protos/src/lib.rs`

 * *Files 1% similar despite different names*

```diff
@@ -450,14 +450,16 @@
                 jobs: vec![WorkflowActivationJob::from(
                     workflow_activation_job::Variant::RemoveFromCache(RemoveFromCache {
                         message,
                         reason: reason as i32,
                     }),
                 )],
                 available_internal_flags: vec![],
+                history_size_bytes: 0,
+                continue_as_new_suggested: false,
             }
         }
 
         pub fn query_to_job(id: String, q: WorkflowQuery) -> QueryWorkflow {
             QueryWorkflow {
                 query_id: id,
                 query_type: q.query_type,
@@ -1496,61 +1498,65 @@
                     fn from(s: workflow_commands::CancelTimer) -> Self {
                         Self::CancelTimerCommandAttributes(CancelTimerCommandAttributes {
                             timer_id: s.seq.to_string(),
                         })
                     }
                 }
 
-                impl From<workflow_commands::ScheduleActivity> for command::Attributes {
-                    fn from(s: workflow_commands::ScheduleActivity) -> Self {
-                        Self::ScheduleActivityTaskCommandAttributes(
-                            ScheduleActivityTaskCommandAttributes {
-                                activity_id: s.activity_id,
-                                activity_type: Some(ActivityType {
-                                    name: s.activity_type,
-                                }),
-                                task_queue: Some(s.task_queue.into()),
-                                header: Some(s.headers.into()),
-                                input: s.arguments.into_payloads(),
-                                schedule_to_close_timeout: s.schedule_to_close_timeout,
-                                schedule_to_start_timeout: s.schedule_to_start_timeout,
-                                start_to_close_timeout: s.start_to_close_timeout,
-                                heartbeat_timeout: s.heartbeat_timeout,
-                                retry_policy: s.retry_policy.map(Into::into),
-                                request_eager_execution: !s.do_not_eagerly_execute,
-                            },
-                        )
-                    }
+                pub fn schedule_activity_cmd_to_api(
+                    s: workflow_commands::ScheduleActivity,
+                    use_compatible_version: bool,
+                ) -> command::Attributes {
+                    command::Attributes::ScheduleActivityTaskCommandAttributes(
+                        ScheduleActivityTaskCommandAttributes {
+                            activity_id: s.activity_id,
+                            activity_type: Some(ActivityType {
+                                name: s.activity_type,
+                            }),
+                            task_queue: Some(s.task_queue.into()),
+                            header: Some(s.headers.into()),
+                            input: s.arguments.into_payloads(),
+                            schedule_to_close_timeout: s.schedule_to_close_timeout,
+                            schedule_to_start_timeout: s.schedule_to_start_timeout,
+                            start_to_close_timeout: s.start_to_close_timeout,
+                            heartbeat_timeout: s.heartbeat_timeout,
+                            retry_policy: s.retry_policy.map(Into::into),
+                            request_eager_execution: !s.do_not_eagerly_execute,
+                            use_compatible_version,
+                        },
+                    )
                 }
 
-                impl From<workflow_commands::StartChildWorkflowExecution> for command::Attributes {
-                    fn from(s: workflow_commands::StartChildWorkflowExecution) -> Self {
-                        Self::StartChildWorkflowExecutionCommandAttributes(
-                            StartChildWorkflowExecutionCommandAttributes {
-                                workflow_id: s.workflow_id,
-                                workflow_type: Some(WorkflowType {
-                                    name: s.workflow_type,
-                                }),
-                                control: "".into(),
-                                namespace: s.namespace,
-                                task_queue: Some(s.task_queue.into()),
-                                header: Some(s.headers.into()),
-                                memo: Some(s.memo.into()),
-                                search_attributes: Some(s.search_attributes.into()),
-                                input: s.input.into_payloads(),
-                                workflow_id_reuse_policy: s.workflow_id_reuse_policy,
-                                workflow_execution_timeout: s.workflow_execution_timeout,
-                                workflow_run_timeout: s.workflow_run_timeout,
-                                workflow_task_timeout: s.workflow_task_timeout,
-                                retry_policy: s.retry_policy.map(Into::into),
-                                cron_schedule: s.cron_schedule.clone(),
-                                parent_close_policy: s.parent_close_policy,
-                            },
-                        )
-                    }
+                pub fn start_child_workflow_cmd_to_api(
+                    s: workflow_commands::StartChildWorkflowExecution,
+                    use_compatible_version: bool,
+                ) -> command::Attributes {
+                    command::Attributes::StartChildWorkflowExecutionCommandAttributes(
+                        StartChildWorkflowExecutionCommandAttributes {
+                            workflow_id: s.workflow_id,
+                            workflow_type: Some(WorkflowType {
+                                name: s.workflow_type,
+                            }),
+                            control: "".into(),
+                            namespace: s.namespace,
+                            task_queue: Some(s.task_queue.into()),
+                            header: Some(s.headers.into()),
+                            memo: Some(s.memo.into()),
+                            search_attributes: Some(s.search_attributes.into()),
+                            input: s.input.into_payloads(),
+                            workflow_id_reuse_policy: s.workflow_id_reuse_policy,
+                            workflow_execution_timeout: s.workflow_execution_timeout,
+                            workflow_run_timeout: s.workflow_run_timeout,
+                            workflow_task_timeout: s.workflow_task_timeout,
+                            retry_policy: s.retry_policy.map(Into::into),
+                            cron_schedule: s.cron_schedule.clone(),
+                            parent_close_policy: s.parent_close_policy,
+                            use_compatible_version,
+                        },
+                    )
                 }
 
                 impl From<workflow_commands::CompleteWorkflowExecution> for command::Attributes {
                     fn from(c: workflow_commands::CompleteWorkflowExecution) -> Self {
                         Self::CompleteWorkflowExecutionCommandAttributes(
                             CompleteWorkflowExecutionCommandAttributes {
                                 result: c.result.map(Into::into),
@@ -1565,43 +1571,45 @@
                             FailWorkflowExecutionCommandAttributes {
                                 failure: c.failure.map(Into::into),
                             },
                         )
                     }
                 }
 
-                impl From<workflow_commands::ContinueAsNewWorkflowExecution> for command::Attributes {
-                    fn from(c: workflow_commands::ContinueAsNewWorkflowExecution) -> Self {
-                        Self::ContinueAsNewWorkflowExecutionCommandAttributes(
-                            ContinueAsNewWorkflowExecutionCommandAttributes {
-                                workflow_type: Some(c.workflow_type.into()),
-                                task_queue: Some(c.task_queue.into()),
-                                input: c.arguments.into_payloads(),
-                                workflow_run_timeout: c.workflow_run_timeout,
-                                workflow_task_timeout: c.workflow_task_timeout,
-                                memo: if c.memo.is_empty() {
-                                    None
-                                } else {
-                                    Some(c.memo.into())
-                                },
-                                header: if c.headers.is_empty() {
-                                    None
-                                } else {
-                                    Some(c.headers.into())
-                                },
-                                retry_policy: c.retry_policy,
-                                search_attributes: if c.search_attributes.is_empty() {
-                                    None
-                                } else {
-                                    Some(c.search_attributes.into())
-                                },
-                                ..Default::default()
+                pub fn continue_as_new_cmd_to_api(
+                    c: workflow_commands::ContinueAsNewWorkflowExecution,
+                    use_compatible_version: bool,
+                ) -> command::Attributes {
+                    command::Attributes::ContinueAsNewWorkflowExecutionCommandAttributes(
+                        ContinueAsNewWorkflowExecutionCommandAttributes {
+                            workflow_type: Some(c.workflow_type.into()),
+                            task_queue: Some(c.task_queue.into()),
+                            input: c.arguments.into_payloads(),
+                            workflow_run_timeout: c.workflow_run_timeout,
+                            workflow_task_timeout: c.workflow_task_timeout,
+                            memo: if c.memo.is_empty() {
+                                None
+                            } else {
+                                Some(c.memo.into())
                             },
-                        )
-                    }
+                            header: if c.headers.is_empty() {
+                                None
+                            } else {
+                                Some(c.headers.into())
+                            },
+                            retry_policy: c.retry_policy,
+                            search_attributes: if c.search_attributes.is_empty() {
+                                None
+                            } else {
+                                Some(c.search_attributes.into())
+                            },
+                            use_compatible_version,
+                            ..Default::default()
+                        },
+                    )
                 }
 
                 impl From<workflow_commands::CancelWorkflowExecution> for command::Attributes {
                     fn from(_c: workflow_commands::CancelWorkflowExecution) -> Self {
                         Self::CancelWorkflowExecutionCommandAttributes(
                             CancelWorkflowExecutionCommandAttributes { details: None },
                         )
@@ -1967,14 +1975,15 @@
                 tonic::include_proto!("temporal.api.taskqueue.v1");
 
                 impl From<String> for TaskQueue {
                     fn from(name: String) -> Self {
                         Self {
                             name,
                             kind: TaskQueueKind::Normal as i32,
+                            normal_name: "".to_string(),
                         }
                     }
                 }
             }
         }
         pub mod testservice {
             pub mod v1 {
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/src/task_token.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/sdk-core-protos/src/task_token.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/test-utils/Cargo.toml` & `temporalio-1.3.0/temporalio/bridge/sdk-core/test-utils/Cargo.toml`

 * *Files 12% similar despite different names*

```diff
@@ -20,15 +20,15 @@
 prost = "0.11"
 prost-types = "0.11"
 rand = "0.8"
 rmp-serde = "1.1"
 serde_json = "1.0"
 temporal-client = { path = "../client" }
 temporal-sdk = { path = "../sdk" }
-temporal-sdk-core = { path = "../core" }
+temporal-sdk-core = { path = "../core", features = ["ephemeral-server"] }
 temporal-sdk-core-api = { path = "../core-api" }
 thiserror = "1.0"
 tokio = "1.1"
 tokio-util = { version = "0.7" }
 tracing = "0.1"
 url = "2.2"
 uuid = "1.1"
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/test-utils/src/canned_histories.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/test-utils/src/canned_histories.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/test-utils/src/histfetch.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/test-utils/src/histfetch.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/test-utils/src/lib.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/test-utils/src/lib.rs`

 * *Files 3% similar despite different names*

```diff
@@ -29,15 +29,15 @@
     interceptors::{FailOnNondeterminismInterceptor, WorkerInterceptor},
     IntoActivityFunc, Worker, WorkflowFunction,
 };
 use temporal_sdk_core::{
     ephemeral_server::{EphemeralExe, EphemeralExeVersion},
     init_replay_worker, init_worker,
     replay::HistoryForReplay,
-    ClientOptions, ClientOptionsBuilder, CoreRuntime, WorkerConfig, WorkerConfigBuilder,
+    ClientOptions, ClientOptionsBuilder, CoreRuntime, WorkerConfigBuilder,
 };
 use temporal_sdk_core_api::{
     errors::{PollActivityError, PollWfError},
     telemetry::{
         Logger, MetricsExporter, OtelCollectorOptions, TelemetryOptions, TelemetryOptionsBuilder,
         TraceExportConfig, TraceExporter,
     },
@@ -57,14 +57,15 @@
 use tokio::sync::{mpsc::unbounded_channel, OnceCell};
 use url::Url;
 
 pub const NAMESPACE: &str = "default";
 pub const TEST_Q: &str = "q";
 /// The env var used to specify where the integ tests should point
 pub const INTEG_SERVER_TARGET_ENV_VAR: &str = "TEMPORAL_SERVICE_ADDRESS";
+pub const INTEG_NAMESPACE_ENV_VAR: &str = "TEMPORAL_NAMESPACE";
 pub const INTEG_USE_TLS_ENV_VAR: &str = "TEMPORAL_USE_TLS";
 /// This env var is set (to any value) if temporal CLI dev server is in use
 pub const INTEG_TEMPORAL_DEV_SERVER_USED_ENV_VAR: &str = "INTEG_TEMPORAL_DEV_SERVER_ON";
 /// This env var is set (to any value) if the test server is in use
 pub const INTEG_TEST_SERVER_USED_ENV_VAR: &str = "INTEG_TEST_SERVER_ON";
 
 /// If set, turn export traces and metrics to the OTel collector at the given URL
@@ -149,49 +150,58 @@
     });
 }
 
 /// Implements a builder pattern to help integ tests initialize core and create workflows
 pub struct CoreWfStarter {
     /// Used for both the task queue and workflow id
     task_queue_name: String,
-    pub worker_config: WorkerConfig,
+    pub worker_config: WorkerConfigBuilder,
     /// Options to use when starting workflow(s)
     pub workflow_options: WorkflowOptions,
     initted_worker: OnceCell<InitializedWorker>,
+    runtime_override: Option<CoreRuntime>,
 }
 struct InitializedWorker {
     worker: Arc<dyn CoreWorker>,
     client: Arc<RetryClient<Client>>,
 }
 
 impl CoreWfStarter {
     pub fn new(test_name: &str) -> Self {
         init_integ_telem();
+        Self::_new(test_name, None)
+    }
+
+    pub fn new_with_runtime(test_name: &str, runtime: CoreRuntime) -> Self {
+        Self::_new(test_name, Some(runtime))
+    }
+
+    fn _new(test_name: &str, runtime_override: Option<CoreRuntime>) -> Self {
         let rand_bytes: Vec<u8> = rand::thread_rng().sample_iter(&Standard).take(6).collect();
         let task_q_salt = BASE64_STANDARD.encode(rand_bytes);
         let task_queue = format!("{test_name}_{task_q_salt}");
+        let mut worker_config = WorkerConfigBuilder::default();
+        worker_config
+            .namespace(env::var(INTEG_NAMESPACE_ENV_VAR).unwrap_or(NAMESPACE.to_string()))
+            .task_queue(task_queue.clone())
+            .worker_build_id("test_build_id")
+            .max_cached_workflows(1000_usize);
         Self {
-            task_queue_name: task_queue.to_owned(),
-            worker_config: WorkerConfigBuilder::default()
-                .namespace(NAMESPACE)
-                .task_queue(task_queue)
-                .worker_build_id("test_build_id")
-                .max_cached_workflows(1000_usize)
-                .build()
-                .unwrap(),
+            task_queue_name: task_queue,
+            worker_config,
             initted_worker: OnceCell::new(),
             workflow_options: Default::default(),
+            runtime_override,
         }
     }
 
     pub async fn worker(&mut self) -> TestWorker {
-        let mut w = TestWorker::new(
-            self.get_worker().await,
-            self.worker_config.task_queue.clone(),
-        );
+        let w = self.get_worker().await;
+        let tq = w.get_config().task_queue.clone();
+        let mut w = TestWorker::new(w, tq);
         w.client = Some(self.get_client().await);
 
         w
     }
 
     pub async fn shutdown(&mut self) {
         self.get_worker().await.shutdown().await;
@@ -223,24 +233,22 @@
                 self.workflow_options.clone(),
             )
             .await
             .unwrap()
     }
 
     pub async fn start_wf_with_id(&self, workflow_id: String) -> String {
-        self.initted_worker
-            .get()
-            .expect(
-                "Worker must be initted before starting a workflow.\
+        let iw = self.initted_worker.get().expect(
+            "Worker must be initted before starting a workflow.\
                              Tests must call `get_worker` first.",
-            )
-            .client
+        );
+        iw.client
             .start_workflow(
                 vec![],
-                self.worker_config.task_queue.clone(),
+                iw.worker.get_config().task_queue.clone(),
                 workflow_id,
                 self.task_queue_name.clone(),
                 None,
                 self.workflow_options.clone(),
             )
             .await
             .unwrap()
@@ -269,76 +277,81 @@
         worker.with_new_core_worker(replay_worker);
         worker.set_worker_interceptor(Box::new(FailOnNondeterminismInterceptor {}));
         worker.run().await.unwrap();
         Ok(())
     }
 
     pub fn get_task_queue(&self) -> &str {
-        &self.worker_config.task_queue
+        &self.task_queue_name
     }
 
     pub fn get_wf_id(&self) -> &str {
         &self.task_queue_name
     }
 
     pub fn max_cached_workflows(&mut self, num: usize) -> &mut Self {
-        self.worker_config.max_cached_workflows = num;
+        self.worker_config.max_cached_workflows(num);
         self
     }
 
     pub fn max_wft(&mut self, max: usize) -> &mut Self {
-        self.worker_config.max_outstanding_workflow_tasks = max;
+        self.worker_config.max_outstanding_workflow_tasks(max);
         self
     }
 
     pub fn max_at(&mut self, max: usize) -> &mut Self {
-        self.worker_config.max_outstanding_activities = max;
+        self.worker_config.max_outstanding_activities(max);
         self
     }
 
     pub fn max_local_at(&mut self, max: usize) -> &mut Self {
-        self.worker_config.max_outstanding_local_activities = max;
+        self.worker_config.max_outstanding_local_activities(max);
         self
     }
 
     pub fn max_at_polls(&mut self, max: usize) -> &mut Self {
-        self.worker_config.max_concurrent_at_polls = max;
+        self.worker_config.max_concurrent_at_polls(max);
+
         self
     }
 
     pub fn no_remote_activities(&mut self) -> &mut Self {
-        self.worker_config.no_remote_activities = true;
+        self.worker_config.no_remote_activities(true);
         self
     }
 
     pub fn enable_wf_state_input_recording(&mut self) -> &mut Self {
         let (ser_tx, ser_rx) = unbounded_channel();
-        let worker_cfg_clone = self.worker_config.clone();
+        let worker_cfg_clone = self.worker_config.build().unwrap();
         tokio::spawn(async move {
             stream_to_file(&worker_cfg_clone, ser_rx).await.unwrap();
         });
-        self.worker_config.wf_state_inputs = Some(ser_tx);
+        self.worker_config.wf_state_inputs(Some(ser_tx));
         self
     }
 
     async fn get_or_init(&mut self) -> &InitializedWorker {
         self.initted_worker
             .get_or_init(|| async {
+                let cfg = self
+                    .worker_config
+                    .build()
+                    .expect("Worker config must be valid");
                 let client = Arc::new(
                     get_integ_server_options()
-                        .connect(self.worker_config.namespace.clone(), None, None)
+                        .connect(cfg.namespace.clone(), None, None)
                         .await
                         .expect("Must connect"),
                 );
-                let worker = init_worker(
-                    INTEG_TESTS_RT.get().unwrap(),
-                    self.worker_config.clone(),
-                    client.clone(),
-                )
-                .expect("Worker inits cleanly");
+                let rt = if let Some(ref rto) = self.runtime_override {
+                    rto
+                } else {
+                    INTEG_TESTS_RT.get().unwrap()
+                };
+                let worker = init_worker(rt, cfg, client.clone()).expect("Worker inits cleanly");
                 InitializedWorker {
                     worker: Arc::new(worker),
                     client,
                 }
             })
             .await
     }
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/test-utils/src/wf_input_saver.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/test-utils/src/wf_input_saver.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/test-utils/src/workflows.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/test-utils/src/workflows.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/fuzzy_workflow.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/fuzzy_workflow.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/heavy_tests.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/heavy_tests.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/client_tests.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/client_tests.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/ephemeral_server_tests.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/ephemeral_server_tests.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/heartbeat_tests.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/heartbeat_tests.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/metrics_tests.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/metrics_tests.rs`

 * *Files 27% similar despite different names*

```diff
@@ -1,22 +1,33 @@
+use assert_matches::assert_matches;
 use std::{sync::Arc, time::Duration};
 use temporal_client::{WorkflowClientTrait, WorkflowOptions, WorkflowService};
 use temporal_sdk_core::{init_worker, CoreRuntime};
 use temporal_sdk_core_api::{telemetry::MetricsExporter, worker::WorkerConfigBuilder, Worker};
 use temporal_sdk_core_protos::{
     coresdk::{
         activity_result::ActivityExecutionResult,
-        workflow_commands::{ScheduleActivity, ScheduleLocalActivity},
+        workflow_activation::{workflow_activation_job, WorkflowActivationJob},
+        workflow_commands::{
+            workflow_command, CancelWorkflowExecution, CompleteWorkflowExecution,
+            ContinueAsNewWorkflowExecution, FailWorkflowExecution, QueryResult, QuerySuccess,
+            ScheduleActivity, ScheduleLocalActivity,
+        },
         workflow_completion::WorkflowActivationCompletion,
         ActivityTaskCompletion,
     },
-    temporal::api::{enums::v1::WorkflowIdReusePolicy, workflowservice::v1::ListNamespacesRequest},
+    temporal::api::{
+        enums::v1::WorkflowIdReusePolicy, failure::v1::Failure, query::v1::WorkflowQuery,
+        workflowservice::v1::ListNamespacesRequest,
+    },
+};
+use temporal_sdk_core_test_utils::{
+    get_integ_server_options, get_integ_telem_options, CoreWfStarter, NAMESPACE,
 };
-use temporal_sdk_core_test_utils::{get_integ_server_options, get_integ_telem_options, NAMESPACE};
-use tokio::sync::Barrier;
+use tokio::{join, sync::Barrier};
 
 static ANY_PORT: &str = "127.0.0.1:0";
 
 async fn get_text(endpoint: String) -> String {
     reqwest::get(endpoint).await.unwrap().text().await.unwrap()
 }
 
@@ -55,18 +66,20 @@
     let rt = CoreRuntime::new_assume_tokio(telemopts).unwrap();
     let addr = rt.telemetry().prom_port().unwrap();
 
     let worker_cfg = WorkerConfigBuilder::default()
         .namespace(NAMESPACE)
         .task_queue(tq)
         .worker_build_id("test_build_id")
-        .max_cached_workflows(1_usize)
+        .max_cached_workflows(2_usize)
         .max_outstanding_activities(1_usize)
         .max_outstanding_local_activities(1_usize)
-        .max_outstanding_workflow_tasks(1_usize)
+        // Need to use two for WFTs because there are a minimum of 2 pollers b/c of sticky polling
+        .max_outstanding_workflow_tasks(2_usize)
+        .max_concurrent_wft_polls(1_usize)
         .build()
         .unwrap();
 
     let client = Arc::new(
         get_integ_server_options()
             .connect(worker_cfg.namespace.clone(), None, None)
             .await
@@ -142,15 +155,15 @@
     let testing = async {
         // Wait just a beat for the poller to initiate
         tokio::time::sleep(Duration::from_millis(50)).await;
         let body = get_text(format!("http://{addr}/metrics")).await;
         assert!(body.contains(&format!(
             "temporal_worker_task_slots_available{{namespace=\"{NAMESPACE}\",\
              service_name=\"temporal-core-sdk\",task_queue=\"one_slot_worker_tq\",\
-             worker_type=\"WorkflowWorker\"}} 1"
+             worker_type=\"WorkflowWorker\"}} 2"
         )));
 
         // Start a workflow so that a task will get delivered
         client
             .start_workflow(
                 vec![],
                 tq.to_owned(),
@@ -170,15 +183,15 @@
 
         // At this point the workflow task is outstanding, so there should be 0 slots, and
         // the activities haven't started, so there should be 1 each.
         let body = get_text(format!("http://{addr}/metrics")).await;
         assert!(body.contains(&format!(
             "temporal_worker_task_slots_available{{namespace=\"{NAMESPACE}\",\
              service_name=\"temporal-core-sdk\",task_queue=\"one_slot_worker_tq\",\
-             worker_type=\"WorkflowWorker\"}} 0"
+             worker_type=\"WorkflowWorker\"}} 1"
         )));
         assert!(body.contains(&format!(
             "temporal_worker_task_slots_available{{namespace=\"{NAMESPACE}\",\
              service_name=\"temporal-core-sdk\",task_queue=\"one_slot_worker_tq\",\
              worker_type=\"ActivityWorker\"}} 1"
         )));
         assert!(body.contains(&format!(
@@ -193,15 +206,15 @@
         wf_task_barr.wait().await;
         // Sometimes the recording takes an extra bit. 🤷
         tokio::time::sleep(Duration::from_millis(100)).await;
         let body = get_text(format!("http://{addr}/metrics")).await;
         assert!(body.contains(&format!(
             "temporal_worker_task_slots_available{{namespace=\"{NAMESPACE}\",\
              service_name=\"temporal-core-sdk\",task_queue=\"one_slot_worker_tq\",\
-             worker_type=\"WorkflowWorker\"}} 1"
+             worker_type=\"WorkflowWorker\"}} 2"
         )));
         assert!(body.contains(&format!(
             "temporal_worker_task_slots_available{{namespace=\"{NAMESPACE}\",\
              service_name=\"temporal-core-sdk\",task_queue=\"one_slot_worker_tq\",\
              worker_type=\"ActivityWorker\"}} 0"
         )));
 
@@ -231,9 +244,129 @@
         let body = get_text(format!("http://{addr}/metrics")).await;
         assert!(body.contains(&format!(
             "temporal_worker_task_slots_available{{namespace=\"{NAMESPACE}\",\
              service_name=\"temporal-core-sdk\",task_queue=\"one_slot_worker_tq\",\
              worker_type=\"LocalActivityWorker\"}} 1"
         )));
     };
-    tokio::join!(wf_polling, act_polling, testing);
+    join!(wf_polling, act_polling, testing);
+}
+
+#[rstest::rstest]
+#[tokio::test]
+async fn query_of_closed_workflow_doesnt_tick_terminal_metric(
+    #[values(
+        CompleteWorkflowExecution { result: None }.into(),
+        FailWorkflowExecution {
+            failure: Some(Failure::application_failure("I'm ded".to_string(), false)),
+        }.into(),
+        ContinueAsNewWorkflowExecution::default().into(),
+        CancelWorkflowExecution { }.into()
+    )]
+    completion: workflow_command::Variant,
+) {
+    let mut telemopts = get_integ_telem_options();
+    telemopts.metrics = Some(MetricsExporter::Prometheus(ANY_PORT.parse().unwrap()));
+    let rt = CoreRuntime::new_assume_tokio(telemopts).unwrap();
+    let addr = rt.telemetry().prom_port().unwrap();
+    let mut starter =
+        CoreWfStarter::new_with_runtime("query_of_closed_workflow_doesnt_tick_terminal_metric", rt);
+    // Disable cache to ensure replay happens completely
+    starter.max_cached_workflows(0);
+    let worker = starter.get_worker().await;
+    let run_id = starter.start_wf().await;
+    let task = worker.poll_workflow_activation().await.unwrap();
+    // Immediately complete the workflow
+    worker
+        .complete_workflow_activation(WorkflowActivationCompletion::from_cmd(
+            task.run_id,
+            completion.clone(),
+        ))
+        .await
+        .unwrap();
+
+    let metric_name = match &completion {
+        workflow_command::Variant::CompleteWorkflowExecution(_) => "temporal_workflow_completed",
+        workflow_command::Variant::FailWorkflowExecution(_) => "temporal_workflow_failed",
+        workflow_command::Variant::ContinueAsNewWorkflowExecution(_) => {
+            "temporal_workflow_continue_as_new"
+        }
+        workflow_command::Variant::CancelWorkflowExecution(_) => "temporal_workflow_canceled",
+        _ => unreachable!(),
+    };
+
+    // Verify there is one tick for the completion metric
+    let body = get_text(format!("http://{addr}/metrics")).await;
+    let matching_line = body
+        .lines()
+        .find(|l| l.starts_with(metric_name))
+        .expect("Must find matching metric");
+    assert!(matching_line.ends_with('1'));
+
+    // Handle cache eviction
+    let task = worker.poll_workflow_activation().await.unwrap();
+    worker
+        .complete_workflow_activation(WorkflowActivationCompletion::empty(task.run_id))
+        .await
+        .unwrap();
+
+    // Query the now-closed workflow
+    let client = starter.get_client().await;
+    let queryer = async {
+        client
+            .query_workflow_execution(
+                starter.get_wf_id().to_string(),
+                run_id,
+                WorkflowQuery {
+                    query_type: "fake_query".to_string(),
+                    query_args: None,
+                    header: None,
+                },
+            )
+            .await
+            .unwrap();
+    };
+    let query_reply = async {
+        // Need to re-complete b/c replay
+        let task = worker.poll_workflow_activation().await.unwrap();
+        worker
+            .complete_workflow_activation(WorkflowActivationCompletion::from_cmd(
+                task.run_id,
+                completion,
+            ))
+            .await
+            .unwrap();
+
+        let task = worker.poll_workflow_activation().await.unwrap();
+        let query = assert_matches!(
+            task.jobs.as_slice(),
+            [WorkflowActivationJob {
+                variant: Some(workflow_activation_job::Variant::QueryWorkflow(q)),
+            }] => q
+        );
+        worker
+            .complete_workflow_activation(WorkflowActivationCompletion::from_cmd(
+                task.run_id,
+                QueryResult {
+                    query_id: query.query_id.clone(),
+                    variant: Some(
+                        QuerySuccess {
+                            response: Some("hi".into()),
+                        }
+                        .into(),
+                    ),
+                }
+                .into(),
+            ))
+            .await
+            .unwrap()
+    };
+    join!(query_reply, queryer);
+
+    // Verify there is still only one tick
+    let body = get_text(format!("http://{addr}/metrics")).await;
+    let matching_line = body
+        .lines()
+        .find(|l| l.starts_with(metric_name))
+        .expect("Must find matching metric");
+    assert!(matching_line.ends_with('1'));
 }
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/polling_tests.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/polling_tests.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/queries_tests.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/queries_tests.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/visibility_tests.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/visibility_tests.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/activities.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/activities.rs`

 * *Files 1% similar despite different names*

```diff
@@ -13,15 +13,17 @@
         activity_result::{
             self, activity_resolution as act_res, ActivityExecutionResult, ActivityResolution,
         },
         activity_task::activity_task as act_task,
         workflow_activation::{
             workflow_activation_job, FireTimer, ResolveActivity, WorkflowActivationJob,
         },
-        workflow_commands::{ActivityCancellationType, RequestCancelActivity, StartTimer},
+        workflow_commands::{
+            ActivityCancellationType, RequestCancelActivity, ScheduleActivity, StartTimer,
+        },
         workflow_completion::WorkflowActivationCompletion,
         ActivityHeartbeat, ActivityTaskCompletion, AsJsonPayloadExt, FromJsonPayloadExt,
         IntoCompletion,
     },
     temporal::api::{
         common::v1::{ActivityType, Payload, Payloads, RetryPolicy},
         enums::v1::RetryState,
@@ -724,41 +726,48 @@
 async fn activity_cancelled_after_heartbeat_times_out() {
     let mut starter = init_core_and_create_wf("activity_cancelled_after_heartbeat_times_out").await;
     let core = starter.get_worker().await;
     let task_q = starter.get_task_queue().to_string();
     let activity_id = "act-1";
     let task = core.poll_workflow_activation().await.unwrap();
     // Complete workflow task and schedule activity
-    core.complete_workflow_activation(
-        schedule_activity_cmd(
-            0,
-            &task_q,
-            activity_id,
-            ActivityCancellationType::WaitCancellationCompleted,
-            Duration::from_secs(60),
-            Duration::from_secs(1),
-        )
-        .into_completion(task.run_id),
-    )
+    core.complete_workflow_activation(WorkflowActivationCompletion::from_cmd(
+        task.run_id,
+        ScheduleActivity {
+            seq: 0,
+            activity_id: activity_id.to_string(),
+            activity_type: "dontcare".to_string(),
+            task_queue: task_q.clone(),
+            schedule_to_close_timeout: Some(prost_dur!(from_secs(10))),
+            heartbeat_timeout: Some(prost_dur!(from_secs(1))),
+            retry_policy: Some(RetryPolicy {
+                maximum_attempts: 2,
+                initial_interval: Some(prost_dur!(from_secs(5))),
+                ..Default::default()
+            }),
+            ..Default::default()
+        }
+        .into(),
+    ))
     .await
     .unwrap();
     // Poll activity and verify that it's been scheduled
     let task = core.poll_activity_task().await.unwrap();
     assert_matches!(task.variant, Some(act_task::Variant::Start(_)));
     // Delay the heartbeat
     sleep(Duration::from_secs(2)).await;
     core.record_activity_heartbeat(ActivityHeartbeat {
         task_token: task.task_token.clone(),
         details: vec![],
     });
 
     // Verify activity got cancelled
     let cancel_task = core.poll_activity_task().await.unwrap();
-    assert_eq!(cancel_task.task_token, task.task_token.clone());
     assert_matches!(cancel_task.variant, Some(act_task::Variant::Cancel(_)));
+    assert_eq!(cancel_task.task_token, task.task_token.clone());
 
     // Complete activity with cancelled result
     core.complete_activity_task(ActivityTaskCompletion {
         task_token: task.task_token.clone(),
         result: Some(ActivityExecutionResult::cancel_from_details(None)),
     })
     .await
@@ -766,15 +775,15 @@
 
     // Verify shutdown completes
     drain_pollers_and_shutdown(&core).await;
     // Cleanup just in case
     starter
         .get_client()
         .await
-        .terminate_workflow_execution(task_q.clone(), None)
+        .terminate_workflow_execution(task_q, None)
         .await
         .unwrap();
 }
 
 #[tokio::test]
 async fn one_activity_abandon_cancelled_after_complete() {
     let wf_name = "one_activity_abandon_cancelled_after_complete";
@@ -901,15 +910,17 @@
     worker.run_until_done().await.unwrap();
 }
 
 #[tokio::test]
 async fn graceful_shutdown() {
     let wf_name = "graceful_shutdown";
     let mut starter = CoreWfStarter::new(wf_name);
-    starter.worker_config.graceful_shutdown_period = Some(Duration::from_millis(500));
+    starter
+        .worker_config
+        .graceful_shutdown_period(Some(Duration::from_millis(500)));
     let mut worker = starter.worker().await;
     let client = starter.get_client().await;
     worker.register_wf(wf_name.to_owned(), |ctx: WfContext| async move {
         let act_futs = (1..=10).map(|_| {
             ctx.activity(ActivityOptions {
                 activity_type: "sleeper".to_string(),
                 start_to_close_timeout: Some(Duration::from_secs(5)),
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/appdata_propagation.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/appdata_propagation.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/cancel_external.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/cancel_external.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/cancel_wf.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/cancel_wf.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/child_workflows.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/child_workflows.rs`

 * *Files 0% similar despite different names*

```diff
@@ -87,15 +87,15 @@
             ctx.timer(Duration::from_secs(1)).await;
             started.result().await;
             Ok(().into())
         },
     );
     worker.register_wf(CHILD_WF_TYPE.to_string(), |mut ctx: WfContext| async move {
         ctx.cancelled().await;
-        Ok(WfExitValue::Cancelled)
+        Ok(WfExitValue::<()>::Cancelled)
     });
 
     worker
         .submit_wf(
             "parent-abandoner".to_string(),
             PARENT_WF_TYPE.to_owned(),
             vec![],
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/continue_as_new.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/continue_as_new.rs`

 * *Files 1% similar despite different names*

```diff
@@ -39,16 +39,16 @@
 
 #[tokio::test]
 async fn continue_as_new_multiple_concurrent() {
     let wf_name = "continue_as_new_multiple_concurrent";
     let mut starter = CoreWfStarter::new(wf_name);
     starter
         .no_remote_activities()
-        .max_cached_workflows(3)
-        .max_wft(3);
+        .max_cached_workflows(5)
+        .max_wft(5);
     let mut worker = starter.worker().await;
     worker.register_wf(wf_name.to_string(), continue_as_new_wf);
 
     let wf_names = (1..=20).map(|i| format!("{wf_name}-{i}"));
     for name in wf_names.clone() {
         worker
             .submit_wf(
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/determinism.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/determinism.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/local_activities.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/local_activities.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/modify_wf_properties.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/modify_wf_properties.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/patches.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/patches.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/replay.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/replay.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/resets.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/resets.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/signals.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/signals.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/stickyness.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/stickyness.rs`

 * *Files 3% similar despite different names*

```diff
@@ -51,15 +51,19 @@
     assert_eq!(RUN_CT.load(Ordering::SeqCst), 2);
 }
 
 #[tokio::test]
 async fn cache_miss_ok() {
     let wf_name = "cache_miss_ok";
     let mut starter = CoreWfStarter::new(wf_name);
-    starter.no_remote_activities().max_wft(1);
+    starter
+        .no_remote_activities()
+        .max_wft(2)
+        .max_cached_workflows(0);
+    starter.worker_config.max_concurrent_wft_polls(1_usize);
     let mut worker = starter.worker().await;
 
     let barr: &'static Barrier = Box::leak(Box::new(Barrier::new(2)));
     worker.register_wf(wf_name.to_owned(), move |ctx: WfContext| async move {
         barr.wait().await;
         ctx.timer(Duration::from_secs(1)).await;
         Ok(().into())
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/timers.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/timers.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/upsert_search_attrs.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/upsert_search_attrs.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests.rs`

 * *Files 0% similar despite different names*

```diff
@@ -430,14 +430,15 @@
     let signal_at_start = "at-start";
     let signal_at_complete = "at-complete";
     let mut wf_starter = CoreWfStarter::new("wft_timeout_doesnt_create_unsolvable_autocomplete");
     wf_starter
         // Test needs eviction on and a short timeout
         .max_cached_workflows(0)
         .max_wft(1);
+    wf_starter.worker_config.max_concurrent_wft_polls(1_usize);
     wf_starter.workflow_options.task_timeout = Some(Duration::from_secs(1));
     let core = wf_starter.get_worker().await;
     let client = wf_starter.get_client().await;
     let task_q = wf_starter.get_task_queue();
     let wf_id = &wf_starter.get_wf_id().to_owned();
 
     // Set up some helpers for polling and completing
```

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/main.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/main.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/runner.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/runner.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/wf_input_replay.rs` & `temporalio-1.3.0/temporalio/bridge/sdk-core/tests/wf_input_replay.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/src/client.rs` & `temporalio-1.3.0/temporalio/bridge/src/client.rs`

 * *Files 1% similar despite different names*

```diff
@@ -128,14 +128,17 @@
                 "get_search_attributes" => {
                     rpc_call!(retry_client, call, get_search_attributes)
                 }
                 "get_system_info" => rpc_call!(retry_client, call, get_system_info),
                 "get_worker_build_id_compatibility" => {
                     rpc_call!(retry_client, call, get_worker_build_id_compatibility)
                 }
+                "get_worker_task_reachability" => {
+                    rpc_call!(retry_client, call, get_worker_task_reachability)
+                }
                 "get_workflow_execution_history" => {
                     rpc_call!(retry_client, call, get_workflow_execution_history)
                 }
                 "get_workflow_execution_history_reverse" => {
                     rpc_call!(retry_client, call, get_workflow_execution_history_reverse)
                 }
                 "list_archived_workflow_executions" => {
```

### Comparing `temporalio-1.2.0/temporalio/bridge/src/lib.rs` & `temporalio-1.3.0/temporalio/bridge/src/lib.rs`

 * *Files 5% similar despite different names*

```diff
@@ -16,15 +16,15 @@
     // Runtime stuff
     m.add_class::<runtime::RuntimeRef>()?;
     m.add_function(wrap_pyfunction!(init_runtime, m)?)?;
     m.add_function(wrap_pyfunction!(raise_in_thread, m)?)?;
 
     // Testing stuff
     m.add_class::<testing::EphemeralServerRef>()?;
-    m.add_function(wrap_pyfunction!(start_temporalite, m)?)?;
+    m.add_function(wrap_pyfunction!(start_dev_server, m)?)?;
     m.add_function(wrap_pyfunction!(start_test_server, m)?)?;
 
     // Worker stuff
     m.add(
         "PollShutdownError",
         py.get_type::<worker::PollShutdownError>(),
     )?;
@@ -51,20 +51,20 @@
 
 #[pyfunction]
 fn raise_in_thread<'a>(py: Python<'a>, thread_id: std::os::raw::c_long, exc: &PyAny) -> bool {
     runtime::raise_in_thread(py, thread_id, exc)
 }
 
 #[pyfunction]
-fn start_temporalite<'a>(
+fn start_dev_server<'a>(
     py: Python<'a>,
     runtime_ref: &runtime::RuntimeRef,
-    config: testing::TemporaliteConfig,
+    config: testing::DevServerConfig,
 ) -> PyResult<&'a PyAny> {
-    testing::start_temporalite(py, &runtime_ref, config)
+    testing::start_dev_server(py, &runtime_ref, config)
 }
 
 #[pyfunction]
 fn start_test_server<'a>(
     py: Python<'a>,
     runtime_ref: &runtime::RuntimeRef,
     config: testing::TestServerConfig,
```

### Comparing `temporalio-1.2.0/temporalio/bridge/src/runtime.rs` & `temporalio-1.3.0/temporalio/bridge/src/runtime.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/bridge/src/testing.rs` & `temporalio-1.3.0/temporalio/bridge/src/testing.rs`

 * *Files 4% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 #[pyclass]
 pub struct EphemeralServerRef {
     server: Option<ephemeral_server::EphemeralServer>,
     runtime: runtime::Runtime,
 }
 
 #[derive(FromPyObject)]
-pub struct TemporaliteConfig {
+pub struct DevServerConfig {
     existing_path: Option<String>,
     sdk_name: String,
     sdk_version: String,
     download_version: String,
     download_dest_dir: Option<String>,
     namespace: String,
     ip: String,
@@ -34,25 +34,25 @@
     sdk_version: String,
     download_version: String,
     download_dest_dir: Option<String>,
     port: Option<u16>,
     extra_args: Vec<String>,
 }
 
-pub fn start_temporalite<'a>(
+pub fn start_dev_server<'a>(
     py: Python<'a>,
     runtime_ref: &runtime::RuntimeRef,
-    config: TemporaliteConfig,
+    config: DevServerConfig,
 ) -> PyResult<&'a PyAny> {
-    let opts: ephemeral_server::TemporaliteConfig = config.try_into()?;
+    let opts: ephemeral_server::TemporalDevServerConfig = config.try_into()?;
     let runtime = runtime_ref.runtime.clone();
     runtime_ref.runtime.future_into_py(py, async move {
         Ok(EphemeralServerRef {
             server: Some(opts.start_server().await.map_err(|err| {
-                PyRuntimeError::new_err(format!("Failed starting Temporalite: {}", err))
+                PyRuntimeError::new_err(format!("Failed starting Temporal dev server: {}", err))
             })?),
             runtime,
         })
     })
 }
 
 pub fn start_test_server<'a>(
@@ -101,19 +101,19 @@
                 })?;
             }
             Ok(())
         })
     }
 }
 
-impl TryFrom<TemporaliteConfig> for ephemeral_server::TemporaliteConfig {
+impl TryFrom<DevServerConfig> for ephemeral_server::TemporalDevServerConfig {
     type Error = PyErr;
 
-    fn try_from(conf: TemporaliteConfig) -> PyResult<Self> {
-        ephemeral_server::TemporaliteConfigBuilder::default()
+    fn try_from(conf: DevServerConfig) -> PyResult<Self> {
+        ephemeral_server::TemporalDevServerConfigBuilder::default()
             .exe(if let Some(existing_path) = conf.existing_path {
                 ephemeral_server::EphemeralExe::ExistingPath(existing_path.to_owned())
             } else {
                 ephemeral_server::EphemeralExe::CachedDownload {
                     version: if conf.download_version != "default" {
                         ephemeral_server::EphemeralExeVersion::Fixed(conf.download_version)
                     } else {
```

### Comparing `temporalio-1.2.0/temporalio/bridge/src/worker.rs` & `temporalio-1.3.0/temporalio/bridge/src/worker.rs`

 * *Files 1% similar despite different names*

```diff
@@ -40,14 +40,15 @@
     no_remote_activities: bool,
     sticky_queue_schedule_to_start_timeout_millis: u64,
     max_heartbeat_throttle_interval_millis: u64,
     default_heartbeat_throttle_interval_millis: u64,
     max_activities_per_second: Option<f64>,
     max_task_queue_activities_per_second: Option<f64>,
     graceful_shutdown_period_millis: u64,
+    use_worker_versioning: bool,
 }
 
 macro_rules! enter_sync {
     ($runtime:expr) => {
         temporal_sdk_core::telemetry::set_trace_subscriber_for_current_thread(
             $runtime.core.trace_subscriber(),
         );
@@ -228,14 +229,15 @@
             ))
             .max_worker_activities_per_second(conf.max_activities_per_second)
             .max_task_queue_activities_per_second(conf.max_task_queue_activities_per_second)
             // Even though grace period is optional, if it is not set then the
             // auto-cancel-activity behavior of shutdown will not occur, so we
             // always set it even if 0.
             .graceful_shutdown_period(Duration::from_millis(conf.graceful_shutdown_period_millis))
+            .use_worker_versioning(conf.use_worker_versioning)
             .build()
             .map_err(|err| PyValueError::new_err(format!("Invalid worker config: {}", err)))
     }
 }
 
 /// For feeding histories into core during replay
 #[pyclass]
```

### Comparing `temporalio-1.2.0/temporalio/bridge/testing.py` & `temporalio-1.3.0/temporalio/bridge/testing.py`

 * *Files 14% similar despite different names*

```diff
@@ -9,16 +9,16 @@
 from typing import Optional, Sequence
 
 import temporalio.bridge.runtime
 import temporalio.bridge.temporal_sdk_bridge
 
 
 @dataclass
-class TemporaliteConfig:
-    """Python representation of the Rust struct for configuring Temporalite."""
+class DevServerConfig:
+    """Python representation of the Rust struct for configuring dev server."""
 
     existing_path: Optional[str]
     sdk_name: str
     sdk_version: str
     download_version: str
     download_dest_dir: Optional[str]
     namespace: str
@@ -44,20 +44,20 @@
     extra_args: Sequence[str]
 
 
 class EphemeralServer:
     """Python representation of a Rust ephemeral server."""
 
     @staticmethod
-    async def start_temporalite(
-        runtime: temporalio.bridge.runtime.Runtime, config: TemporaliteConfig
+    async def start_dev_server(
+        runtime: temporalio.bridge.runtime.Runtime, config: DevServerConfig
     ) -> EphemeralServer:
-        """Start a Temporalite instance."""
+        """Start a dev server instance."""
         return EphemeralServer(
-            await temporalio.bridge.temporal_sdk_bridge.start_temporalite(
+            await temporalio.bridge.temporal_sdk_bridge.start_dev_server(
                 runtime._ref, config
             )
         )
 
     @staticmethod
     async def start_test_server(
         runtime: temporalio.bridge.runtime.Runtime, config: TestServerConfig
```

### Comparing `temporalio-1.2.0/temporalio/bridge/worker.py` & `temporalio-1.3.0/temporalio/bridge/worker.py`

 * *Files 0% similar despite different names*

```diff
@@ -43,14 +43,15 @@
     no_remote_activities: bool
     sticky_queue_schedule_to_start_timeout_millis: int
     max_heartbeat_throttle_interval_millis: int
     default_heartbeat_throttle_interval_millis: int
     max_activities_per_second: Optional[float]
     max_task_queue_activities_per_second: Optional[float]
     graceful_shutdown_period_millis: int
+    use_worker_versioning: bool
 
 
 class Worker:
     """SDK Core worker."""
 
     @staticmethod
     def create(client: temporalio.bridge.client.Client, config: WorkerConfig) -> Worker:
```

### Comparing `temporalio-1.2.0/temporalio/client.py` & `temporalio-1.3.0/temporalio/client.py`

 * *Files 5% similar despite different names*

```diff
@@ -8,21 +8,22 @@
 import json
 import re
 import uuid
 import warnings
 from abc import ABC, abstractmethod
 from dataclasses import dataclass
 from datetime import datetime, timedelta, timezone
-from enum import IntEnum
+from enum import Enum, IntEnum
 from typing import (
     Any,
     AsyncIterator,
     Awaitable,
     Callable,
     Dict,
+    FrozenSet,
     Generic,
     Iterable,
     Mapping,
     Optional,
     Sequence,
     Type,
     Union,
@@ -403,14 +404,16 @@
         """
         # Use definition if callable
         name: str
         if isinstance(workflow, str):
             name = workflow
         elif callable(workflow):
             defn = temporalio.workflow._Definition.must_from_run_fn(workflow)
+            if not defn.name:
+                raise ValueError("Cannot invoke dynamic workflow explicitly")
             name = defn.name
             if result_type is None:
                 result_type = defn.ret_type
         else:
             raise TypeError("Workflow must be a string or callable")
 
         return await self._impl.start_workflow(
@@ -750,17 +753,14 @@
         memo: Optional[Mapping[str, Any]] = None,
         search_attributes: Optional[temporalio.common.SearchAttributes] = None,
         rpc_metadata: Mapping[str, str] = {},
         rpc_timeout: Optional[timedelta] = None,
     ) -> ScheduleHandle:
         """Create a schedule and return its handle.
 
-        .. warning::
-            Schedules are an experimental feature.
-
         Args:
             id: Unique identifier of the schedule.
             schedule: Schedule to create.
             trigger_immediately: If true, trigger one action immediately when
                 creating the schedule.
             backfill: Set of time periods to take actions on as if that time
                 passed right now.
@@ -790,19 +790,15 @@
                 search_attributes=search_attributes,
                 rpc_metadata=rpc_metadata,
                 rpc_timeout=rpc_timeout,
             )
         )
 
     def get_schedule_handle(self, id: str) -> ScheduleHandle:
-        """Get a schedule handle for the given ID.
-
-        .. warning::
-            Schedules are an experimental feature.
-        """
+        """Get a schedule handle for the given ID."""
         return ScheduleHandle(self, id)
 
     async def list_schedules(
         self,
         *,
         page_size: int = 1000,
         next_page_token: Optional[bytes] = None,
@@ -813,17 +809,14 @@
 
         This does not make a request until the first iteration is attempted.
         Therefore any errors will not occur until then.
 
         Note, this list is eventually consistent. Therefore if a schedule is
         added or deleted, it may not be available in the list immediately.
 
-        .. warning::
-            Schedules are an experimental feature.
-
         Args:
             page_size: Maximum number of results for each page.
             next_page_token: A previously obtained next page token if doing
                 pagination. Usually not needed as the iterator automatically
                 starts from the beginning.
             rpc_metadata: Headers used on each RPC call. Keys here override
                 client-level RPC metadata keys.
@@ -837,14 +830,116 @@
                 page_size=page_size,
                 next_page_token=next_page_token,
                 rpc_metadata=rpc_metadata,
                 rpc_timeout=rpc_timeout,
             )
         )
 
+    async def update_worker_build_id_compatibility(
+        self,
+        task_queue: str,
+        operation: BuildIdOp,
+        rpc_metadata: Mapping[str, str] = {},
+        rpc_timeout: Optional[timedelta] = None,
+    ) -> None:
+        """Used to add new Build IDs or otherwise update the relative compatibility of Build Ids as
+        defined on a specific task queue for the Worker Versioning feature.
+
+        For more on this feature, see https://docs.temporal.io/workers#worker-versioning
+
+        .. warning::
+           This API is experimental
+
+        Args:
+            task_queue: The task queue to target.
+            operation: The operation to perform.
+            rpc_metadata: Headers used on each RPC call. Keys here override
+                client-level RPC metadata keys.
+            rpc_timeout: Optional RPC deadline to set for each RPC call.
+        """
+        return await self._impl.update_worker_build_id_compatibility(
+            UpdateWorkerBuildIdCompatibilityInput(
+                task_queue,
+                operation,
+                rpc_metadata=rpc_metadata,
+                rpc_timeout=rpc_timeout,
+            )
+        )
+
+    async def get_worker_build_id_compatibility(
+        self,
+        task_queue: str,
+        max_sets: Optional[int] = None,
+        rpc_metadata: Mapping[str, str] = {},
+        rpc_timeout: Optional[timedelta] = None,
+    ) -> WorkerBuildIdVersionSets:
+        """Get the Build ID compatibility sets for a specific task queue.
+
+        For more on this feature, see https://docs.temporal.io/workers#worker-versioning
+
+        .. warning::
+           This API is experimental
+
+        Args:
+            task_queue: The task queue to target.
+            max_sets: The maximum number of sets to return. If not specified, all sets will be
+                returned.
+            rpc_metadata: Headers used on each RPC call. Keys here override
+                client-level RPC metadata keys.
+            rpc_timeout: Optional RPC deadline to set for each RPC call.
+        """
+        return await self._impl.get_worker_build_id_compatibility(
+            GetWorkerBuildIdCompatibilityInput(
+                task_queue,
+                max_sets,
+                rpc_metadata=rpc_metadata,
+                rpc_timeout=rpc_timeout,
+            )
+        )
+
+    async def get_worker_task_reachability(
+        self,
+        build_ids: Sequence[str],
+        task_queues: Sequence[str] = [],
+        reachability_type: Optional[TaskReachabilityType] = None,
+        rpc_metadata: Mapping[str, str] = {},
+        rpc_timeout: Optional[timedelta] = None,
+    ) -> WorkerTaskReachability:
+        """Determine if some Build IDs for certain Task Queues could have tasks dispatched to them.
+
+        For more on this feature, see https://docs.temporal.io/workers#worker-versioning
+
+        .. warning::
+           This API is experimental
+
+        Args:
+            build_ids: The Build IDs to query the reachability of. At least one must be specified.
+            task_queues: Task Queues to restrict the query to. If not specified, all Task Queues
+                will be searched. When requesting a large number of task queues or all task queues
+                associated with the given Build IDs in a namespace, all Task Queues will be listed
+                in the response but some of them may not contain reachability information due to a
+                server enforced limit. When reaching the limit, task queues that reachability
+                information could not be retrieved for will be marked with a `NotFetched` entry in
+                {@link BuildIdReachability.taskQueueReachability}. The caller may issue another call
+                to get the reachability for those task queues.
+            reachability_type: The kind of reachability this request is concerned with.
+            rpc_metadata: Headers used on each RPC call. Keys here override
+                client-level RPC metadata keys.
+            rpc_timeout: Optional RPC deadline to set for each RPC call.
+        """
+        return await self._impl.get_worker_task_reachability(
+            GetWorkerTaskReachabilityInput(
+                build_ids,
+                task_queues,
+                reachability_type,
+                rpc_metadata=rpc_metadata,
+                rpc_timeout=rpc_timeout,
+            )
+        )
+
 
 class ClientConfig(TypedDict, total=False):
     """TypedDict of config originally passed to :py:meth:`Client`."""
 
     service_client: temporalio.service.ServiceClient
     namespace: str
     data_converter: temporalio.converter.DataConverter
@@ -1283,26 +1378,28 @@
     @overload
     async def query(
         self,
         query: str,
         arg: Any = temporalio.common._arg_unset,
         *,
         args: Sequence[Any] = [],
+        result_type: Optional[Type] = None,
         reject_condition: Optional[temporalio.common.QueryRejectCondition] = None,
         rpc_metadata: Mapping[str, str] = {},
         rpc_timeout: Optional[timedelta] = None,
     ) -> Any:
         ...
 
     async def query(
         self,
         query: Union[str, Callable],
         arg: Any = temporalio.common._arg_unset,
         *,
         args: Sequence[Any] = [],
+        result_type: Optional[Type] = None,
         reject_condition: Optional[temporalio.common.QueryRejectCondition] = None,
         rpc_metadata: Mapping[str, str] = {},
         rpc_timeout: Optional[timedelta] = None,
     ) -> Any:
         """Query the workflow.
 
         This will query for :py:attr:`run_id` if present. To use a different
@@ -1314,29 +1411,31 @@
             query the latest workflow with the same workflow ID even if it is
             unrelated to the started workflow.
 
         Args:
             query: Query function or name on the workflow.
             arg: Single argument to the query.
             args: Multiple arguments to the query. Cannot be set if arg is.
+            result_type: For string queries, this can set the specific result
+                type hint to deserialize into.
             reject_condition: Condition for rejecting the query. If unset/None,
                 defaults to the client's default (which is defaulted to None).
             rpc_metadata: Headers used on the RPC call. Keys here override
                 client-level RPC metadata keys.
             rpc_timeout: Optional RPC deadline to set for the RPC call.
 
         Returns:
             Result of the query.
 
         Raises:
             WorkflowQueryRejectedError: A query reject condition was satisfied.
             RPCError: Workflow details could not be fetched.
         """
         query_name: str
-        ret_type: Optional[Type] = None
+        ret_type = result_type
         if callable(query):
             defn = temporalio.workflow._QueryDefinition.from_fn(query)
             if not defn:
                 raise RuntimeError(
                     f"Query definition not found on {query.__qualname__}, "
                     "is it decorated with @workflow.query?"
                 )
@@ -2097,17 +2196,14 @@
 
 class ScheduleHandle:
     """Handle for interacting with a schedule.
 
     This is usually created via :py:meth:`Client.get_schedule_handle` or
     returned from :py:meth:`Client.create_schedule`.
 
-    .. warning::
-        Schedules are an experimental feature.
-
     Attributes:
         id: ID of the schedule.
     """
 
     def __init__(self, client: Client, id: str) -> None:
         """Create schedule handle."""
         self._client = client
@@ -2313,17 +2409,14 @@
 
 @dataclass
 class ScheduleSpec:
     """Specification of the times scheduled actions may occur.
 
     The times are the union of :py:attr:`calendars`, :py:attr:`intervals`, and
     :py:attr:`cron_expressions` excluding anything in :py:attr:`skip`.
-
-    .. warning::
-        Schedules are an experimental feature.
     """
 
     calendars: Sequence[ScheduleCalendarSpec] = dataclasses.field(default_factory=list)
     """Calendar-based specification of times."""
 
     intervals: Sequence[ScheduleIntervalSpec] = dataclasses.field(default_factory=list)
     """Interval-based specification of times."""
@@ -2401,19 +2494,15 @@
             jitter=jitter,
             timezone_name=self.time_zone_name or "",
         )
 
 
 @dataclass(frozen=True)
 class ScheduleRange:
-    """Inclusive range for a schedule match value.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Inclusive range for a schedule match value."""
 
     start: int
     """Inclusive start of the range."""
 
     end: int = 0
     """Inclusive end of the range.
     
@@ -2423,14 +2512,22 @@
     step: int = 0
     """
     Step to take between each value.
 
     Unset or 0 defaults as 1.
     """
 
+    def __post_init__(self):
+        """Set field defaults."""
+        # Class is frozen, so we must setattr bypassing dataclass setattr
+        if self.end < self.start:
+            object.__setattr__(self, "end", self.start)
+        if self.step == 0:
+            object.__setattr__(self, "step", 1)
+
     @staticmethod
     def _from_protos(
         ranges: Sequence[temporalio.api.schedule.v1.Range],
     ) -> Sequence[ScheduleRange]:
         return tuple(ScheduleRange._from_proto(r) for r in ranges)
 
     @staticmethod
@@ -2452,17 +2549,14 @@
 @dataclass
 class ScheduleCalendarSpec:
     """Specification relative to calendar time when to run an action.
 
     A timestamp matches if at least one range of each field matches except for
     year. If year is missing, that means all years match. For all fields besides
     year, at least one range must be present to match anything.
-
-    .. warning::
-        Schedules are an experimental feature.
     """
 
     second: Sequence[ScheduleRange] = (ScheduleRange(0),)
     """Second range to match, 0-59. Default matches 0."""
 
     minute: Sequence[ScheduleRange] = (ScheduleRange(0),)
     """Minute range to match, 0-59. Default matches 0."""
@@ -2515,17 +2609,14 @@
 
 
 @dataclass
 class ScheduleIntervalSpec:
     """Specification for scheduling on an interval.
 
     Matches times expressed as epoch + (n * every) + offset.
-
-    .. warning::
-        Schedules are an experimental feature.
     """
 
     every: timedelta
     """Period to repeat the interval."""
 
     offset: Optional[timedelta] = None
     """Fixed offset added to each interval period."""
@@ -2550,17 +2641,14 @@
 
 
 class ScheduleAction(ABC):
     """Base class for an action a schedule can take.
 
     See :py:class:`ScheduleActionStartWorkflow` for the most commonly used
     implementation.
-
-    .. warning::
-        Schedules are an experimental feature.
     """
 
     @staticmethod
     def _from_proto(
         action: temporalio.api.schedule.v1.ScheduleAction,
     ) -> ScheduleAction:
         if action.HasField("start_workflow"):
@@ -2573,19 +2661,15 @@
         self, client: Client
     ) -> temporalio.api.schedule.v1.ScheduleAction:
         ...
 
 
 @dataclass
 class ScheduleActionStartWorkflow(ScheduleAction):
-    """Schedule action to start a workflow.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Schedule action to start a workflow."""
 
     workflow: str
     args: Union[Sequence[Any], Sequence[temporalio.api.common.v1.Payload]]
     id: str
     task_queue: str
     execution_timeout: Optional[timedelta]
     run_timeout: Optional[timedelta]
@@ -2741,14 +2825,16 @@
             if not id:
                 raise ValueError("ID required")
             if not task_queue:
                 raise ValueError("Task queue required")
             # Use definition if callable
             if callable(workflow):
                 defn = temporalio.workflow._Definition.must_from_run_fn(workflow)
+                if not defn.name:
+                    raise ValueError("Cannot schedule dynamic workflow explicitly")
                 workflow = defn.name
             elif not isinstance(workflow, str):
                 raise TypeError("Workflow must be a string or callable")
             self.workflow = workflow
             self.args = temporalio.common._arg_or_args(arg, args)
             self.id = id
             self.task_queue = task_queue
@@ -2822,17 +2908,14 @@
         )
 
 
 @dataclass
 class ScheduleOverlapPolicy(IntEnum):
     """Controls what happens when a workflow would be started by a schedule but
     one is already running.
-
-    .. warning::
-        Schedules are an experimental feature.
     """
 
     SKIP = int(
         temporalio.api.enums.v1.ScheduleOverlapPolicy.SCHEDULE_OVERLAP_POLICY_SKIP
     )
     """Don't start anything.
     
@@ -2878,17 +2961,14 @@
     be available since workflows are not sequential."""
 
 
 @dataclass
 class ScheduleBackfill:
     """Time period and policy for actions taken as if the time passed right
     now.
-
-    .. warning::
-        Schedules are an experimental feature.
     """
 
     start_at: datetime
     """Start of the range to evaluate the schedule in.
     
     This is exclusive
     """
@@ -2912,19 +2992,15 @@
             end_time=end_time,
             overlap_policy=overlap_policy,
         )
 
 
 @dataclass
 class SchedulePolicy:
-    """Policies of a schedule.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Policies of a schedule."""
 
     overlap: ScheduleOverlapPolicy = dataclasses.field(
         default_factory=lambda: ScheduleOverlapPolicy.SKIP
     )
     """Controls what happens when an action is started while another is still
     running."""
 
@@ -2957,19 +3033,15 @@
             catchup_window=catchup_window,
             pause_on_failure=self.pause_on_failure,
         )
 
 
 @dataclass
 class ScheduleState:
-    """State of a schedule
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """State of a schedule."""
 
     note: Optional[str] = None
     """Human readable message for the schedule.
     
     The system may overwrite this value on certain conditions like
     pause-on-failure.
     """
@@ -2978,15 +3050,16 @@
     """Whether the schedule is paused."""
 
     # Cannot be set to True on create
     limited_actions: bool = False
     """
     If true, remaining actions will be decremented for each action taken.
 
-    Cannot be set on create.
+    On schedule create, this must be set to true if :py:attr:`remaining_actions`
+    is non-zero and left false if :py:attr:`remaining_actions` is zero.
     """
 
     remaining_actions: int = 0
     """Actions remaining on this schedule.
     
     Once this number hits 0, no further actions are scheduled automatically.
     """
@@ -3007,19 +3080,15 @@
             limited_actions=self.limited_actions,
             remaining_actions=self.remaining_actions,
         )
 
 
 @dataclass
 class Schedule:
-    """A schedule for periodically running an action.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """A schedule for periodically running an action."""
 
     action: ScheduleAction
     """Action taken when scheduled."""
 
     spec: ScheduleSpec
     """When the action is taken."""
 
@@ -3047,19 +3116,15 @@
             policies=self.policy._to_proto(),
             state=self.state._to_proto(),
         )
 
 
 @dataclass
 class ScheduleDescription:
-    """Description of a schedule.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Description of a schedule."""
 
     id: str
     """ID of the schedule."""
 
     schedule: Schedule
     """Schedule details that can be mutated."""
 
@@ -3156,19 +3221,15 @@
                 [payload], [type_hint] if type_hint else None
             )
         )[0]
 
 
 @dataclass
 class ScheduleInfo:
-    """Information about a schedule.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Information about a schedule."""
 
     num_actions: int
     """Number of actions taken by this schedule."""
 
     num_actions_missed_catchup_window: int
     """Number of times an action was skipped due to missing the catchup
     window."""
@@ -3212,30 +3273,22 @@
             last_updated_at=info.update_time.ToDatetime().replace(tzinfo=timezone.utc)
             if info.HasField("update_time")
             else None,
         )
 
 
 class ScheduleActionExecution(ABC):
-    """Base class for an action execution.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Base class for an action execution."""
 
     pass
 
 
 @dataclass
 class ScheduleActionExecutionStartWorkflow(ScheduleActionExecution):
-    """Execution of a scheduled workflow start.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Execution of a scheduled workflow start."""
 
     workflow_id: str
     """Workflow ID."""
 
     first_execution_run_id: str
     """Workflow run ID."""
 
@@ -3247,19 +3300,15 @@
             workflow_id=exec.workflow_id,
             first_execution_run_id=exec.run_id,
         )
 
 
 @dataclass
 class ScheduleActionResult:
-    """Information about when an action took place.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Information about when an action took place."""
 
     scheduled_at: datetime
     """Scheduled time of the action including jitter."""
 
     started_at: datetime
     """When the action actually started."""
 
@@ -3277,43 +3326,31 @@
                 res.start_workflow_result
             ),
         )
 
 
 @dataclass
 class ScheduleUpdateInput:
-    """Parameter for an update callback for :py:meth:`ScheduleHandle.update`.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Parameter for an update callback for :py:meth:`ScheduleHandle.update`."""
 
     description: ScheduleDescription
     """Current description of the schedule."""
 
 
 @dataclass
 class ScheduleUpdate:
-    """Result of an update callback for :py:meth:`ScheduleHandle.update`.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Result of an update callback for :py:meth:`ScheduleHandle.update`."""
 
     schedule: Schedule
     """Schedule to update."""
 
 
 @dataclass
 class ScheduleListDescription:
-    """Description of a listed schedule.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Description of a listed schedule."""
 
     id: str
     """ID of the schedule."""
 
     schedule: Optional[ScheduleListSchedule]
     """Schedule details that can be mutated.
     
@@ -3421,19 +3458,15 @@
                 [payload], [type_hint] if type_hint else None
             )
         )[0]
 
 
 @dataclass
 class ScheduleListSchedule:
-    """Details for a listed schedule.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Details for a listed schedule."""
 
     action: ScheduleListAction
     """Action taken when scheduled."""
 
     spec: ScheduleSpec
     """When the action is taken."""
 
@@ -3451,42 +3484,30 @@
             action=ScheduleListActionStartWorkflow(workflow=info.workflow_type.name),
             spec=ScheduleSpec._from_proto(info.spec),
             state=ScheduleListState._from_proto(info),
         )
 
 
 class ScheduleListAction(ABC):
-    """Base class for an action a listed schedule can take.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Base class for an action a listed schedule can take."""
 
     pass
 
 
 @dataclass
 class ScheduleListActionStartWorkflow(ScheduleListAction):
-    """Action to start a workflow on a listed schedule.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Action to start a workflow on a listed schedule."""
 
     workflow: str
     """Workflow type name."""
 
 
 @dataclass
 class ScheduleListInfo:
-    """Information about a listed schedule.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Information about a listed schedule."""
 
     recent_actions: Sequence[ScheduleActionResult]
     """Most recent actions, oldest first.
     
     This may be a smaller amount than present on
     :py:attr:`ScheduleDescription.info`.
     """
@@ -3511,19 +3532,15 @@
                 for f in info.future_action_times
             ],
         )
 
 
 @dataclass
 class ScheduleListState:
-    """State of a listed schedule.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """State of a listed schedule."""
 
     note: Optional[str]
     """Human readable message for the schedule.
     
     The system may overwrite this value on certain conditions like
     pause-on-failure.
     """
@@ -3695,19 +3712,15 @@
 
     def __init__(self) -> None:
         """Create async activity cancelled error."""
         super().__init__("Activity cancelled")
 
 
 class ScheduleAlreadyRunningError(temporalio.exceptions.TemporalError):
-    """Error when a schedule is already running.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Error when a schedule is already running."""
 
     def __init__(self) -> None:
         """Create schedule already running error."""
         super().__init__("Schedule already running")
 
 
 @dataclass
@@ -3863,144 +3876,139 @@
     details: Sequence[Any]
     rpc_metadata: Mapping[str, str]
     rpc_timeout: Optional[timedelta]
 
 
 @dataclass
 class CreateScheduleInput:
-    """Input for :py:meth:`OutboundInterceptor.create_schedule`.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Input for :py:meth:`OutboundInterceptor.create_schedule`."""
 
     id: str
     schedule: Schedule
     trigger_immediately: bool
     backfill: Sequence[ScheduleBackfill]
     memo: Optional[Mapping[str, Any]]
     search_attributes: Optional[temporalio.common.SearchAttributes]
     rpc_metadata: Mapping[str, str]
     rpc_timeout: Optional[timedelta]
 
 
 @dataclass
 class ListSchedulesInput:
-    """Input for :py:meth:`OutboundInterceptor.list_schedules`.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Input for :py:meth:`OutboundInterceptor.list_schedules`."""
 
     page_size: int
     next_page_token: Optional[bytes]
     rpc_metadata: Mapping[str, str]
     rpc_timeout: Optional[timedelta]
 
 
 @dataclass
 class BackfillScheduleInput:
-    """Input for :py:meth:`OutboundInterceptor.backfill_schedule`.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Input for :py:meth:`OutboundInterceptor.backfill_schedule`."""
 
     id: str
     backfills: Sequence[ScheduleBackfill]
     rpc_metadata: Mapping[str, str]
     rpc_timeout: Optional[timedelta]
 
 
 @dataclass
 class DeleteScheduleInput:
-    """Input for :py:meth:`OutboundInterceptor.delete_schedule`.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Input for :py:meth:`OutboundInterceptor.delete_schedule`."""
 
     id: str
     rpc_metadata: Mapping[str, str]
     rpc_timeout: Optional[timedelta]
 
 
 @dataclass
 class DescribeScheduleInput:
-    """Input for :py:meth:`OutboundInterceptor.describe_schedule`.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Input for :py:meth:`OutboundInterceptor.describe_schedule`."""
 
     id: str
     rpc_metadata: Mapping[str, str]
     rpc_timeout: Optional[timedelta]
 
 
 @dataclass
 class PauseScheduleInput:
-    """Input for :py:meth:`OutboundInterceptor.pause_schedule`.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Input for :py:meth:`OutboundInterceptor.pause_schedule`."""
 
     id: str
     note: Optional[str]
     rpc_metadata: Mapping[str, str]
     rpc_timeout: Optional[timedelta]
 
 
 @dataclass
 class TriggerScheduleInput:
-    """Input for :py:meth:`OutboundInterceptor.trigger_schedule`.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Input for :py:meth:`OutboundInterceptor.trigger_schedule`."""
 
     id: str
     overlap: Optional[ScheduleOverlapPolicy]
     rpc_metadata: Mapping[str, str]
     rpc_timeout: Optional[timedelta]
 
 
 @dataclass
 class UnpauseScheduleInput:
-    """Input for :py:meth:`OutboundInterceptor.unpause_schedule`.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Input for :py:meth:`OutboundInterceptor.unpause_schedule`."""
 
     id: str
     note: Optional[str]
     rpc_metadata: Mapping[str, str]
     rpc_timeout: Optional[timedelta]
 
 
 @dataclass
 class UpdateScheduleInput:
-    """Input for :py:meth:`OutboundInterceptor.update_schedule`.
-
-    .. warning::
-        Schedules are an experimental feature.
-    """
+    """Input for :py:meth:`OutboundInterceptor.update_schedule`."""
 
     id: str
     updater: Callable[
         [ScheduleUpdateInput],
         Union[Optional[ScheduleUpdate], Awaitable[Optional[ScheduleUpdate]]],
     ]
     rpc_metadata: Mapping[str, str]
     rpc_timeout: Optional[timedelta]
 
 
 @dataclass
+class UpdateWorkerBuildIdCompatibilityInput:
+    """Input for :py:meth:`OutboundInterceptor.update_worker_build_id_compatibility`."""
+
+    task_queue: str
+    operation: BuildIdOp
+    rpc_metadata: Mapping[str, str]
+    rpc_timeout: Optional[timedelta]
+
+
+@dataclass
+class GetWorkerBuildIdCompatibilityInput:
+    """Input for :py:meth:`OutboundInterceptor.get_worker_build_id_compatibility`."""
+
+    task_queue: str
+    max_sets: Optional[int]
+    rpc_metadata: Mapping[str, str]
+    rpc_timeout: Optional[timedelta]
+
+
+@dataclass
+class GetWorkerTaskReachabilityInput:
+    """Input for :py:meth:`OutboundInterceptor.get_worker_build_id_reachability`."""
+
+    build_ids: Sequence[str]
+    task_queues: Sequence[str]
+    reachability: Optional[TaskReachabilityType]
+    rpc_metadata: Mapping[str, str]
+    rpc_timeout: Optional[timedelta]
+
+
+@dataclass
 class Interceptor:
     """Interceptor for clients.
 
     This should be extended by any client interceptors.
     """
 
     def intercept_client(self, next: OutboundInterceptor) -> OutboundInterceptor:
@@ -4131,14 +4139,32 @@
         """Called for every :py:meth:`ScheduleHandle.unpause` call."""
         await self.next.unpause_schedule(input)
 
     async def update_schedule(self, input: UpdateScheduleInput) -> None:
         """Called for every :py:meth:`ScheduleHandle.update` call."""
         await self.next.update_schedule(input)
 
+    async def update_worker_build_id_compatibility(
+        self, input: UpdateWorkerBuildIdCompatibilityInput
+    ) -> None:
+        """Called for every :py:meth:`Client.update_worker_build_id_compatibility` call."""
+        await self.next.update_worker_build_id_compatibility(input)
+
+    async def get_worker_build_id_compatibility(
+        self, input: GetWorkerBuildIdCompatibilityInput
+    ) -> WorkerBuildIdVersionSets:
+        """Called for every :py:meth:`Client.get_worker_build_id_compatibility` call."""
+        return await self.next.get_worker_build_id_compatibility(input)
+
+    async def get_worker_task_reachability(
+        self, input: GetWorkerTaskReachabilityInput
+    ) -> WorkerTaskReachability:
+        """Called for every :py:meth:`Client.get_worker_build_id_reachability` call."""
+        return await self.next.get_worker_task_reachability(input)
+
 
 class _ClientImpl(OutboundInterceptor):
     def __init__(self, client: Client) -> None:
         # We are intentionally not calling the base class's __init__ here
         self._client = client
 
     ### Workflow calls
@@ -4524,14 +4550,31 @@
                 metadata=input.rpc_metadata,
                 timeout=input.rpc_timeout,
             )
 
     ### Schedule calls
 
     async def create_schedule(self, input: CreateScheduleInput) -> ScheduleHandle:
+        # Limited actions must be false if remaining actions is 0 and must be
+        # true if remaining actions is non-zero
+        if (
+            input.schedule.state.limited_actions
+            and not input.schedule.state.remaining_actions
+        ):
+            raise ValueError(
+                "Must set limited actions to false if there are no remaining actions set"
+            )
+        if (
+            not input.schedule.state.limited_actions
+            and input.schedule.state.remaining_actions
+        ):
+            raise ValueError(
+                "Must set limited actions to true if there are remaining actions set"
+            )
+
         initial_patch: Optional[temporalio.api.schedule.v1.SchedulePatch] = None
         if input.trigger_immediately or input.backfill:
             initial_patch = temporalio.api.schedule.v1.SchedulePatch(
                 trigger_immediately=temporalio.api.schedule.v1.TriggerImmediatelyRequest(
                     overlap_policy=temporalio.api.enums.v1.ScheduleOverlapPolicy.ValueType(
                         input.schedule.policy.overlap
                     ),
@@ -4721,14 +4764,53 @@
                 request_id=str(uuid.uuid4()),
             ),
             retry=True,
             metadata=input.rpc_metadata,
             timeout=input.rpc_timeout,
         )
 
+    async def update_worker_build_id_compatibility(
+        self, input: UpdateWorkerBuildIdCompatibilityInput
+    ) -> None:
+        req = input.operation._as_partial_proto()
+        req.namespace = self._client.namespace
+        req.task_queue = input.task_queue
+        await self._client.workflow_service.update_worker_build_id_compatibility(
+            req, retry=True, metadata=input.rpc_metadata, timeout=input.rpc_timeout
+        )
+
+    async def get_worker_build_id_compatibility(
+        self, input: GetWorkerBuildIdCompatibilityInput
+    ) -> WorkerBuildIdVersionSets:
+        req = temporalio.api.workflowservice.v1.GetWorkerBuildIdCompatibilityRequest(
+            namespace=self._client.namespace,
+            task_queue=input.task_queue,
+            max_sets=input.max_sets or 0,
+        )
+        resp = await self._client.workflow_service.get_worker_build_id_compatibility(
+            req, retry=True, metadata=input.rpc_metadata, timeout=input.rpc_timeout
+        )
+        return WorkerBuildIdVersionSets._from_proto(resp)
+
+    async def get_worker_task_reachability(
+        self, input: GetWorkerTaskReachabilityInput
+    ) -> WorkerTaskReachability:
+        req = temporalio.api.workflowservice.v1.GetWorkerTaskReachabilityRequest(
+            namespace=self._client.namespace,
+            build_ids=input.build_ids,
+            task_queues=input.task_queues,
+            reachability=input.reachability._to_proto()
+            if input.reachability
+            else temporalio.api.enums.v1.TaskReachability.TASK_REACHABILITY_UNSPECIFIED,
+        )
+        resp = await self._client.workflow_service.get_worker_task_reachability(
+            req, retry=True, metadata=input.rpc_metadata, timeout=input.rpc_timeout
+        )
+        return WorkerTaskReachability._from_proto(resp)
+
 
 def _history_from_json(
     history: Union[str, Dict[str, Any]]
 ) -> temporalio.api.history.v1.History:
     if isinstance(history, str):
         history = json.loads(history)
     else:
@@ -4843,7 +4925,277 @@
                 )
         elif isinstance(child, dict) and len(attrs) > 1:
             _fix_history_enum(prefix, child, *attrs[1:])
         elif isinstance(child, list) and len(attrs) > 1:
             for child_item in child:
                 if isinstance(child_item, dict):
                     _fix_history_enum(prefix, child_item, *attrs[1:])
+
+
+@dataclass(frozen=True)
+class WorkerBuildIdVersionSets:
+    """Represents the sets of compatible Build ID versions associated with some Task Queue, as
+    fetched by :py:meth:`Client.get_worker_build_id_compatibility`.
+    """
+
+    version_sets: Sequence[BuildIdVersionSet]
+    """All version sets that were fetched for this task queue."""
+
+    def default_set(self) -> BuildIdVersionSet:
+        """Returns the default version set for this task queue."""
+        return self.version_sets[-1]
+
+    def default_build_id(self) -> str:
+        """Returns the default Build ID for this task queue."""
+        return self.default_set().default()
+
+    @staticmethod
+    def _from_proto(
+        resp: temporalio.api.workflowservice.v1.GetWorkerBuildIdCompatibilityResponse,
+    ) -> WorkerBuildIdVersionSets:
+        return WorkerBuildIdVersionSets(
+            version_sets=[
+                BuildIdVersionSet(mvs.build_ids) for mvs in resp.major_version_sets
+            ]
+        )
+
+
+@dataclass(frozen=True)
+class BuildIdVersionSet:
+    """A set of Build IDs which are compatible with each other."""
+
+    build_ids: Sequence[str]
+    """All Build IDs contained in the set."""
+
+    def default(self) -> str:
+        """Returns the default Build ID for this set."""
+        return self.build_ids[-1]
+
+
+class BuildIdOp(ABC):
+    """Base class for Build ID operations as used by
+    :py:meth:`Client.update_worker_build_id_compatibility`.
+    """
+
+    @abstractmethod
+    def _as_partial_proto(
+        self,
+    ) -> temporalio.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest:
+        """Returns a partial request with the operation populated. Caller must populate
+        non-operation fields. This is done b/c there's no good way to assign a non-primitive message
+        as the operation after initializing the request.
+        """
+        ...
+
+
+@dataclass(frozen=True)
+class BuildIdOpAddNewDefault(BuildIdOp):
+    """Adds a new Build Id into a new set, which will be used as the default set for
+    the queue. This means all new workflows will start on this Build Id.
+    """
+
+    build_id: str
+
+    def _as_partial_proto(
+        self,
+    ) -> temporalio.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest:
+        return (
+            temporalio.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest(
+                add_new_build_id_in_new_default_set=self.build_id
+            )
+        )
+
+
+@dataclass(frozen=True)
+class BuildIdOpAddNewCompatible(BuildIdOp):
+    """Adds a new Build Id into an existing compatible set. The newly added ID becomes
+    the default for that compatible set, and thus new workflow tasks for workflows which have been
+    executing on workers in that set will now start on this new Build Id.
+    """
+
+    build_id: str
+    """The Build Id to add to the compatible set."""
+
+    existing_compatible_build_id: str
+    """A Build Id which must already be defined on the task queue, and is used to find the 
+    compatible set to add the new id to.
+    """
+
+    promote_set: bool = False
+    """If set to true, the targeted set will also be promoted to become the overall default set for
+    the queue."""
+
+    def _as_partial_proto(
+        self,
+    ) -> temporalio.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest:
+        return temporalio.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest(
+            add_new_compatible_build_id=temporalio.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest.AddNewCompatibleVersion(
+                new_build_id=self.build_id,
+                existing_compatible_build_id=self.existing_compatible_build_id,
+                make_set_default=self.promote_set,
+            )
+        )
+
+
+@dataclass(frozen=True)
+class BuildIdOpPromoteSetByBuildId(BuildIdOp):
+    """Promotes a set of compatible Build Ids to become the current default set for the task queue.
+    Any Build Id in the set may be used to target it.
+    """
+
+    build_id: str
+    """A Build Id which must already be defined on the task queue, and is used to find the 
+    compatible set to promote."""
+
+    def _as_partial_proto(
+        self,
+    ) -> temporalio.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest:
+        return (
+            temporalio.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest(
+                promote_set_by_build_id=self.build_id
+            )
+        )
+
+
+@dataclass(frozen=True)
+class BuildIdOpPromoteBuildIdWithinSet(BuildIdOp):
+    """Promotes a Build Id within an existing set to become the default ID for that set."""
+
+    build_id: str
+
+    def _as_partial_proto(
+        self,
+    ) -> temporalio.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest:
+        return (
+            temporalio.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest(
+                promote_build_id_within_set=self.build_id
+            )
+        )
+
+
+@dataclass(frozen=True)
+class BuildIdOpMergeSets(BuildIdOp):
+    """Merges two sets into one set, thus declaring all the Build Ids in both as compatible with one
+    another. The default of the primary set is maintained as the merged set's overall default.
+    """
+
+    primary_build_id: str
+    """A Build Id which and is used to find the primary set to be merged."""
+
+    secondary_build_id: str
+    """A Build Id which and is used to find the secondary set to be merged."""
+
+    def _as_partial_proto(
+        self,
+    ) -> temporalio.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest:
+        return temporalio.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest(
+            merge_sets=temporalio.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest.MergeSets(
+                primary_set_build_id=self.primary_build_id,
+                secondary_set_build_id=self.secondary_build_id,
+            )
+        )
+
+
+@dataclass(frozen=True)
+class WorkerTaskReachability:
+    """Contains information about the reachability of some Build IDs"""
+
+    build_id_reachability: Mapping[str, BuildIdReachability]
+    """Maps Build IDs to information about their reachability"""
+
+    @staticmethod
+    def _from_proto(
+        resp: temporalio.api.workflowservice.v1.GetWorkerTaskReachabilityResponse,
+    ) -> WorkerTaskReachability:
+        mapping = dict()
+        for bid_reach in resp.build_id_reachability:
+            tq_mapping = dict()
+            unretrieved = set()
+            for tq_reach in bid_reach.task_queue_reachability:
+                if tq_reach.reachability == [
+                    temporalio.api.enums.v1.TaskReachability.TASK_REACHABILITY_UNSPECIFIED
+                ]:
+                    unretrieved.add(tq_reach.task_queue)
+                    continue
+                tq_mapping[tq_reach.task_queue] = [
+                    TaskReachabilityType._from_proto(r) for r in tq_reach.reachability
+                ]
+
+            mapping[bid_reach.build_id] = BuildIdReachability(
+                task_queue_reachability=tq_mapping,
+                unretrieved_task_queues=frozenset(unretrieved),
+            )
+
+        return WorkerTaskReachability(build_id_reachability=mapping)
+
+
+@dataclass(frozen=True)
+class BuildIdReachability:
+    """Contains information about the reachability of a specific Build ID"""
+
+    task_queue_reachability: Mapping[str, Sequence[TaskReachabilityType]]
+    """Maps Task Queue names to the reachability status of the Build ID on that queue. If the value
+    is an empty list, the Build ID is not reachable on that queue.
+    """
+
+    unretrieved_task_queues: FrozenSet[str]
+    """If any Task Queues could not be retrieved because the server limits the number that can be 
+    queried at once, they will be listed here.
+    """
+
+
+class TaskReachabilityType(Enum):
+    """Enumerates how a task might reach certain kinds of workflows"""
+
+    NEW_WORKFLOWS = 1
+    EXISTING_WORKFLOWS = 2
+    OPEN_WORKFLOWS = 3
+    CLOSED_WORKFLOWS = 4
+
+    @staticmethod
+    def _from_proto(
+        reachability: temporalio.api.enums.v1.TaskReachability.ValueType,
+    ) -> TaskReachabilityType:
+        if (
+            reachability
+            == temporalio.api.enums.v1.TaskReachability.TASK_REACHABILITY_NEW_WORKFLOWS
+        ):
+            return TaskReachabilityType.NEW_WORKFLOWS
+        elif (
+            reachability
+            == temporalio.api.enums.v1.TaskReachability.TASK_REACHABILITY_EXISTING_WORKFLOWS
+        ):
+            return TaskReachabilityType.EXISTING_WORKFLOWS
+        elif (
+            reachability
+            == temporalio.api.enums.v1.TaskReachability.TASK_REACHABILITY_OPEN_WORKFLOWS
+        ):
+            return TaskReachabilityType.OPEN_WORKFLOWS
+        elif (
+            reachability
+            == temporalio.api.enums.v1.TaskReachability.TASK_REACHABILITY_CLOSED_WORKFLOWS
+        ):
+            return TaskReachabilityType.CLOSED_WORKFLOWS
+        else:
+            raise ValueError(f"Cannot convert reachability type: {reachability}")
+
+    def _to_proto(self) -> temporalio.api.enums.v1.TaskReachability.ValueType:
+        if self == TaskReachabilityType.NEW_WORKFLOWS:
+            return (
+                temporalio.api.enums.v1.TaskReachability.TASK_REACHABILITY_NEW_WORKFLOWS
+            )
+        elif self == TaskReachabilityType.EXISTING_WORKFLOWS:
+            return (
+                temporalio.api.enums.v1.TaskReachability.TASK_REACHABILITY_EXISTING_WORKFLOWS
+            )
+        elif self == TaskReachabilityType.OPEN_WORKFLOWS:
+            return (
+                temporalio.api.enums.v1.TaskReachability.TASK_REACHABILITY_OPEN_WORKFLOWS
+            )
+        elif self == TaskReachabilityType.CLOSED_WORKFLOWS:
+            return (
+                temporalio.api.enums.v1.TaskReachability.TASK_REACHABILITY_CLOSED_WORKFLOWS
+            )
+        else:
+            return (
+                temporalio.api.enums.v1.TaskReachability.TASK_REACHABILITY_UNSPECIFIED
+            )
```

### Comparing `temporalio-1.2.0/temporalio/common.py` & `temporalio-1.3.0/temporalio/common.py`

 * *Files 10% similar despite different names*

```diff
@@ -134,14 +134,42 @@
         temporalio.api.enums.v1.QueryRejectCondition.QUERY_REJECT_CONDITION_NOT_OPEN
     )
     NOT_COMPLETED_CLEANLY = int(
         temporalio.api.enums.v1.QueryRejectCondition.QUERY_REJECT_CONDITION_NOT_COMPLETED_CLEANLY
     )
 
 
+@dataclass(frozen=True)
+class RawValue:
+    """Representation of an unconverted, raw payload.
+
+    This type can be used as a parameter or return type in workflows,
+    activities, signals, and queries to pass through a raw payload.
+    Encoding/decoding of the payload is still done by the system.
+    """
+
+    payload: temporalio.api.common.v1.Payload
+
+    def __getstate__(self) -> object:
+        """Pickle support."""
+        # We'll convert payload to bytes and prepend a version number just in
+        # case we want to extend in the future
+        return b"1" + self.payload.SerializeToString()
+
+    def __setstate__(self, state: object) -> None:
+        """Pickle support."""
+        if not isinstance(state, bytes):
+            raise TypeError(f"Expected bytes state, got {type(state)}")
+        if not state[:1] == b"1":
+            raise ValueError("Bad version prefix")
+        object.__setattr__(
+            self, "payload", temporalio.api.common.v1.Payload.FromString(state[1:])
+        )
+
+
 # We choose to make this a list instead of an sequence so we can catch if people
 # are not sending lists each time but maybe accidentally sending a string (which
 # is a sequence)
 SearchAttributeValues: TypeAlias = Union[
     List[str], List[int], List[float], List[bool], List[datetime]
 ]
 
@@ -228,15 +256,18 @@
     ret = ret_hint if ret_hint is not inspect.Signature.empty else None
     args: List[Type] = []
     for index, value in enumerate(sig.parameters.values()):
         # Ignore self on methods
         if (
             index == 0
             and value.name == "self"
-            and value.annotation is inspect.Parameter.empty
+            and (
+                value.annotation is inspect.Parameter.empty
+                or str(value.annotation) == "typing.Self"
+            )
         ):
             continue
         # Stop if non-positional or not a class
         if (
             value.kind is not inspect.Parameter.POSITIONAL_ONLY
             and value.kind is not inspect.Parameter.POSITIONAL_OR_KEYWORD
         ):
```

### Comparing `temporalio-1.2.0/temporalio/contrib/opentelemetry.py` & `temporalio-1.3.0/temporalio/contrib/opentelemetry.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/converter.py` & `temporalio-1.3.0/temporalio/converter.py`

 * *Files 2% similar despite different names*

```diff
@@ -27,26 +27,28 @@
     Optional,
     Sequence,
     Tuple,
     Type,
     TypeVar,
     Union,
     get_type_hints,
+    overload,
 )
 
 import google.protobuf.json_format
 import google.protobuf.message
 import google.protobuf.symbol_database
 from typing_extensions import Literal
 
 import temporalio.api.common.v1
 import temporalio.api.enums.v1
 import temporalio.api.failure.v1
 import temporalio.common
 import temporalio.exceptions
+import temporalio.types
 
 if sys.version_info < (3, 11):
     # Python's datetime.fromisoformat doesn't support certain formats pre-3.11
     from dateutil import parser  # type: ignore
 # StrEnum is available in 3.11+
 if sys.version_info >= (3, 11):
     from enum import StrEnum
@@ -63,14 +65,17 @@
 
     @abstractmethod
     def to_payloads(
         self, values: Sequence[Any]
     ) -> List[temporalio.api.common.v1.Payload]:
         """Encode values into payloads.
 
+        Implementers are expected to just return the payload for
+        :py:class:`temporalio.common.RawValue`.
+
         Args:
             values: Values to be converted.
 
         Returns:
             Converted payloads. Note, this does not have to be the same number
             as values given, but must be at least one and cannot be more than
             was given.
@@ -84,14 +89,17 @@
     def from_payloads(
         self,
         payloads: Sequence[temporalio.api.common.v1.Payload],
         type_hints: Optional[List[Type]] = None,
     ) -> List[Any]:
         """Decode payloads into values.
 
+        Implementers are expected to treat a type hint of
+        :py:class:`temporalio.common.RawValue` as just the raw value.
+
         Args:
             payloads: Payloads to convert to Python values.
             type_hints: Types that are expected if any. This may not have any
                 types if there are no annotations on the target. If this is
                 present, it must have the exact same length as payloads even if
                 the values are just "object".
 
@@ -118,14 +126,59 @@
         """:py:meth:`from_payloads` for the
         :py:class:`temporalio.api.common.v1.Payloads` wrapper.
         """
         if not payloads or not payloads.payloads:
             return []
         return self.from_payloads(payloads.payloads)
 
+    def to_payload(self, value: Any) -> temporalio.api.common.v1.Payload:
+        """Convert a single value to a payload.
+
+        This is a shortcut for :py:meth:`to_payloads` with a single-item list
+        and result.
+
+        Args:
+            value: Value to convert to a single payload.
+
+        Returns:
+            Single converted payload.
+        """
+        return self.to_payloads([value])[0]
+
+    @overload
+    def from_payload(self, payload: temporalio.api.common.v1.Payload) -> Any:
+        ...
+
+    @overload
+    def from_payload(
+        self,
+        payload: temporalio.api.common.v1.Payload,
+        type_hint: Type[temporalio.types.AnyType],
+    ) -> temporalio.types.AnyType:
+        ...
+
+    def from_payload(
+        self,
+        payload: temporalio.api.common.v1.Payload,
+        type_hint: Optional[Type] = None,
+    ) -> Any:
+        """Convert a single payload to a value.
+
+        This is a shortcut for :py:meth:`from_payloads` with a single-item list
+        and result.
+
+        Args:
+            payload: Payload to convert to value.
+            type_hint: Optional type hint to say which type to convert to.
+
+        Returns:
+            Single converted value.
+        """
+        return self.from_payloads([payload], [type_hint] if type_hint else None)[0]
+
 
 class EncodingPayloadConverter(ABC):
     """Base converter to/from single payload/value with a known encoding for use in CompositePayloadConverter."""
 
     @property
     @abstractmethod
     def encoding(self) -> str:
@@ -205,18 +258,22 @@
             RuntimeError: No known converter
         """
         payloads = []
         for index, value in enumerate(values):
             # We intentionally attempt these serially just in case a stateful
             # converter may rely on the previous values
             payload = None
-            for converter in self.converters.values():
-                payload = converter.to_payload(value)
-                if payload is not None:
-                    break
+            # RawValue should just pass through
+            if isinstance(value, temporalio.common.RawValue):
+                payload = value.payload
+            else:
+                for converter in self.converters.values():
+                    payload = converter.to_payload(value)
+                    if payload is not None:
+                        break
             if payload is None:
                 raise RuntimeError(
                     f"Value at index {index} of type {type(value)} has no known converter"
                 )
             payloads.append(payload)
         return payloads
 
@@ -231,21 +288,25 @@
 
         Raises:
             KeyError: Unknown payload encoding
             RuntimeError: Error during decode
         """
         values = []
         for index, payload in enumerate(payloads):
+            type_hint = None
+            if type_hints and len(type_hints) > index:
+                type_hint = type_hints[index]
+            # Raw value should just wrap
+            if type_hint == temporalio.common.RawValue:
+                values.append(temporalio.common.RawValue(payload))
+                continue
             encoding = payload.metadata.get("encoding", b"<unknown>")
             converter = self.converters.get(encoding)
             if converter is None:
                 raise KeyError(f"Unknown payload encoding {encoding.decode()}")
-            type_hint = None
-            if type_hints is not None:
-                type_hint = type_hints[index]
             try:
                 values.append(converter.from_payload(payload, type_hint))
             except RuntimeError as err:
                 raise RuntimeError(
                     f"Payload at index {index} with encoding {encoding.decode()} could not be converted"
                 ) from err
         return values
```

### Comparing `temporalio-1.2.0/temporalio/exceptions.py` & `temporalio-1.3.0/temporalio/exceptions.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,9 +1,10 @@
 """Common Temporal exceptions."""
 
+import asyncio
 from enum import IntEnum
 from typing import Any, Optional, Sequence, Tuple
 
 import temporalio.api.common.v1
 import temporalio.api.enums.v1
 import temporalio.api.failure.v1
 
@@ -318,7 +319,36 @@
         """Started event ID for this error."""
         return self._started_event_id
 
     @property
     def retry_state(self) -> Optional[RetryState]:
         """Retry state for this error."""
         return self._retry_state
+
+
+def is_cancelled_exception(exception: BaseException) -> bool:
+    """Check whether the given exception is considered a cancellation exception
+    according to Temporal.
+
+    This is often used in a conditional of a catch clause to check whether a
+    cancel occurred inside of a workflow. This can occur from
+    :py:class:`asyncio.CancelledError` or :py:class:`CancelledError` or either
+    :py:class:`ActivityError` or :py:class:`ChildWorkflowError` if either of
+    those latter two have a :py:class:`CancelledError` cause.
+
+    Args:
+        exception: Exception to check.
+
+    Returns:
+        True if a cancelled exception, false if not.
+    """
+    return (
+        isinstance(exception, asyncio.CancelledError)
+        or isinstance(exception, CancelledError)
+        or (
+            (
+                isinstance(exception, ActivityError)
+                or isinstance(exception, ChildWorkflowError)
+            )
+            and isinstance(exception.cause, CancelledError)
+        )
+    )
```

### Comparing `temporalio-1.2.0/temporalio/runtime.py` & `temporalio-1.3.0/temporalio/runtime.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/service.py` & `temporalio-1.3.0/temporalio/service.py`

 * *Files 2% similar despite different names*

```diff
@@ -21,15 +21,15 @@
 import temporalio.api.testservice.v1
 import temporalio.api.workflowservice.v1
 import temporalio.bridge.client
 import temporalio.bridge.proto.health.v1
 import temporalio.exceptions
 import temporalio.runtime
 
-__version__ = "1.2.0"
+__version__ = "1.3.0"
 
 ServiceRequest = TypeVar("ServiceRequest", bound=google.protobuf.message.Message)
 ServiceResponse = TypeVar("ServiceResponse", bound=google.protobuf.message.Message)
 
 logger = logging.getLogger(__name__)
 
 # Set to true to log all requests and responses
@@ -309,14 +309,19 @@
             wsv1.GetSystemInfoResponse,
         )
         self.get_worker_build_id_compatibility = client._new_call(
             "get_worker_build_id_compatibility",
             wsv1.GetWorkerBuildIdCompatibilityRequest,
             wsv1.GetWorkerBuildIdCompatibilityResponse,
         )
+        self.get_worker_task_reachability = client._new_call(
+            "get_worker_task_reachability",
+            wsv1.GetWorkerTaskReachabilityRequest,
+            wsv1.GetWorkerTaskReachabilityResponse,
+        )
         self.get_workflow_execution_history = client._new_call(
             "get_workflow_execution_history",
             wsv1.GetWorkflowExecutionHistoryRequest,
             wsv1.GetWorkflowExecutionHistoryResponse,
         )
         self.get_workflow_execution_history_reverse = client._new_call(
             "get_workflow_execution_history_reverse",
```

### Comparing `temporalio-1.2.0/temporalio/testing/_activity.py` & `temporalio-1.3.0/temporalio/testing/_activity.py`

 * *Files 6% similar despite different names*

```diff
@@ -8,14 +8,15 @@
 from contextlib import contextmanager
 from datetime import datetime, timedelta, timezone
 from typing import Any, Callable, Optional, Set, TypeVar
 
 from typing_extensions import ParamSpec
 
 import temporalio.activity
+import temporalio.converter
 import temporalio.exceptions
 import temporalio.worker._activity
 
 _Params = ParamSpec("_Params")
 _Return = TypeVar("_Return")
 
 _utc_zero = datetime.fromtimestamp(0).replace(tzinfo=timezone.utc)
@@ -48,20 +49,26 @@
     run an activity function or any function within an activity context.
 
     Attributes:
         info: The info that is returned from :py:func:`temporalio.activity.info`
             function.
         on_heartbeat: Function called on each heartbeat invocation by the
             activity.
+        payload_converter: Payload converter set on the activity context. This
+            must be set before :py:meth:`run`. Changes after the activity has
+            started do not take effect.
     """
 
     def __init__(self) -> None:
         """Create an ActivityEnvironment for running activity code."""
         self.info = _default_info
         self.on_heartbeat: Callable[..., None] = lambda *args: None
+        self.payload_converter = (
+            temporalio.converter.DataConverter.default.payload_converter
+        )
         self._cancelled = False
         self._worker_shutdown = False
         self._activities: Set[_Activity] = set()
 
     def cancel(self) -> None:
         """Cancel the activity.
 
@@ -135,14 +142,15 @@
             worker_shutdown_event=temporalio.activity._CompositeEvent(
                 thread_event=threading.Event(),
                 async_event=asyncio.Event() if self.is_async else None,
             ),
             shield_thread_cancel_exception=None
             if not self.cancel_thread_raiser
             else self.cancel_thread_raiser.shielded,
+            payload_converter_class_or_instance=env.payload_converter,
         )
         self.task: Optional[asyncio.Task] = None
 
     def run(self, *args, **kwargs) -> Any:
         if self.cancel_thread_raiser:
             thread_id = threading.current_thread().ident
             if thread_id is not None:
```

### Comparing `temporalio-1.2.0/temporalio/testing/_workflow.py` & `temporalio-1.3.0/temporalio/testing/_workflow.py`

 * *Files 16% similar despite different names*

```diff
@@ -87,39 +87,38 @@
         identity: Optional[str] = None,
         tls: bool | temporalio.client.TLSConfig = False,
         ip: str = "127.0.0.1",
         port: Optional[int] = None,
         download_dest_dir: Optional[str] = None,
         ui: bool = False,
         runtime: Optional[temporalio.runtime.Runtime] = None,
-        temporalite_existing_path: Optional[str] = None,
-        temporalite_database_filename: Optional[str] = None,
-        temporalite_log_format: str = "pretty",
-        temporalite_log_level: Optional[str] = "warn",
-        temporalite_download_version: str = "default",
-        temporalite_extra_args: Sequence[str] = [],
+        dev_server_existing_path: Optional[str] = None,
+        dev_server_database_filename: Optional[str] = None,
+        dev_server_log_format: str = "pretty",
+        dev_server_log_level: Optional[str] = "warn",
+        dev_server_download_version: str = "default",
+        dev_server_extra_args: Sequence[str] = [],
     ) -> WorkflowEnvironment:
         """Start a full Temporal server locally, downloading if necessary.
 
         This environment is good for testing full server capabilities, but does
         not support time skipping like :py:meth:`start_time_skipping` does.
         :py:attr:`supports_time_skipping` will always return ``False`` for this
         environment. :py:meth:`sleep` will sleep the actual amount of time and
         :py:meth:`get_current_time` will return the current time.
 
-        Internally, this uses
-        `Temporalite <https://github.com/temporalio/temporalite>`_. Which is a
-        self-contained binary for Temporal using Sqlite persistence. This will
-        download Temporalite to a temporary directory by default if it has not
-        already been downloaded before and ``temporalite_existing_path`` is not
-        set.
+        Internally, this uses the Temporal CLI dev server from
+        https://github.com/temporalio/cli. This is a self-contained binary for
+        Temporal using Sqlite persistence. This call will download the CLI to a
+        temporary directory by default if it has not already been downloaded
+        before and ``dev_server_existing_path`` is not set.
 
-        In the future, the Temporalite implementation may be changed to another
-        implementation. Therefore, all ``temporalite_`` prefixed parameters are
-        Temporalite specific and may not apply to newer versions.
+        In the future, the dev server implementation may be changed to another
+        implementation. Therefore, all ``dev_server_`` prefixed parameters are
+        dev-server specific and may not apply to newer versions.
 
         Args:
             namespace: Namespace name to use for this environment.
             data_converter: See parameter of the same name on
                 :py:meth:`temporalio.client.Client.connect`.
             interceptors: See parameter of the same name on
                 :py:meth:`temporalio.client.Client.connect`.
@@ -133,63 +132,63 @@
                 :py:meth:`temporalio.client.Client.connect`.
             tls: See parameter of the same name on
                 :py:meth:`temporalio.client.Client.connect`.
             ip: IP address to bind to, or 127.0.0.1 by default.
             port: Port number to bind to, or an OS-provided port by default.
             download_dest_dir: Directory to download binary to if a download is
                 needed. If unset, this is the system's temporary directory.
-            ui: If ``True``, will start a UI in Temporalite.
+            ui: If ``True``, will start a UI in the dev server.
             runtime: Specific runtime to use or default if unset.
-            temporalite_existing_path: Existing path to the Temporalite binary.
+            dev_server_existing_path: Existing path to the CLI binary.
                 If present, no download will be attempted to fetch the binary.
-            temporalite_database_filename: Path to the Sqlite database to use
-                for Temporalite. Unset default means only in-memory Sqlite will
-                be used.
-            temporalite_log_format: Log format for Temporalite.
-            temporalite_log_level: Log level to use for Temporalite. Default is
-                ``warn``, but if set to ``None`` this will translate the Python
-                logger's level to a Temporalite level.
-            temporalite_download_version: Specific Temporalite version to
-                download. Defaults to ``default`` which downloads the version
-                known to work best with this SDK.
-            temporalite_extra_args: Extra arguments for the Temporalite binary.
+            dev_server_database_filename: Path to the Sqlite database to use
+                for the dev server. Unset default means only in-memory Sqlite
+                will be used.
+            dev_server_log_format: Log format for the dev server.
+            dev_server_log_level: Log level to use for the dev server. Default
+                is ``warn``, but if set to ``None`` this will translate the
+                Python logger's level to a dev server log level.
+            dev_server_download_version: Specific CLI version to download.
+                Defaults to ``default`` which downloads the version known to
+                work best with this SDK.
+            dev_server_extra_args: Extra arguments for the CLI binary.
 
         Returns:
-            The started Temporalite workflow environment.
+            The started CLI dev server workflow environment.
         """
         # Use the logger's configured level if none given
-        if not temporalite_log_level:
+        if not dev_server_log_level:
             if logger.isEnabledFor(logging.DEBUG):
-                temporalite_log_level = "debug"
+                dev_server_log_level = "debug"
             elif logger.isEnabledFor(logging.INFO):
-                temporalite_log_level = "info"
+                dev_server_log_level = "info"
             elif logger.isEnabledFor(logging.WARNING):
-                temporalite_log_level = "warn"
+                dev_server_log_level = "warn"
             elif logger.isEnabledFor(logging.ERROR):
-                temporalite_log_level = "error"
+                dev_server_log_level = "error"
             else:
-                temporalite_log_level = "fatal"
-        # Start Temporalite
+                dev_server_log_level = "fatal"
+        # Start CLI dev server
         runtime = runtime or temporalio.runtime.Runtime.default()
-        server = await temporalio.bridge.testing.EphemeralServer.start_temporalite(
+        server = await temporalio.bridge.testing.EphemeralServer.start_dev_server(
             runtime._core_runtime,
-            temporalio.bridge.testing.TemporaliteConfig(
-                existing_path=temporalite_existing_path,
+            temporalio.bridge.testing.DevServerConfig(
+                existing_path=dev_server_existing_path,
                 sdk_name="sdk-python",
                 sdk_version=temporalio.service.__version__,
-                download_version=temporalite_download_version,
+                download_version=dev_server_download_version,
                 download_dest_dir=download_dest_dir,
                 namespace=namespace,
                 ip=ip,
                 port=port,
-                database_filename=temporalite_database_filename,
+                database_filename=dev_server_database_filename,
                 ui=ui,
-                log_format=temporalite_log_format,
-                log_level=temporalite_log_level,
-                extra_args=temporalite_extra_args,
+                log_format=dev_server_log_format,
+                log_level=dev_server_log_level,
+                extra_args=dev_server_extra_args,
             ),
         )
         # If we can't connect to the server, we should shut it down
         try:
             return _EphemeralServerWorkflowEnvironment(
                 await temporalio.client.Client.connect(
                     server.target,
```

### Comparing `temporalio-1.2.0/temporalio/types.py` & `temporalio-1.3.0/temporalio/types.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/worker/__init__.py` & `temporalio-1.3.0/temporalio/worker/__init__.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/worker/_activity.py` & `temporalio-1.3.0/temporalio/worker/_activity.py`

 * *Files 4% similar despite different names*

```diff
@@ -81,14 +81,15 @@
         self._worker_shutdown_event: Optional[
             temporalio.activity._CompositeEvent
         ] = None
         self._seen_sync_activity = False
 
         # Validate and build activity dict
         self._activities: Dict[str, temporalio.activity._Definition] = {}
+        self._dynamic_activity: Optional[temporalio.activity._Definition] = None
         for activity in activities:
             # Get definition
             defn = temporalio.activity._Definition.must_from_callable(activity)
             # Confirm name unique
             if defn.name in self._activities:
                 raise ValueError(f"More than one activity named {defn.name}")
 
@@ -123,15 +124,20 @@
                     # TODO(cretz): Is this too expensive/unnecessary?
                     try:
                         pickle.dumps(activity)
                     except Exception as err:
                         raise TypeError(
                             f"Activity {defn.name} must be picklable when using a process executor"
                         ) from err
-            self._activities[defn.name] = defn
+            if defn.name:
+                self._activities[defn.name] = defn
+            elif self._dynamic_activity:
+                raise TypeError("More than one dynamic activity")
+            else:
+                self._dynamic_activity = defn
 
     async def run(self) -> None:
         # Create a task that fails when we get a failure on the queue
         async def raise_from_queue() -> NoReturn:
             raise await self._fail_worker_exception_queue.get()
 
         exception_task = asyncio.create_task(raise_from_queue())
@@ -261,15 +267,17 @@
         # a try block so we can mark the workflow as failed on any error instead
         # of having error handling in the interceptor
         completion = temporalio.bridge.proto.ActivityTaskCompletion(
             task_token=task_token
         )
         try:
             # Find activity or fail
-            activity_def = self._activities.get(start.activity_type)
+            activity_def = self._activities.get(
+                start.activity_type, self._dynamic_activity
+            )
             if not activity_def:
                 activity_names = ", ".join(sorted(self._activities.keys()))
                 raise temporalio.exceptions.ApplicationError(
                     f"Activity function {start.activity_type} is not registered on this worker, available activities: {activity_names}",
                     type="NotFoundError",
                 )
 
@@ -313,31 +321,37 @@
             else:
                 # We have to set the async form of events
                 running_activity.cancelled_event = temporalio.activity._CompositeEvent(
                     thread_event=threading.Event(),
                     async_event=asyncio.Event(),
                 )
 
-            # Convert arguments. We only use arg type hints if they match the
-            # input count.
+            # Convert arguments. We use raw value for dynamic. Otherwise, we
+            # only use arg type hints if they match the input count.
             arg_types = activity_def.arg_types
-            if arg_types is not None and len(arg_types) != len(start.input):
+            if not activity_def.name:
+                # Dynamic is just the raw value for each input value
+                arg_types = [temporalio.common.RawValue] * len(start.input)
+            elif arg_types is not None and len(arg_types) != len(start.input):
                 arg_types = None
             try:
                 args = (
                     []
                     if not start.input
                     else await self._data_converter.decode(
                         start.input, type_hints=arg_types
                     )
                 )
             except Exception as err:
                 raise temporalio.exceptions.ApplicationError(
                     "Failed decoding arguments"
                 ) from err
+            # Put the args inside a list if dynamic
+            if not activity_def.name:
+                args = [args]
 
             # Convert heartbeat details
             # TODO(cretz): Allow some way to configure heartbeat type hinting?
             try:
                 heartbeat_details = (
                     []
                     if not start.heartbeat_details
@@ -395,14 +409,15 @@
                     info=lambda: info,
                     heartbeat=None,
                     cancelled_event=running_activity.cancelled_event,
                     worker_shutdown_event=self._worker_shutdown_event,
                     shield_thread_cancel_exception=None
                     if not running_activity.cancel_thread_raiser
                     else running_activity.cancel_thread_raiser.shielded,
+                    payload_converter_class_or_instance=self._data_converter.payload_converter,
                 )
             )
             temporalio.activity.logger.debug("Starting activity")
 
             # Build the interceptors chaining in reverse. We build a context right
             # now even though the info() can't be intercepted and heartbeat() will
             # fail. The interceptors may want to use the info() during init.
@@ -417,20 +432,15 @@
             result = await impl.execute_activity(input)
             # Convert result even if none. Since Python essentially only
             # supports single result types (even if they are tuples), we will do
             # the same.
             completion.result.completed.result.CopyFrom(
                 (await self._data_converter.encode([result]))[0]
             )
-        except (
-            Exception,
-            asyncio.CancelledError,
-            temporalio.exceptions.CancelledError,
-            temporalio.activity._CompleteAsyncError,
-        ) as err:
+        except BaseException as err:
             try:
                 if isinstance(err, temporalio.activity._CompleteAsyncError):
                     temporalio.activity.logger.debug("Completing asynchronously")
                     completion.result.will_complete_async.SetInParent()
                 elif (
                     isinstance(
                         err,
@@ -629,14 +639,22 @@
                 # Should always be present in worker, pre-checked on init
                 shared_manager = self._worker._shared_state_manager
                 assert shared_manager
                 heartbeat = await shared_manager.register_heartbeater(
                     info.task_token, ctx.heartbeat
                 )
 
+            # The payload converter is the already instantiated one for thread
+            # or the picklable class for non-thread
+            payload_converter_class_or_instance = (
+                self._worker._data_converter.payload_converter
+                if isinstance(input.executor, concurrent.futures.ThreadPoolExecutor)
+                else self._worker._data_converter.payload_converter_class
+            )
+
             try:
                 # Cancel and shutdown event always present here
                 cancelled_event = self._running_activity.cancelled_event
                 assert cancelled_event
                 worker_shutdown_event = self._worker._worker_shutdown_event
                 assert worker_shutdown_event
                 # Prepare func and args
@@ -644,14 +662,15 @@
                 args = [
                     info,
                     heartbeat,
                     self._running_activity.cancel_thread_raiser,
                     # Only thread event, this may cross a process boundary
                     cancelled_event.thread_event,
                     worker_shutdown_event.thread_event,
+                    payload_converter_class_or_instance,
                     input.fn,
                     *input.args,
                 ]
                 # If we're threaded, we want to pass the context through. We
                 # have to do this manually, see
                 # https://github.com/python/cpython/issues/78195.
                 if isinstance(input.executor, concurrent.futures.ThreadPoolExecutor):
@@ -686,14 +705,18 @@
 def _execute_sync_activity(
     info: temporalio.activity.Info,
     heartbeat: Union[Callable[..., None], SharedHeartbeatSender],
     # This is only set for threaded activities
     cancel_thread_raiser: Optional[_ThreadExceptionRaiser],
     cancelled_event: threading.Event,
     worker_shutdown_event: threading.Event,
+    payload_converter_class_or_instance: Union[
+        Type[temporalio.converter.PayloadConverter],
+        temporalio.converter.PayloadConverter,
+    ],
     fn: Callable[..., Any],
     *args: Any,
 ) -> Any:
     if cancel_thread_raiser:
         thread_id = threading.current_thread().ident
         if thread_id is not None:
             cancel_thread_raiser.set_thread_id(thread_id)
@@ -715,14 +738,15 @@
             ),
             worker_shutdown_event=temporalio.activity._CompositeEvent(
                 thread_event=worker_shutdown_event, async_event=None
             ),
             shield_thread_cancel_exception=None
             if not cancel_thread_raiser
             else cancel_thread_raiser.shielded,
+            payload_converter_class_or_instance=payload_converter_class_or_instance,
         )
     )
     return fn(*args)
 
 
 class SharedStateManager(ABC):
     """Base class for a shared state manager providing cross-process-safe
```

### Comparing `temporalio-1.2.0/temporalio/worker/_interceptor.py` & `temporalio-1.3.0/temporalio/worker/_interceptor.py`

 * *Files 2% similar despite different names*

```diff
@@ -18,14 +18,15 @@
     Type,
 )
 
 import temporalio.activity
 import temporalio.api.common.v1
 import temporalio.common
 import temporalio.workflow
+from temporalio.workflow import VersioningIntent
 
 
 class Interceptor:
     """Interceptor for workers.
 
     This should be extended by any worker interceptors.
     """
@@ -150,14 +151,15 @@
     task_queue: Optional[str]
     run_timeout: Optional[timedelta]
     task_timeout: Optional[timedelta]
     retry_policy: Optional[temporalio.common.RetryPolicy]
     memo: Optional[Mapping[str, Any]]
     search_attributes: Optional[temporalio.common.SearchAttributes]
     headers: Mapping[str, temporalio.api.common.v1.Payload]
+    versioning_intent: Optional[VersioningIntent]
     # The types may be absent
     arg_types: Optional[List[Type]]
 
 
 @dataclass
 class ExecuteWorkflowInput:
     """Input for :py:meth:`WorkflowInboundInterceptor.execute_workflow`."""
@@ -222,14 +224,15 @@
     schedule_to_start_timeout: Optional[timedelta]
     start_to_close_timeout: Optional[timedelta]
     heartbeat_timeout: Optional[timedelta]
     retry_policy: Optional[temporalio.common.RetryPolicy]
     cancellation_type: temporalio.workflow.ActivityCancellationType
     headers: Mapping[str, temporalio.api.common.v1.Payload]
     disable_eager_execution: bool
+    versioning_intent: Optional[VersioningIntent]
     # The types may be absent
     arg_types: Optional[List[Type]]
     ret_type: Optional[Type]
 
 
 @dataclass
 class StartChildWorkflowInput:
@@ -246,14 +249,15 @@
     task_timeout: Optional[timedelta]
     id_reuse_policy: temporalio.common.WorkflowIDReusePolicy
     retry_policy: Optional[temporalio.common.RetryPolicy]
     cron_schedule: str
     memo: Optional[Mapping[str, Any]]
     search_attributes: Optional[temporalio.common.SearchAttributes]
     headers: Mapping[str, temporalio.api.common.v1.Payload]
+    versioning_intent: Optional[VersioningIntent]
     # The types may be absent
     arg_types: Optional[List[Type]]
     ret_type: Optional[Type]
 
 
 @dataclass
 class StartLocalActivityInput:
```

### Comparing `temporalio-1.2.0/temporalio/worker/_replayer.py` & `temporalio-1.3.0/temporalio/worker/_replayer.py`

 * *Files 0% similar despite different names*

```diff
@@ -158,28 +158,29 @@
             runtime._core_runtime,
             temporalio.bridge.worker.WorkerConfig(
                 namespace=self._config["namespace"],
                 task_queue=task_queue,
                 build_id=self._config["build_id"] or load_default_build_id(),
                 identity_override=self._config["identity"],
                 # All values below are ignored but required by Core
-                max_cached_workflows=1,
-                max_outstanding_workflow_tasks=1,
+                max_cached_workflows=2,
+                max_outstanding_workflow_tasks=2,
                 max_outstanding_activities=1,
                 max_outstanding_local_activities=1,
                 max_concurrent_workflow_task_polls=1,
                 nonsticky_to_sticky_poll_ratio=1,
                 max_concurrent_activity_task_polls=1,
                 no_remote_activities=True,
                 sticky_queue_schedule_to_start_timeout_millis=1000,
                 max_heartbeat_throttle_interval_millis=1000,
                 default_heartbeat_throttle_interval_millis=1000,
                 max_activities_per_second=None,
                 max_task_queue_activities_per_second=None,
                 graceful_shutdown_period_millis=0,
+                use_worker_versioning=False,
             ),
         )
 
         try:
             last_replay_failure: Optional[Exception]
             last_replay_complete = asyncio.Event()
```

### Comparing `temporalio-1.2.0/temporalio/worker/_worker.py` & `temporalio-1.3.0/temporalio/worker/_worker.py`

 * *Files 2% similar despite different names*

```diff
@@ -71,14 +71,15 @@
         max_activities_per_second: Optional[float] = None,
         max_task_queue_activities_per_second: Optional[float] = None,
         graceful_shutdown_timeout: timedelta = timedelta(),
         shared_state_manager: Optional[SharedStateManager] = None,
         debug_mode: bool = False,
         disable_eager_activity_execution: bool = False,
         on_fatal_error: Optional[Callable[[BaseException], Awaitable[None]]] = None,
+        use_worker_versioning: bool = False,
     ) -> None:
         """Create a worker to process workflows and/or activities.
 
         Args:
             client: Client to use for this worker. This is required and must be
                 the :py:class:`temporalio.client.Client` instance or have a
                 worker_service_client attribute with reference to the original
@@ -173,17 +174,26 @@
                 activity execution. Eager activity execution is an optimization
                 on some servers that sends activities back to the same worker as
                 the calling workflow if they can run there. This setting is
                 experimental and may be removed in a future release.
             on_fatal_error: An async function that can handle a failure before
                 the worker shutdown commences. This cannot stop the shutdown and
                 any exception raised is logged and ignored.
+            use_worker_versioning: If true, the `build_id` argument must be specified, and this
+                worker opts into the worker versioning feature. This ensures it only receives
+                workflow tasks for workflows which it claims to be compatible with.
+
+                For more information, see https://docs.temporal.io/workers#worker-versioning
         """
         if not activities and not workflows:
             raise ValueError("At least one activity or workflow must be specified")
+        if use_worker_versioning and not build_id:
+            raise ValueError(
+                "build_id must be specified when use_worker_versioning is True"
+            )
 
         # Prepend applicable client interceptors to the given ones
         client_config = client.config()
         interceptors_from_client = cast(
             List[Interceptor],
             [i for i in client_config["interceptors"] if isinstance(i, Interceptor)],
         )
@@ -234,14 +244,15 @@
             max_activities_per_second=max_activities_per_second,
             max_task_queue_activities_per_second=max_task_queue_activities_per_second,
             graceful_shutdown_timeout=graceful_shutdown_timeout,
             shared_state_manager=shared_state_manager,
             debug_mode=debug_mode,
             disable_eager_activity_execution=disable_eager_activity_execution,
             on_fatal_error=on_fatal_error,
+            use_worker_versioning=use_worker_versioning,
         )
         self._started = False
         self._shutdown_event = asyncio.Event()
         self._shutdown_complete_event = asyncio.Event()
         self._async_context_inner_task: Optional[asyncio.Task] = None
         self._async_context_run_task: Optional[asyncio.Task] = None
         self._async_context_run_exception: Optional[BaseException] = None
@@ -320,14 +331,15 @@
                     1000 * default_heartbeat_throttle_interval.total_seconds()
                 ),
                 max_activities_per_second=max_activities_per_second,
                 max_task_queue_activities_per_second=max_task_queue_activities_per_second,
                 graceful_shutdown_period_millis=int(
                     1000 * graceful_shutdown_timeout.total_seconds()
                 ),
+                use_worker_versioning=use_worker_versioning,
             ),
         )
 
     def config(self) -> WorkerConfig:
         """Config, as a dictionary, used to create this worker.
 
         Returns:
@@ -554,14 +566,15 @@
     max_activities_per_second: Optional[float]
     max_task_queue_activities_per_second: Optional[float]
     graceful_shutdown_timeout: timedelta
     shared_state_manager: Optional[SharedStateManager]
     debug_mode: bool
     disable_eager_activity_execution: bool
     on_fatal_error: Optional[Callable[[BaseException], Awaitable[None]]]
+    use_worker_versioning: bool
 
 
 _default_build_id: Optional[str] = None
 
 
 def load_default_build_id(*, memoize: bool = True) -> str:
     """Load the default worker build ID.
```

### Comparing `temporalio-1.2.0/temporalio/worker/_workflow.py` & `temporalio-1.3.0/temporalio/worker/_workflow.py`

 * *Files 2% similar despite different names*

```diff
@@ -92,29 +92,35 @@
         # deadlock detection, otherwise set to 2 seconds
         self._deadlock_timeout_seconds = (
             None if debug_mode or os.environ.get("TEMPORAL_DEBUG") else 2
         )
 
         # Validate and build workflow dict
         self._workflows: Dict[str, temporalio.workflow._Definition] = {}
+        self._dynamic_workflow: Optional[temporalio.workflow._Definition] = None
         for workflow in workflows:
             defn = temporalio.workflow._Definition.must_from_class(workflow)
             # Confirm name unique
             if defn.name in self._workflows:
                 raise ValueError(f"More than one workflow named {defn.name}")
             # Prepare the workflow with the runner (this will error in the
             # sandbox if an import fails somehow)
             try:
                 if defn.sandboxed:
                     workflow_runner.prepare_workflow(defn)
                 else:
                     unsandboxed_workflow_runner.prepare_workflow(defn)
             except Exception as err:
                 raise RuntimeError(f"Failed validating workflow {defn.name}") from err
-            self._workflows[defn.name] = defn
+            if defn.name:
+                self._workflows[defn.name] = defn
+            elif self._dynamic_workflow:
+                raise TypeError("More than one dynamic workflow")
+            else:
+                self._dynamic_workflow = defn
 
     async def run(self) -> None:
         # Continually poll for workflow work
         task_tag = object()
         try:
             while True:
                 act = await self._bridge_worker().poll_workflow_activation()
@@ -286,15 +292,17 @@
         start_job = next((j for j in act.jobs if j.HasField("start_workflow")), None)
         if not start_job:
             raise RuntimeError(
                 "Missing start workflow, workflow could have unexpectedly been removed from cache"
             )
 
         # Get the definition
-        defn = self._workflows.get(start_job.start_workflow.workflow_type)
+        defn = self._workflows.get(
+            start_job.start_workflow.workflow_type, self._dynamic_workflow
+        )
         if not defn:
             workflow_names = ", ".join(sorted(self._workflows.keys()))
             raise temporalio.exceptions.ApplicationError(
                 f"Workflow class {start_job.start_workflow.workflow_type} is not registered on this worker, available workflows: {workflow_names}",
                 type="NotFoundError",
             )
```

### Comparing `temporalio-1.2.0/temporalio/worker/_workflow_instance.py` & `temporalio-1.3.0/temporalio/worker/_workflow_instance.py`

 * *Files 4% similar despite different names*

```diff
@@ -6,24 +6,27 @@
 import collections
 import contextvars
 import inspect
 import logging
 import random
 import sys
 import traceback
+import warnings
 from abc import ABC, abstractmethod
+from contextlib import contextmanager
 from dataclasses import dataclass
 from datetime import timedelta
 from typing import (
     Any,
     Awaitable,
     Callable,
     Deque,
     Dict,
     Generator,
+    Iterator,
     List,
     Mapping,
     MutableMapping,
     NoReturn,
     Optional,
     Sequence,
     Set,
@@ -188,14 +191,15 @@
         # TODO(cretz): Any concerns about not sharing this? Maybe the types I
         # need to lookup should be done at definition time?
         self._exception_handler: Optional[_ExceptionHandler] = None
         # The actual instance, instantiated on first _run_once
         self._object: Any = None
         self._is_replaying: bool = False
         self._random = random.Random(det.randomness_seed)
+        self._read_only = False
 
         # Patches we have been notified of and memoized patch responses
         self._patches_notified: Set[str] = set()
         self._patches_memoized: Dict[str, bool] = {}
 
         # Tasks stored by asyncio are weak references and therefore can get GC'd
         # which can cause warnings like "Task was destroyed but it is pending!".
@@ -218,15 +222,17 @@
             fn=self._stack_trace,
             is_method=False,
             arg_types=[],
             ret_type=str,
         )
 
         # Maintain buffered signals for later-added dynamic handlers
-        self._buffered_signals: Dict[str, List[HandleSignalInput]] = {}
+        self._buffered_signals: Dict[
+            str, List[temporalio.bridge.proto.workflow_activation.SignalWorkflow]
+        ] = {}
 
         # Create interceptors. We do this with our runtime on the loop just in
         # case they want to access info() during init().
         temporalio.workflow._Runtime.set_on_loop(asyncio.get_running_loop(), self)
         try:
             root_inbound = _WorkflowInboundImpl(self)
             self._inbound: WorkflowInboundInterceptor = root_inbound
@@ -238,14 +244,24 @@
         finally:
             # Remove our runtime from the loop
             temporalio.workflow._Runtime.set_on_loop(asyncio.get_running_loop(), None)
 
         # Set ourselves on our own loop
         temporalio.workflow._Runtime.set_on_loop(self, self)
 
+        # After GC, Python raises GeneratorExit calls from all awaiting tasks.
+        # Then in a finally of such an await, another exception can swallow
+        # these causing even more issues. We will set ourselves as deleted so we
+        # can check in some places to swallow these errors on tear down.
+        self._deleting = False
+
+    def __del__(self) -> None:
+        # We have confirmed there are no super() versions of __del__
+        self._deleting = True
+
     #### Activation functions ####
     # These are in alphabetical order and besides "activate", all other calls
     # are "_apply_" + the job field name.
 
     def activate(
         self, act: temporalio.bridge.proto.workflow_activation.WorkflowActivation
     ) -> temporalio.bridge.proto.workflow_completion.WorkflowActivationCompletion:
@@ -255,14 +271,15 @@
         )
         self._current_completion.successful.SetInParent()
         self._current_activation_error: Optional[Exception] = None
         self._current_history_length = act.history_length
         self._time_ns = act.timestamp.ToNanoseconds()
         self._is_replaying = act.is_replaying
 
+        activation_err: Optional[Exception] = None
         try:
             # Split into job sets with patches, then signals, then non-queries, then
             # queries
             job_sets: List[
                 List[temporalio.bridge.proto.workflow_activation.WorkflowActivationJob]
             ] = [[], [], [], []]
             for job in act.jobs:
@@ -283,24 +300,34 @@
                     # Let errors bubble out of these to the caller to fail the task
                     self._apply(job)
 
                 # Run one iteration of the loop. We do not allow conditions to
                 # be checked in patch jobs (first index) or query jobs (last
                 # index).
                 self._run_once(check_conditions=index == 1 or index == 2)
+        except temporalio.exceptions.FailureError as err:
+            # We want failure errors during activation, like those that can
+            # happen during payload conversion, to fail the workflow not the
+            # task
+            try:
+                self._set_workflow_failure(err)
+            except Exception as inner_err:
+                activation_err = inner_err
         except Exception as err:
+            activation_err = err
+        if activation_err:
             logger.warning(
                 f"Failed activation on workflow {self._info.workflow_type} with ID {self._info.workflow_id} and run ID {self._info.run_id}",
                 exc_info=True,
             )
             # Set completion failure
             self._current_completion.failed.failure.SetInParent()
             try:
                 self._failure_converter.to_failure(
-                    err,
+                    activation_err,
                     self._payload_converter,
                     self._current_completion.failed.failure,
                 )
             except Exception as inner_err:
                 logger.exception(
                     f"Failed converting activation exception on workflow with run ID {act.run_id}"
                 )
@@ -388,58 +415,66 @@
         handle = self._pending_timers.pop(job.seq, None)
         if handle:
             self._ready.append(handle)
 
     def _apply_query_workflow(
         self, job: temporalio.bridge.proto.workflow_activation.QueryWorkflow
     ) -> None:
-        # Async call to run on the scheduler thread
-        async def run_query(input: HandleQueryInput) -> None:
+        # Wrap entire bunch of work in a task
+        async def run_query() -> None:
             command = self._add_command()
             command.respond_to_query.query_id = job.query_id
             try:
-                success = await self._inbound.handle_query(input)
-                result_payloads = self._payload_converter.to_payloads([success])
-                if len(result_payloads) != 1:
-                    raise ValueError(
-                        f"Expected 1 result payload, got {len(result_payloads)}"
+                with self._as_read_only():
+                    # Named query or dynamic
+                    defn = self._queries.get(job.query_type) or self._queries.get(None)
+                    if not defn:
+                        known_queries = sorted([k for k in self._queries.keys() if k])
+                        raise RuntimeError(
+                            f"Query handler for '{job.query_type}' expected but not found, "
+                            f"known queries: [{' '.join(known_queries)}]"
+                        )
+
+                    # Create input
+                    args = self._process_handler_args(
+                        job.query_type,
+                        job.arguments,
+                        defn.name,
+                        defn.arg_types,
+                        defn.dynamic_vararg,
+                    )
+                    input = HandleQueryInput(
+                        id=job.query_id,
+                        query=job.query_type,
+                        args=args,
+                        headers=job.headers,
+                    )
+                    success = await self._inbound.handle_query(input)
+                    result_payloads = self._payload_converter.to_payloads([success])
+                    if len(result_payloads) != 1:
+                        raise ValueError(
+                            f"Expected 1 result payload, got {len(result_payloads)}"
+                        )
+                    command.respond_to_query.succeeded.response.CopyFrom(
+                        result_payloads[0]
                     )
-                command.respond_to_query.succeeded.response.CopyFrom(result_payloads[0])
             except Exception as err:
                 try:
                     self._failure_converter.to_failure(
                         err,
                         self._payload_converter,
                         command.respond_to_query.failed,
                     )
                 except Exception as inner_err:
                     raise ValueError(
                         "Failed converting application error"
                     ) from inner_err
 
-        # Just find the arg types for now. The interceptor will be responsible
-        # for checking whether the query definition actually exists.
-        arg_types: Optional[List[Type]] = None
-        query_defn = self._queries.get(job.query_type)
-        if query_defn:
-            arg_types = query_defn.arg_types
-        args = self._convert_payloads(job.arguments, arg_types)
-
         # Schedule it
-        self.create_task(
-            run_query(
-                HandleQueryInput(
-                    id=job.query_id,
-                    query=job.query_type,
-                    args=args,
-                    headers=job.headers,
-                )
-            ),
-            name=f"query: {job.query_type}",
-        )
+        self.create_task(run_query(), name=f"query: {job.query_type}")
 
     def _apply_notify_has_patch(
         self, job: temporalio.bridge.proto.workflow_activation.NotifyHasPatch
     ) -> None:
         self._patches_notified.add(job.patch_id)
 
     def _apply_resolve_activity(
@@ -585,58 +620,64 @@
             )
         else:
             fut.set_result(None)
 
     def _apply_signal_workflow(
         self, job: temporalio.bridge.proto.workflow_activation.SignalWorkflow
     ) -> None:
-        # Just find the arg types for now. The interceptor will be responsible
-        # for checking whether the signal definition actually exists.
-        arg_types: Optional[List[Type]] = None
-        signal_defn = self._signals.get(job.signal_name)
-        if signal_defn:
-            arg_types = signal_defn.arg_types
-        input = HandleSignalInput(
-            signal=job.signal_name,
-            args=self._convert_payloads(job.input, arg_types),
-            headers=job.headers,
-        )
-
-        # If there is no definition or dynamic, we buffer and ignore
-        if not signal_defn and None not in self._signals:
-            self._buffered_signals.setdefault(job.signal_name, []).append(input)
+        # Apply to named or to dynamic or buffer
+        signal_defn = self._signals.get(job.signal_name) or self._signals.get(None)
+        if not signal_defn:
+            self._buffered_signals.setdefault(job.signal_name, []).append(job)
             return
-
-        # Schedule the handler
-        self.create_task(
-            self._run_top_level_workflow_function(self._inbound.handle_signal(input)),
-            name=f"signal: {job.signal_name}",
-        )
+        self._process_signal_job(signal_defn, job)
 
     def _apply_start_workflow(
         self, job: temporalio.bridge.proto.workflow_activation.StartWorkflow
     ) -> None:
         # Async call to run on the scheduler thread. This will be wrapped in
         # another function which applies exception handling.
         async def run_workflow(input: ExecuteWorkflowInput) -> None:
-            result = await self._inbound.execute_workflow(input)
-            result_payloads = self._payload_converter.to_payloads([result])
-            if len(result_payloads) != 1:
-                raise ValueError(
-                    f"Expected 1 result payload, got {len(result_payloads)}"
-                )
-            command = self._add_command()
-            command.complete_workflow_execution.result.CopyFrom(result_payloads[0])
+            try:
+                result = await self._inbound.execute_workflow(input)
+                result_payloads = self._payload_converter.to_payloads([result])
+                if len(result_payloads) != 1:
+                    raise ValueError(
+                        f"Expected 1 result payload, got {len(result_payloads)}"
+                    )
+                command = self._add_command()
+                command.complete_workflow_execution.result.CopyFrom(result_payloads[0])
+            except BaseException as err:
+                # During tear down, generator exit and event loop exceptions can occur
+                if not self._deleting:
+                    raise
+                if not isinstance(
+                    err,
+                    (GeneratorExit, temporalio.workflow._NotInWorkflowEventLoopError),
+                ):
+                    logger.debug(
+                        "Ignoring exception while deleting workflow", exc_info=True
+                    )
+
+        # Set arg types, using raw values for dynamic
+        arg_types = self._defn.arg_types
+        if not self._defn.name:
+            # Dynamic is just the raw value for each input value
+            arg_types = [temporalio.common.RawValue] * len(job.arguments)
+        args = self._convert_payloads(job.arguments, arg_types)
+        # Put args in a list if dynamic
+        if not self._defn.name:
+            args = [args]
 
         # Schedule it
         input = ExecuteWorkflowInput(
             type=self._defn.cls,
             # TODO(cretz): Remove cast when https://github.com/python/mypy/issues/5485 fixed
             run_fn=cast(Callable[..., Awaitable[Any]], self._defn.run_fn),
-            args=self._convert_payloads(job.arguments, self._defn.arg_types),
+            args=args,
             headers=job.headers,
         )
         self._primary_task = self.create_task(
             self._run_top_level_workflow_function(run_workflow(input)),
             name=f"run",
         )
 
@@ -654,15 +695,17 @@
         workflow: Union[None, Callable, str],
         task_queue: Optional[str],
         run_timeout: Optional[timedelta],
         task_timeout: Optional[timedelta],
         retry_policy: Optional[temporalio.common.RetryPolicy],
         memo: Optional[Mapping[str, Any]],
         search_attributes: Optional[temporalio.common.SearchAttributes],
+        versioning_intent: Optional[temporalio.workflow.VersioningIntent],
     ) -> NoReturn:
+        self._assert_not_read_only("continue as new")
         # Use definition if callable
         name: Optional[str] = None
         arg_types: Optional[List[Type]] = None
         if isinstance(workflow, str):
             name = workflow
         elif callable(workflow):
             defn = temporalio.workflow._Definition.must_from_run_fn(workflow)
@@ -679,14 +722,15 @@
                 run_timeout=run_timeout,
                 task_timeout=task_timeout,
                 retry_policy=retry_policy,
                 memo=memo,
                 search_attributes=search_attributes,
                 headers={},
                 arg_types=arg_types,
+                versioning_intent=versioning_intent,
             )
         )
         # TODO(cretz): Why can't MyPy infer the above never returns?
         raise RuntimeError("Unreachable")
 
     def workflow_extern_functions(self) -> Mapping[str, Callable]:
         return self._extern_functions
@@ -750,77 +794,98 @@
         self._patches_memoized[id] = use_patch
         if use_patch:
             command = self._add_command()
             command.set_patch_marker.patch_id = id
             command.set_patch_marker.deprecated = deprecated
         return use_patch
 
+    def workflow_payload_converter(self) -> temporalio.converter.PayloadConverter:
+        return self._payload_converter
+
     def workflow_random(self) -> random.Random:
+        self._assert_not_read_only("random")
         return self._random
 
     def workflow_set_query_handler(
         self, name: Optional[str], handler: Optional[Callable]
     ) -> None:
+        self._assert_not_read_only("set query handler")
         if handler:
-            self._queries[name] = temporalio.workflow._QueryDefinition(
+            if inspect.iscoroutinefunction(handler):
+                warnings.warn(
+                    "Queries as async def functions are deprecated",
+                    DeprecationWarning,
+                    stacklevel=3,
+                )
+            defn = temporalio.workflow._QueryDefinition(
                 name=name, fn=handler, is_method=False
             )
+            self._queries[name] = defn
+            if defn.dynamic_vararg:
+                warnings.warn(
+                    "Dynamic queries with vararg third param is deprecated, use Sequence[RawValue]",
+                    DeprecationWarning,
+                    stacklevel=3,
+                )
         else:
             self._queries.pop(name, None)
 
     def workflow_set_signal_handler(
         self, name: Optional[str], handler: Optional[Callable]
     ) -> None:
+        self._assert_not_read_only("set signal handler")
         if handler:
-            self._signals[name] = temporalio.workflow._SignalDefinition(
+            defn = temporalio.workflow._SignalDefinition(
                 name=name, fn=handler, is_method=False
             )
+            self._signals[name] = defn
+            if defn.dynamic_vararg:
+                warnings.warn(
+                    "Dynamic signals with vararg third param is deprecated, use Sequence[RawValue]",
+                    DeprecationWarning,
+                    stacklevel=3,
+                )
             # We have to send buffered signals to the handler if they apply
             if name:
-                for input in self._buffered_signals.pop(name, []):
-                    self.create_task(
-                        self._run_top_level_workflow_function(
-                            self._inbound.handle_signal(input)
-                        ),
-                        name=f"signal: {input.signal} (buffered)",
-                    )
+                for job in self._buffered_signals.pop(name, []):
+                    self._process_signal_job(defn, job)
             else:
-                for inputs in self._buffered_signals.values():
-                    for input in inputs:
-                        self.create_task(
-                            self._run_top_level_workflow_function(
-                                self._inbound.handle_signal(input)
-                            ),
-                            name=f"signal: {input.signal} (buffered)",
-                        )
+                for jobs in self._buffered_signals.values():
+                    for job in jobs:
+                        self._process_signal_job(defn, job)
                 self._buffered_signals.clear()
         else:
             self._signals.pop(name, None)
 
     def workflow_start_activity(
         self,
         activity: Any,
         *args: Any,
         task_queue: Optional[str],
+        result_type: Optional[Type],
         schedule_to_close_timeout: Optional[timedelta],
         schedule_to_start_timeout: Optional[timedelta],
         start_to_close_timeout: Optional[timedelta],
         heartbeat_timeout: Optional[timedelta],
         retry_policy: Optional[temporalio.common.RetryPolicy],
         cancellation_type: temporalio.workflow.ActivityCancellationType,
         activity_id: Optional[str],
+        versioning_intent: Optional[temporalio.workflow.VersioningIntent],
     ) -> temporalio.workflow.ActivityHandle[Any]:
+        self._assert_not_read_only("start activity")
         # Get activity definition if it's callable
         name: str
         arg_types: Optional[List[Type]] = None
-        ret_type: Optional[Type] = None
+        ret_type = result_type
         if isinstance(activity, str):
             name = activity
         elif callable(activity):
             defn = temporalio.activity._Definition.must_from_callable(activity)
+            if not defn.name:
+                raise ValueError("Cannot invoke dynamic activity explicitly")
             name = defn.name
             arg_types = defn.arg_types
             ret_type = defn.ret_type
         else:
             raise TypeError("Activity must be a string or callable")
 
         return self._outbound.start_activity(
@@ -835,42 +900,47 @@
                 heartbeat_timeout=heartbeat_timeout,
                 retry_policy=retry_policy,
                 cancellation_type=cancellation_type,
                 headers={},
                 disable_eager_execution=self._disable_eager_activity_execution,
                 arg_types=arg_types,
                 ret_type=ret_type,
+                versioning_intent=versioning_intent,
             )
         )
 
     async def workflow_start_child_workflow(
         self,
         workflow: Any,
         *args: Any,
         id: str,
         task_queue: Optional[str],
+        result_type: Optional[Type],
         cancellation_type: temporalio.workflow.ChildWorkflowCancellationType,
         parent_close_policy: temporalio.workflow.ParentClosePolicy,
         execution_timeout: Optional[timedelta],
         run_timeout: Optional[timedelta],
         task_timeout: Optional[timedelta],
         id_reuse_policy: temporalio.common.WorkflowIDReusePolicy,
         retry_policy: Optional[temporalio.common.RetryPolicy],
         cron_schedule: str,
         memo: Optional[Mapping[str, Any]],
         search_attributes: Optional[temporalio.common.SearchAttributes],
+        versioning_intent: Optional[temporalio.workflow.VersioningIntent],
     ) -> temporalio.workflow.ChildWorkflowHandle[Any, Any]:
         # Use definition if callable
         name: str
         arg_types: Optional[List[Type]] = None
-        ret_type: Optional[Type] = None
+        ret_type = result_type
         if isinstance(workflow, str):
             name = workflow
         elif callable(workflow):
             defn = temporalio.workflow._Definition.must_from_run_fn(workflow)
+            if not defn.name:
+                raise TypeError("Cannot invoke dynamic workflow explicitly")
             name = defn.name
             arg_types = defn.arg_types
             ret_type = defn.ret_type
         else:
             raise TypeError("Workflow must be a string or callable")
 
         return await self._outbound.start_child_workflow(
@@ -888,37 +958,41 @@
                 retry_policy=retry_policy,
                 cron_schedule=cron_schedule,
                 memo=memo,
                 search_attributes=search_attributes,
                 headers={},
                 arg_types=arg_types,
                 ret_type=ret_type,
+                versioning_intent=versioning_intent,
             )
         )
 
     def workflow_start_local_activity(
         self,
         activity: Any,
         *args: Any,
+        result_type: Optional[Type],
         schedule_to_close_timeout: Optional[timedelta],
         schedule_to_start_timeout: Optional[timedelta],
         start_to_close_timeout: Optional[timedelta],
         retry_policy: Optional[temporalio.common.RetryPolicy],
         local_retry_threshold: Optional[timedelta],
         cancellation_type: temporalio.workflow.ActivityCancellationType,
         activity_id: Optional[str],
     ) -> temporalio.workflow.ActivityHandle[Any]:
         # Get activity definition if it's callable
         name: str
         arg_types: Optional[List[Type]] = None
-        ret_type: Optional[Type] = None
+        ret_type = result_type
         if isinstance(activity, str):
             name = activity
         elif callable(activity):
             defn = temporalio.activity._Definition.must_from_callable(activity)
+            if not defn.name:
+                raise ValueError("Cannot invoke dynamic activity explicitly")
             name = defn.name
             arg_types = defn.arg_types
             ret_type = defn.ret_type
         else:
             raise TypeError("Activity must be a string or callable")
 
         return self._outbound.start_local_activity(
@@ -951,14 +1025,15 @@
         # as empty lists which matches what the server does. We know this is
         # mutable, so we can cast it as such.
         cast(MutableMapping, self._info.search_attributes).update(attributes)
 
     async def workflow_wait_condition(
         self, fn: Callable[[], bool], *, timeout: Optional[float] = None
     ) -> None:
+        self._assert_not_read_only("wait condition")
         fut = self.create_future()
         self._conditions.append((fn, fut))
         await asyncio.wait_for(fut, timeout)
 
     #### Calls from outbound impl ####
     # These are in alphabetical order and all start with "_outbound_".
 
@@ -1092,16 +1167,32 @@
             except asyncio.CancelledError:
                 apply_child_cancel_error()
 
     #### Miscellaneous helpers ####
     # These are in alphabetical order.
 
     def _add_command(self) -> temporalio.bridge.proto.workflow_commands.WorkflowCommand:
+        self._assert_not_read_only("add command")
         return self._current_completion.successful.commands.add()
 
+    @contextmanager
+    def _as_read_only(self) -> Iterator[None]:
+        prev_val = self._read_only
+        self._read_only = True
+        try:
+            yield None
+        finally:
+            self._read_only = prev_val
+
+    def _assert_not_read_only(self, action_attempted: str) -> None:
+        if self._read_only:
+            raise temporalio.workflow.ReadOnlyContextError(
+                f"While in read-only function, action attempted: {action_attempted}"
+            )
+
     async def _cancel_external_workflow(
         self,
         # Should not have seq set
         command: temporalio.bridge.proto.workflow_commands.WorkflowCommand,
     ) -> None:
         seq = self._next_seq("external_cancel")
         done_fut = self.create_future()
@@ -1130,28 +1221,82 @@
         if types and len(types) != len(payloads):
             types = None
         try:
             return self._payload_converter.from_payloads(
                 payloads,
                 type_hints=types,
             )
+        except temporalio.exceptions.FailureError:
+            # Don't wrap payload conversion errors that would fail the workflow
+            raise
         except Exception as err:
             raise RuntimeError("Failed decoding arguments") from err
 
     def _next_seq(self, type: str) -> int:
         seq = self._curr_seqs.get(type, 0) + 1
         self._curr_seqs[type] = seq
         return seq
 
+    def _process_handler_args(
+        self,
+        job_name: str,
+        job_input: Sequence[temporalio.api.common.v1.Payload],
+        defn_name: Optional[str],
+        defn_arg_types: Optional[List[Type]],
+        defn_dynamic_vararg: bool,
+    ) -> List[Any]:
+        # If dynamic old-style vararg, args become name + varargs of given arg
+        # types. If dynamic new-style raw value sequence, args become name +
+        # seq of raw values.
+        if not defn_name and defn_dynamic_vararg:
+            # Take off the string type hint for conversion
+            arg_types = defn_arg_types[1:] if defn_arg_types else None
+            return [job_name] + self._convert_payloads(job_input, arg_types)
+        if not defn_name:
+            return [
+                job_name,
+                self._convert_payloads(
+                    job_input, [temporalio.common.RawValue] * len(job_input)
+                ),
+            ]
+        return self._convert_payloads(job_input, defn_arg_types)
+
+    def _process_signal_job(
+        self,
+        defn: temporalio.workflow._SignalDefinition,
+        job: temporalio.bridge.proto.workflow_activation.SignalWorkflow,
+    ) -> None:
+        try:
+            args = self._process_handler_args(
+                job.signal_name,
+                job.input,
+                defn.name,
+                defn.arg_types,
+                defn.dynamic_vararg,
+            )
+        except Exception:
+            logger.exception(
+                f"Failed deserializing signal input for {job.signal_name}, dropping the signal"
+            )
+            return
+        input = HandleSignalInput(
+            signal=job.signal_name, args=args, headers=job.headers
+        )
+        self.create_task(
+            self._run_top_level_workflow_function(self._inbound.handle_signal(input)),
+            name=f"signal: {job.signal_name}",
+        )
+
     def _register_task(
         self,
         task: asyncio.Task,
         *,
         name: Optional[str],
     ) -> None:
+        self._assert_not_read_only("create task")
         # Name not supported on older Python versions
         if sys.version_info >= (3, 8):
             # Put the workflow info at the end of the task name
             name = name or task.get_name()
             name += f" (workflow: {self._info.workflow_type}, id: {self._info.workflow_id}, run: {self._info.run_id})"
             task.set_name(name)
         # Add to and remove from our own non-weak set instead of relying on
@@ -1223,40 +1368,43 @@
 
             # If a cancel was ever requested and this is a cancellation, or an
             # activity/child cancellation, we add a cancel command. Technically
             # this means that a swallowed cancel followed by, say, an activity
             # cancel later on will show the workflow as cancelled. But this is
             # a Temporal limitation in that cancellation is a state not an
             # event.
-            if self._cancel_requested and (
-                isinstance(err, temporalio.exceptions.CancelledError)
-                or (
-                    (
-                        isinstance(err, temporalio.exceptions.ActivityError)
-                        or isinstance(err, temporalio.exceptions.ChildWorkflowError)
-                    )
-                    and isinstance(err.cause, temporalio.exceptions.CancelledError)
-                )
+            if self._cancel_requested and temporalio.exceptions.is_cancelled_exception(
+                err
             ):
                 self._add_command().cancel_workflow_execution.SetInParent()
             elif isinstance(err, temporalio.exceptions.FailureError):
                 # All other failure errors fail the workflow
-                failure = self._add_command().fail_workflow_execution.failure
-                failure.SetInParent()
-                try:
-                    self._failure_converter.to_failure(
-                        err, self._payload_converter, failure
-                    )
-                except Exception as inner_err:
-                    raise ValueError(
-                        "Failed converting workflow exception"
-                    ) from inner_err
+                self._set_workflow_failure(err)
             else:
                 # All other exceptions fail the task
                 self._current_activation_error = err
+        except BaseException as err:
+            # During tear down, generator exit and no-runtime exceptions can appear
+            if not self._deleting:
+                raise
+            if not isinstance(
+                err, (GeneratorExit, temporalio.workflow._NotInWorkflowEventLoopError)
+            ):
+                logger.debug(
+                    "Ignoring exception while deleting workflow", exc_info=True
+                )
+
+    def _set_workflow_failure(self, err: temporalio.exceptions.FailureError) -> None:
+        # All other failure errors fail the workflow
+        failure = self._add_command().fail_workflow_execution.failure
+        failure.SetInParent()
+        try:
+            self._failure_converter.to_failure(err, self._payload_converter, failure)
+        except Exception as inner_err:
+            raise ValueError("Failed converting workflow exception") from inner_err
 
     async def _signal_external_workflow(
         self,
         # Should not have seq set
         command: temporalio.bridge.proto.workflow_commands.WorkflowCommand,
     ) -> None:
         seq = self._next_seq("external_signal")
@@ -1306,25 +1454,27 @@
 
     def call_soon(
         self,
         callback: Callable[..., Any],
         *args: Any,
         context: Optional[contextvars.Context] = None,
     ) -> asyncio.Handle:
+        self._assert_not_read_only("schedule task")
         handle = asyncio.Handle(callback, args, self, context)
         self._ready.append(handle)
         return handle
 
     def call_later(
         self,
         delay: float,
         callback: Callable[..., Any],
         *args: Any,
         context: Optional[contextvars.Context] = None,
     ) -> asyncio.TimerHandle:
+        self._assert_not_read_only("schedule timer")
         # Delay must be positive
         if delay < 0:
             raise RuntimeError("Attempting to schedule timer with negative delay")
 
         # Create, schedule, and return
         seq = self._next_seq("timer")
         handle = _TimerHandle(seq, self.time() + delay, callback, args, self, context)
@@ -1449,54 +1599,34 @@
         self._outbound = outbound
 
     async def execute_workflow(self, input: ExecuteWorkflowInput) -> Any:
         args = [self._instance._object] + list(input.args)
         return await input.run_fn(*args)
 
     async def handle_signal(self, input: HandleSignalInput) -> None:
-        # Get the definition or fall through to dynamic
-        handler = self._instance.workflow_get_signal_handler(input.signal)
-        dynamic = False
-        if not handler:
-            handler = self._instance.workflow_get_signal_handler(None)
-            dynamic = True
-            # Technically this is checked before the interceptor is invoked, but
-            # an interceptor could have changed the name
-            if not handler:
-                raise RuntimeError(
-                    f"Signal handler for {input.signal} expected but not found"
-                )
-        # Put name first if dynamic
-        args = list(input.args) if not dynamic else [input.signal] + list(input.args)
+        handler = self._instance.workflow_get_signal_handler(
+            input.signal
+        ) or self._instance.workflow_get_signal_handler(None)
+        # Handler should always be present at this point
+        assert handler
         if inspect.iscoroutinefunction(handler):
-            await handler(*args)
+            await handler(*input.args)
         else:
-            handler(*args)
+            handler(*input.args)
 
     async def handle_query(self, input: HandleQueryInput) -> Any:
-        # Get the definition or fall through to dynamic
-        handler = self._instance.workflow_get_query_handler(input.query)
-        dynamic = False
-        if not handler:
-            handler = self._instance.workflow_get_query_handler(None)
-            dynamic = True
-            # Technically this is checked before the interceptor is invoked, but
-            # an interceptor could have changed the name
-            if not handler:
-                known_queries = sorted([k for k in self._instance._queries.keys() if k])
-                raise RuntimeError(
-                    f"Query handler for '{input.query}' expected but not found, "
-                    f"known queries: [{' '.join(known_queries)}]"
-                )
-        # Put name first if dynamic
-        args = list(input.args) if not dynamic else [input.query] + list(input.args)
+        handler = self._instance.workflow_get_query_handler(
+            input.query
+        ) or self._instance.workflow_get_query_handler(None)
+        # Handler should always be present at this point
+        assert handler
         if inspect.iscoroutinefunction(handler):
-            return await handler(*args)
+            return await handler(*input.args)
         else:
-            return handler(*args)
+            return handler(*input.args)
 
 
 class _WorkflowOutboundImpl(WorkflowOutboundInterceptor):
     def __init__(self, instance: _WorkflowInstanceImpl) -> None:
         # We are intentionally not calling the base class's __init__ here
         self._instance = instance
 
@@ -1578,14 +1708,15 @@
         self._seq = instance._next_seq("activity")
         self._input = input
         self._result_fut = instance.create_future()
         self._started = False
         instance._register_task(self, name=f"activity: {input.activity}")
 
     def cancel(self, msg: Optional[Any] = None) -> bool:
+        self._instance._assert_not_read_only("cancel activity handle")
         # We override this because if it's not yet started and not done, we need
         # to send a cancel command because the async function won't run to trap
         # the cancel (i.e. cancelled before started)
         if not self._started and not self.done():
             self._apply_cancel_command(self._instance._add_command())
         # Message not supported in older versions
         if sys.version_info < (3, 9):
@@ -1665,14 +1796,18 @@
             if self._input.heartbeat_timeout:
                 command.schedule_activity.heartbeat_timeout.FromTimedelta(
                     self._input.heartbeat_timeout
                 )
             command.schedule_activity.do_not_eagerly_execute = (
                 self._input.disable_eager_execution
             )
+            if self._input.versioning_intent:
+                command.schedule_activity.versioning_intent = (
+                    self._input.versioning_intent._to_proto()
+                )
         if isinstance(self._input, StartLocalActivityInput):
             if self._input.local_retry_threshold:
                 command.schedule_local_activity.local_retry_threshold.FromTimedelta(
                     self._input.local_retry_threshold
                 )
             if local_backoff:
                 command.schedule_local_activity.attempt = local_backoff.attempt
@@ -1720,14 +1855,15 @@
     async def signal(
         self,
         signal: Union[str, Callable],
         arg: Any = temporalio.common._arg_unset,
         *,
         args: Sequence[Any] = [],
     ) -> None:
+        self._instance._assert_not_read_only("signal child handle")
         await self._instance._outbound.signal_child_workflow(
             SignalChildWorkflowInput(
                 signal=temporalio.workflow._SignalDefinition.must_name_from_fn_or_str(
                     signal
                 ),
                 args=temporalio.common._arg_or_args(arg, args),
                 child_workflow_id=self._input.id,
@@ -1796,14 +1932,16 @@
             _encode_search_attributes(
                 self._input.search_attributes, v.search_attributes
             )
         v.cancellation_type = cast(
             "temporalio.bridge.proto.child_workflow.ChildWorkflowCancellationType.ValueType",
             int(self._input.cancellation_type),
         )
+        if self._input.versioning_intent:
+            v.versioning_intent = self._input.versioning_intent._to_proto()
 
     # If request cancel external, result does _not_ have seq
     def _apply_cancel_command(
         self,
         command: temporalio.bridge.proto.workflow_commands.WorkflowCommand,
     ) -> None:
         command.cancel_child_workflow_execution.child_workflow_seq = self._seq
@@ -1832,28 +1970,30 @@
     async def signal(
         self,
         signal: Union[str, Callable],
         arg: Any = temporalio.common._arg_unset,
         *,
         args: Sequence[Any] = [],
     ) -> None:
+        self._instance._assert_not_read_only("signal external handle")
         await self._instance._outbound.signal_external_workflow(
             SignalExternalWorkflowInput(
                 signal=temporalio.workflow._SignalDefinition.must_name_from_fn_or_str(
                     signal
                 ),
                 args=temporalio.common._arg_or_args(arg, args),
                 namespace=self._instance._info.namespace,
                 workflow_id=self._id,
                 workflow_run_id=self._run_id,
                 headers={},
             )
         )
 
     async def cancel(self) -> None:
+        self._instance._assert_not_read_only("cancel external handle")
         command = self._instance._add_command()
         v = command.request_cancel_external_workflow_execution
         v.workflow_execution.namespace = self._instance._info.namespace
         v.workflow_execution.workflow_id = self._id
         if self._run_id:
             v.workflow_execution.run_id = self._run_id
         await self._instance._cancel_external_workflow(command)
@@ -1893,14 +2033,16 @@
                 v.memo[k].CopyFrom(
                     self._instance._payload_converter.to_payloads([val])[0]
                 )
         if self._input.search_attributes:
             _encode_search_attributes(
                 self._input.search_attributes, v.search_attributes
             )
+        if self._input.versioning_intent:
+            v.versioning_intent = self._input.versioning_intent._to_proto()
 
 
 def _encode_search_attributes(
     attributes: temporalio.common.SearchAttributes,
     payloads: Mapping[str, temporalio.api.common.v1.Payload],
 ) -> None:
     """Encode search attributes as bridge payloads."""
```

### Comparing `temporalio-1.2.0/temporalio/worker/workflow_sandbox/__init__.py` & `temporalio-1.3.0/temporalio/worker/workflow_sandbox/__init__.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/worker/workflow_sandbox/_importer.py` & `temporalio-1.3.0/temporalio/worker/workflow_sandbox/_importer.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/worker/workflow_sandbox/_in_sandbox.py` & `temporalio-1.3.0/temporalio/worker/workflow_sandbox/_in_sandbox.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/worker/workflow_sandbox/_restrictions.py` & `temporalio-1.3.0/temporalio/worker/workflow_sandbox/_restrictions.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/worker/workflow_sandbox/_runner.py` & `temporalio-1.3.0/temporalio/worker/workflow_sandbox/_runner.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.2.0/temporalio/workflow.py` & `temporalio-1.3.0/temporalio/workflow.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,19 +3,20 @@
 from __future__ import annotations
 
 import asyncio
 import inspect
 import logging
 import threading
 import uuid
+import warnings
 from abc import ABC, abstractmethod
 from contextlib import contextmanager
 from dataclasses import dataclass
 from datetime import datetime, timedelta, timezone
-from enum import IntEnum
+from enum import Enum, IntEnum
 from functools import partial
 from random import Random
 from typing import (
     TYPE_CHECKING,
     Any,
     Awaitable,
     Callable,
@@ -37,14 +38,15 @@
 
 from typing_extensions import Concatenate, Literal, TypedDict
 
 import temporalio.api.common.v1
 import temporalio.bridge.proto.child_workflow
 import temporalio.bridge.proto.workflow_commands
 import temporalio.common
+import temporalio.converter
 import temporalio.exceptions
 
 from .types import (
     AnyType,
     CallableAsyncNoParam,
     CallableAsyncSingleParam,
     CallableAsyncType,
@@ -74,36 +76,50 @@
 @overload
 def defn(
     *, name: Optional[str] = None, sandboxed: bool = True
 ) -> Callable[[ClassType], ClassType]:
     ...
 
 
+@overload
+def defn(
+    *, sandboxed: bool = True, dynamic: bool = False
+) -> Callable[[ClassType], ClassType]:
+    ...
+
+
 def defn(
     cls: Optional[ClassType] = None,
     *,
     name: Optional[str] = None,
     sandboxed: bool = True,
+    dynamic: bool = False,
 ):
     """Decorator for workflow classes.
 
     This must be set on any registered workflow class (it is ignored if on a
     base class).
 
     Args:
         cls: The class to decorate.
-        name: Name to use for the workflow. Defaults to class ``__name__``.
+        name: Name to use for the workflow. Defaults to class ``__name__``. This
+            cannot be set if dynamic is set.
         sandboxed: Whether the workflow should run in a sandbox. Default is
             true.
+        dynamic: If true, this activity will be dynamic. Dynamic workflows have
+            to accept a single 'Sequence[RawValue]' parameter. This cannot be
+            set to true if name is present.
     """
 
     def decorator(cls: ClassType) -> ClassType:
         # This performs validation
         _Definition._apply_to_class(
-            cls, workflow_name=name or cls.__name__, sandboxed=sandboxed
+            cls,
+            workflow_name=name or cls.__name__ if not dynamic else None,
+            sandboxed=sandboxed,
         )
         return cls
 
     if cls is not None:
         return decorator(cls)
     return decorator
 
@@ -180,22 +196,22 @@
             ``*args`` positional varargs. Cannot be present when ``name`` is
             present.
     """
 
     def with_name(
         name: Optional[str], fn: CallableSyncOrAsyncReturnNoneType
     ) -> CallableSyncOrAsyncReturnNoneType:
-        if not name:
-            _assert_dynamic_signature(fn)
-        # TODO(cretz): Validate type attributes?
-        setattr(
-            fn,
-            "__temporal_signal_definition",
-            _SignalDefinition(name=name, fn=fn, is_method=True),
-        )
+        defn = _SignalDefinition(name=name, fn=fn, is_method=True)
+        setattr(fn, "__temporal_signal_definition", defn)
+        if defn.dynamic_vararg:
+            warnings.warn(
+                "Dynamic signals with vararg third param is deprecated, use Sequence[RawValue]",
+                DeprecationWarning,
+                stacklevel=2,
+            )
         return fn
 
     if name is not None or dynamic:
         if name is not None and dynamic:
             raise RuntimeError("Cannot provide name and dynamic boolean")
         return partial(with_name, name)
     if fn is None:
@@ -222,65 +238,65 @@
     fn: Optional[CallableType] = None,
     *,
     name: Optional[str] = None,
     dynamic: Optional[bool] = False,
 ):
     """Decorator for a workflow query method.
 
-    This is set on any async or non-async method that expects to handle a
-    query. If a function overrides one with this decorator, it too must be
-    decorated.
+    This is set on any non-async method that expects to handle a query. If a
+    function overrides one with this decorator, it too must be decorated.
 
     Query methods can only have positional parameters. Best practice for
     non-dynamic query methods is to only take a single object/dataclass
     argument that can accept more fields later if needed. The return value is
     the resulting query value. Query methods must not mutate any workflow state.
 
     Args:
         fn: The function to decorate.
         name: Query name. Defaults to method ``__name__``. Cannot be present
             when ``dynamic`` is present.
         dynamic: If true, this handles all queries not otherwise handled. The
-            parameters of the method must be self, a string name, and a
-            ``*args`` positional varargs. Cannot be present when ``name`` is
+            parameters of the method should be self, a string name, and a
+            `Sequence[RawValue]`. An older form of this accepted vararg
+            parameters which will now warn. Cannot be present when ``name`` is
             present.
     """
 
-    def with_name(name: Optional[str], fn: CallableType) -> CallableType:
-        if not name:
-            _assert_dynamic_signature(fn)
-        # TODO(cretz): Validate type attributes?
-        setattr(
-            fn,
-            "__temporal_query_definition",
-            _QueryDefinition(name=name, fn=fn, is_method=True),
-        )
+    def with_name(
+        name: Optional[str], fn: CallableType, *, bypass_async_check: bool = False
+    ) -> CallableType:
+        if not bypass_async_check and inspect.iscoroutinefunction(fn):
+            warnings.warn(
+                "Queries as async def functions are deprecated",
+                DeprecationWarning,
+                stacklevel=2,
+            )
+        defn = _QueryDefinition(name=name, fn=fn, is_method=True)
+        setattr(fn, "__temporal_query_definition", defn)
+        if defn.dynamic_vararg:
+            warnings.warn(
+                "Dynamic queries with vararg third param is deprecated, use Sequence[RawValue]",
+                DeprecationWarning,
+                stacklevel=2,
+            )
         return fn
 
     if name is not None or dynamic:
         if name is not None and dynamic:
             raise RuntimeError("Cannot provide name and dynamic boolean")
         return partial(with_name, name)
     if fn is None:
         raise RuntimeError("Cannot create query without function or name or dynamic")
-    return with_name(fn.__name__, fn)
-
-
-def _assert_dynamic_signature(fn: Callable) -> None:
-    # If dynamic, must have three args: self, name, and varargs
-    sig = inspect.signature(fn)
-    params = list(sig.parameters.values())
-    if (
-        len(params) != 3
-        or params[1].kind is not inspect.Parameter.POSITIONAL_OR_KEYWORD
-        or params[2].kind is not inspect.Parameter.VAR_POSITIONAL
-    ):
-        raise RuntimeError(
-            "Dynamic handler must have 3 arguments: self, name, and var args"
+    if inspect.iscoroutinefunction(fn):
+        warnings.warn(
+            "Queries as async def functions are deprecated",
+            DeprecationWarning,
+            stacklevel=2,
         )
+    return with_name(fn.__name__, fn, bypass_async_check=True)
 
 
 @dataclass(frozen=True)
 class Info:
     """Information about the running workflow.
 
     Retrieved inside a workflow via :py:func:`info`. This object is immutable
@@ -336,15 +352,15 @@
 
 
 class _Runtime(ABC):
     @staticmethod
     def current() -> _Runtime:
         loop = _Runtime.maybe_current()
         if not loop:
-            raise RuntimeError("Not in workflow event loop")
+            raise _NotInWorkflowEventLoopError("Not in workflow event loop")
         return loop
 
     @staticmethod
     def maybe_current() -> Optional[_Runtime]:
         return getattr(asyncio.get_running_loop(), "__temporal_workflow_runtime", None)
 
     @staticmethod
@@ -373,14 +389,15 @@
         workflow: Union[None, Callable, str],
         task_queue: Optional[str],
         run_timeout: Optional[timedelta],
         task_timeout: Optional[timedelta],
         retry_policy: Optional[temporalio.common.RetryPolicy],
         memo: Optional[Mapping[str, Any]],
         search_attributes: Optional[temporalio.common.SearchAttributes],
+        versioning_intent: Optional[VersioningIntent],
     ) -> NoReturn:
         ...
 
     @abstractmethod
     def workflow_extern_functions(self) -> Mapping[str, Callable]:
         ...
 
@@ -421,14 +438,18 @@
         ...
 
     @abstractmethod
     def workflow_patch(self, id: str, *, deprecated: bool) -> bool:
         ...
 
     @abstractmethod
+    def workflow_payload_converter(self) -> temporalio.converter.PayloadConverter:
+        ...
+
+    @abstractmethod
     def workflow_random(self) -> Random:
         ...
 
     @abstractmethod
     def workflow_set_query_handler(
         self, name: Optional[str], handler: Optional[Callable]
     ) -> None:
@@ -442,49 +463,54 @@
 
     @abstractmethod
     def workflow_start_activity(
         self,
         activity: Any,
         *args: Any,
         task_queue: Optional[str],
+        result_type: Optional[Type],
         schedule_to_close_timeout: Optional[timedelta],
         schedule_to_start_timeout: Optional[timedelta],
         start_to_close_timeout: Optional[timedelta],
         heartbeat_timeout: Optional[timedelta],
         retry_policy: Optional[temporalio.common.RetryPolicy],
         cancellation_type: ActivityCancellationType,
         activity_id: Optional[str],
+        versioning_intent: Optional[VersioningIntent],
     ) -> ActivityHandle[Any]:
         ...
 
     @abstractmethod
     async def workflow_start_child_workflow(
         self,
         workflow: Any,
         *args: Any,
         id: str,
         task_queue: Optional[str],
+        result_type: Optional[Type],
         cancellation_type: ChildWorkflowCancellationType,
         parent_close_policy: ParentClosePolicy,
         execution_timeout: Optional[timedelta],
         run_timeout: Optional[timedelta],
         task_timeout: Optional[timedelta],
         id_reuse_policy: temporalio.common.WorkflowIDReusePolicy,
         retry_policy: Optional[temporalio.common.RetryPolicy],
         cron_schedule: str,
         memo: Optional[Mapping[str, Any]],
         search_attributes: Optional[temporalio.common.SearchAttributes],
+        versioning_intent: Optional[VersioningIntent],
     ) -> ChildWorkflowHandle[Any, Any]:
         ...
 
     @abstractmethod
     def workflow_start_local_activity(
         self,
         activity: Any,
         *args: Any,
+        result_type: Optional[Type],
         schedule_to_close_timeout: Optional[timedelta],
         schedule_to_start_timeout: Optional[timedelta],
         start_to_close_timeout: Optional[timedelta],
         retry_policy: Optional[temporalio.common.RetryPolicy],
         local_retry_threshold: Optional[timedelta],
         cancellation_type: ActivityCancellationType,
         activity_id: Optional[str],
@@ -626,14 +652,23 @@
     Returns:
         True if this should take the newer path, false if it should take the
         older path.
     """
     return _Runtime.current().workflow_patch(id, deprecated=False)
 
 
+def payload_converter() -> temporalio.converter.PayloadConverter:
+    """Get the payload converter for the current workflow.
+
+    This is often used for dynamic workflows/signals/queries to convert
+    payloads.
+    """
+    return _Runtime.current().workflow_payload_converter()
+
+
 def random() -> Random:
     """Get a deterministic pseudo-random number generator.
 
     Note, this random number generator is not cryptographically safe and should
     not be used for security purposes.
 
     Returns:
@@ -861,15 +896,15 @@
 
 Logs are skipped during replay by default.
 """
 
 
 @dataclass(frozen=True)
 class _Definition:
-    name: str
+    name: Optional[str]
     cls: Type
     run_fn: Callable[..., Awaitable]
     signals: Mapping[Optional[str], _SignalDefinition]
     queries: Mapping[Optional[str], _QueryDefinition]
     sandboxed: bool
     # Types loaded on post init if both are None
     arg_types: Optional[List[Type]] = None
@@ -904,15 +939,17 @@
             return ret
         fn_name = getattr(fn, "__qualname__", "<unknown>")
         raise ValueError(
             f"Function {fn_name} missing attributes, was it decorated with @workflow.run and was its class decorated with @workflow.defn?"
         )
 
     @staticmethod
-    def _apply_to_class(cls: Type, *, workflow_name: str, sandboxed: bool) -> None:
+    def _apply_to_class(
+        cls: Type, *, workflow_name: Optional[str], sandboxed: bool
+    ) -> None:
         # Check it's not being doubly applied
         if _Definition.from_class(cls):
             raise ValueError("Class already contains workflow definition")
         issues: List[str] = []
 
         # Collect run fn and all signal/query fns
         members = inspect.getmembers(cls)
@@ -1014,15 +1051,25 @@
             sandboxed=sandboxed,
         )
         setattr(cls, "__temporal_workflow_definition", defn)
         setattr(run_fn, "__temporal_workflow_definition", defn)
 
     def __post_init__(self) -> None:
         if self.arg_types is None and self.ret_type is None:
+            dynamic = self.name is None
             arg_types, ret_type = temporalio.common._type_hints_from_func(self.run_fn)
+            # If dynamic, must be a sequence of raw values
+            if dynamic and (
+                not arg_types
+                or len(arg_types) != 1
+                or arg_types[0] != Sequence[temporalio.common.RawValue]
+            ):
+                raise TypeError(
+                    "Dynamic workflow must accept a single Sequence[temporalio.common.RawValue]"
+                )
             object.__setattr__(self, "arg_types", arg_types)
             object.__setattr__(self, "ret_type", ret_type)
 
 
 # Async safe version of partial
 def _bind_method(obj: Any, fn: Callable[..., Any]) -> Callable[..., Any]:
     # Curry instance on the definition function since that represents an
@@ -1035,22 +1082,51 @@
         async def with_object(*args, **kwargs) -> Any:
             return await fn(obj, *args, **kwargs)
 
         return with_object
     return partial(fn, obj)
 
 
+# Returns true if normal form, false if vararg form
+def _assert_dynamic_handler_args(
+    fn: Callable, arg_types: Optional[List[Type]], is_method: bool
+) -> bool:
+    # Dynamic query/signal must have three args: self, name, and
+    # Sequence[RawValue]. An older form accepted varargs for the third param so
+    # we will too (but will warn in the signal/query code)
+    params = list(inspect.signature(fn).parameters.values())
+    total_expected_params = 3 if is_method else 2
+    if (
+        len(params) == total_expected_params
+        and params[-2].kind is inspect.Parameter.POSITIONAL_OR_KEYWORD
+        and params[-1].kind is inspect.Parameter.VAR_POSITIONAL
+    ):
+        # Old var-arg form
+        return False
+    if (
+        not arg_types
+        or len(arg_types) != 2
+        or arg_types[0] != str
+        or arg_types[1] != Sequence[temporalio.common.RawValue]
+    ):
+        raise RuntimeError(
+            "Dynamic handler must have 3 arguments: self, str, and Sequence[temporalio.common.RawValue]"
+        )
+    return True
+
+
 @dataclass(frozen=True)
 class _SignalDefinition:
     # None if dynamic
     name: Optional[str]
     fn: Callable[..., Union[None, Awaitable[None]]]
     is_method: bool
     # Types loaded on post init if None
     arg_types: Optional[List[Type]] = None
+    dynamic_vararg: bool = False
 
     @staticmethod
     def from_fn(fn: Callable) -> Optional[_SignalDefinition]:
         return getattr(fn, "__temporal_signal_definition", None)
 
     @staticmethod
     def must_name_from_fn_or_str(signal: Union[str, Callable]) -> str:
@@ -1066,14 +1142,23 @@
             # TODO(cretz): Check count/type of args at runtime?
             return defn.name
         return str(signal)
 
     def __post_init__(self) -> None:
         if self.arg_types is None:
             arg_types, _ = temporalio.common._type_hints_from_func(self.fn)
+            # If dynamic, assert it
+            if not self.name:
+                object.__setattr__(
+                    self,
+                    "dynamic_vararg",
+                    not _assert_dynamic_handler_args(
+                        self.fn, arg_types, self.is_method
+                    ),
+                )
             object.__setattr__(self, "arg_types", arg_types)
 
     def bind_fn(self, obj: Any) -> Callable[..., Any]:
         return _bind_method(obj, self.fn)
 
 
 @dataclass(frozen=True)
@@ -1081,22 +1166,32 @@
     # None if dynamic
     name: Optional[str]
     fn: Callable[..., Any]
     is_method: bool
     # Types loaded on post init if both are None
     arg_types: Optional[List[Type]] = None
     ret_type: Optional[Type] = None
+    dynamic_vararg: bool = False
 
     @staticmethod
     def from_fn(fn: Callable) -> Optional[_QueryDefinition]:
         return getattr(fn, "__temporal_query_definition", None)
 
     def __post_init__(self) -> None:
         if self.arg_types is None and self.ret_type is None:
             arg_types, ret_type = temporalio.common._type_hints_from_func(self.fn)
+            # If dynamic, assert it
+            if not self.name:
+                object.__setattr__(
+                    self,
+                    "dynamic_vararg",
+                    not _assert_dynamic_handler_args(
+                        self.fn, arg_types, self.is_method
+                    ),
+                )
             object.__setattr__(self, "arg_types", arg_types)
             object.__setattr__(self, "ret_type", ret_type)
 
     def bind_fn(self, obj: Any) -> Callable[..., Any]:
         return _bind_method(obj, self.fn)
 
 
@@ -1145,14 +1240,15 @@
     schedule_to_close_timeout: Optional[timedelta]
     schedule_to_start_timeout: Optional[timedelta]
     start_to_close_timeout: Optional[timedelta]
     heartbeat_timeout: Optional[timedelta]
     retry_policy: Optional[temporalio.common.RetryPolicy]
     cancellation_type: ActivityCancellationType
     activity_id: Optional[str]
+    versioning_intent: Optional[VersioningIntent]
 
 
 # Overload for async no-param activity
 @overload
 def start_activity(
     activity: CallableAsyncNoParam[ReturnType],
     *,
@@ -1160,14 +1256,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync no-param activity
 @overload
 def start_activity(
@@ -1177,14 +1274,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for async single-param activity
 @overload
 def start_activity(
@@ -1195,14 +1293,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync single-param activity
 @overload
 def start_activity(
@@ -1213,14 +1312,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for async multi-param activity
 @overload
 def start_activity(
@@ -1231,14 +1331,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync multi-param activity
 @overload
 def start_activity(
@@ -1249,62 +1350,69 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for string-name activity
 @overload
 def start_activity(
     activity: str,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
     task_queue: Optional[str] = None,
+    result_type: Optional[Type] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[Any]:
     ...
 
 
 def start_activity(
     activity: Any,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
     task_queue: Optional[str] = None,
+    result_type: Optional[Type] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[Any]:
     """Start an activity and return its handle.
 
     At least one of ``schedule_to_close_timeout`` or ``start_to_close_timeout``
     must be present.
 
     Args:
         activity: Activity name or function reference.
         arg: Single argument to the activity.
         args: Multiple arguments to the activity. Cannot be set if arg is.
         task_queue: Task queue to run the activity on. Defaults to the current
             workflow's task queue.
+        result_type: For string activities, this can set the specific result
+            type hint to deserialize into.
         schedule_to_close_timeout: Max amount of time the activity can take from
             first being scheduled to being completed before it times out. This
             is inclusive of all retries.
         schedule_to_start_timeout: Max amount of time the activity can take to
             be started from first being scheduled.
         start_to_close_timeout: Max amount of time a single activity run can
             take from when it starts to when it completes. This is per retry.
@@ -1314,29 +1422,33 @@
             server-defined default is used. Set maximum attempts to 1 to disable
             retries.
         cancellation_type: How the activity is treated when it is cancelled from
             the workflow.
         activity_id: Optional unique identifier for the activity. This is an
             advanced setting that should not be set unless users are sure they
             need to. Contact Temporal before setting this value.
+        versioning_intent: When using the Worker Versioning feature, specifies whether this Activity
+            should run on a worker with a compatible Build Id or not.
 
     Returns:
         An activity handle to the activity which is an async task.
     """
     return _Runtime.current().workflow_start_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
         task_queue=task_queue,
+        result_type=result_type,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         heartbeat_timeout=heartbeat_timeout,
         retry_policy=retry_policy,
         cancellation_type=cancellation_type,
         activity_id=activity_id,
+        versioning_intent=versioning_intent,
     )
 
 
 # Overload for async no-param activity
 @overload
 async def execute_activity(
     activity: CallableAsyncNoParam[ReturnType],
@@ -1345,14 +1457,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync no-param activity
 @overload
 async def execute_activity(
@@ -1362,14 +1475,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for async single-param activity
 @overload
 async def execute_activity(
@@ -1380,14 +1494,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync single-param activity
 @overload
 async def execute_activity(
@@ -1398,14 +1513,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for async multi-param activity
 @overload
 async def execute_activity(
@@ -1416,14 +1532,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync multi-param activity
 @overload
 async def execute_activity(
@@ -1434,68 +1551,75 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for string-name activity
 @overload
 async def execute_activity(
     activity: str,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
     task_queue: Optional[str] = None,
+    result_type: Optional[Type] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> Any:
     ...
 
 
 async def execute_activity(
     activity: Any,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
     task_queue: Optional[str] = None,
+    result_type: Optional[Type] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> Any:
     """Start an activity and wait for completion.
 
     This is a shortcut for ``await`` :py:meth:`start_activity`.
     """
     # We call the runtime directly instead of top-level start_activity to ensure
     # we don't miss new parameters
     return await _Runtime.current().workflow_start_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
         task_queue=task_queue,
+        result_type=result_type,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         heartbeat_timeout=heartbeat_timeout,
         retry_policy=retry_policy,
         cancellation_type=cancellation_type,
         activity_id=activity_id,
+        versioning_intent=versioning_intent,
     )
 
 
 # Overload for async no-param activity
 @overload
 def start_activity_class(
     activity: Type[CallableAsyncNoParam[ReturnType]],
@@ -1504,14 +1628,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync no-param activity
 @overload
 def start_activity_class(
@@ -1521,14 +1646,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for async single-param activity
 @overload
 def start_activity_class(
@@ -1539,14 +1665,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync single-param activity
 @overload
 def start_activity_class(
@@ -1557,14 +1684,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for async multi-param activity
 @overload
 def start_activity_class(
@@ -1575,14 +1703,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync multi-param activity
 @overload
 def start_activity_class(
@@ -1593,14 +1722,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 def start_activity_class(
     activity: Type[Callable],
     arg: Any = temporalio.common._arg_unset,
@@ -1610,30 +1740,33 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[Any]:
     """Start an activity from a callable class.
 
     See :py:meth:`start_activity` for parameter and return details.
     """
     return _Runtime.current().workflow_start_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
         task_queue=task_queue,
+        result_type=None,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         heartbeat_timeout=heartbeat_timeout,
         retry_policy=retry_policy,
         cancellation_type=cancellation_type,
         activity_id=activity_id,
+        versioning_intent=versioning_intent,
     )
 
 
 # Overload for async no-param activity
 @overload
 async def execute_activity_class(
     activity: Type[CallableAsyncNoParam[ReturnType]],
@@ -1642,14 +1775,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync no-param activity
 @overload
 async def execute_activity_class(
@@ -1659,14 +1793,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for async single-param activity
 @overload
 async def execute_activity_class(
@@ -1677,14 +1812,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync single-param activity
 @overload
 async def execute_activity_class(
@@ -1695,14 +1831,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for async multi-param activity
 @overload
 async def execute_activity_class(
@@ -1713,14 +1850,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync multi-param activity
 @overload
 async def execute_activity_class(
@@ -1731,14 +1869,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ReturnType:
     ...
 
 
 async def execute_activity_class(
     activity: Type[Callable],
     arg: Any = temporalio.common._arg_unset,
@@ -1748,30 +1887,33 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> Any:
     """Start an activity from a callable class and wait for completion.
 
     This is a shortcut for ``await`` :py:meth:`start_activity_class`.
     """
     return await _Runtime.current().workflow_start_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
         task_queue=task_queue,
+        result_type=None,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         heartbeat_timeout=heartbeat_timeout,
         retry_policy=retry_policy,
         cancellation_type=cancellation_type,
         activity_id=activity_id,
+        versioning_intent=versioning_intent,
     )
 
 
 # Overload for async no-param activity
 @overload
 def start_activity_method(
     activity: MethodAsyncNoParam[SelfType, ReturnType],
@@ -1780,14 +1922,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync no-param activity
 @overload
 def start_activity_method(
@@ -1797,14 +1940,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for async single-param activity
 @overload
 def start_activity_method(
@@ -1815,14 +1959,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync single-param activity
 @overload
 def start_activity_method(
@@ -1833,14 +1978,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for async multi-param activity
 @overload
 def start_activity_method(
@@ -1851,14 +1997,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync multi-param activity
 @overload
 def start_activity_method(
@@ -1869,14 +2016,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 def start_activity_method(
     activity: Callable,
     arg: Any = temporalio.common._arg_unset,
@@ -1886,30 +2034,33 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ActivityHandle[Any]:
     """Start an activity from a method.
 
     See :py:meth:`start_activity` for parameter and return details.
     """
     return _Runtime.current().workflow_start_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
         task_queue=task_queue,
+        result_type=None,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         heartbeat_timeout=heartbeat_timeout,
         retry_policy=retry_policy,
         cancellation_type=cancellation_type,
         activity_id=activity_id,
+        versioning_intent=versioning_intent,
     )
 
 
 # Overload for async no-param activity
 @overload
 async def execute_activity_method(
     activity: MethodAsyncNoParam[SelfType, ReturnType],
@@ -1918,14 +2069,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync no-param activity
 @overload
 async def execute_activity_method(
@@ -1935,14 +2087,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for async single-param activity
 @overload
 async def execute_activity_method(
@@ -1953,14 +2106,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync single-param activity
 @overload
 async def execute_activity_method(
@@ -1971,14 +2125,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for async multi-param activity
 @overload
 async def execute_activity_method(
@@ -1989,14 +2144,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync multi-param activity
 @overload
 async def execute_activity_method(
@@ -2007,14 +2163,15 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ReturnType:
     ...
 
 
 async def execute_activity_method(
     activity: Callable,
     arg: Any = temporalio.common._arg_unset,
@@ -2024,32 +2181,35 @@
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> Any:
     """Start an activity from a method and wait for completion.
 
     This is a shortcut for ``await`` :py:meth:`start_activity_method`.
     """
     # We call the runtime directly instead of top-level start_activity to ensure
     # we don't miss new parameters
     return await _Runtime.current().workflow_start_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
         task_queue=task_queue,
+        result_type=None,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         heartbeat_timeout=heartbeat_timeout,
         retry_policy=retry_policy,
         cancellation_type=cancellation_type,
         activity_id=activity_id,
+        versioning_intent=versioning_intent,
     )
 
 
 class LocalActivityConfig(TypedDict, total=False):
     """TypedDict of config that can be used for :py:func:`start_local_activity`
     and :py:func:`execute_local_activity`.
     """
@@ -2166,14 +2326,15 @@
 # Overload for string-name activity
 @overload
 def start_local_activity(
     activity: str,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
+    result_type: Optional[Type] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
@@ -2182,14 +2343,15 @@
 
 
 def start_local_activity(
     activity: Any,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
+    result_type: Optional[Type] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
@@ -2202,14 +2364,16 @@
     .. warning::
         Local activities are currently experimental.
 
     Args:
         activity: Activity name or function reference.
         arg: Single argument to the activity.
         args: Multiple arguments to the activity. Cannot be set if arg is.
+        result_type: For string activities, this can set the specific result
+            type hint to deserialize into.
         activity_id: Optional unique identifier for the activity.
         schedule_to_close_timeout: Max amount of time the activity can take from
             first being scheduled to being completed before it times out. This
             is inclusive of all retries.
         schedule_to_start_timeout: Max amount of time the activity can take to
             be started from first being scheduled.
         start_to_close_timeout: Max amount of time a single activity run can
@@ -2225,14 +2389,15 @@
 
     Returns:
         An activity handle to the activity which is an async task.
     """
     return _Runtime.current().workflow_start_local_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
+        result_type=result_type,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         retry_policy=retry_policy,
         local_retry_threshold=local_retry_threshold,
         cancellation_type=cancellation_type,
         activity_id=activity_id,
@@ -2342,14 +2507,15 @@
 # Overload for string-name activity
 @overload
 async def execute_local_activity(
     activity: str,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
+    result_type: Optional[Type] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
@@ -2358,14 +2524,15 @@
 
 
 async def execute_local_activity(
     activity: Any,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
+    result_type: Optional[Type] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
     activity_id: Optional[str] = None,
@@ -2378,14 +2545,15 @@
         Local activities are currently experimental.
     """
     # We call the runtime directly instead of top-level start_local_activity to
     # ensure we don't miss new parameters
     return await _Runtime.current().workflow_start_local_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
+        result_type=result_type,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         retry_policy=retry_policy,
         local_retry_threshold=local_retry_threshold,
         cancellation_type=cancellation_type,
         activity_id=activity_id,
@@ -2511,14 +2679,15 @@
 
     .. warning::
         Local activities are currently experimental.
     """
     return _Runtime.current().workflow_start_local_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
+        result_type=None,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         retry_policy=retry_policy,
         local_retry_threshold=local_retry_threshold,
         cancellation_type=cancellation_type,
         activity_id=activity_id,
@@ -2646,14 +2815,15 @@
         Local activities are currently experimental.
     """
     # We call the runtime directly instead of top-level start_local_activity to
     # ensure we don't miss new parameters
     return await _Runtime.current().workflow_start_local_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
+        result_type=None,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         retry_policy=retry_policy,
         local_retry_threshold=local_retry_threshold,
         cancellation_type=cancellation_type,
         activity_id=activity_id,
@@ -2779,14 +2949,15 @@
 
     .. warning::
         Local activities are currently experimental.
     """
     return _Runtime.current().workflow_start_local_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
+        result_type=None,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         retry_policy=retry_policy,
         local_retry_threshold=local_retry_threshold,
         cancellation_type=cancellation_type,
         activity_id=activity_id,
@@ -2914,14 +3085,15 @@
         Local activities are currently experimental.
     """
     # We call the runtime directly instead of top-level start_local_activity to
     # ensure we don't miss new parameters
     return await _Runtime.current().workflow_start_local_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
+        result_type=None,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         retry_policy=retry_policy,
         local_retry_threshold=local_retry_threshold,
         cancellation_type=cancellation_type,
         activity_id=activity_id,
@@ -3066,14 +3238,15 @@
     run_timeout: Optional[timedelta] = None,
     task_timeout: Optional[timedelta] = None,
     id_reuse_policy: temporalio.common.WorkflowIDReusePolicy = temporalio.common.WorkflowIDReusePolicy.ALLOW_DUPLICATE,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cron_schedule: str = "",
     memo: Optional[Mapping[str, Any]] = None,
     search_attributes: Optional[temporalio.common.SearchAttributes] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ChildWorkflowHandle[SelfType, ReturnType]:
     ...
 
 
 # Overload for single-param workflow
 @overload
 async def start_child_workflow(
@@ -3088,14 +3261,15 @@
     run_timeout: Optional[timedelta] = None,
     task_timeout: Optional[timedelta] = None,
     id_reuse_policy: temporalio.common.WorkflowIDReusePolicy = temporalio.common.WorkflowIDReusePolicy.ALLOW_DUPLICATE,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cron_schedule: str = "",
     memo: Optional[Mapping[str, Any]] = None,
     search_attributes: Optional[temporalio.common.SearchAttributes] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ChildWorkflowHandle[SelfType, ReturnType]:
     ...
 
 
 # Overload for multi-param workflow
 @overload
 async def start_child_workflow(
@@ -3110,101 +3284,112 @@
     run_timeout: Optional[timedelta] = None,
     task_timeout: Optional[timedelta] = None,
     id_reuse_policy: temporalio.common.WorkflowIDReusePolicy = temporalio.common.WorkflowIDReusePolicy.ALLOW_DUPLICATE,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cron_schedule: str = "",
     memo: Optional[Mapping[str, Any]] = None,
     search_attributes: Optional[temporalio.common.SearchAttributes] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ChildWorkflowHandle[SelfType, ReturnType]:
     ...
 
 
 # Overload for string-name workflow
 @overload
 async def start_child_workflow(
     workflow: str,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
     id: Optional[str] = None,
     task_queue: Optional[str] = None,
+    result_type: Optional[Type] = None,
     cancellation_type: ChildWorkflowCancellationType = ChildWorkflowCancellationType.WAIT_CANCELLATION_COMPLETED,
     parent_close_policy: ParentClosePolicy = ParentClosePolicy.TERMINATE,
     execution_timeout: Optional[timedelta] = None,
     run_timeout: Optional[timedelta] = None,
     task_timeout: Optional[timedelta] = None,
     id_reuse_policy: temporalio.common.WorkflowIDReusePolicy = temporalio.common.WorkflowIDReusePolicy.ALLOW_DUPLICATE,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cron_schedule: str = "",
     memo: Optional[Mapping[str, Any]] = None,
     search_attributes: Optional[temporalio.common.SearchAttributes] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ChildWorkflowHandle[Any, Any]:
     ...
 
 
 async def start_child_workflow(
     workflow: Any,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
     id: Optional[str] = None,
     task_queue: Optional[str] = None,
+    result_type: Optional[Type] = None,
     cancellation_type: ChildWorkflowCancellationType = ChildWorkflowCancellationType.WAIT_CANCELLATION_COMPLETED,
     parent_close_policy: ParentClosePolicy = ParentClosePolicy.TERMINATE,
     execution_timeout: Optional[timedelta] = None,
     run_timeout: Optional[timedelta] = None,
     task_timeout: Optional[timedelta] = None,
     id_reuse_policy: temporalio.common.WorkflowIDReusePolicy = temporalio.common.WorkflowIDReusePolicy.ALLOW_DUPLICATE,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cron_schedule: str = "",
     memo: Optional[Mapping[str, Any]] = None,
     search_attributes: Optional[temporalio.common.SearchAttributes] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ChildWorkflowHandle[Any, Any]:
     """Start a child workflow and return its handle.
 
     Args:
         workflow: String name or class method decorated with ``@workflow.run``
             for the workflow to start.
         arg: Single argument to the child workflow.
         args: Multiple arguments to the child workflow. Cannot be set if arg is.
         id: Optional unique identifier for the workflow execution. If not set,
             defaults to :py:func:`uuid4`.
         task_queue: Task queue to run the workflow on. Defaults to the current
             workflow's task queue.
+        result_type: For string workflows, this can set the specific result type
+            hint to deserialize into.
         cancellation_type: How the child workflow will react to cancellation.
         parent_close_policy: How to handle the child workflow when the parent
             workflow closes.
         execution_timeout: Total workflow execution timeout including
             retries and continue as new.
         run_timeout: Timeout of a single workflow run.
         task_timeout: Timeout of a single workflow task.
         id_reuse_policy: How already-existing IDs are treated.
         retry_policy: Retry policy for the workflow.
         cron_schedule: See https://docs.temporal.io/docs/content/what-is-a-temporal-cron-job/
         memo: Memo for the workflow.
         search_attributes: Search attributes for the workflow.
+        versioning_intent:  When using the Worker Versioning feature, specifies whether this Child
+            Workflow should run on a worker with a compatible Build Id or not.
 
     Returns:
         A workflow handle to the started/existing workflow.
     """
     return await _Runtime.current().workflow_start_child_workflow(
         workflow,
         *temporalio.common._arg_or_args(arg, args),
         id=id or str(uuid4()),
         task_queue=task_queue,
+        result_type=result_type,
         cancellation_type=cancellation_type,
         parent_close_policy=parent_close_policy,
         execution_timeout=execution_timeout,
         run_timeout=run_timeout,
         task_timeout=task_timeout,
         id_reuse_policy=id_reuse_policy,
         retry_policy=retry_policy,
         cron_schedule=cron_schedule,
         memo=memo,
         search_attributes=search_attributes,
+        versioning_intent=versioning_intent,
     )
 
 
 # Overload for no-param workflow
 @overload
 async def execute_child_workflow(
     workflow: MethodAsyncNoParam[SelfType, ReturnType],
@@ -3217,14 +3402,15 @@
     run_timeout: Optional[timedelta] = None,
     task_timeout: Optional[timedelta] = None,
     id_reuse_policy: temporalio.common.WorkflowIDReusePolicy = temporalio.common.WorkflowIDReusePolicy.ALLOW_DUPLICATE,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cron_schedule: str = "",
     memo: Optional[Mapping[str, Any]] = None,
     search_attributes: Optional[temporalio.common.SearchAttributes] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for single-param workflow
 @overload
 async def execute_child_workflow(
@@ -3239,14 +3425,15 @@
     run_timeout: Optional[timedelta] = None,
     task_timeout: Optional[timedelta] = None,
     id_reuse_policy: temporalio.common.WorkflowIDReusePolicy = temporalio.common.WorkflowIDReusePolicy.ALLOW_DUPLICATE,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cron_schedule: str = "",
     memo: Optional[Mapping[str, Any]] = None,
     search_attributes: Optional[temporalio.common.SearchAttributes] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for multi-param workflow
 @overload
 async def execute_child_workflow(
@@ -3261,80 +3448,87 @@
     run_timeout: Optional[timedelta] = None,
     task_timeout: Optional[timedelta] = None,
     id_reuse_policy: temporalio.common.WorkflowIDReusePolicy = temporalio.common.WorkflowIDReusePolicy.ALLOW_DUPLICATE,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cron_schedule: str = "",
     memo: Optional[Mapping[str, Any]] = None,
     search_attributes: Optional[temporalio.common.SearchAttributes] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for string-name workflow
 @overload
 async def execute_child_workflow(
     workflow: str,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
     id: Optional[str] = None,
     task_queue: Optional[str] = None,
+    result_type: Optional[Type] = None,
     cancellation_type: ChildWorkflowCancellationType = ChildWorkflowCancellationType.WAIT_CANCELLATION_COMPLETED,
     parent_close_policy: ParentClosePolicy = ParentClosePolicy.TERMINATE,
     execution_timeout: Optional[timedelta] = None,
     run_timeout: Optional[timedelta] = None,
     task_timeout: Optional[timedelta] = None,
     id_reuse_policy: temporalio.common.WorkflowIDReusePolicy = temporalio.common.WorkflowIDReusePolicy.ALLOW_DUPLICATE,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cron_schedule: str = "",
     memo: Optional[Mapping[str, Any]] = None,
     search_attributes: Optional[temporalio.common.SearchAttributes] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> Any:
     ...
 
 
 async def execute_child_workflow(
     workflow: Any,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
     id: Optional[str] = None,
     task_queue: Optional[str] = None,
+    result_type: Optional[Type] = None,
     cancellation_type: ChildWorkflowCancellationType = ChildWorkflowCancellationType.WAIT_CANCELLATION_COMPLETED,
     parent_close_policy: ParentClosePolicy = ParentClosePolicy.TERMINATE,
     execution_timeout: Optional[timedelta] = None,
     run_timeout: Optional[timedelta] = None,
     task_timeout: Optional[timedelta] = None,
     id_reuse_policy: temporalio.common.WorkflowIDReusePolicy = temporalio.common.WorkflowIDReusePolicy.ALLOW_DUPLICATE,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cron_schedule: str = "",
     memo: Optional[Mapping[str, Any]] = None,
     search_attributes: Optional[temporalio.common.SearchAttributes] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> Any:
     """Start a child workflow and wait for completion.
 
     This is a shortcut for ``await`` :py:meth:`start_child_workflow`.
     """
     # We call the runtime directly instead of top-level start_child_workflow to
     # ensure we don't miss new parameters
     handle = await _Runtime.current().workflow_start_child_workflow(
         workflow,
         *temporalio.common._arg_or_args(arg, args),
         id=id or str(uuid4()),
         task_queue=task_queue,
+        result_type=result_type,
         cancellation_type=cancellation_type,
         parent_close_policy=parent_close_policy,
         execution_timeout=execution_timeout,
         run_timeout=run_timeout,
         task_timeout=task_timeout,
         id_reuse_policy=id_reuse_policy,
         retry_policy=retry_policy,
         cron_schedule=cron_schedule,
         memo=memo,
         search_attributes=search_attributes,
+        versioning_intent=versioning_intent,
     )
     return await handle
 
 
 class ExternalWorkflowHandle(Generic[SelfType]):
     """Handle for interacting with an external workflow.
 
@@ -3469,14 +3663,15 @@
     args: Sequence[Any] = [],
     task_queue: Optional[str] = None,
     run_timeout: Optional[timedelta] = None,
     task_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     memo: Optional[Mapping[str, Any]] = None,
     search_attributes: Optional[temporalio.common.SearchAttributes] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> NoReturn:
     ...
 
 
 # Overload for no-param workflow
 @overload
 def continue_as_new(
@@ -3484,14 +3679,15 @@
     workflow: MethodAsyncNoParam[SelfType, Any],
     task_queue: Optional[str] = None,
     run_timeout: Optional[timedelta] = None,
     task_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     memo: Optional[Mapping[str, Any]] = None,
     search_attributes: Optional[temporalio.common.SearchAttributes] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> NoReturn:
     ...
 
 
 # Overload for single-param workflow
 @overload
 def continue_as_new(
@@ -3500,14 +3696,15 @@
     workflow: MethodAsyncSingleParam[SelfType, ParamType, Any],
     task_queue: Optional[str] = None,
     run_timeout: Optional[timedelta] = None,
     task_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     memo: Optional[Mapping[str, Any]] = None,
     search_attributes: Optional[temporalio.common.SearchAttributes] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> NoReturn:
     ...
 
 
 # Overload for multi-param workflow
 @overload
 def continue_as_new(
@@ -3516,14 +3713,15 @@
     args: Sequence[Any],
     task_queue: Optional[str] = None,
     run_timeout: Optional[timedelta] = None,
     task_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     memo: Optional[Mapping[str, Any]] = None,
     search_attributes: Optional[temporalio.common.SearchAttributes] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> NoReturn:
     ...
 
 
 # Overload for string-name workflow
 @overload
 def continue_as_new(
@@ -3532,14 +3730,15 @@
     args: Sequence[Any] = [],
     task_queue: Optional[str] = None,
     run_timeout: Optional[timedelta] = None,
     task_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     memo: Optional[Mapping[str, Any]] = None,
     search_attributes: Optional[temporalio.common.SearchAttributes] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> NoReturn:
     ...
 
 
 def continue_as_new(
     arg: Any = temporalio.common._arg_unset,
     *,
@@ -3547,14 +3746,15 @@
     workflow: Union[None, Callable, str] = None,
     task_queue: Optional[str] = None,
     run_timeout: Optional[timedelta] = None,
     task_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     memo: Optional[Mapping[str, Any]] = None,
     search_attributes: Optional[temporalio.common.SearchAttributes] = None,
+    versioning_intent: Optional[VersioningIntent] = None,
 ) -> NoReturn:
     """Stop the workflow immediately and continue as new.
 
     Args:
         arg: Single argument to the continued workflow.
         args: Multiple arguments to the continued workflow. Cannot be set if arg
             is.
@@ -3565,14 +3765,16 @@
         run_timeout: Timeout of a single workflow run. Defaults to the current
             workflow's run timeout.
         task_timeout: Timeout of a single workflow task. Defaults to the current
             workflow's task timeout.
         memo: Memo for the workflow. Defaults to the current workflow's memo.
         search_attributes: Search attributes for the workflow. Defaults to the
             current workflow's search attributes.
+        versioning_intent: When using the Worker Versioning feature, specifies whether this Workflow
+            should Continue-as-New onto a worker with a compatible Build Id or not.
 
     Returns:
         Never returns, always raises a :py:class:`ContinueAsNewError`.
 
     Raises:
         ContinueAsNewError: Always raised by this function. Should not be caught
             but instead be allowed to
@@ -3582,14 +3784,15 @@
         workflow=workflow,
         task_queue=task_queue,
         run_timeout=run_timeout,
         task_timeout=task_timeout,
         retry_policy=retry_policy,
         memo=memo,
         search_attributes=search_attributes,
+        versioning_intent=versioning_intent,
     )
 
 
 def get_signal_handler(name: str) -> Optional[Callable]:
     """Get the signal handler for the given name if any.
 
     This includes handlers created via the ``@workflow.signal`` decorator.
@@ -3723,7 +3926,51 @@
 class NondeterminismError(temporalio.exceptions.TemporalError):
     """Error that can be thrown during replay for non-deterministic workflow."""
 
     def __init__(self, message: str) -> None:
         """Initialize a nondeterminism error."""
         super().__init__(message)
         self.message = message
+
+
+class ReadOnlyContextError(temporalio.exceptions.TemporalError):
+    """Error thrown when trying to do mutable workflow calls in a read-only
+    context like a query or update validator.
+    """
+
+    def __init__(self, message: str) -> None:
+        """Initialize a read-only context error."""
+        super().__init__(message)
+        self.message = message
+
+
+class _NotInWorkflowEventLoopError(temporalio.exceptions.TemporalError):
+    def __init__(self, *args: object) -> None:
+        super().__init__("Not in workflow event loop")
+        self.message = "Not in workflow event loop"
+
+
+class VersioningIntent(Enum):
+    """Indicates whether the user intends certain commands to be run on a compatible worker Build
+    Id version or not.
+
+    `COMPATIBLE` indicates that the command should run on a worker with compatible version if
+    possible. It may not be possible if the target task queue does not also have knowledge of the
+    current worker's Build Id.
+
+    `DEFAULT` indicates that the command should run on the target task queue's current
+    overall-default Build Id.
+
+    Where this type is accepted optionally, an unset value indicates that the SDK should choose the
+    most sensible default behavior for the type of command, accounting for whether the command will
+    be run on the same task queue as the current worker.
+    """
+
+    COMPATIBLE = 1
+    DEFAULT = 2
+
+    def _to_proto(self) -> temporalio.bridge.proto.common.VersioningIntent.ValueType:
+        if self == VersioningIntent.COMPATIBLE:
+            return temporalio.bridge.proto.common.VersioningIntent.COMPATIBLE
+        elif self == VersioningIntent.DEFAULT:
+            return temporalio.bridge.proto.common.VersioningIntent.DEFAULT
+        return temporalio.bridge.proto.common.VersioningIntent.UNSPECIFIED
```

### Comparing `temporalio-1.2.0/setup.py` & `temporalio-1.3.0/setup.py`

 * *Files 4% similar despite different names*

```diff
@@ -135,14 +135,15 @@
                        'sdk-core/protos/api_upstream/temporal/api/schedule/v1/*',
                        'sdk-core/protos/api_upstream/temporal/api/sdk/v1/*',
                        'sdk-core/protos/api_upstream/temporal/api/taskqueue/v1/*',
                        'sdk-core/protos/api_upstream/temporal/api/update/v1/*',
                        'sdk-core/protos/api_upstream/temporal/api/version/v1/*',
                        'sdk-core/protos/api_upstream/temporal/api/workflow/v1/*',
                        'sdk-core/protos/api_upstream/temporal/api/workflowservice/v1/*',
+                       'sdk-core/protos/google/rpc/*',
                        'sdk-core/protos/grpc/health/v1/*',
                        'sdk-core/protos/local/temporal/sdk/core/*',
                        'sdk-core/protos/local/temporal/sdk/core/activity_result/*',
                        'sdk-core/protos/local/temporal/sdk/core/activity_task/*',
                        'sdk-core/protos/local/temporal/sdk/core/child_workflow/*',
                        'sdk-core/protos/local/temporal/sdk/core/common/*',
                        'sdk-core/protos/local/temporal/sdk/core/external_data/*',
@@ -171,17 +172,17 @@
 {':python_version < "3.11"': ['python-dateutil>=2.8.2,<3.0.0'],
  'grpc': ['grpcio>=1.48.0,<2.0.0'],
  'opentelemetry': ['opentelemetry-api>=1.11.1,<2.0.0',
                    'opentelemetry-sdk>=1.11.1,<2.0.0']}
 
 setup_kwargs = {
     'name': 'temporalio',
-    'version': '1.2.0',
+    'version': '1.3.0',
     'description': 'Temporal.io Python SDK',
-    'long_description': '![Temporal Python SDK](https://assets.temporal.io/w/py-banner.svg)\n\n[![Python 3.7+](https://img.shields.io/pypi/pyversions/temporalio.svg?style=for-the-badge)](https://pypi.org/project/temporalio)\n[![PyPI](https://img.shields.io/pypi/v/temporalio.svg?style=for-the-badge)](https://pypi.org/project/temporalio)\n[![MIT](https://img.shields.io/pypi/l/temporalio.svg?style=for-the-badge)](LICENSE)\n\n[Temporal](https://temporal.io/) is a distributed, scalable, durable, and highly available orchestration engine used to\nexecute asynchronous, long-running business logic in a scalable and resilient way.\n\n"Temporal Python SDK" is the framework for authoring workflows and activities using the Python programming language.\n\nAlso see:\n* [Application Development Guide](https://docs.temporal.io/application-development?lang=python) - Once you\'ve tried our [Quick Start](#quick-start), check out our guide on how to use Temporal in your Python applications, including information around Temporal core concepts.\n* [Python Code Samples](https://github.com/temporalio/samples-python)\n* [API Documentation](https://python.temporal.io) - Complete Temporal Python SDK Package reference.\n\nIn addition to features common across all Temporal SDKs, the Python SDK also has the following interesting features:\n\n**Type Safe**\n\nThis library uses the latest typing and MyPy support with generics to ensure all calls can be typed. For example,\nstarting a workflow with an `int` parameter when it accepts a `str` parameter would cause MyPy to fail.\n\n**Different Activity Types**\n\nThe activity worker has been developed to work with `async def`, threaded, and multiprocess activities. While\n`async def` activities are the easiest and recommended, care has been taken to make heartbeating and cancellation also\nwork across threads/processes.\n\n**Custom `asyncio` Event Loop**\n\nThe workflow implementation basically turns `async def` functions into workflows backed by a distributed, fault-tolerant\nevent loop. This means task management, sleep, cancellation, etc have all been developed to seamlessly integrate with\n`asyncio` concepts.\n\n---\n\n<!-- START doctoc generated TOC please keep comment here to allow auto update -->\n<!-- DON\'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->\n**Contents**\n\n- [Quick Start](#quick-start)\n  - [Installation](#installation)\n  - [Implementing a Workflow](#implementing-a-workflow)\n  - [Running a Workflow](#running-a-workflow)\n  - [Next Steps](#next-steps)\n- [Usage](#usage)\n    - [Client](#client)\n      - [Data Conversion](#data-conversion)\n        - [Custom Type Data Conversion](#custom-type-data-conversion)\n    - [Workers](#workers)\n    - [Workflows](#workflows)\n      - [Definition](#definition)\n      - [Running](#running)\n      - [Invoking Activities](#invoking-activities)\n      - [Invoking Child Workflows](#invoking-child-workflows)\n      - [Timers](#timers)\n      - [Conditions](#conditions)\n      - [Asyncio and Cancellation](#asyncio-and-cancellation)\n      - [Workflow Utilities](#workflow-utilities)\n      - [Exceptions](#exceptions)\n      - [External Workflows](#external-workflows)\n      - [Testing](#testing)\n        - [Automatic Time Skipping](#automatic-time-skipping)\n        - [Manual Time Skipping](#manual-time-skipping)\n        - [Mocking Activities](#mocking-activities)\n      - [Workflow Sandbox](#workflow-sandbox)\n        - [How the Sandbox Works](#how-the-sandbox-works)\n        - [Avoiding the Sandbox](#avoiding-the-sandbox)\n        - [Customizing the Sandbox](#customizing-the-sandbox)\n          - [Passthrough Modules](#passthrough-modules)\n          - [Invalid Module Members](#invalid-module-members)\n        - [Known Sandbox Issues](#known-sandbox-issues)\n          - [Global Import/Builtins](#global-importbuiltins)\n          - [Sandbox is not Secure](#sandbox-is-not-secure)\n          - [Sandbox Performance](#sandbox-performance)\n          - [Extending Restricted Classes](#extending-restricted-classes)\n          - [Certain Standard Library Calls on Restricted Objects](#certain-standard-library-calls-on-restricted-objects)\n          - [is_subclass of ABC-based Restricted Classes](#is_subclass-of-abc-based-restricted-classes)\n          - [Compiled Pydantic Sometimes Using Wrong Types](#compiled-pydantic-sometimes-using-wrong-types)\n    - [Activities](#activities)\n      - [Definition](#definition-1)\n      - [Types of Activities](#types-of-activities)\n        - [Asynchronous Activities](#asynchronous-activities)\n        - [Synchronous Activities](#synchronous-activities)\n          - [Synchronous Multithreaded Activities](#synchronous-multithreaded-activities)\n          - [Synchronous Multiprocess/Other Activities](#synchronous-multiprocessother-activities)\n      - [Activity Context](#activity-context)\n        - [Heartbeating and Cancellation](#heartbeating-and-cancellation)\n        - [Worker Shutdown](#worker-shutdown)\n      - [Testing](#testing-1)\n    - [Workflow Replay](#workflow-replay)\n    - [OpenTelemetry Support](#opentelemetry-support)\n    - [Protobuf 3.x vs 4.x](#protobuf-3x-vs-4x)\n    - [Known Compatibility Issues](#known-compatibility-issues)\n      - [gevent Patching](#gevent-patching)\n- [Development](#development)\n    - [Building](#building)\n      - [Prepare](#prepare)\n      - [Build](#build)\n      - [Use](#use)\n    - [Local SDK development environment](#local-sdk-development-environment)\n      - [Testing](#testing-2)\n      - [Proto Generation and Testing](#proto-generation-and-testing)\n    - [Style](#style)\n\n<!-- END doctoc generated TOC please keep comment here to allow auto update -->\n\n# Quick Start\n\nWe will guide you through the Temporal basics to create a "hello, world!" script on your machine. It is not intended as one of the ways to use Temporal, but in reality it is very simplified and decidedly not "the only way" to use Temporal. For more information, check out the docs references in "Next Steps" below the quick start.\n\n## Installation\n\nInstall the `temporalio` package from [PyPI](https://pypi.org/project/temporalio).\n\nThese steps can be followed to use with a virtual environment and `pip`:\n\n* [Create a virtual environment](https://packaging.python.org/en/latest/tutorials/installing-packages/#creating-virtual-environments)\n* Update `pip` - `python -m pip install -U pip`\n  * Needed because older versions of `pip` may not pick the right wheel\n* Install Temporal SDK - `python -m pip install temporalio`\n\nThe SDK is now ready for use. To build from source, see "Building" near the end of this documentation.\n\n**NOTE: This README is for the current branch and not necessarily what\'s released on `PyPI`.**\n\n## Implementing a Workflow\n\nCreate the following in `activities.py`:\n\n```python\nfrom temporalio import activity\n\n@activity.defn\nasync def say_hello(name: str) -> str:\n    return f"Hello, {name}!"\n```\n\nCreate the following in `workflows.py`:\n\n```python\nfrom datetime import timedelta\nfrom temporalio import workflow\n\n# Import our activity, passing it through the sandbox\nwith workflow.unsafe.imports_passed_through():\n    from .activities import say_hello\n\n@workflow.defn\nclass SayHello:\n    @workflow.run\n    async def run(self, name: str) -> str:\n        return await workflow.execute_activity(\n            say_hello, name, schedule_to_close_timeout=timedelta(seconds=5)\n        )\n```\n\nCreate the following in `run_worker.py`:\n\n```python\nimport asyncio\nfrom temporalio.client import Client\nfrom temporalio.worker import Worker\n\n# Import the activity and workflow from our other files\nfrom .activities import say_hello\nfrom .workflows import SayHello\n\nasync def main():\n    # Create client connected to server at the given address\n    client = await Client.connect("localhost:7233")\n\n    # Run the worker\n    worker = Worker(client, task_queue="my-task-queue", workflows=[SayHello], activities=[say_hello])\n    await worker.run()\n\nif __name__ == "__main__":\n    asyncio.run(main())\n```\n\nAssuming you have a [Temporal server running on localhost](https://docs.temporal.io/docs/server/quick-install/), this\nwill run the worker:\n\n    python run_worker.py\n\n## Running a Workflow\n\nCreate the following script at `run_workflow.py`:\n\n```python\nimport asyncio\nfrom temporalio.client import Client\n\n# Import the workflow from the previous code\nfrom .workflows import SayHello\n\nasync def main():\n    # Create client connected to server at the given address\n    client = await Client.connect("localhost:7233")\n\n    # Execute a workflow\n    result = await client.execute_workflow(SayHello.run, "my name", id="my-workflow-id", task_queue="my-task-queue")\n\n    print(f"Result: {result}")\n\nif __name__ == "__main__":\n    asyncio.run(main())\n```\n\nAssuming you have `run_worker.py` running from before, this will run the workflow:\n\n    python run_workflow.py\n\nThe output will be:\n\n    Result: Hello, my-name!\n\n## Next Steps\n\nTemporal can be implemented in your code in many different ways, to suit your application\'s needs. The links below will\ngive you much more information about how Temporal works with Python:\n\n* [Code Samples](https://github.com/temporalio/samples-python) - If you want to start with some code, we have provided\n  some pre-built samples.\n* [Application Development Guide](https://docs.temporal.io/application-development?lang=python) Our Python specific\n  Developer\'s Guide will give you much more information on how to build with Temporal in your Python applications than\n  our SDK README ever could (or should).\n* [API Documentation](https://python.temporal.io) - Full Temporal Python SDK package documentation.\n\n---\n\n# Usage\n\nFrom here, you will find reference documentation about specific pieces of the Temporal Python SDK that were built around Temporal concepts. \n*This section is not intended as a how-to guide* -- For more how-to oriented information, check out the links in the [Next Steps](#next-steps) section above.\n\n### Client\n\nA client can be created and used to start a workflow like so:\n\n```python\nfrom temporalio.client import Client\n\nasync def main():\n    # Create client connected to server at the given address and namespace\n    client = await Client.connect("localhost:7233", namespace="my-namespace")\n\n    # Start a workflow\n    handle = await client.start_workflow(MyWorkflow.run, "some arg", id="my-workflow-id", task_queue="my-task-queue")\n\n    # Wait for result\n    result = await handle.result()\n    print(f"Result: {result}")\n```\n\nSome things to note about the above code:\n\n* A `Client` does not have an explicit "close"\n* To enable TLS, the `tls` argument to `connect` can be set to `True` or a `TLSConfig` object\n* A single positional argument can be passed to `start_workflow`. If there are multiple arguments, only the\n  non-type-safe form of `start_workflow` can be used (i.e. the one accepting a string workflow name) and it must be in\n  the `args` keyword argument.\n* The `handle` represents the workflow that was started and can be used for more than just getting the result\n* Since we are just getting the handle and waiting on the result, we could have called `client.execute_workflow` which\n  does the same thing\n* Clients can have many more options not shown here (e.g. data converters and interceptors)\n* A string can be used instead of the method reference to call a workflow by name (e.g. if defined in another language)\n\nClients also provide a shallow copy of their config for use in making slightly different clients backed by the same\nconnection. For instance, given the `client` above, this is how to have a client in another namespace:\n\n```python\nconfig = client.config()\nconfig["namespace"] = "my-other-namespace"\nother_ns_client = Client(**config)\n```\n\n#### Data Conversion\n\nData converters are used to convert raw Temporal payloads to/from actual Python types. A custom data converter of type\n`temporalio.converter.DataConverter` can be set via the `data_converter` client parameter. Data converters are a\ncombination of payload converters, payload codecs, and failure converters. Payload converters convert Python values\nto/from serialized bytes. Payload codecs convert bytes to bytes (e.g. for compression or encryption). Failure converters\nconvert exceptions to/from serialized failures.\n\nThe default data converter supports converting multiple types including:\n\n* `None`\n* `bytes`\n* `google.protobuf.message.Message` - As JSON when encoding, but has ability to decode binary proto from other languages\n* Anything that can be converted to JSON including:\n  * Anything that [`json.dump`](https://docs.python.org/3/library/json.html#json.dump) supports natively\n  * [dataclasses](https://docs.python.org/3/library/dataclasses.html)\n  * Iterables including ones JSON dump may not support by default, e.g. `set`\n  * Any class with a `dict()` method and a static `parse_obj()` method, e.g.\n    [Pydantic models](https://pydantic-docs.helpmanual.io/usage/models)\n    * The default data converter is deprecated for Pydantic models and will warn if used since not all fields work.\n      See [this sample](https://github.com/temporalio/samples-python/tree/main/pydantic_converter) for the recommended\n      approach.\n  * [IntEnum, StrEnum](https://docs.python.org/3/library/enum.html) based enumerates\n  * [UUID](https://docs.python.org/3/library/uuid.html)\n\nThis notably doesn\'t include any `date`, `time`, or `datetime` objects as they may not work across SDKs.\n\nUsers are strongly encouraged to use a single `dataclass` for parameter and return types so fields with defaults can be\neasily added without breaking compatibility.\n\nClasses with generics may not have the generics properly resolved. The current implementation, similar to Pydantic, does\nnot have generic type resolution. Users should use concrete types.\n\n##### Custom Type Data Conversion\n\nFor converting from JSON, the workflow/activity type hint is taken into account to convert to the proper type. Care has\nbeen taken to support all common typings including `Optional`, `Union`, all forms of iterables and mappings, `NewType`,\netc in addition to the regular JSON values mentioned before.\n\nData converters contain a reference to a payload converter class that is used to convert to/from payloads/values. This\nis a class and not an instance because it is instantiated on every workflow run inside the sandbox. The payload\nconverter is usually a `CompositePayloadConverter` which contains a multiple `EncodingPayloadConverter`s it uses to try\nto serialize/deserialize payloads. Upon serialization, each `EncodingPayloadConverter` is tried until one succeeds. The\n`EncodingPayloadConverter` provides an "encoding" string serialized onto the payload so that, upon deserialization, the\nspecific `EncodingPayloadConverter` for the given "encoding" is used.\n\nThe default data converter uses the `DefaultPayloadConverter` which is simply a `CompositePayloadConverter` with a known\nset of default `EncodingPayloadConverter`s. To implement a custom encoding for a custom type, a new\n`EncodingPayloadConverter` can be created for the new type. For example, to support `IPv4Address` types:\n\n```python\nclass IPv4AddressEncodingPayloadConverter(EncodingPayloadConverter):\n    @property\n    def encoding(self) -> str:\n        return "text/ipv4-address"\n\n    def to_payload(self, value: Any) -> Optional[Payload]:\n        if isinstance(value, ipaddress.IPv4Address):\n            return Payload(\n                metadata={"encoding": self.encoding.encode()},\n                data=str(value).encode(),\n            )\n        else:\n            return None\n\n    def from_payload(self, payload: Payload, type_hint: Optional[Type] = None) -> Any:\n        assert not type_hint or type_hint is ipaddress.IPv4Address\n        return ipaddress.IPv4Address(payload.data.decode())\n\nclass IPv4AddressPayloadConverter(CompositePayloadConverter):\n    def __init__(self) -> None:\n        # Just add ours as first before the defaults\n        super().__init__(\n            IPv4AddressEncodingPayloadConverter(),\n            *DefaultPayloadConverter.default_encoding_payload_converters,\n        )\n\nmy_data_converter = dataclasses.replace(\n    DataConverter.default,\n    payload_converter_class=IPv4AddressPayloadConverter,\n)\n```\n\nImports are left off for brevity.\n\nThis is good for many custom types. However, sometimes you want to override the behavior of the just the existing JSON\nencoding payload converter to support a new type. It is already the last encoding data converter in the list, so it\'s\nthe fall-through behavior for any otherwise unknown type. Customizing the existing JSON converter has the benefit of\nmaking the type work in lists, unions, etc.\n\nThe `JSONPlainPayloadConverter` uses the Python [json](https://docs.python.org/3/library/json.html) library with an\nadvanced JSON encoder by default and a custom value conversion method to turn `json.load`ed values to their type hints.\nThe conversion can be customized for serialization with a custom `json.JSONEncoder` and deserialization with a custom\n`JSONTypeConverter`. For example, to support `IPv4Address` types in existing JSON conversion:\n\n```python\nclass IPv4AddressJSONEncoder(AdvancedJSONEncoder):\n    def default(self, o: Any) -> Any:\n        if isinstance(o, ipaddress.IPv4Address):\n            return str(o)\n        return super().default(o)\nclass IPv4AddressJSONTypeConverter(JSONTypeConverter):\n    def to_typed_value(\n        self, hint: Type, value: Any\n    ) -> Union[Optional[Any], _JSONTypeConverterUnhandled]:\n        if issubclass(hint, ipaddress.IPv4Address):\n            return ipaddress.IPv4Address(value)\n        return JSONTypeConverter.Unhandled\n\nclass IPv4AddressPayloadConverter(CompositePayloadConverter):\n    def __init__(self) -> None:\n        # Replace default JSON plain with our own that has our encoder and type\n        # converter\n        json_converter = JSONPlainPayloadConverter(\n            encoder=IPv4AddressJSONEncoder,\n            custom_type_converters=[IPv4AddressJSONTypeConverter()],\n        )\n        super().__init__(\n            *[\n                c if not isinstance(c, JSONPlainPayloadConverter) else json_converter\n                for c in DefaultPayloadConverter.default_encoding_payload_converters\n            ]\n        )\n\nmy_data_converter = dataclasses.replace(\n    DataConverter.default,\n    payload_converter_class=IPv4AddressPayloadConverter,\n)\n```\n\nNow `IPv4Address` can be used in type hints including collections, optionals, etc.\n\n### Workers\n\nWorkers host workflows and/or activities. Here\'s how to run a worker:\n\n```python\nimport asyncio\nimport logging\nfrom temporalio.client import Client\nfrom temporalio.worker import Worker\n# Import your own workflows and activities\nfrom my_workflow_package import MyWorkflow, my_activity\n\nasync def run_worker(stop_event: asyncio.Event):\n    # Create client connected to server at the given address\n    client = await Client.connect("localhost:7233", namespace="my-namespace")\n\n    # Run the worker until the event is set\n    worker = Worker(client, task_queue="my-task-queue", workflows=[MyWorkflow], activities=[my_activity])\n    async with worker:\n        await stop_event.wait()\n```\n\nSome things to note about the above code:\n\n* This creates/uses the same client that is used for starting workflows\n* While this example accepts a stop event and uses `async with`, `run()` and `shutdown()` may be used instead\n* Workers can have many more options not shown here (e.g. data converters and interceptors)\n\n### Workflows\n\n#### Definition\n\nWorkflows are defined as classes decorated with `@workflow.defn`. The method invoked for the workflow is decorated with\n`@workflow.run`. Methods for signals and queries are decorated with `@workflow.signal` and `@workflow.query`\nrespectively. Here\'s an example of a workflow:\n\n```python\nimport asyncio\nfrom datetime import timedelta\nfrom temporalio import workflow\n\n# Pass the activities through the sandbox\nwith workflow.unsafe.imports_passed_through():\n    from .my_activities import GreetingInfo, create_greeting_activity\n\n@workflow.defn\nclass GreetingWorkflow:\n    def __init__() -> None:\n        self._current_greeting = "<unset>"\n        self._greeting_info = GreetingInfo()\n        self._greeting_info_update = asyncio.Event()\n        self._complete = asyncio.Event()\n\n    @workflow.run\n    async def run(self, name: str) -> str:\n        self._greeting_info.name = name\n        while True:\n            # Store greeting\n            self._current_greeting = await workflow.execute_activity(\n                create_greeting_activity,\n                self._greeting_info,\n                start_to_close_timeout=timedelta(seconds=5),\n            )\n            workflow.logger.debug("Greeting set to %s", self._current_greeting)\n            \n            # Wait for salutation update or complete signal (this can be\n            # cancelled)\n            await asyncio.wait(\n                [\n                    asyncio.create_task(self._greeting_info_update.wait()),\n                    asyncio.create_task(self._complete.wait()),\n                ],\n                return_when=asyncio.FIRST_COMPLETED,\n            )\n            if self._complete.is_set():\n                return self._current_greeting\n            self._greeting_info_update.clear()\n\n    @workflow.signal\n    async def update_salutation(self, salutation: str) -> None:\n        self._greeting_info.salutation = salutation\n        self._greeting_info_update.set()\n\n    @workflow.signal\n    async def complete_with_greeting(self) -> None:\n        self._complete.set()\n\n    @workflow.query\n    async def current_greeting(self) -> str:\n        return self._current_greeting\n\n```\n\nThis assumes there\'s an activity in `my_activities.py` like:\n\n```python\nfrom dataclasses import dataclass\nfrom temporalio import workflow\n\n@dataclass\nclass GreetingInfo:\n    salutation: str = "Hello"\n    name: str = "<unknown>"\n\n@activity.defn\nasync def create_greeting_activity(info: GreetingInfo) -> str:\n    return f"{info.salutation}, {info.name}!"\n```\n\nSome things to note about the above workflow code:\n\n* Workflows run in a sandbox by default.\n  * Users are encouraged to define workflows in files with no side effects or other complicated code or unnecessary\n    imports to other third party libraries.\n  * Non-standard-library, non-`temporalio` imports should usually be "passed through" the sandbox. See the\n    [Workflow Sandbox](#workflow-sandbox) section for more details.\n* This workflow continually updates the queryable current greeting when signalled and can complete with the greeting on\n  a different signal\n* Workflows are always classes and must have a single `@workflow.run` which is an `async def` function\n* Workflow code must be deterministic. This means no threading, no randomness, no external calls to processes, no\n  network IO, and no global state mutation. All code must run in the implicit `asyncio` event loop and be deterministic.\n* `@activity.defn` is explained in a later section. For normal simple string concatenation, this would just be done in\n  the workflow. The activity is for demonstration purposes only.\n* `workflow.execute_activity(create_greeting_activity, ...` is actually a typed signature, and MyPy will fail if the\n  `self._greeting_info` parameter is not a `GreetingInfo`\n\nHere are the decorators that can be applied:\n\n* `@workflow.defn` - Defines a workflow class\n  * Must be defined on the class given to the worker (ignored if present on a base class)\n  * Can have a `name` param to customize the workflow name, otherwise it defaults to the unqualified class name\n* `@workflow.run` - Defines the primary workflow run method\n  * Must be defined on the same class as `@workflow.defn`, not a base class (but can _also_ be defined on the same\n    method of a base class)\n  * Exactly one method name must have this decorator, no more or less\n  * Must be defined on an `async def` method\n  * The method\'s arguments are the workflow\'s arguments\n  * The first parameter must be `self`, followed by positional arguments. Best practice is to only take a single\n    argument that is an object/dataclass of fields that can be added to as needed.\n* `@workflow.signal` - Defines a method as a signal\n  * Can be defined on an `async` or non-`async` function at any hierarchy depth, but if decorated method is overridden,\n    the override must also be decorated\n  * The method\'s arguments are the signal\'s arguments\n  * Can have a `name` param to customize the signal name, otherwise it defaults to the unqualified method name\n  * Can have `dynamic=True` which means all otherwise unhandled signals fall through to this. If present, cannot have\n    `name` argument, and method parameters must be `self`, a string signal name, and a `*args` varargs param.\n  * Non-dynamic method can only have positional arguments. Best practice is to only take a single argument that is an\n    object/dataclass of fields that can be added to as needed.\n  * Return value is ignored\n* `@workflow.query` - Defines a method as a query\n  * All the same constraints as `@workflow.signal` but should return a value\n  * Temporal queries should never mutate anything in the workflow\n\n#### Running\n\nTo start a locally-defined workflow from a client, you can simply reference its method like so:\n\n```python\nfrom temporalio.client import Client\nfrom my_workflow_package import GreetingWorkflow\n\nasync def create_greeting(client: Client) -> str:\n    # Start the workflow\n    handle = await client.start_workflow(GreetingWorkflow.run, "my name", id="my-workflow-id", task_queue="my-task-queue")\n    # Change the salutation\n    await handle.signal(GreetingWorkflow.update_salutation, "Aloha")\n    # Tell it to complete\n    await handle.signal(GreetingWorkflow.complete_with_greeting)\n    # Wait and return result\n    return await handle.result()\n```\n\nSome things to note about the above code:\n\n* This uses the `GreetingWorkflow` from the previous section\n* The result of calling this function is `"Aloha, my name!"`\n* `id` and `task_queue` are required for running a workflow\n* `client.start_workflow` is typed, so MyPy would fail if `"my name"` were something besides a string\n* `handle.signal` is typed, so MyPy would fail if `"Aloha"` were something besides a string or if we provided a\n  parameter to the parameterless `complete_with_greeting`\n* `handle.result` is typed to the workflow itself, so MyPy would fail if we said this `create_greeting` returned\n  something besides a string\n\n#### Invoking Activities\n\n* Activities are started with non-async `workflow.start_activity()` which accepts either an activity function reference\n  or a string name.\n* A single argument to the activity is positional. Multiple arguments are not supported in the type-safe form of\n  start/execute activity and must be supplied via the `args` keyword argument.\n* Activity options are set as keyword arguments after the activity arguments. At least one of `start_to_close_timeout`\n  or `schedule_to_close_timeout` must be provided.\n* The result is an activity handle which is an `asyncio.Task` and supports basic task features\n* An async `workflow.execute_activity()` helper is provided which takes the same arguments as\n  `workflow.start_activity()` and `await`s on the result. This should be used in most cases unless advanced task\n  capabilities are needed.\n* Local activities work very similarly except the functions are `workflow.start_local_activity()` and\n  `workflow.execute_local_activity()`\n  * ⚠️Local activities are currently experimental\n* Activities can be methods of a class. Invokers should use `workflow.start_activity_method()`,\n  `workflow.execute_activity_method()`, `workflow.start_local_activity_method()`, and\n  `workflow.execute_local_activity_method()` instead.\n* Activities can callable classes (i.e. that define `__call__`). Invokers should use `workflow.start_activity_class()`,\n  `workflow.execute_activity_class()`, `workflow.start_local_activity_class()`, and\n  `workflow.execute_local_activity_class()` instead.\n\n#### Invoking Child Workflows\n\n* Child workflows are started with async `workflow.start_child_workflow()` which accepts either a workflow run method\n  reference or a string name. The arguments to the workflow are positional.\n* A single argument to the child workflow is positional. Multiple arguments are not supported in the type-safe form of\n  start/execute child workflow and must be supplied via the `args` keyword argument.\n* Child workflow options are set as keyword arguments after the arguments. At least `id` must be provided.\n* The `await` of the start does not complete until the start has been accepted by the server\n* The result is a child workflow handle which is an `asyncio.Task` and supports basic task features. The handle also has\n  some child info and supports signalling the child workflow\n* An async `workflow.execute_child_workflow()` helper is provided which takes the same arguments as\n  `workflow.start_child_workflow()` and `await`s on the result. This should be used in most cases unless advanced task\n  capabilities are needed.\n\n#### Timers\n\n* A timer is represented by normal `asyncio.sleep()`\n* Timers are also implicitly started on any `asyncio` calls with timeouts (e.g. `asyncio.wait_for`)\n* Timers are Temporal server timers, not local ones, so sub-second resolution rarely has value\n\n#### Conditions\n\n* `workflow.wait_condition` is an async function that doesn\'t return until a provided callback returns true\n* A `timeout` can optionally be provided which will throw a `asyncio.TimeoutError` if reached (internally backed by\n  `asyncio.wait_for` which uses a timer)\n\n#### Asyncio and Cancellation\n\nWorkflows are backed by a custom [asyncio](https://docs.python.org/3/library/asyncio.html) event loop. This means many\nof the common `asyncio` calls work as normal. Some asyncio features are disabled such as:\n\n* Thread related calls such as `to_thread()`, `run_coroutine_threadsafe()`, `loop.run_in_executor()`, etc\n* Calls that alter the event loop such as `loop.close()`, `loop.stop()`, `loop.run_forever()`,\n  `loop.set_task_factory()`, etc\n* Calls that use a specific time such as `loop.call_at()`\n* Calls that use anything external such as networking, subprocesses, disk IO, etc\n\nCancellation is done the same way as `asyncio`. Specifically, a task can be requested to be cancelled but does not\nnecessarily have to respect that cancellation immediately. This also means that `asyncio.shield()` can be used to\nprotect against cancellation. The following tasks, when cancelled, perform a Temporal cancellation:\n\n* Activities - when the task executing an activity is cancelled, a cancellation request is sent to the activity\n* Child workflows - when the task starting or executing a child workflow is cancelled, a cancellation request is sent to\n  cancel the child workflow\n* Timers - when the task executing a timer is cancelled (whether started via sleep or timeout), the timer is cancelled\n\nWhen the workflow itself is requested to cancel, `Task.cancel` is called on the main workflow task. Therefore,\n`asyncio.CancelledError` can be caught in order to handle the cancel gracefully.\n\nWorkflows follow `asyncio` cancellation rules exactly which can cause confusion among Python developers. Cancelling a\ntask doesn\'t always cancel the thing it created. For example, given\n`task = asyncio.create_task(workflow.start_child_workflow(...`, calling `task.cancel` does not cancel the child\nworkflow, it only cancels the starting of it, which has no effect if it has already started. However, cancelling the\nresult of `handle = await workflow.start_child_workflow(...` or\n`task = asyncio.create_task(workflow.execute_child_workflow(...` _does_ cancel the child workflow.\n\nAlso, due to Temporal rules, a cancellation request is a state not an event. Therefore, repeated cancellation requests\nare not delivered, only the first. If the workflow chooses swallow a cancellation, it cannot be requested again.\n\n#### Workflow Utilities\n\nWhile running in a workflow, in addition to features documented elsewhere, the following items are available from the\n`temporalio.workflow` package:\n\n* `continue_as_new()` - Async function to stop the workflow immediately and continue as new\n* `info()` - Returns information about the current workflow\n* `logger` - A logger for use in a workflow (properly skips logging on replay)\n* `now()` - Returns the "current time" from the workflow\'s perspective\n\n#### Exceptions\n\n* Workflows can raise exceptions to fail the workflow or the "workflow task" (i.e. suspend the workflow retrying).\n* Exceptions that are instances of `temporalio.exceptions.FailureError` will fail the workflow with that exception\n  * For failing the workflow explicitly with a user exception, use `temporalio.exceptions.ApplicationError`. This can\n    be marked non-retryable or include details as needed.\n  * Other exceptions that come from activity execution, child execution, cancellation, etc are already instances of\n    `FailureError` and will fail the workflow when uncaught.\n* All other exceptions fail the "workflow task" which means the workflow will continually retry until the workflow is\n  fixed. This is helpful for bad code or other non-predictable exceptions. To actually fail the workflow, use an\n  `ApplicationError` as mentioned above.\n\n#### External Workflows\n\n* `workflow.get_external_workflow_handle()` inside a workflow returns a handle to interact with another workflow\n* `workflow.get_external_workflow_handle_for()` can be used instead for a type safe handle\n* `await handle.signal()` can be called on the handle to signal the external workflow\n* `await handle.cancel()` can be called on the handle to send a cancel to the external workflow\n\n#### Testing\n\nWorkflow testing can be done in an integration-test fashion against a real server, however it is hard to simulate\ntimeouts and other long time-based code. Using the time-skipping workflow test environment can help there.\n\nThe time-skipping `temporalio.testing.WorkflowEnvironment` can be created via the static async `start_time_skipping()`.\nThis internally downloads the Temporal time-skipping test server to a temporary directory if it doesn\'t already exist,\nthen starts the test server which has special APIs for skipping time.\n\n##### Automatic Time Skipping\n\nAnytime a workflow result is waited on, the time-skipping server automatically advances to the next event it can. To\nmanually advance time before waiting on the result of a workflow, the `WorkflowEnvironment.sleep` method can be used.\n\nHere\'s a simple example of a workflow that sleeps for 24 hours:\n\n```python\nimport asyncio\nfrom temporalio import workflow\n\n@workflow.defn\nclass WaitADayWorkflow:\n    @workflow.run\n    async def run(self) -> str:\n        await asyncio.sleep(24 * 60 * 60)\n        return "all done"\n```\n\nAn integration test of this workflow would be way too slow. However the time-skipping server automatically skips to the\nnext event when we wait on the result. Here\'s a test for that workflow:\n\n```python\nfrom temporalio.testing import WorkflowEnvironment\nfrom temporalio.worker import Worker\n\nasync def test_wait_a_day_workflow():\n    async with await WorkflowEnvironment.start_time_skipping() as env:\n        async with Worker(env.client, task_queue="tq1", workflows=[WaitADayWorkflow]):\n            assert "all done" == await env.client.execute_workflow(WaitADayWorkflow.run, id="wf1", task_queue="tq1")\n```\n\nThat test will run almost instantly. This is because by calling `execute_workflow` on our client, we have asked the\nenvironment to automatically skip time as much as it can (basically until the end of the workflow or until an activity\nis run).\n\nTo disable automatic time-skipping while waiting for a workflow result, run code inside a\n`with env.auto_time_skipping_disabled():` block.\n\n##### Manual Time Skipping\n\nUntil a workflow is waited on, all time skipping in the time-skipping environment is done manually via\n`WorkflowEnvironment.sleep`.\n\nHere\'s workflow that waits for a signal or times out:\n\n```python\nimport asyncio\nfrom temporalio import workflow\n\n@workflow.defn\nclass SignalWorkflow:\n    def __init__(self) -> None:\n        self.signal_received = False\n\n    @workflow.run\n    async def run(self) -> str:\n        # Wait for signal or timeout in 45 seconds\n        try:\n            await workflow.wait_condition(lambda: self.signal_received, timeout=45)\n            return "got signal"\n        except asyncio.TimeoutError:\n            return "got timeout"\n\n    @workflow.signal\n    def some_signal(self) -> None:\n        self.signal_received = True\n```\n\nTo test a normal signal, you might:\n\n```python\nfrom temporalio.testing import WorkflowEnvironment\nfrom temporalio.worker import Worker\n\nasync def test_signal_workflow():\n    async with await WorkflowEnvironment.start_time_skipping() as env:\n        async with Worker(env.client, task_queue="tq1", workflows=[SignalWorkflow]):\n            # Start workflow, send signal, check result\n            handle = await env.client.start_workflow(SignalWorkflow.run, id="wf1", task_queue="tq1")\n            await handle.signal(SignalWorkflow.some_signal)\n            assert "got signal" == await handle.result()\n```\n\nBut how would you test the timeout part? Like so:\n\n```python\nfrom temporalio.testing import WorkflowEnvironment\nfrom temporalio.worker import Worker\n\nasync def test_signal_workflow_timeout():\n    async with await WorkflowEnvironment.start_time_skipping() as env:\n        async with Worker(env.client, task_queue="tq1", workflows=[SignalWorkflow]):\n            # Start workflow, advance time past timeout, check result\n            handle = await env.client.start_workflow(SignalWorkflow.run, id="wf1", task_queue="tq1")\n            await env.sleep(50)\n            assert "got timeout" == await handle.result()\n```\n\nAlso, the current time of the workflow environment can be obtained via the async `WorkflowEnvironment.get_current_time`\nmethod.\n\n##### Mocking Activities\n\nActivities are just functions decorated with `@activity.defn`. Simply write different ones and pass those to the worker\nto have different activities called during the test.\n\n#### Workflow Sandbox\n\nBy default workflows are run in a sandbox to help avoid non-deterministic code. If a call that is known to be\nnon-deterministic is performed, an exception will be thrown in the workflow which will "fail the task" which means the\nworkflow will not progress until fixed.\n\nThe sandbox is not foolproof and non-determinism can still occur. It is simply a best-effort way to catch bad code\nearly. Users are encouraged to define their workflows in files with no other side effects.\n\nThe sandbox offers a mechanism to pass through modules from outside the sandbox. By default this already includes all\nstandard library modules and Temporal modules. **For performance and behavior reasons, users are encouraged to pass\nthrough all third party modules whose calls will be deterministic.** This includes modules containing the activities to\nbe referenced in workflows. See "Passthrough Modules" below on how to do this.\n\nIf you are getting an error like:\n\n> temporalio.worker.workflow_sandbox._restrictions.RestrictedWorkflowAccessError: Cannot access\n> http.client.IncompleteRead.\\_\\_mro_entries\\_\\_ from inside a workflow. If this is code from a module not used in a\n> workflow or known to only be used deterministically from a workflow, mark the import as pass through.\n\nThen you are either using an invalid construct from the workflow, this is a known limitation of the sandbox, or most\ncommonly this is from a module that is safe to pass through (see "Passthrough Modules" section below).\n\n##### How the Sandbox Works\n\nThe sandbox is made up of two components that work closely together:\n\n* Global state isolation\n* Restrictions preventing known non-deterministic library calls\n\nGlobal state isolation is performed by using `exec`. Upon workflow start, the file that the workflow is defined in is\nimported into a new sandbox created for that workflow run. In order to keep the sandbox performant a known set of\n"passthrough modules" are passed through from outside of the sandbox when they are imported. These are expected to be\nside-effect free on import and have their non-deterministic aspects restricted. By default the entire Python standard\nlibrary, `temporalio`, and a couple of other modules are passed through from outside of the sandbox. To update this\nlist, see "Customizing the Sandbox".\n\nRestrictions preventing known non-deterministic library calls are achieved using proxy objects on modules wrapped around\nthe custom importer set in the sandbox. Many restrictions apply at workflow import time and workflow run time, while\nsome restrictions only apply at workflow run time. A default set of restrictions is included that prevents most\ndangerous standard library calls. However it is known in Python that some otherwise-non-deterministic invocations, like\nreading a file from disk via `open` or using `os.environ`, are done as part of importing modules. To customize what is\nand isn\'t restricted, see "Customizing the Sandbox".\n\n##### Avoiding the Sandbox\n\nThere are three increasingly-scoped ways to avoid the sandbox. Users are discouraged from avoiding the sandbox if\npossible.\n\nTo remove restrictions around a particular block of code, use `with temporalio.workflow.unsafe.sandbox_unrestricted():`.\nThe workflow will still be running in the sandbox, but no restrictions for invalid library calls will be applied.\n\nTo run an entire workflow outside of a sandbox, set `sandboxed=False` on the `@workflow.defn` decorator when defining\nit. This will run the entire workflow outside of the workflow which means it can share global state and other bad\nthings.\n\nTo disable the sandbox entirely for a worker, set the `Worker` init\'s `workflow_runner` keyword argument to \n`temporalio.worker.UnsandboxedWorkflowRunner()`. This value is defaulted to\n`temporalio.worker.workflow_sandbox.SandboxedWorkflowRunner()` so by changing it to the unsandboxed runner, the sandbox\nwill not be used at all.\n\n##### Customizing the Sandbox\n\n⚠️ WARNING: APIs in the `temporalio.worker.workflow_sandbox` module are not yet considered stable and may change in\nfuture releases.\n\nWhen creating the `Worker`, the `workflow_runner` is defaulted to\n`temporalio.worker.workflow_sandbox.SandboxedWorkflowRunner()`. The `SandboxedWorkflowRunner`\'s init accepts a\n`restrictions` keyword argument that is defaulted to `SandboxRestrictions.default`. The `SandboxRestrictions` dataclass\nis immutable and contains three fields that can be customized, but only two have notable value. See below.\n\n###### Passthrough Modules\n\nBy default the sandbox completely reloads non-standard-library and non-Temporal modules for every workflow run. To make\nthe sandbox quicker and use less memory when importing known-side-effect-free third party modules, they can be marked\nas passthrough modules.\n\n**For performance and behavior reasons, users are encouraged to pass through all third party modules whose calls will be\ndeterministic.**\n\nOne way to pass through a module is at import time in the workflow file using the `imports_passed_through` context\nmanager like so:\n\n```python\n# my_workflow_file.py\n\nfrom temporalio import workflow\n\nwith workflow.unsafe.imports_passed_through():\n    import pydantic\n\n@workflow.defn\nclass MyWorkflow:\n    ...\n```\n\nAlternatively, this can be done at worker creation time by customizing the runner\'s restrictions. For example:\n\n```python\nmy_worker = Worker(\n  ...,\n  workflow_runner=SandboxedWorkflowRunner(\n    restrictions=SandboxRestrictions.default.with_passthrough_modules("pydantic")\n  )\n)\n```\n\nIn both of these cases, now the `pydantic` module will be passed through from outside of the sandbox instead of\nbeing reloaded for every workflow run.\n\n###### Invalid Module Members\n\n`SandboxRestrictions.invalid_module_members` contains a root matcher that applies to all module members. This already\nhas a default set which includes things like `datetime.date.today()` which should never be called from a workflow. To\nremove this restriction:\n\n```python\nmy_restrictions = dataclasses.replace(\n    SandboxRestrictions.default,\n    invalid_module_members=SandboxRestrictions.invalid_module_members_default.with_child_unrestricted(\n      "datetime", "date", "today",\n    ),\n)\nmy_worker = Worker(..., workflow_runner=SandboxedWorkflowRunner(restrictions=my_restrictions))\n```\n\nRestrictions can also be added by `|`\'ing together matchers, for example to restrict the `datetime.date` class from\nbeing used altogether:\n\n```python\nmy_restrictions = dataclasses.replace(\n    SandboxRestrictions.default,\n    invalid_module_members=SandboxRestrictions.invalid_module_members_default | SandboxMatcher(\n      children={"datetime": SandboxMatcher(use={"date"})},\n    ),\n)\nmy_worker = Worker(..., workflow_runner=SandboxedWorkflowRunner(restrictions=my_restrictions))\n```\n\nSee the API for more details on exact fields and their meaning.\n\n##### Known Sandbox Issues\n\nBelow are known sandbox issues. As the sandbox is developed and matures, some may be resolved.\n\n###### Global Import/Builtins\n\nCurrently the sandbox references/alters the global `sys.modules` and `builtins` fields while running workflow code. In\norder to prevent affecting other sandboxed code, thread locals are leveraged to only intercept these values during the\nworkflow thread running. Therefore, technically if top-level import code starts a thread, it may lose sandbox\nprotection.\n\n###### Sandbox is not Secure\n\nThe sandbox is built to catch many non-deterministic and state sharing issues, but it is not secure. Some known bad\ncalls are intercepted, but for performance reasons, every single attribute get/set cannot be checked. Therefore a simple\ncall like `setattr(temporalio.common, "__my_key", "my value")` will leak across sandbox runs.\n\nThe sandbox is only a helper, it does not provide full protection.\n\n###### Sandbox Performance\n\nThe sandbox does not add significant CPU or memory overhead for workflows that are in files which only import standard\nlibrary modules. This is because they are passed through from outside of the sandbox. However, every\nnon-standard-library import that is performed at the top of the same file the workflow is in will add CPU overhead (the\nmodule is re-imported every workflow run) and memory overhead (each module independently cached as part of the workflow\nrun for isolation reasons). This becomes more apparent for large numbers of workflow runs.\n\nTo mitigate this, users should:\n\n* Define workflows in files that have as few non-standard-library imports as possible\n* Alter the max workflow cache and/or max concurrent workflows settings if memory grows too large\n* Set third-party libraries as passthrough modules if they are known to be side-effect free\n\n###### Extending Restricted Classes\n\nExtending a restricted class causes Python to instantiate the restricted metaclass which is unsupported. Therefore if\nyou attempt to use a class in the sandbox that extends a restricted class, it will fail. For example, if you have a\n`class MyZipFile(zipfile.ZipFile)` and try to use that class inside a workflow, it will fail.\n\nClasses used inside the workflow should not extend restricted classes. For situations where third-party modules need to\nat import time, they should be marked as pass through modules.\n\n###### Certain Standard Library Calls on Restricted Objects\n\nIf an object is restricted, internal C Python validation may fail in some cases. For example, running\n`dict.items(os.__dict__)` will fail with:\n\n> descriptor \'items\' for \'dict\' objects doesn\'t apply to a \'_RestrictedProxy\' object\n\nThis is a low-level check that cannot be subverted. The solution is to not use restricted objects inside the sandbox.\nFor situations where third-party modules need to at import time, they should be marked as pass through modules.\n\n###### is_subclass of ABC-based Restricted Classes\n\nDue to [https://bugs.python.org/issue44847](https://bugs.python.org/issue44847), classes that are wrapped and then\nchecked to see if they are subclasses of another via `is_subclass` may fail (see also\n[this wrapt issue](https://github.com/GrahamDumpleton/wrapt/issues/130)).\n\n###### Compiled Pydantic Sometimes Using Wrong Types\n\nIf the Pydantic dependency is in compiled form (the default) and you are using a Pydantic model inside a workflow\nsandbox that uses a `datetime` type, it will grab the wrong validator and use `date` instead. This is because our\npatched form of `issubclass` is bypassed by compiled Pydantic.\n\nTo work around, either don\'t use `datetime`-based Pydantic model fields in workflows, or mark `datetime` library as\npassthrough (means you lose protection against calling the non-deterministic `now()`), or use non-compiled Pydantic\ndependency.\n\n### Activities\n\n#### Definition\n\nActivities are decorated with `@activity.defn` like so:\n\n```python\nfrom temporalio import activity\n\n@activity.defn\nasync def say_hello_activity(name: str) -> str:\n    return f"Hello, {name}!"\n```\n\nSome things to note about activity definitions:\n\n* The `say_hello_activity` is `async` which is the recommended activity type (see "Types of Activities" below)\n* A custom name for the activity can be set with a decorator argument, e.g. `@activity.defn(name="my activity")`\n* Long running activities should regularly heartbeat and handle cancellation\n* Activities can only have positional arguments. Best practice is to only take a single argument that is an\n  object/dataclass of fields that can be added to as needed.\n* Activities can be defined on methods instead of top-level functions. This allows the instance to carry state that an\n  activity may need (e.g. a DB connection). The instance method should be what is registered with the worker.\n* Activities can also be defined on callable classes (i.e. classes with `__call__`). An instance of the class should be\n  what is registered with the worker.\n\n#### Types of Activities\n\nThere are 3 types of activity callables accepted and described below: asynchronous, synchronous multithreaded, and\nsynchronous multiprocess/other. Only positional parameters are allowed in activity callables.\n\n##### Asynchronous Activities\n\nAsynchronous activities, i.e. functions using `async def`, are the recommended activity type. When using asynchronous\nactivities no special worker parameters are needed.\n\nCancellation for asynchronous activities is done via\n[`asyncio.Task.cancel`](https://docs.python.org/3/library/asyncio-task.html#asyncio.Task.cancel). This means that\n`asyncio.CancelledError` will be raised (and can be caught, but it is not recommended). A non-local activity must\nheartbeat to receive cancellation and there are other ways to be notified about cancellation (see "Activity Context" and\n"Heartbeating and Cancellation" later).\n\n##### Synchronous Activities\n\nSynchronous activities, i.e. functions that do not have `async def`, can be used with workers, but the\n`activity_executor` worker parameter must be set with a `concurrent.futures.Executor` instance to use for executing the\nactivities.\n\nAll long running, non-local activities should heartbeat so they can be cancelled. Cancellation in threaded activities\nthrows but multiprocess/other activities does not. The sections below on each synchronous type explain further. There\nare also calls on the context that can check for cancellation. For more information, see "Activity Context" and\n"Heartbeating and Cancellation" sections later.\n\nNote, all calls from an activity to functions in the `temporalio.activity` package are powered by\n[contextvars](https://docs.python.org/3/library/contextvars.html). Therefore, new threads starting _inside_ of\nactivities must `copy_context()` and then `.run()` manually to ensure `temporalio.activity` calls like `heartbeat` still\nfunction in the new threads.\n\nIf any activity ever throws a `concurrent.futures.BrokenExecutor`, the failure is consisted unrecoverable and the worker\nwill fail and shutdown.\n\n###### Synchronous Multithreaded Activities\n\nIf `activity_executor` is set to an instance of `concurrent.futures.ThreadPoolExecutor` then the synchronous activities\nare considered multithreaded activities. Besides `activity_executor`, no other worker parameters are required for\nsynchronous multithreaded activities.\n\nBy default, cancellation of a synchronous multithreaded activity is done via a `temporalio.exceptions.CancelledError`\nthrown into the activity thread. Activities that do not wish to have cancellation thrown can set\n`no_thread_cancel_exception=True` in the `@activity.defn` decorator.\n\nCode that wishes to be temporarily shielded from the cancellation exception can run inside\n`with activity.shield_thread_cancel_exception():`. But once the last nested form of that block is finished, even if\nthere is a return statement within, it will throw the cancellation if there was one. A `try` +\n`except temporalio.exceptions.CancelledError` would have to surround the `with` to handle the cancellation explicitly.\n\n###### Synchronous Multiprocess/Other Activities\n\nIf `activity_executor` is set to an instance of `concurrent.futures.Executor` that is _not_\n`concurrent.futures.ThreadPoolExecutor`, then the synchronous activities are considered multiprocess/other activities.\n\nThese require special primitives for heartbeating and cancellation. The `shared_state_manager` worker parameter must be\nset to an instance of `temporalio.worker.SharedStateManager`. The most common implementation can be created by passing a\n`multiprocessing.managers.SyncManager` (i.e. result of `multiprocessing.managers.Manager()`) to\n`temporalio.worker.SharedStateManager.create_from_multiprocessing()`.\n\nAlso, all of these activity functions must be\n["picklable"](https://docs.python.org/3/library/pickle.html#what-can-be-pickled-and-unpickled).\n\n#### Activity Context\n\nDuring activity execution, an implicit activity context is set as a\n[context variable](https://docs.python.org/3/library/contextvars.html). The context variable itself is not visible, but\ncalls in the `temporalio.activity` package make use of it. Specifically:\n\n* `in_activity()` - Whether an activity context is present\n* `info()` - Returns the immutable info of the currently running activity\n* `heartbeat(*details)` - Record a heartbeat\n* `is_cancelled()` - Whether a cancellation has been requested on this activity\n* `wait_for_cancelled()` - `async` call to wait for cancellation request\n* `wait_for_cancelled_sync(timeout)` - Synchronous blocking call to wait for cancellation request\n* `shield_thread_cancel_exception()` - Context manager for use in `with` clauses by synchronous multithreaded activities\n  to prevent cancel exception from being thrown during the block of code\n* `is_worker_shutdown()` - Whether the worker has started graceful shutdown\n* `wait_for_worker_shutdown()` - `async` call to wait for start of graceful worker shutdown\n* `wait_for_worker_shutdown_sync(timeout)` - Synchronous blocking call to wait for start of graceful worker shutdown\n* `raise_complete_async()` - Raise an error that this activity will be completed asynchronously (i.e. after return of\n  the activity function in a separate client call)\n\nWith the exception of `in_activity()`, if any of the functions are called outside of an activity context, an error\noccurs. Synchronous activities cannot call any of the `async` functions.\n\n##### Heartbeating and Cancellation\n\nIn order for a non-local activity to be notified of cancellation requests, it must be given a `heartbeat_timeout` at\ninvocation time and invoke `temporalio.activity.heartbeat()` inside the activity. It is strongly recommended that all\nbut the fastest executing activities call this function regularly. "Types of Activities" has specifics on cancellation\nfor asynchronous and synchronous activities.\n\nIn addition to obtaining cancellation information, heartbeats also support detail data that is persisted on the server\nfor retrieval during activity retry. If an activity calls `temporalio.activity.heartbeat(123, 456)` and then fails and\nis retried, `temporalio.activity.info().heartbeat_details` will return an iterable containing `123` and `456` on the\nnext run.\n\nHeartbeating has no effect on local activities.\n\n##### Worker Shutdown\n\nAn activity can react to a worker shutdown. Using `is_worker_shutdown` or one of the `wait_for_worker_shutdown`\nfunctions an activity can react to a shutdown.\n\nWhen the `graceful_shutdown_timeout` worker parameter is given a `datetime.timedelta`, on shutdown the worker will\nnotify activities of the graceful shutdown. Once that timeout has passed (or if wasn\'t set), the worker will perform\ncancellation of all outstanding activities.\n\nThe `shutdown()` invocation will wait on all activities to complete, so if a long-running activity does not at least\nrespect cancellation, the shutdown may never complete.\n\n#### Testing\n\nUnit testing an activity or any code that could run in an activity is done via the\n`temporalio.testing.ActivityEnvironment` class. Simply instantiate this and any callable + params passed to `run` will\nbe invoked inside the activity context. The following are attributes/methods on the environment that can be used to\naffect calls activity code might make to functions on the `temporalio.activity` package.\n\n* `info` property can be set to customize what is returned from `activity.info()`\n* `on_heartbeat` property can be set to handle `activity.heartbeat()` calls\n* `cancel()` can be invoked to simulate a cancellation of the activity\n* `worker_shutdown()` can be invoked to simulate a worker shutdown during execution of the activity\n\n### Workflow Replay\n\nGiven a workflow\'s history, it can be replayed locally to check for things like non-determinism errors. For example,\nassuming `history_str` is populated with a JSON string history either exported from the web UI or from `tctl`, the\nfollowing function will replay it:\n\n```python\nfrom temporalio.client import WorkflowHistory\nfrom temporalio.worker import Replayer\n\nasync def run_replayer(history_str: str):\n  replayer = Replayer(workflows=[SayHello])\n  await replayer.replay_workflow(WorkflowHistory.from_json(history_str))\n```\n\nThis will throw an error if any non-determinism is detected.\n\nReplaying from workflow history is a powerful concept that many use to test that workflow alterations won\'t cause\nnon-determinisms with past-complete workflows. The following code will make sure that all workflow histories for a\ncertain workflow type (i.e. workflow class) are safe with the current code.\n\n```python\nfrom temporalio.client import Client, WorkflowHistory\nfrom temporalio.worker import Replayer\n\nasync def check_past_histories(my_client: Client):\n  replayer = Replayer(workflows=[SayHello])\n  await replayer.replay_workflows(\n    await my_client.list_workflows("WorkflowType = \'SayHello\'").map_histories(),\n  )\n```\n\n### OpenTelemetry Support\n\nOpenTelemetry support requires the optional `opentelemetry` dependencies which are part of the `opentelemetry` extra.\nWhen using `pip`, running\n\n    pip install temporalio[opentelemetry]\n\nwill install needed dependencies. Then the `temporalio.contrib.opentelemetry.TracingInterceptor` can be created and set\nas an interceptor on the `interceptors` argument of `Client.connect`. When set, spans will be created for all client\ncalls and for all activity and workflow invocations on the worker, spans will be created and properly serialized through\nthe server to give one proper trace for a workflow execution.\n\n### Protobuf 3.x vs 4.x\n\nPython currently has two somewhat-incompatible protobuf library versions - the 3.x series and the 4.x series. Python\ncurrently recommends 4.x and that is the primary supported version. Some libraries like\n[Pulumi](https://github.com/pulumi/pulumi) require 4.x. Other libraries such as [ONNX](https://github.com/onnx/onnx) and\n[Streamlit](https://github.com/streamlit/streamlit), for one reason or another, have/will not leave 3.x.\n\nTo support these, Temporal Python SDK allows any protobuf library >= 3.19. However, the C extension in older Python\nversions can cause issues with the sandbox due to global state sharing. Temporal strongly recommends using the latest\nprotobuf 4.x library unless you absolutely cannot at which point some proto libraries may have to be marked as\n[Passthrough Modules](#passthrough-modules).\n\n### Known Compatibility Issues\n\nBelow are known compatibility issues with the Python SDK.\n\n#### gevent Patching\n\nWhen using `gevent.monkey.patch_all()`, asyncio event loops can get messed up, especially those using custom event loops\nlike Temporal. See [this gevent issue](https://github.com/gevent/gevent/issues/982) and\n[this Python SDK issue](https://github.com/temporalio/sdk-python/issues/59) for more details.\n\n# Development\n\nThe Python SDK is built to work with Python 3.7 and newer. It is built using\n[SDK Core](https://github.com/temporalio/sdk-core/) which is written in Rust.\n\n### Building\n\n#### Prepare\n\nTo build the SDK from source for use as a dependency, the following prerequisites are required:\n\n* [Python](https://www.python.org/) >= 3.7\n* [Rust](https://www.rust-lang.org/)\n* [poetry](https://github.com/python-poetry/poetry) (e.g. `python -m pip install poetry`)\n* [poe](https://github.com/nat-n/poethepoet) (e.g. `python -m pip install poethepoet`)\n\nmacOS note: If errors are encountered, it may be better to install Python and Rust as recommended from their websites\ninstead of via `brew`.\n\nWith the prerequisites installed, first clone the SDK repository recursively:\n\n```bash\ngit clone --recursive https://github.com/temporalio/sdk-python.git\ncd sdk-python\n```\n\nUse `poetry` to install the dependencies with `--no-root` to not install this package (because we still need to build\nit):\n\n```bash\npoetry install --no-root\n```\n\n#### Build\n\nNow perform the release build:\n\n> This will take a while because Rust will compile the core project in release mode (see [Local SDK development\nenvironment](#local-sdk-development-environment) for the quicker approach to local development).\n\n```bash\npoetry build\n```\n\nThe compiled wheel doesn\'t have the exact right tags yet for use, so run this script to fix it:\n\n```bash\npoe fix-wheel\n```\n\nThe `whl` wheel file in `dist/` is now ready to use.\n\n#### Use\n\nThe wheel can now be installed into any virtual environment.\n\nFor example,\n[create a virtual environment](https://packaging.python.org/en/latest/tutorials/installing-packages/#creating-virtual-environments)\nsomewhere and then run the following inside the virtual environment:\n\n```bash\npip install wheel\n```\n\n```bash\npip install /path/to/cloned/sdk-python/dist/*.whl\n```\n\nCreate this Python file at `example.py`:\n\n```python\nimport asyncio\nfrom temporalio import workflow, activity\nfrom temporalio.client import Client\nfrom temporalio.worker import Worker\n\n@workflow.defn\nclass SayHello:\n    @workflow.run\n    async def run(self, name: str) -> str:\n        return f"Hello, {name}!"\n\nasync def main():\n    client = await Client.connect("localhost:7233")\n    async with Worker(client, task_queue="my-task-queue", workflows=[SayHello]):\n        result = await client.execute_workflow(SayHello.run, "Temporal",\n            id="my-workflow-id", task_queue="my-task-queue")\n        print(f"Result: {result}")\n\nif __name__ == "__main__":\n    asyncio.run(main())\n```\n\nAssuming there is a [local Temporal server](https://docs.temporal.io/docs/server/quick-install/) running, execute the\nfile with `python` (or `python3` if necessary):\n\n```bash\npython example.py\n```\n\nIt should output:\n\n    Result: Hello, Temporal!\n\n### Local SDK development environment\n\nFor local development, it is often quicker to use debug builds and a local virtual environment.\n\nWhile not required, it often helps IDEs if we put the virtual environment `.venv` directory in the project itself. This\ncan be configured system-wide via:\n\n```bash\npoetry config virtualenvs.in-project true\n```\n\nNow perform the same steps as the "Prepare" section above by installing the prerequisites, cloning the project,\ninstalling dependencies, and generating the protobuf code:\n\n```bash\ngit clone --recursive https://github.com/temporalio/sdk-python.git\ncd sdk-python\npoetry install --no-root\n```\n\nNow compile the Rust extension in develop mode which is quicker than release mode:\n\n```bash\npoe build-develop\n```\n\nThat step can be repeated for any Rust changes made.\n\nThe environment is now ready to develop in.\n\n#### Testing\n\nTo execute tests:\n\n```bash\npoe test\n```\n\nThis runs against [Temporalite](https://github.com/temporalio/temporalite). To run against the time-skipping test\nserver, pass `--workflow-environment time-skipping`. To run against the `default` namespace of an already-running\nserver, pass the `host:port` to `--workflow-environment`. Can also use regular pytest arguments. For example, here\'s how\nto run a single test with debug logs on the console:\n\n```bash\npoe test -s --log-cli-level=DEBUG -k test_sync_activity_thread_cancel_caught\n```\n\n#### Proto Generation and Testing\n\nTo allow for backwards compatibility, protobuf code is generated on the 3.x series of the protobuf library. To generate\nprotobuf code, you must be on Python <= 3.10, and then run `poetry add "protobuf<4"`. Then the protobuf files can be\ngenerated via `poe gen-protos`. Tests can be run for protobuf version 3 by setting the `TEMPORAL_TEST_PROTO3` env var\nto `1` prior to running tests.\n\nDo not commit `poetry.lock` or `pyproject.toml` changes. To go back from this downgrade, restore `pyproject.toml` and\nrun `poetry update protobuf grpcio-tools`.\n\n### Style\n\n* Mostly [Google Style Guide](https://google.github.io/styleguide/pyguide.html). Notable exceptions:\n  * We use [Black](https://github.com/psf/black) for formatting, so that takes precedence\n  * In tests and example code, can import individual classes/functions to make it more readable. Can also do this for\n    rarely in library code for some Python common items (e.g. `dataclass` or `partial`), but not allowed to do this for\n    any `temporalio` packages (except `temporalio.types`) or any classes/functions that aren\'t clear when unqualified.\n  * We allow relative imports for private packages\n  * We allow `@staticmethod`\n',
+    'long_description': '![Temporal Python SDK](https://assets.temporal.io/w/py-banner.svg)\n\n[![Python 3.7+](https://img.shields.io/pypi/pyversions/temporalio.svg?style=for-the-badge)](https://pypi.org/project/temporalio)\n[![PyPI](https://img.shields.io/pypi/v/temporalio.svg?style=for-the-badge)](https://pypi.org/project/temporalio)\n[![MIT](https://img.shields.io/pypi/l/temporalio.svg?style=for-the-badge)](LICENSE)\n\n[Temporal](https://temporal.io/) is a distributed, scalable, durable, and highly available orchestration engine used to\nexecute asynchronous, long-running business logic in a scalable and resilient way.\n\n"Temporal Python SDK" is the framework for authoring workflows and activities using the Python programming language.\n\nAlso see:\n* [Application Development Guide](https://docs.temporal.io/application-development?lang=python) - Once you\'ve tried our [Quick Start](#quick-start), check out our guide on how to use Temporal in your Python applications, including information around Temporal core concepts.\n* [Python Code Samples](https://github.com/temporalio/samples-python)\n* [API Documentation](https://python.temporal.io) - Complete Temporal Python SDK Package reference.\n\nIn addition to features common across all Temporal SDKs, the Python SDK also has the following interesting features:\n\n**Type Safe**\n\nThis library uses the latest typing and MyPy support with generics to ensure all calls can be typed. For example,\nstarting a workflow with an `int` parameter when it accepts a `str` parameter would cause MyPy to fail.\n\n**Different Activity Types**\n\nThe activity worker has been developed to work with `async def`, threaded, and multiprocess activities. While\n`async def` activities are the easiest and recommended, care has been taken to make heartbeating and cancellation also\nwork across threads/processes.\n\n**Custom `asyncio` Event Loop**\n\nThe workflow implementation basically turns `async def` functions into workflows backed by a distributed, fault-tolerant\nevent loop. This means task management, sleep, cancellation, etc have all been developed to seamlessly integrate with\n`asyncio` concepts.\n\nSee the [blog post](https://temporal.io/blog/durable-distributed-asyncio-event-loop) introducing the Python SDK for an\ninformal introduction to the features and their implementation.\n\n---\n\n<!-- START doctoc generated TOC please keep comment here to allow auto update -->\n<!-- DON\'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->\n**Contents**\n\n- [Quick Start](#quick-start)\n  - [Installation](#installation)\n  - [Implementing a Workflow](#implementing-a-workflow)\n  - [Running a Workflow](#running-a-workflow)\n  - [Next Steps](#next-steps)\n- [Usage](#usage)\n    - [Client](#client)\n      - [Data Conversion](#data-conversion)\n        - [Custom Type Data Conversion](#custom-type-data-conversion)\n    - [Workers](#workers)\n    - [Workflows](#workflows)\n      - [Definition](#definition)\n      - [Running](#running)\n      - [Invoking Activities](#invoking-activities)\n      - [Invoking Child Workflows](#invoking-child-workflows)\n      - [Timers](#timers)\n      - [Conditions](#conditions)\n      - [Asyncio and Cancellation](#asyncio-and-cancellation)\n      - [Workflow Utilities](#workflow-utilities)\n      - [Exceptions](#exceptions)\n      - [External Workflows](#external-workflows)\n      - [Testing](#testing)\n        - [Automatic Time Skipping](#automatic-time-skipping)\n        - [Manual Time Skipping](#manual-time-skipping)\n        - [Mocking Activities](#mocking-activities)\n      - [Workflow Sandbox](#workflow-sandbox)\n        - [How the Sandbox Works](#how-the-sandbox-works)\n        - [Avoiding the Sandbox](#avoiding-the-sandbox)\n        - [Customizing the Sandbox](#customizing-the-sandbox)\n          - [Passthrough Modules](#passthrough-modules)\n          - [Invalid Module Members](#invalid-module-members)\n        - [Known Sandbox Issues](#known-sandbox-issues)\n          - [Global Import/Builtins](#global-importbuiltins)\n          - [Sandbox is not Secure](#sandbox-is-not-secure)\n          - [Sandbox Performance](#sandbox-performance)\n          - [Extending Restricted Classes](#extending-restricted-classes)\n          - [Certain Standard Library Calls on Restricted Objects](#certain-standard-library-calls-on-restricted-objects)\n          - [is_subclass of ABC-based Restricted Classes](#is_subclass-of-abc-based-restricted-classes)\n          - [Compiled Pydantic Sometimes Using Wrong Types](#compiled-pydantic-sometimes-using-wrong-types)\n    - [Activities](#activities)\n      - [Definition](#definition-1)\n      - [Types of Activities](#types-of-activities)\n        - [Asynchronous Activities](#asynchronous-activities)\n        - [Synchronous Activities](#synchronous-activities)\n          - [Synchronous Multithreaded Activities](#synchronous-multithreaded-activities)\n          - [Synchronous Multiprocess/Other Activities](#synchronous-multiprocessother-activities)\n      - [Activity Context](#activity-context)\n        - [Heartbeating and Cancellation](#heartbeating-and-cancellation)\n        - [Worker Shutdown](#worker-shutdown)\n      - [Testing](#testing-1)\n    - [Workflow Replay](#workflow-replay)\n    - [OpenTelemetry Support](#opentelemetry-support)\n    - [Protobuf 3.x vs 4.x](#protobuf-3x-vs-4x)\n    - [Known Compatibility Issues](#known-compatibility-issues)\n      - [gevent Patching](#gevent-patching)\n- [Development](#development)\n    - [Building](#building)\n      - [Prepare](#prepare)\n      - [Build](#build)\n      - [Use](#use)\n    - [Local SDK development environment](#local-sdk-development-environment)\n      - [Testing](#testing-2)\n      - [Proto Generation and Testing](#proto-generation-and-testing)\n    - [Style](#style)\n\n<!-- END doctoc generated TOC please keep comment here to allow auto update -->\n\n# Quick Start\n\nWe will guide you through the Temporal basics to create a "hello, world!" script on your machine. It is not intended as one of the ways to use Temporal, but in reality it is very simplified and decidedly not "the only way" to use Temporal. For more information, check out the docs references in "Next Steps" below the quick start.\n\n## Installation\n\nInstall the `temporalio` package from [PyPI](https://pypi.org/project/temporalio).\n\nThese steps can be followed to use with a virtual environment and `pip`:\n\n* [Create a virtual environment](https://packaging.python.org/en/latest/tutorials/installing-packages/#creating-virtual-environments)\n* Update `pip` - `python -m pip install -U pip`\n  * Needed because older versions of `pip` may not pick the right wheel\n* Install Temporal SDK - `python -m pip install temporalio`\n\nThe SDK is now ready for use. To build from source, see "Building" near the end of this documentation.\n\n**NOTE: This README is for the current branch and not necessarily what\'s released on `PyPI`.**\n\n## Implementing a Workflow\n\nCreate the following in `activities.py`:\n\n```python\nfrom temporalio import activity\n\n@activity.defn\nasync def say_hello(name: str) -> str:\n    return f"Hello, {name}!"\n```\n\nCreate the following in `workflows.py`:\n\n```python\nfrom datetime import timedelta\nfrom temporalio import workflow\n\n# Import our activity, passing it through the sandbox\nwith workflow.unsafe.imports_passed_through():\n    from .activities import say_hello\n\n@workflow.defn\nclass SayHello:\n    @workflow.run\n    async def run(self, name: str) -> str:\n        return await workflow.execute_activity(\n            say_hello, name, schedule_to_close_timeout=timedelta(seconds=5)\n        )\n```\n\nCreate the following in `run_worker.py`:\n\n```python\nimport asyncio\nfrom temporalio.client import Client\nfrom temporalio.worker import Worker\n\n# Import the activity and workflow from our other files\nfrom .activities import say_hello\nfrom .workflows import SayHello\n\nasync def main():\n    # Create client connected to server at the given address\n    client = await Client.connect("localhost:7233")\n\n    # Run the worker\n    worker = Worker(client, task_queue="my-task-queue", workflows=[SayHello], activities=[say_hello])\n    await worker.run()\n\nif __name__ == "__main__":\n    asyncio.run(main())\n```\n\nAssuming you have a [Temporal server running on localhost](https://docs.temporal.io/docs/server/quick-install/), this\nwill run the worker:\n\n    python run_worker.py\n\n## Running a Workflow\n\nCreate the following script at `run_workflow.py`:\n\n```python\nimport asyncio\nfrom temporalio.client import Client\n\n# Import the workflow from the previous code\nfrom .workflows import SayHello\n\nasync def main():\n    # Create client connected to server at the given address\n    client = await Client.connect("localhost:7233")\n\n    # Execute a workflow\n    result = await client.execute_workflow(SayHello.run, "my name", id="my-workflow-id", task_queue="my-task-queue")\n\n    print(f"Result: {result}")\n\nif __name__ == "__main__":\n    asyncio.run(main())\n```\n\nAssuming you have `run_worker.py` running from before, this will run the workflow:\n\n    python run_workflow.py\n\nThe output will be:\n\n    Result: Hello, my-name!\n\n## Next Steps\n\nTemporal can be implemented in your code in many different ways, to suit your application\'s needs. The links below will\ngive you much more information about how Temporal works with Python:\n\n* [Code Samples](https://github.com/temporalio/samples-python) - If you want to start with some code, we have provided\n  some pre-built samples.\n* [Application Development Guide](https://docs.temporal.io/application-development?lang=python) Our Python specific\n  Developer\'s Guide will give you much more information on how to build with Temporal in your Python applications than\n  our SDK README ever could (or should).\n* [API Documentation](https://python.temporal.io) - Full Temporal Python SDK package documentation.\n\n---\n\n# Usage\n\nFrom here, you will find reference documentation about specific pieces of the Temporal Python SDK that were built around Temporal concepts. \n*This section is not intended as a how-to guide* -- For more how-to oriented information, check out the links in the [Next Steps](#next-steps) section above.\n\n### Client\n\nA client can be created and used to start a workflow like so:\n\n```python\nfrom temporalio.client import Client\n\nasync def main():\n    # Create client connected to server at the given address and namespace\n    client = await Client.connect("localhost:7233", namespace="my-namespace")\n\n    # Start a workflow\n    handle = await client.start_workflow(MyWorkflow.run, "some arg", id="my-workflow-id", task_queue="my-task-queue")\n\n    # Wait for result\n    result = await handle.result()\n    print(f"Result: {result}")\n```\n\nSome things to note about the above code:\n\n* A `Client` does not have an explicit "close"\n* To enable TLS, the `tls` argument to `connect` can be set to `True` or a `TLSConfig` object\n* A single positional argument can be passed to `start_workflow`. If there are multiple arguments, only the\n  non-type-safe form of `start_workflow` can be used (i.e. the one accepting a string workflow name) and it must be in\n  the `args` keyword argument.\n* The `handle` represents the workflow that was started and can be used for more than just getting the result\n* Since we are just getting the handle and waiting on the result, we could have called `client.execute_workflow` which\n  does the same thing\n* Clients can have many more options not shown here (e.g. data converters and interceptors)\n* A string can be used instead of the method reference to call a workflow by name (e.g. if defined in another language)\n\nClients also provide a shallow copy of their config for use in making slightly different clients backed by the same\nconnection. For instance, given the `client` above, this is how to have a client in another namespace:\n\n```python\nconfig = client.config()\nconfig["namespace"] = "my-other-namespace"\nother_ns_client = Client(**config)\n```\n\n#### Data Conversion\n\nData converters are used to convert raw Temporal payloads to/from actual Python types. A custom data converter of type\n`temporalio.converter.DataConverter` can be set via the `data_converter` client parameter. Data converters are a\ncombination of payload converters, payload codecs, and failure converters. Payload converters convert Python values\nto/from serialized bytes. Payload codecs convert bytes to bytes (e.g. for compression or encryption). Failure converters\nconvert exceptions to/from serialized failures.\n\nThe default data converter supports converting multiple types including:\n\n* `None`\n* `bytes`\n* `google.protobuf.message.Message` - As JSON when encoding, but has ability to decode binary proto from other languages\n* Anything that can be converted to JSON including:\n  * Anything that [`json.dump`](https://docs.python.org/3/library/json.html#json.dump) supports natively\n  * [dataclasses](https://docs.python.org/3/library/dataclasses.html)\n  * Iterables including ones JSON dump may not support by default, e.g. `set`\n  * Any class with a `dict()` method and a static `parse_obj()` method, e.g.\n    [Pydantic models](https://pydantic-docs.helpmanual.io/usage/models)\n    * The default data converter is deprecated for Pydantic models and will warn if used since not all fields work.\n      See [this sample](https://github.com/temporalio/samples-python/tree/main/pydantic_converter) for the recommended\n      approach.\n  * [IntEnum, StrEnum](https://docs.python.org/3/library/enum.html) based enumerates\n  * [UUID](https://docs.python.org/3/library/uuid.html)\n\nThis notably doesn\'t include any `date`, `time`, or `datetime` objects as they may not work across SDKs.\n\nUsers are strongly encouraged to use a single `dataclass` for parameter and return types so fields with defaults can be\neasily added without breaking compatibility.\n\nClasses with generics may not have the generics properly resolved. The current implementation does not have generic\ntype resolution. Users should use concrete types.\n\n##### Custom Type Data Conversion\n\nFor converting from JSON, the workflow/activity type hint is taken into account to convert to the proper type. Care has\nbeen taken to support all common typings including `Optional`, `Union`, all forms of iterables and mappings, `NewType`,\netc in addition to the regular JSON values mentioned before.\n\nData converters contain a reference to a payload converter class that is used to convert to/from payloads/values. This\nis a class and not an instance because it is instantiated on every workflow run inside the sandbox. The payload\nconverter is usually a `CompositePayloadConverter` which contains a multiple `EncodingPayloadConverter`s it uses to try\nto serialize/deserialize payloads. Upon serialization, each `EncodingPayloadConverter` is tried until one succeeds. The\n`EncodingPayloadConverter` provides an "encoding" string serialized onto the payload so that, upon deserialization, the\nspecific `EncodingPayloadConverter` for the given "encoding" is used.\n\nThe default data converter uses the `DefaultPayloadConverter` which is simply a `CompositePayloadConverter` with a known\nset of default `EncodingPayloadConverter`s. To implement a custom encoding for a custom type, a new\n`EncodingPayloadConverter` can be created for the new type. For example, to support `IPv4Address` types:\n\n```python\nclass IPv4AddressEncodingPayloadConverter(EncodingPayloadConverter):\n    @property\n    def encoding(self) -> str:\n        return "text/ipv4-address"\n\n    def to_payload(self, value: Any) -> Optional[Payload]:\n        if isinstance(value, ipaddress.IPv4Address):\n            return Payload(\n                metadata={"encoding": self.encoding.encode()},\n                data=str(value).encode(),\n            )\n        else:\n            return None\n\n    def from_payload(self, payload: Payload, type_hint: Optional[Type] = None) -> Any:\n        assert not type_hint or type_hint is ipaddress.IPv4Address\n        return ipaddress.IPv4Address(payload.data.decode())\n\nclass IPv4AddressPayloadConverter(CompositePayloadConverter):\n    def __init__(self) -> None:\n        # Just add ours as first before the defaults\n        super().__init__(\n            IPv4AddressEncodingPayloadConverter(),\n            *DefaultPayloadConverter.default_encoding_payload_converters,\n        )\n\nmy_data_converter = dataclasses.replace(\n    DataConverter.default,\n    payload_converter_class=IPv4AddressPayloadConverter,\n)\n```\n\nImports are left off for brevity.\n\nThis is good for many custom types. However, sometimes you want to override the behavior of the just the existing JSON\nencoding payload converter to support a new type. It is already the last encoding data converter in the list, so it\'s\nthe fall-through behavior for any otherwise unknown type. Customizing the existing JSON converter has the benefit of\nmaking the type work in lists, unions, etc.\n\nThe `JSONPlainPayloadConverter` uses the Python [json](https://docs.python.org/3/library/json.html) library with an\nadvanced JSON encoder by default and a custom value conversion method to turn `json.load`ed values to their type hints.\nThe conversion can be customized for serialization with a custom `json.JSONEncoder` and deserialization with a custom\n`JSONTypeConverter`. For example, to support `IPv4Address` types in existing JSON conversion:\n\n```python\nclass IPv4AddressJSONEncoder(AdvancedJSONEncoder):\n    def default(self, o: Any) -> Any:\n        if isinstance(o, ipaddress.IPv4Address):\n            return str(o)\n        return super().default(o)\nclass IPv4AddressJSONTypeConverter(JSONTypeConverter):\n    def to_typed_value(\n        self, hint: Type, value: Any\n    ) -> Union[Optional[Any], _JSONTypeConverterUnhandled]:\n        if issubclass(hint, ipaddress.IPv4Address):\n            return ipaddress.IPv4Address(value)\n        return JSONTypeConverter.Unhandled\n\nclass IPv4AddressPayloadConverter(CompositePayloadConverter):\n    def __init__(self) -> None:\n        # Replace default JSON plain with our own that has our encoder and type\n        # converter\n        json_converter = JSONPlainPayloadConverter(\n            encoder=IPv4AddressJSONEncoder,\n            custom_type_converters=[IPv4AddressJSONTypeConverter()],\n        )\n        super().__init__(\n            *[\n                c if not isinstance(c, JSONPlainPayloadConverter) else json_converter\n                for c in DefaultPayloadConverter.default_encoding_payload_converters\n            ]\n        )\n\nmy_data_converter = dataclasses.replace(\n    DataConverter.default,\n    payload_converter_class=IPv4AddressPayloadConverter,\n)\n```\n\nNow `IPv4Address` can be used in type hints including collections, optionals, etc.\n\n### Workers\n\nWorkers host workflows and/or activities. Here\'s how to run a worker:\n\n```python\nimport asyncio\nimport logging\nfrom temporalio.client import Client\nfrom temporalio.worker import Worker\n# Import your own workflows and activities\nfrom my_workflow_package import MyWorkflow, my_activity\n\nasync def run_worker(stop_event: asyncio.Event):\n    # Create client connected to server at the given address\n    client = await Client.connect("localhost:7233", namespace="my-namespace")\n\n    # Run the worker until the event is set\n    worker = Worker(client, task_queue="my-task-queue", workflows=[MyWorkflow], activities=[my_activity])\n    async with worker:\n        await stop_event.wait()\n```\n\nSome things to note about the above code:\n\n* This creates/uses the same client that is used for starting workflows\n* While this example accepts a stop event and uses `async with`, `run()` and `shutdown()` may be used instead\n* Workers can have many more options not shown here (e.g. data converters and interceptors)\n\n### Workflows\n\n#### Definition\n\nWorkflows are defined as classes decorated with `@workflow.defn`. The method invoked for the workflow is decorated with\n`@workflow.run`. Methods for signals and queries are decorated with `@workflow.signal` and `@workflow.query`\nrespectively. Here\'s an example of a workflow:\n\n```python\nimport asyncio\nfrom datetime import timedelta\nfrom temporalio import workflow\n\n# Pass the activities through the sandbox\nwith workflow.unsafe.imports_passed_through():\n    from .my_activities import GreetingInfo, create_greeting_activity\n\n@workflow.defn\nclass GreetingWorkflow:\n    def __init__() -> None:\n        self._current_greeting = "<unset>"\n        self._greeting_info = GreetingInfo()\n        self._greeting_info_update = asyncio.Event()\n        self._complete = asyncio.Event()\n\n    @workflow.run\n    async def run(self, name: str) -> str:\n        self._greeting_info.name = name\n        while True:\n            # Store greeting\n            self._current_greeting = await workflow.execute_activity(\n                create_greeting_activity,\n                self._greeting_info,\n                start_to_close_timeout=timedelta(seconds=5),\n            )\n            workflow.logger.debug("Greeting set to %s", self._current_greeting)\n            \n            # Wait for salutation update or complete signal (this can be\n            # cancelled)\n            await asyncio.wait(\n                [\n                    asyncio.create_task(self._greeting_info_update.wait()),\n                    asyncio.create_task(self._complete.wait()),\n                ],\n                return_when=asyncio.FIRST_COMPLETED,\n            )\n            if self._complete.is_set():\n                return self._current_greeting\n            self._greeting_info_update.clear()\n\n    @workflow.signal\n    async def update_salutation(self, salutation: str) -> None:\n        self._greeting_info.salutation = salutation\n        self._greeting_info_update.set()\n\n    @workflow.signal\n    async def complete_with_greeting(self) -> None:\n        self._complete.set()\n\n    @workflow.query\n    def current_greeting(self) -> str:\n        return self._current_greeting\n\n```\n\nThis assumes there\'s an activity in `my_activities.py` like:\n\n```python\nfrom dataclasses import dataclass\nfrom temporalio import workflow\n\n@dataclass\nclass GreetingInfo:\n    salutation: str = "Hello"\n    name: str = "<unknown>"\n\n@activity.defn\nasync def create_greeting_activity(info: GreetingInfo) -> str:\n    return f"{info.salutation}, {info.name}!"\n```\n\nSome things to note about the above workflow code:\n\n* Workflows run in a sandbox by default.\n  * Users are encouraged to define workflows in files with no side effects or other complicated code or unnecessary\n    imports to other third party libraries.\n  * Non-standard-library, non-`temporalio` imports should usually be "passed through" the sandbox. See the\n    [Workflow Sandbox](#workflow-sandbox) section for more details.\n* This workflow continually updates the queryable current greeting when signalled and can complete with the greeting on\n  a different signal\n* Workflows are always classes and must have a single `@workflow.run` which is an `async def` function\n* Workflow code must be deterministic. This means no threading, no randomness, no external calls to processes, no\n  network IO, and no global state mutation. All code must run in the implicit `asyncio` event loop and be deterministic.\n* `@activity.defn` is explained in a later section. For normal simple string concatenation, this would just be done in\n  the workflow. The activity is for demonstration purposes only.\n* `workflow.execute_activity(create_greeting_activity, ...` is actually a typed signature, and MyPy will fail if the\n  `self._greeting_info` parameter is not a `GreetingInfo`\n\nHere are the decorators that can be applied:\n\n* `@workflow.defn` - Defines a workflow class\n  * Must be defined on the class given to the worker (ignored if present on a base class)\n  * Can have a `name` param to customize the workflow name, otherwise it defaults to the unqualified class name\n  * Can have `dynamic=True` which means all otherwise unhandled workflows fall through to this. If present, cannot have\n    `name` argument, and run method must accept a single parameter of `Sequence[temporalio.common.RawValue]` type. The\n    payload of the raw value can be converted via `workflow.payload_converter().from_payload`.\n* `@workflow.run` - Defines the primary workflow run method\n  * Must be defined on the same class as `@workflow.defn`, not a base class (but can _also_ be defined on the same\n    method of a base class)\n  * Exactly one method name must have this decorator, no more or less\n  * Must be defined on an `async def` method\n  * The method\'s arguments are the workflow\'s arguments\n  * The first parameter must be `self`, followed by positional arguments. Best practice is to only take a single\n    argument that is an object/dataclass of fields that can be added to as needed.\n* `@workflow.signal` - Defines a method as a signal\n  * Can be defined on an `async` or non-`async` function at any hierarchy depth, but if decorated method is overridden,\n    the override must also be decorated\n  * The method\'s arguments are the signal\'s arguments\n  * Can have a `name` param to customize the signal name, otherwise it defaults to the unqualified method name\n  * Can have `dynamic=True` which means all otherwise unhandled signals fall through to this. If present, cannot have\n    `name` argument, and method parameters must be `self`, a string signal name, and a\n    `Sequence[temporalio.common.RawValue]`.\n  * Non-dynamic method can only have positional arguments. Best practice is to only take a single argument that is an\n    object/dataclass of fields that can be added to as needed.\n  * Return value is ignored\n* `@workflow.query` - Defines a method as a query\n  * All the same constraints as `@workflow.signal` but should return a value\n  * Should not be `async`\n  * Temporal queries should never mutate anything in the workflow or call any calls that would mutate the workflow\n\n#### Running\n\nTo start a locally-defined workflow from a client, you can simply reference its method like so:\n\n```python\nfrom temporalio.client import Client\nfrom my_workflow_package import GreetingWorkflow\n\nasync def create_greeting(client: Client) -> str:\n    # Start the workflow\n    handle = await client.start_workflow(GreetingWorkflow.run, "my name", id="my-workflow-id", task_queue="my-task-queue")\n    # Change the salutation\n    await handle.signal(GreetingWorkflow.update_salutation, "Aloha")\n    # Tell it to complete\n    await handle.signal(GreetingWorkflow.complete_with_greeting)\n    # Wait and return result\n    return await handle.result()\n```\n\nSome things to note about the above code:\n\n* This uses the `GreetingWorkflow` from the previous section\n* The result of calling this function is `"Aloha, my name!"`\n* `id` and `task_queue` are required for running a workflow\n* `client.start_workflow` is typed, so MyPy would fail if `"my name"` were something besides a string\n* `handle.signal` is typed, so MyPy would fail if `"Aloha"` were something besides a string or if we provided a\n  parameter to the parameterless `complete_with_greeting`\n* `handle.result` is typed to the workflow itself, so MyPy would fail if we said this `create_greeting` returned\n  something besides a string\n\n#### Invoking Activities\n\n* Activities are started with non-async `workflow.start_activity()` which accepts either an activity function reference\n  or a string name.\n* A single argument to the activity is positional. Multiple arguments are not supported in the type-safe form of\n  start/execute activity and must be supplied via the `args` keyword argument.\n* Activity options are set as keyword arguments after the activity arguments. At least one of `start_to_close_timeout`\n  or `schedule_to_close_timeout` must be provided.\n* The result is an activity handle which is an `asyncio.Task` and supports basic task features\n* An async `workflow.execute_activity()` helper is provided which takes the same arguments as\n  `workflow.start_activity()` and `await`s on the result. This should be used in most cases unless advanced task\n  capabilities are needed.\n* Local activities work very similarly except the functions are `workflow.start_local_activity()` and\n  `workflow.execute_local_activity()`\n  * ⚠️Local activities are currently experimental\n* Activities can be methods of a class. Invokers should use `workflow.start_activity_method()`,\n  `workflow.execute_activity_method()`, `workflow.start_local_activity_method()`, and\n  `workflow.execute_local_activity_method()` instead.\n* Activities can callable classes (i.e. that define `__call__`). Invokers should use `workflow.start_activity_class()`,\n  `workflow.execute_activity_class()`, `workflow.start_local_activity_class()`, and\n  `workflow.execute_local_activity_class()` instead.\n\n#### Invoking Child Workflows\n\n* Child workflows are started with async `workflow.start_child_workflow()` which accepts either a workflow run method\n  reference or a string name. The arguments to the workflow are positional.\n* A single argument to the child workflow is positional. Multiple arguments are not supported in the type-safe form of\n  start/execute child workflow and must be supplied via the `args` keyword argument.\n* Child workflow options are set as keyword arguments after the arguments. At least `id` must be provided.\n* The `await` of the start does not complete until the start has been accepted by the server\n* The result is a child workflow handle which is an `asyncio.Task` and supports basic task features. The handle also has\n  some child info and supports signalling the child workflow\n* An async `workflow.execute_child_workflow()` helper is provided which takes the same arguments as\n  `workflow.start_child_workflow()` and `await`s on the result. This should be used in most cases unless advanced task\n  capabilities are needed.\n\n#### Timers\n\n* A timer is represented by normal `asyncio.sleep()`\n* Timers are also implicitly started on any `asyncio` calls with timeouts (e.g. `asyncio.wait_for`)\n* Timers are Temporal server timers, not local ones, so sub-second resolution rarely has value\n\n#### Conditions\n\n* `workflow.wait_condition` is an async function that doesn\'t return until a provided callback returns true\n* A `timeout` can optionally be provided which will throw a `asyncio.TimeoutError` if reached (internally backed by\n  `asyncio.wait_for` which uses a timer)\n\n#### Asyncio and Cancellation\n\nWorkflows are backed by a custom [asyncio](https://docs.python.org/3/library/asyncio.html) event loop. This means many\nof the common `asyncio` calls work as normal. Some asyncio features are disabled such as:\n\n* Thread related calls such as `to_thread()`, `run_coroutine_threadsafe()`, `loop.run_in_executor()`, etc\n* Calls that alter the event loop such as `loop.close()`, `loop.stop()`, `loop.run_forever()`,\n  `loop.set_task_factory()`, etc\n* Calls that use a specific time such as `loop.call_at()`\n* Calls that use anything external such as networking, subprocesses, disk IO, etc\n\nCancellation is done the same way as `asyncio`. Specifically, a task can be requested to be cancelled but does not\nnecessarily have to respect that cancellation immediately. This also means that `asyncio.shield()` can be used to\nprotect against cancellation. The following tasks, when cancelled, perform a Temporal cancellation:\n\n* Activities - when the task executing an activity is cancelled, a cancellation request is sent to the activity\n* Child workflows - when the task starting or executing a child workflow is cancelled, a cancellation request is sent to\n  cancel the child workflow\n* Timers - when the task executing a timer is cancelled (whether started via sleep or timeout), the timer is cancelled\n\nWhen the workflow itself is requested to cancel, `Task.cancel` is called on the main workflow task. Therefore,\n`asyncio.CancelledError` can be caught in order to handle the cancel gracefully.\n\nWorkflows follow `asyncio` cancellation rules exactly which can cause confusion among Python developers. Cancelling a\ntask doesn\'t always cancel the thing it created. For example, given\n`task = asyncio.create_task(workflow.start_child_workflow(...`, calling `task.cancel` does not cancel the child\nworkflow, it only cancels the starting of it, which has no effect if it has already started. However, cancelling the\nresult of `handle = await workflow.start_child_workflow(...` or\n`task = asyncio.create_task(workflow.execute_child_workflow(...` _does_ cancel the child workflow.\n\nAlso, due to Temporal rules, a cancellation request is a state not an event. Therefore, repeated cancellation requests\nare not delivered, only the first. If the workflow chooses swallow a cancellation, it cannot be requested again.\n\n#### Workflow Utilities\n\nWhile running in a workflow, in addition to features documented elsewhere, the following items are available from the\n`temporalio.workflow` package:\n\n* `continue_as_new()` - Async function to stop the workflow immediately and continue as new\n* `info()` - Returns information about the current workflow\n* `logger` - A logger for use in a workflow (properly skips logging on replay)\n* `now()` - Returns the "current time" from the workflow\'s perspective\n\n#### Exceptions\n\n* Workflows can raise exceptions to fail the workflow or the "workflow task" (i.e. suspend the workflow retrying).\n* Exceptions that are instances of `temporalio.exceptions.FailureError` will fail the workflow with that exception\n  * For failing the workflow explicitly with a user exception, use `temporalio.exceptions.ApplicationError`. This can\n    be marked non-retryable or include details as needed.\n  * Other exceptions that come from activity execution, child execution, cancellation, etc are already instances of\n    `FailureError` and will fail the workflow when uncaught.\n* All other exceptions fail the "workflow task" which means the workflow will continually retry until the workflow is\n  fixed. This is helpful for bad code or other non-predictable exceptions. To actually fail the workflow, use an\n  `ApplicationError` as mentioned above.\n\n#### External Workflows\n\n* `workflow.get_external_workflow_handle()` inside a workflow returns a handle to interact with another workflow\n* `workflow.get_external_workflow_handle_for()` can be used instead for a type safe handle\n* `await handle.signal()` can be called on the handle to signal the external workflow\n* `await handle.cancel()` can be called on the handle to send a cancel to the external workflow\n\n#### Testing\n\nWorkflow testing can be done in an integration-test fashion against a real server, however it is hard to simulate\ntimeouts and other long time-based code. Using the time-skipping workflow test environment can help there.\n\nThe time-skipping `temporalio.testing.WorkflowEnvironment` can be created via the static async `start_time_skipping()`.\nThis internally downloads the Temporal time-skipping test server to a temporary directory if it doesn\'t already exist,\nthen starts the test server which has special APIs for skipping time.\n\n##### Automatic Time Skipping\n\nAnytime a workflow result is waited on, the time-skipping server automatically advances to the next event it can. To\nmanually advance time before waiting on the result of a workflow, the `WorkflowEnvironment.sleep` method can be used.\n\nHere\'s a simple example of a workflow that sleeps for 24 hours:\n\n```python\nimport asyncio\nfrom temporalio import workflow\n\n@workflow.defn\nclass WaitADayWorkflow:\n    @workflow.run\n    async def run(self) -> str:\n        await asyncio.sleep(24 * 60 * 60)\n        return "all done"\n```\n\nAn integration test of this workflow would be way too slow. However the time-skipping server automatically skips to the\nnext event when we wait on the result. Here\'s a test for that workflow:\n\n```python\nfrom temporalio.testing import WorkflowEnvironment\nfrom temporalio.worker import Worker\n\nasync def test_wait_a_day_workflow():\n    async with await WorkflowEnvironment.start_time_skipping() as env:\n        async with Worker(env.client, task_queue="tq1", workflows=[WaitADayWorkflow]):\n            assert "all done" == await env.client.execute_workflow(WaitADayWorkflow.run, id="wf1", task_queue="tq1")\n```\n\nThat test will run almost instantly. This is because by calling `execute_workflow` on our client, we have asked the\nenvironment to automatically skip time as much as it can (basically until the end of the workflow or until an activity\nis run).\n\nTo disable automatic time-skipping while waiting for a workflow result, run code inside a\n`with env.auto_time_skipping_disabled():` block.\n\n##### Manual Time Skipping\n\nUntil a workflow is waited on, all time skipping in the time-skipping environment is done manually via\n`WorkflowEnvironment.sleep`.\n\nHere\'s workflow that waits for a signal or times out:\n\n```python\nimport asyncio\nfrom temporalio import workflow\n\n@workflow.defn\nclass SignalWorkflow:\n    def __init__(self) -> None:\n        self.signal_received = False\n\n    @workflow.run\n    async def run(self) -> str:\n        # Wait for signal or timeout in 45 seconds\n        try:\n            await workflow.wait_condition(lambda: self.signal_received, timeout=45)\n            return "got signal"\n        except asyncio.TimeoutError:\n            return "got timeout"\n\n    @workflow.signal\n    def some_signal(self) -> None:\n        self.signal_received = True\n```\n\nTo test a normal signal, you might:\n\n```python\nfrom temporalio.testing import WorkflowEnvironment\nfrom temporalio.worker import Worker\n\nasync def test_signal_workflow():\n    async with await WorkflowEnvironment.start_time_skipping() as env:\n        async with Worker(env.client, task_queue="tq1", workflows=[SignalWorkflow]):\n            # Start workflow, send signal, check result\n            handle = await env.client.start_workflow(SignalWorkflow.run, id="wf1", task_queue="tq1")\n            await handle.signal(SignalWorkflow.some_signal)\n            assert "got signal" == await handle.result()\n```\n\nBut how would you test the timeout part? Like so:\n\n```python\nfrom temporalio.testing import WorkflowEnvironment\nfrom temporalio.worker import Worker\n\nasync def test_signal_workflow_timeout():\n    async with await WorkflowEnvironment.start_time_skipping() as env:\n        async with Worker(env.client, task_queue="tq1", workflows=[SignalWorkflow]):\n            # Start workflow, advance time past timeout, check result\n            handle = await env.client.start_workflow(SignalWorkflow.run, id="wf1", task_queue="tq1")\n            await env.sleep(50)\n            assert "got timeout" == await handle.result()\n```\n\nAlso, the current time of the workflow environment can be obtained via the async `WorkflowEnvironment.get_current_time`\nmethod.\n\n##### Mocking Activities\n\nActivities are just functions decorated with `@activity.defn`. Simply write different ones and pass those to the worker\nto have different activities called during the test.\n\n#### Workflow Sandbox\n\nBy default workflows are run in a sandbox to help avoid non-deterministic code. If a call that is known to be\nnon-deterministic is performed, an exception will be thrown in the workflow which will "fail the task" which means the\nworkflow will not progress until fixed.\n\nThe sandbox is not foolproof and non-determinism can still occur. It is simply a best-effort way to catch bad code\nearly. Users are encouraged to define their workflows in files with no other side effects.\n\nThe sandbox offers a mechanism to pass through modules from outside the sandbox. By default this already includes all\nstandard library modules and Temporal modules. **For performance and behavior reasons, users are encouraged to pass\nthrough all third party modules whose calls will be deterministic.** This includes modules containing the activities to\nbe referenced in workflows. See "Passthrough Modules" below on how to do this.\n\nIf you are getting an error like:\n\n> temporalio.worker.workflow_sandbox._restrictions.RestrictedWorkflowAccessError: Cannot access\n> http.client.IncompleteRead.\\_\\_mro_entries\\_\\_ from inside a workflow. If this is code from a module not used in a\n> workflow or known to only be used deterministically from a workflow, mark the import as pass through.\n\nThen you are either using an invalid construct from the workflow, this is a known limitation of the sandbox, or most\ncommonly this is from a module that is safe to pass through (see "Passthrough Modules" section below).\n\n##### How the Sandbox Works\n\nThe sandbox is made up of two components that work closely together:\n\n* Global state isolation\n* Restrictions preventing known non-deterministic library calls\n\nGlobal state isolation is performed by using `exec`. Upon workflow start, the file that the workflow is defined in is\nimported into a new sandbox created for that workflow run. In order to keep the sandbox performant a known set of\n"passthrough modules" are passed through from outside of the sandbox when they are imported. These are expected to be\nside-effect free on import and have their non-deterministic aspects restricted. By default the entire Python standard\nlibrary, `temporalio`, and a couple of other modules are passed through from outside of the sandbox. To update this\nlist, see "Customizing the Sandbox".\n\nRestrictions preventing known non-deterministic library calls are achieved using proxy objects on modules wrapped around\nthe custom importer set in the sandbox. Many restrictions apply at workflow import time and workflow run time, while\nsome restrictions only apply at workflow run time. A default set of restrictions is included that prevents most\ndangerous standard library calls. However it is known in Python that some otherwise-non-deterministic invocations, like\nreading a file from disk via `open` or using `os.environ`, are done as part of importing modules. To customize what is\nand isn\'t restricted, see "Customizing the Sandbox".\n\n##### Avoiding the Sandbox\n\nThere are three increasingly-scoped ways to avoid the sandbox. Users are discouraged from avoiding the sandbox if\npossible.\n\nTo remove restrictions around a particular block of code, use `with temporalio.workflow.unsafe.sandbox_unrestricted():`.\nThe workflow will still be running in the sandbox, but no restrictions for invalid library calls will be applied.\n\nTo run an entire workflow outside of a sandbox, set `sandboxed=False` on the `@workflow.defn` decorator when defining\nit. This will run the entire workflow outside of the workflow which means it can share global state and other bad\nthings.\n\nTo disable the sandbox entirely for a worker, set the `Worker` init\'s `workflow_runner` keyword argument to \n`temporalio.worker.UnsandboxedWorkflowRunner()`. This value is defaulted to\n`temporalio.worker.workflow_sandbox.SandboxedWorkflowRunner()` so by changing it to the unsandboxed runner, the sandbox\nwill not be used at all.\n\n##### Customizing the Sandbox\n\n⚠️ WARNING: APIs in the `temporalio.worker.workflow_sandbox` module are not yet considered stable and may change in\nfuture releases.\n\nWhen creating the `Worker`, the `workflow_runner` is defaulted to\n`temporalio.worker.workflow_sandbox.SandboxedWorkflowRunner()`. The `SandboxedWorkflowRunner`\'s init accepts a\n`restrictions` keyword argument that is defaulted to `SandboxRestrictions.default`. The `SandboxRestrictions` dataclass\nis immutable and contains three fields that can be customized, but only two have notable value. See below.\n\n###### Passthrough Modules\n\nBy default the sandbox completely reloads non-standard-library and non-Temporal modules for every workflow run. To make\nthe sandbox quicker and use less memory when importing known-side-effect-free third party modules, they can be marked\nas passthrough modules.\n\n**For performance and behavior reasons, users are encouraged to pass through all third party modules whose calls will be\ndeterministic.**\n\nOne way to pass through a module is at import time in the workflow file using the `imports_passed_through` context\nmanager like so:\n\n```python\n# my_workflow_file.py\n\nfrom temporalio import workflow\n\nwith workflow.unsafe.imports_passed_through():\n    import pydantic\n\n@workflow.defn\nclass MyWorkflow:\n    ...\n```\n\nAlternatively, this can be done at worker creation time by customizing the runner\'s restrictions. For example:\n\n```python\nmy_worker = Worker(\n  ...,\n  workflow_runner=SandboxedWorkflowRunner(\n    restrictions=SandboxRestrictions.default.with_passthrough_modules("pydantic")\n  )\n)\n```\n\nIn both of these cases, now the `pydantic` module will be passed through from outside of the sandbox instead of\nbeing reloaded for every workflow run.\n\n###### Invalid Module Members\n\n`SandboxRestrictions.invalid_module_members` contains a root matcher that applies to all module members. This already\nhas a default set which includes things like `datetime.date.today()` which should never be called from a workflow. To\nremove this restriction:\n\n```python\nmy_restrictions = dataclasses.replace(\n    SandboxRestrictions.default,\n    invalid_module_members=SandboxRestrictions.invalid_module_members_default.with_child_unrestricted(\n      "datetime", "date", "today",\n    ),\n)\nmy_worker = Worker(..., workflow_runner=SandboxedWorkflowRunner(restrictions=my_restrictions))\n```\n\nRestrictions can also be added by `|`\'ing together matchers, for example to restrict the `datetime.date` class from\nbeing used altogether:\n\n```python\nmy_restrictions = dataclasses.replace(\n    SandboxRestrictions.default,\n    invalid_module_members=SandboxRestrictions.invalid_module_members_default | SandboxMatcher(\n      children={"datetime": SandboxMatcher(use={"date"})},\n    ),\n)\nmy_worker = Worker(..., workflow_runner=SandboxedWorkflowRunner(restrictions=my_restrictions))\n```\n\nSee the API for more details on exact fields and their meaning.\n\n##### Known Sandbox Issues\n\nBelow are known sandbox issues. As the sandbox is developed and matures, some may be resolved.\n\n###### Global Import/Builtins\n\nCurrently the sandbox references/alters the global `sys.modules` and `builtins` fields while running workflow code. In\norder to prevent affecting other sandboxed code, thread locals are leveraged to only intercept these values during the\nworkflow thread running. Therefore, technically if top-level import code starts a thread, it may lose sandbox\nprotection.\n\n###### Sandbox is not Secure\n\nThe sandbox is built to catch many non-deterministic and state sharing issues, but it is not secure. Some known bad\ncalls are intercepted, but for performance reasons, every single attribute get/set cannot be checked. Therefore a simple\ncall like `setattr(temporalio.common, "__my_key", "my value")` will leak across sandbox runs.\n\nThe sandbox is only a helper, it does not provide full protection.\n\n###### Sandbox Performance\n\nThe sandbox does not add significant CPU or memory overhead for workflows that are in files which only import standard\nlibrary modules. This is because they are passed through from outside of the sandbox. However, every\nnon-standard-library import that is performed at the top of the same file the workflow is in will add CPU overhead (the\nmodule is re-imported every workflow run) and memory overhead (each module independently cached as part of the workflow\nrun for isolation reasons). This becomes more apparent for large numbers of workflow runs.\n\nTo mitigate this, users should:\n\n* Define workflows in files that have as few non-standard-library imports as possible\n* Alter the max workflow cache and/or max concurrent workflows settings if memory grows too large\n* Set third-party libraries as passthrough modules if they are known to be side-effect free\n\n###### Extending Restricted Classes\n\nExtending a restricted class causes Python to instantiate the restricted metaclass which is unsupported. Therefore if\nyou attempt to use a class in the sandbox that extends a restricted class, it will fail. For example, if you have a\n`class MyZipFile(zipfile.ZipFile)` and try to use that class inside a workflow, it will fail.\n\nClasses used inside the workflow should not extend restricted classes. For situations where third-party modules need to\nat import time, they should be marked as pass through modules.\n\n###### Certain Standard Library Calls on Restricted Objects\n\nIf an object is restricted, internal C Python validation may fail in some cases. For example, running\n`dict.items(os.__dict__)` will fail with:\n\n> descriptor \'items\' for \'dict\' objects doesn\'t apply to a \'_RestrictedProxy\' object\n\nThis is a low-level check that cannot be subverted. The solution is to not use restricted objects inside the sandbox.\nFor situations where third-party modules need to at import time, they should be marked as pass through modules.\n\n###### is_subclass of ABC-based Restricted Classes\n\nDue to [https://bugs.python.org/issue44847](https://bugs.python.org/issue44847), classes that are wrapped and then\nchecked to see if they are subclasses of another via `is_subclass` may fail (see also\n[this wrapt issue](https://github.com/GrahamDumpleton/wrapt/issues/130)).\n\n###### Compiled Pydantic Sometimes Using Wrong Types\n\nIf the Pydantic dependency is in compiled form (the default) and you are using a Pydantic model inside a workflow\nsandbox that uses a `datetime` type, it will grab the wrong validator and use `date` instead. This is because our\npatched form of `issubclass` is bypassed by compiled Pydantic.\n\nTo work around, either don\'t use `datetime`-based Pydantic model fields in workflows, or mark `datetime` library as\npassthrough (means you lose protection against calling the non-deterministic `now()`), or use non-compiled Pydantic\ndependency.\n\n### Activities\n\n#### Definition\n\nActivities are decorated with `@activity.defn` like so:\n\n```python\nfrom temporalio import activity\n\n@activity.defn\nasync def say_hello_activity(name: str) -> str:\n    return f"Hello, {name}!"\n```\n\nSome things to note about activity definitions:\n\n* The `say_hello_activity` is `async` which is the recommended activity type (see "Types of Activities" below)\n* A custom name for the activity can be set with a decorator argument, e.g. `@activity.defn(name="my activity")`\n* Long running activities should regularly heartbeat and handle cancellation\n* Activities can only have positional arguments. Best practice is to only take a single argument that is an\n  object/dataclass of fields that can be added to as needed.\n* Activities can be defined on methods instead of top-level functions. This allows the instance to carry state that an\n  activity may need (e.g. a DB connection). The instance method should be what is registered with the worker.\n* Activities can also be defined on callable classes (i.e. classes with `__call__`). An instance of the class should be\n  what is registered with the worker.\n* The `@activity.defn` can have `dynamic=True` set which means all otherwise unhandled activities fall through to this.\n  If present, cannot have `name` argument, and the activity function must accept a single parameter of\n  `Sequence[temporalio.common.RawValue]`. The payload of the raw value can be converted via\n  `activity.payload_converter().from_payload`.\n\n#### Types of Activities\n\nThere are 3 types of activity callables accepted and described below: asynchronous, synchronous multithreaded, and\nsynchronous multiprocess/other. Only positional parameters are allowed in activity callables.\n\n##### Asynchronous Activities\n\nAsynchronous activities, i.e. functions using `async def`, are the recommended activity type. When using asynchronous\nactivities no special worker parameters are needed.\n\nCancellation for asynchronous activities is done via\n[`asyncio.Task.cancel`](https://docs.python.org/3/library/asyncio-task.html#asyncio.Task.cancel). This means that\n`asyncio.CancelledError` will be raised (and can be caught, but it is not recommended). A non-local activity must\nheartbeat to receive cancellation and there are other ways to be notified about cancellation (see "Activity Context" and\n"Heartbeating and Cancellation" later).\n\n##### Synchronous Activities\n\nSynchronous activities, i.e. functions that do not have `async def`, can be used with workers, but the\n`activity_executor` worker parameter must be set with a `concurrent.futures.Executor` instance to use for executing the\nactivities.\n\nAll long running, non-local activities should heartbeat so they can be cancelled. Cancellation in threaded activities\nthrows but multiprocess/other activities does not. The sections below on each synchronous type explain further. There\nare also calls on the context that can check for cancellation. For more information, see "Activity Context" and\n"Heartbeating and Cancellation" sections later.\n\nNote, all calls from an activity to functions in the `temporalio.activity` package are powered by\n[contextvars](https://docs.python.org/3/library/contextvars.html). Therefore, new threads starting _inside_ of\nactivities must `copy_context()` and then `.run()` manually to ensure `temporalio.activity` calls like `heartbeat` still\nfunction in the new threads.\n\nIf any activity ever throws a `concurrent.futures.BrokenExecutor`, the failure is consisted unrecoverable and the worker\nwill fail and shutdown.\n\n###### Synchronous Multithreaded Activities\n\nIf `activity_executor` is set to an instance of `concurrent.futures.ThreadPoolExecutor` then the synchronous activities\nare considered multithreaded activities. Besides `activity_executor`, no other worker parameters are required for\nsynchronous multithreaded activities.\n\nBy default, cancellation of a synchronous multithreaded activity is done via a `temporalio.exceptions.CancelledError`\nthrown into the activity thread. Activities that do not wish to have cancellation thrown can set\n`no_thread_cancel_exception=True` in the `@activity.defn` decorator.\n\nCode that wishes to be temporarily shielded from the cancellation exception can run inside\n`with activity.shield_thread_cancel_exception():`. But once the last nested form of that block is finished, even if\nthere is a return statement within, it will throw the cancellation if there was one. A `try` +\n`except temporalio.exceptions.CancelledError` would have to surround the `with` to handle the cancellation explicitly.\n\n###### Synchronous Multiprocess/Other Activities\n\nIf `activity_executor` is set to an instance of `concurrent.futures.Executor` that is _not_\n`concurrent.futures.ThreadPoolExecutor`, then the synchronous activities are considered multiprocess/other activities.\n\nThese require special primitives for heartbeating and cancellation. The `shared_state_manager` worker parameter must be\nset to an instance of `temporalio.worker.SharedStateManager`. The most common implementation can be created by passing a\n`multiprocessing.managers.SyncManager` (i.e. result of `multiprocessing.managers.Manager()`) to\n`temporalio.worker.SharedStateManager.create_from_multiprocessing()`.\n\nAlso, all of these activity functions must be\n["picklable"](https://docs.python.org/3/library/pickle.html#what-can-be-pickled-and-unpickled).\n\n#### Activity Context\n\nDuring activity execution, an implicit activity context is set as a\n[context variable](https://docs.python.org/3/library/contextvars.html). The context variable itself is not visible, but\ncalls in the `temporalio.activity` package make use of it. Specifically:\n\n* `in_activity()` - Whether an activity context is present\n* `info()` - Returns the immutable info of the currently running activity\n* `heartbeat(*details)` - Record a heartbeat\n* `is_cancelled()` - Whether a cancellation has been requested on this activity\n* `wait_for_cancelled()` - `async` call to wait for cancellation request\n* `wait_for_cancelled_sync(timeout)` - Synchronous blocking call to wait for cancellation request\n* `shield_thread_cancel_exception()` - Context manager for use in `with` clauses by synchronous multithreaded activities\n  to prevent cancel exception from being thrown during the block of code\n* `is_worker_shutdown()` - Whether the worker has started graceful shutdown\n* `wait_for_worker_shutdown()` - `async` call to wait for start of graceful worker shutdown\n* `wait_for_worker_shutdown_sync(timeout)` - Synchronous blocking call to wait for start of graceful worker shutdown\n* `raise_complete_async()` - Raise an error that this activity will be completed asynchronously (i.e. after return of\n  the activity function in a separate client call)\n\nWith the exception of `in_activity()`, if any of the functions are called outside of an activity context, an error\noccurs. Synchronous activities cannot call any of the `async` functions.\n\n##### Heartbeating and Cancellation\n\nIn order for a non-local activity to be notified of cancellation requests, it must be given a `heartbeat_timeout` at\ninvocation time and invoke `temporalio.activity.heartbeat()` inside the activity. It is strongly recommended that all\nbut the fastest executing activities call this function regularly. "Types of Activities" has specifics on cancellation\nfor asynchronous and synchronous activities.\n\nIn addition to obtaining cancellation information, heartbeats also support detail data that is persisted on the server\nfor retrieval during activity retry. If an activity calls `temporalio.activity.heartbeat(123, 456)` and then fails and\nis retried, `temporalio.activity.info().heartbeat_details` will return an iterable containing `123` and `456` on the\nnext run.\n\nHeartbeating has no effect on local activities.\n\n##### Worker Shutdown\n\nAn activity can react to a worker shutdown. Using `is_worker_shutdown` or one of the `wait_for_worker_shutdown`\nfunctions an activity can react to a shutdown.\n\nWhen the `graceful_shutdown_timeout` worker parameter is given a `datetime.timedelta`, on shutdown the worker will\nnotify activities of the graceful shutdown. Once that timeout has passed (or if wasn\'t set), the worker will perform\ncancellation of all outstanding activities.\n\nThe `shutdown()` invocation will wait on all activities to complete, so if a long-running activity does not at least\nrespect cancellation, the shutdown may never complete.\n\n#### Testing\n\nUnit testing an activity or any code that could run in an activity is done via the\n`temporalio.testing.ActivityEnvironment` class. Simply instantiate this and any callable + params passed to `run` will\nbe invoked inside the activity context. The following are attributes/methods on the environment that can be used to\naffect calls activity code might make to functions on the `temporalio.activity` package.\n\n* `info` property can be set to customize what is returned from `activity.info()`\n* `on_heartbeat` property can be set to handle `activity.heartbeat()` calls\n* `cancel()` can be invoked to simulate a cancellation of the activity\n* `worker_shutdown()` can be invoked to simulate a worker shutdown during execution of the activity\n\n### Workflow Replay\n\nGiven a workflow\'s history, it can be replayed locally to check for things like non-determinism errors. For example,\nassuming `history_str` is populated with a JSON string history either exported from the web UI or from `tctl`, the\nfollowing function will replay it:\n\n```python\nfrom temporalio.client import WorkflowHistory\nfrom temporalio.worker import Replayer\n\nasync def run_replayer(history_str: str):\n  replayer = Replayer(workflows=[SayHello])\n  await replayer.replay_workflow(WorkflowHistory.from_json(history_str))\n```\n\nThis will throw an error if any non-determinism is detected.\n\nReplaying from workflow history is a powerful concept that many use to test that workflow alterations won\'t cause\nnon-determinisms with past-complete workflows. The following code will make sure that all workflow histories for a\ncertain workflow type (i.e. workflow class) are safe with the current code.\n\n```python\nfrom temporalio.client import Client, WorkflowHistory\nfrom temporalio.worker import Replayer\n\nasync def check_past_histories(my_client: Client):\n  replayer = Replayer(workflows=[SayHello])\n  await replayer.replay_workflows(\n    await my_client.list_workflows("WorkflowType = \'SayHello\'").map_histories(),\n  )\n```\n\n### OpenTelemetry Support\n\nOpenTelemetry support requires the optional `opentelemetry` dependencies which are part of the `opentelemetry` extra.\nWhen using `pip`, running\n\n    pip install temporalio[opentelemetry]\n\nwill install needed dependencies. Then the `temporalio.contrib.opentelemetry.TracingInterceptor` can be created and set\nas an interceptor on the `interceptors` argument of `Client.connect`. When set, spans will be created for all client\ncalls and for all activity and workflow invocations on the worker, spans will be created and properly serialized through\nthe server to give one proper trace for a workflow execution.\n\n### Protobuf 3.x vs 4.x\n\nPython currently has two somewhat-incompatible protobuf library versions - the 3.x series and the 4.x series. Python\ncurrently recommends 4.x and that is the primary supported version. Some libraries like\n[Pulumi](https://github.com/pulumi/pulumi) require 4.x. Other libraries such as [ONNX](https://github.com/onnx/onnx) and\n[Streamlit](https://github.com/streamlit/streamlit), for one reason or another, have/will not leave 3.x.\n\nTo support these, Temporal Python SDK allows any protobuf library >= 3.19. However, the C extension in older Python\nversions can cause issues with the sandbox due to global state sharing. Temporal strongly recommends using the latest\nprotobuf 4.x library unless you absolutely cannot at which point some proto libraries may have to be marked as\n[Passthrough Modules](#passthrough-modules).\n\n### Known Compatibility Issues\n\nBelow are known compatibility issues with the Python SDK.\n\n#### gevent Patching\n\nWhen using `gevent.monkey.patch_all()`, asyncio event loops can get messed up, especially those using custom event loops\nlike Temporal. See [this gevent issue](https://github.com/gevent/gevent/issues/982) and\n[this Python SDK issue](https://github.com/temporalio/sdk-python/issues/59) for more details.\n\n# Development\n\nThe Python SDK is built to work with Python 3.7 and newer. It is built using\n[SDK Core](https://github.com/temporalio/sdk-core/) which is written in Rust.\n\n### Building\n\n#### Prepare\n\nTo build the SDK from source for use as a dependency, the following prerequisites are required:\n\n* [Python](https://www.python.org/) >= 3.7\n* [Rust](https://www.rust-lang.org/)\n* [poetry](https://github.com/python-poetry/poetry) (e.g. `python -m pip install poetry`)\n* [poe](https://github.com/nat-n/poethepoet) (e.g. `python -m pip install poethepoet`)\n\nmacOS note: If errors are encountered, it may be better to install Python and Rust as recommended from their websites\ninstead of via `brew`.\n\nWith the prerequisites installed, first clone the SDK repository recursively:\n\n```bash\ngit clone --recursive https://github.com/temporalio/sdk-python.git\ncd sdk-python\n```\n\nUse `poetry` to install the dependencies with `--no-root` to not install this package (because we still need to build\nit):\n\n```bash\npoetry install --no-root\n```\n\n#### Build\n\nNow perform the release build:\n\n> This will take a while because Rust will compile the core project in release mode (see [Local SDK development\nenvironment](#local-sdk-development-environment) for the quicker approach to local development).\n\n```bash\npoetry build\n```\n\nThe compiled wheel doesn\'t have the exact right tags yet for use, so run this script to fix it:\n\n```bash\npoe fix-wheel\n```\n\nThe `whl` wheel file in `dist/` is now ready to use.\n\n#### Use\n\nThe wheel can now be installed into any virtual environment.\n\nFor example,\n[create a virtual environment](https://packaging.python.org/en/latest/tutorials/installing-packages/#creating-virtual-environments)\nsomewhere and then run the following inside the virtual environment:\n\n```bash\npip install wheel\n```\n\n```bash\npip install /path/to/cloned/sdk-python/dist/*.whl\n```\n\nCreate this Python file at `example.py`:\n\n```python\nimport asyncio\nfrom temporalio import workflow, activity\nfrom temporalio.client import Client\nfrom temporalio.worker import Worker\n\n@workflow.defn\nclass SayHello:\n    @workflow.run\n    async def run(self, name: str) -> str:\n        return f"Hello, {name}!"\n\nasync def main():\n    client = await Client.connect("localhost:7233")\n    async with Worker(client, task_queue="my-task-queue", workflows=[SayHello]):\n        result = await client.execute_workflow(SayHello.run, "Temporal",\n            id="my-workflow-id", task_queue="my-task-queue")\n        print(f"Result: {result}")\n\nif __name__ == "__main__":\n    asyncio.run(main())\n```\n\nAssuming there is a [local Temporal server](https://docs.temporal.io/docs/server/quick-install/) running, execute the\nfile with `python` (or `python3` if necessary):\n\n```bash\npython example.py\n```\n\nIt should output:\n\n    Result: Hello, Temporal!\n\n### Local SDK development environment\n\nFor local development, it is often quicker to use debug builds and a local virtual environment.\n\nWhile not required, it often helps IDEs if we put the virtual environment `.venv` directory in the project itself. This\ncan be configured system-wide via:\n\n```bash\npoetry config virtualenvs.in-project true\n```\n\nNow perform the same steps as the "Prepare" section above by installing the prerequisites, cloning the project,\ninstalling dependencies, and generating the protobuf code:\n\n```bash\ngit clone --recursive https://github.com/temporalio/sdk-python.git\ncd sdk-python\npoetry install --no-root\n```\n\nNow compile the Rust extension in develop mode which is quicker than release mode:\n\n```bash\npoe build-develop\n```\n\nThat step can be repeated for any Rust changes made.\n\nThe environment is now ready to develop in.\n\n#### Testing\n\nTo execute tests:\n\n```bash\npoe test\n```\n\nThis runs against [Temporalite](https://github.com/temporalio/temporalite). To run against the time-skipping test\nserver, pass `--workflow-environment time-skipping`. To run against the `default` namespace of an already-running\nserver, pass the `host:port` to `--workflow-environment`. Can also use regular pytest arguments. For example, here\'s how\nto run a single test with debug logs on the console:\n\n```bash\npoe test -s --log-cli-level=DEBUG -k test_sync_activity_thread_cancel_caught\n```\n\n#### Proto Generation and Testing\n\nTo allow for backwards compatibility, protobuf code is generated on the 3.x series of the protobuf library. To generate\nprotobuf code, you must be on Python <= 3.10, and then run `poetry add "protobuf<4"`. Then the protobuf files can be\ngenerated via `poe gen-protos`. Tests can be run for protobuf version 3 by setting the `TEMPORAL_TEST_PROTO3` env var\nto `1` prior to running tests.\n\nDo not commit `poetry.lock` or `pyproject.toml` changes. To go back from this downgrade, restore `pyproject.toml` and\nrun `poetry update protobuf grpcio-tools`.\n\n### Style\n\n* Mostly [Google Style Guide](https://google.github.io/styleguide/pyguide.html). Notable exceptions:\n  * We use [Black](https://github.com/psf/black) for formatting, so that takes precedence\n  * In tests and example code, can import individual classes/functions to make it more readable. Can also do this for\n    rarely in library code for some Python common items (e.g. `dataclass` or `partial`), but not allowed to do this for\n    any `temporalio` packages (except `temporalio.types`) or any classes/functions that aren\'t clear when unqualified.\n  * We allow relative imports for private packages\n  * We allow `@staticmethod`\n',
     'author': 'Temporal Technologies Inc',
     'author_email': 'sdk@temporal.io',
     'maintainer': 'None',
     'maintainer_email': 'None',
     'url': 'https://github.com/temporalio/sdk-python',
     'packages': packages,
     'package_data': package_data,
```

### Comparing `temporalio-1.2.0/PKG-INFO` & `temporalio-1.3.0/PKG-INFO`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: temporalio
-Version: 1.2.0
+Version: 1.3.0
 Summary: Temporal.io Python SDK
 Home-page: https://github.com/temporalio/sdk-python
 License: MIT
 Keywords: temporal,workflow
 Author: Temporal Technologies Inc
 Author-email: sdk@temporal.io
 Requires-Python: >=3.7,<4.0
@@ -60,14 +60,17 @@
 
 **Custom `asyncio` Event Loop**
 
 The workflow implementation basically turns `async def` functions into workflows backed by a distributed, fault-tolerant
 event loop. This means task management, sleep, cancellation, etc have all been developed to seamlessly integrate with
 `asyncio` concepts.
 
+See the [blog post](https://temporal.io/blog/durable-distributed-asyncio-event-loop) introducing the Python SDK for an
+informal introduction to the features and their implementation.
+
 ---
 
 <!-- START doctoc generated TOC please keep comment here to allow auto update -->
 <!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
 **Contents**
 
 - [Quick Start](#quick-start)
@@ -333,16 +336,16 @@
   * [UUID](https://docs.python.org/3/library/uuid.html)
 
 This notably doesn't include any `date`, `time`, or `datetime` objects as they may not work across SDKs.
 
 Users are strongly encouraged to use a single `dataclass` for parameter and return types so fields with defaults can be
 easily added without breaking compatibility.
 
-Classes with generics may not have the generics properly resolved. The current implementation, similar to Pydantic, does
-not have generic type resolution. Users should use concrete types.
+Classes with generics may not have the generics properly resolved. The current implementation does not have generic
+type resolution. Users should use concrete types.
 
 ##### Custom Type Data Conversion
 
 For converting from JSON, the workflow/activity type hint is taken into account to convert to the proper type. Care has
 been taken to support all common typings including `Optional`, `Union`, all forms of iterables and mappings, `NewType`,
 etc in addition to the regular JSON values mentioned before.
 
@@ -523,15 +526,15 @@
         self._greeting_info_update.set()
 
     @workflow.signal
     async def complete_with_greeting(self) -> None:
         self._complete.set()
 
     @workflow.query
-    async def current_greeting(self) -> str:
+    def current_greeting(self) -> str:
         return self._current_greeting
 
 ```
 
 This assumes there's an activity in `my_activities.py` like:
 
 ```python
@@ -566,35 +569,40 @@
   `self._greeting_info` parameter is not a `GreetingInfo`
 
 Here are the decorators that can be applied:
 
 * `@workflow.defn` - Defines a workflow class
   * Must be defined on the class given to the worker (ignored if present on a base class)
   * Can have a `name` param to customize the workflow name, otherwise it defaults to the unqualified class name
+  * Can have `dynamic=True` which means all otherwise unhandled workflows fall through to this. If present, cannot have
+    `name` argument, and run method must accept a single parameter of `Sequence[temporalio.common.RawValue]` type. The
+    payload of the raw value can be converted via `workflow.payload_converter().from_payload`.
 * `@workflow.run` - Defines the primary workflow run method
   * Must be defined on the same class as `@workflow.defn`, not a base class (but can _also_ be defined on the same
     method of a base class)
   * Exactly one method name must have this decorator, no more or less
   * Must be defined on an `async def` method
   * The method's arguments are the workflow's arguments
   * The first parameter must be `self`, followed by positional arguments. Best practice is to only take a single
     argument that is an object/dataclass of fields that can be added to as needed.
 * `@workflow.signal` - Defines a method as a signal
   * Can be defined on an `async` or non-`async` function at any hierarchy depth, but if decorated method is overridden,
     the override must also be decorated
   * The method's arguments are the signal's arguments
   * Can have a `name` param to customize the signal name, otherwise it defaults to the unqualified method name
   * Can have `dynamic=True` which means all otherwise unhandled signals fall through to this. If present, cannot have
-    `name` argument, and method parameters must be `self`, a string signal name, and a `*args` varargs param.
+    `name` argument, and method parameters must be `self`, a string signal name, and a
+    `Sequence[temporalio.common.RawValue]`.
   * Non-dynamic method can only have positional arguments. Best practice is to only take a single argument that is an
     object/dataclass of fields that can be added to as needed.
   * Return value is ignored
 * `@workflow.query` - Defines a method as a query
   * All the same constraints as `@workflow.signal` but should return a value
-  * Temporal queries should never mutate anything in the workflow
+  * Should not be `async`
+  * Temporal queries should never mutate anything in the workflow or call any calls that would mutate the workflow
 
 #### Running
 
 To start a locally-defined workflow from a client, you can simply reference its method like so:
 
 ```python
 from temporalio.client import Client
@@ -1078,14 +1086,18 @@
 * Long running activities should regularly heartbeat and handle cancellation
 * Activities can only have positional arguments. Best practice is to only take a single argument that is an
   object/dataclass of fields that can be added to as needed.
 * Activities can be defined on methods instead of top-level functions. This allows the instance to carry state that an
   activity may need (e.g. a DB connection). The instance method should be what is registered with the worker.
 * Activities can also be defined on callable classes (i.e. classes with `__call__`). An instance of the class should be
   what is registered with the worker.
+* The `@activity.defn` can have `dynamic=True` set which means all otherwise unhandled activities fall through to this.
+  If present, cannot have `name` argument, and the activity function must accept a single parameter of
+  `Sequence[temporalio.common.RawValue]`. The payload of the raw value can be converted via
+  `activity.payload_converter().from_payload`.
 
 #### Types of Activities
 
 There are 3 types of activity callables accepted and described below: asynchronous, synchronous multithreaded, and
 synchronous multiprocess/other. Only positional parameters are allowed in activity callables.
 
 ##### Asynchronous Activities
```

