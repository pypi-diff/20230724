# Comparing `tmp/datarobot_model_metrics-0.1.7-py2.py3-none-any.whl.zip` & `tmp/datarobot_model_metrics-0.1.8-py2.py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,24 +1,24 @@
-Zip file size: 29248 bytes, number of entries: 22
--rw-r--r--  2.0 unx      385 b- defN 23-Jul-20 12:44 dmm/__init__.py
--rw-r--r--  2.0 unx     9663 b- defN 23-Jul-20 12:44 dmm/batch_metric_evaluator.py
--rw-r--r--  2.0 unx      747 b- defN 23-Jul-20 12:44 dmm/constants.py
--rw-r--r--  2.0 unx     6955 b- defN 23-Jul-20 12:44 dmm/example_data_helper.py
--rw-r--r--  2.0 unx    14267 b- defN 23-Jul-20 12:44 dmm/metric_evaluator.py
--rw-r--r--  2.0 unx     3164 b- defN 23-Jul-20 12:44 dmm/time_bucket.py
--rw-r--r--  2.0 unx     1690 b- defN 23-Jul-20 12:44 dmm/utils.py
--rw-r--r--  2.0 unx      525 b- defN 23-Jul-20 12:44 dmm/data_source/__init__.py
--rw-r--r--  2.0 unx     2096 b- defN 23-Jul-20 12:44 dmm/data_source/data_source_base.py
--rw-r--r--  2.0 unx     2698 b- defN 23-Jul-20 12:44 dmm/data_source/dataframe_source.py
--rw-r--r--  2.0 unx    60597 b- defN 23-Jul-20 12:44 dmm/data_source/datarobot_source.py
--rw-r--r--  2.0 unx     3003 b- defN 23-Jul-20 12:44 dmm/data_source/generator_source.py
--rw-r--r--  2.0 unx      396 b- defN 23-Jul-20 12:44 dmm/metric/__init__.py
--rw-r--r--  2.0 unx     1620 b- defN 23-Jul-20 12:44 dmm/metric/asymmetric_error.py
--rw-r--r--  2.0 unx      320 b- defN 23-Jul-20 12:44 dmm/metric/median_absolute_error.py
--rw-r--r--  2.0 unx     3569 b- defN 23-Jul-20 12:44 dmm/metric/metric_base.py
--rw-r--r--  2.0 unx      957 b- defN 23-Jul-20 12:44 dmm/metric/missing_values.py
--rw-r--r--  2.0 unx     2014 b- defN 23-Jul-20 12:44 dmm/metric/sklearn_metric.py
--rw-r--r--  2.0 unx      886 b- defN 23-Jul-20 12:46 datarobot_model_metrics-0.1.7.dist-info/METADATA
--rw-r--r--  2.0 unx      110 b- defN 23-Jul-20 12:46 datarobot_model_metrics-0.1.7.dist-info/WHEEL
--rw-r--r--  2.0 unx        4 b- defN 23-Jul-20 12:46 datarobot_model_metrics-0.1.7.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     1857 b- defN 23-Jul-20 12:46 datarobot_model_metrics-0.1.7.dist-info/RECORD
-22 files, 117523 bytes uncompressed, 26222 bytes compressed:  77.7%
+Zip file size: 29456 bytes, number of entries: 22
+-rw-r--r--  2.0 unx      385 b- defN 23-Jul-24 14:24 dmm/__init__.py
+-rw-r--r--  2.0 unx     9663 b- defN 23-Jul-24 14:24 dmm/batch_metric_evaluator.py
+-rw-r--r--  2.0 unx      771 b- defN 23-Jul-24 14:24 dmm/constants.py
+-rw-r--r--  2.0 unx     6955 b- defN 23-Jul-24 14:24 dmm/example_data_helper.py
+-rw-r--r--  2.0 unx    14267 b- defN 23-Jul-24 14:24 dmm/metric_evaluator.py
+-rw-r--r--  2.0 unx     3428 b- defN 23-Jul-24 14:24 dmm/time_bucket.py
+-rw-r--r--  2.0 unx     1690 b- defN 23-Jul-24 14:24 dmm/utils.py
+-rw-r--r--  2.0 unx      525 b- defN 23-Jul-24 14:24 dmm/data_source/__init__.py
+-rw-r--r--  2.0 unx     2096 b- defN 23-Jul-24 14:24 dmm/data_source/data_source_base.py
+-rw-r--r--  2.0 unx     3113 b- defN 23-Jul-24 14:24 dmm/data_source/dataframe_source.py
+-rw-r--r--  2.0 unx    60597 b- defN 23-Jul-24 14:24 dmm/data_source/datarobot_source.py
+-rw-r--r--  2.0 unx     3003 b- defN 23-Jul-24 14:24 dmm/data_source/generator_source.py
+-rw-r--r--  2.0 unx      396 b- defN 23-Jul-24 14:24 dmm/metric/__init__.py
+-rw-r--r--  2.0 unx     1620 b- defN 23-Jul-24 14:24 dmm/metric/asymmetric_error.py
+-rw-r--r--  2.0 unx      320 b- defN 23-Jul-24 14:24 dmm/metric/median_absolute_error.py
+-rw-r--r--  2.0 unx     3569 b- defN 23-Jul-24 14:24 dmm/metric/metric_base.py
+-rw-r--r--  2.0 unx      957 b- defN 23-Jul-24 14:24 dmm/metric/missing_values.py
+-rw-r--r--  2.0 unx     2014 b- defN 23-Jul-24 14:24 dmm/metric/sklearn_metric.py
+-rw-r--r--  2.0 unx      886 b- defN 23-Jul-24 14:25 datarobot_model_metrics-0.1.8.dist-info/METADATA
+-rw-r--r--  2.0 unx      110 b- defN 23-Jul-24 14:25 datarobot_model_metrics-0.1.8.dist-info/WHEEL
+-rw-r--r--  2.0 unx        4 b- defN 23-Jul-24 14:25 datarobot_model_metrics-0.1.8.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     1857 b- defN 23-Jul-24 14:25 datarobot_model_metrics-0.1.8.dist-info/RECORD
+22 files, 118226 bytes uncompressed, 26430 bytes compressed:  77.6%
```

## zipnote {}

```diff
@@ -48,20 +48,20 @@
 
 Filename: dmm/metric/missing_values.py
 Comment: 
 
 Filename: dmm/metric/sklearn_metric.py
 Comment: 
 
-Filename: datarobot_model_metrics-0.1.7.dist-info/METADATA
+Filename: datarobot_model_metrics-0.1.8.dist-info/METADATA
 Comment: 
 
-Filename: datarobot_model_metrics-0.1.7.dist-info/WHEEL
+Filename: datarobot_model_metrics-0.1.8.dist-info/WHEEL
 Comment: 
 
-Filename: datarobot_model_metrics-0.1.7.dist-info/top_level.txt
+Filename: datarobot_model_metrics-0.1.8.dist-info/top_level.txt
 Comment: 
 
-Filename: datarobot_model_metrics-0.1.7.dist-info/RECORD
+Filename: datarobot_model_metrics-0.1.8.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## dmm/constants.py

```diff
@@ -17,14 +17,15 @@
 class TimeBucket:
     SECOND = "second"
     MINUTE = "minute"
     HOUR = "hour"
     DAY = "day"
     WEEK = "week"
     MONTH = "month"
+    QUARTER = "quarter"
     ALL = "all"
 
 
 class DataGroups:
     SCORING = "scoring"
     PREDICTIONS = "predictions"
     ACTUALS = "actuals"
```

## dmm/time_bucket.py

```diff
@@ -49,14 +49,18 @@
         if date1.isocalendar()[1] != date2.isocalendar()[1]:
             return False
         return True
     if time_bucket == TimeBucket.MONTH:
         if date1.month != date2.month:
             return False
         return True
+    if time_bucket == TimeBucket.QUARTER:
+        if pd.Timestamp(date1).quarter != pd.Timestamp(date2).quarter:
+            return False
+        return True
     if time_bucket == TimeBucket.SECOND:
         if total_seconds >= 1:
             return False
         return True
 
     if time_bucket == TimeBucket.ALL:
         return True
@@ -77,14 +81,17 @@
 
     if time_bucket == TimeBucket.ALL:
         return pd.Series(True, index=date1.index)
 
     if time_bucket == TimeBucket.MONTH:
         return date1.dt.month == date2.month
 
+    if time_bucket == TimeBucket.QUARTER:
+        return date1.dt.quarter == pd.Timestamp(date2).quarter
+
     timedelta_obj = (date2 - date1).dt
     total_seconds = abs(timedelta_obj.total_seconds())
     if time_bucket == TimeBucket.SECOND:
         return total_seconds < 1
     if time_bucket == TimeBucket.MINUTE:
         return (total_seconds < SECONDS) & (date1.dt.minute == date2.minute)
     if time_bucket == TimeBucket.HOUR:
```

## dmm/data_source/dataframe_source.py

```diff
@@ -6,22 +6,22 @@
 from dmm.time_bucket import check_if_in_same_time_bucket
 
 
 class DataFrameSource(DataSourceBase):
     def __init__(
         self,
         df: pd.DataFrame,
-        max_rows=100,
-        timestamp_col: ColumnName = ColumnName.TIMESTAMP,
+        max_rows=10000,
+        timestamp_col: str = ColumnName.TIMESTAMP,
     ):
         super().__init__(max_rows)
         if max_rows <= 0:
             raise Exception("max_rows must be > 0, got {}".format(max_rows))
 
-        self._df = df
+        self._df = self.preprocess_df(df.copy(), timestamp_col)
         self._timestamp_col = timestamp_col
         self.reset()
         self._current_row = 0
         self._current_chunk_id = 0
         self._prev_chunk_datetime = None
 
     def init(self, time_bucket):
@@ -29,25 +29,36 @@
         self.reset()
         return self
 
     def reset(self) -> None:
         self._current_row = 0
         self._current_chunk_id = 0
 
+    @staticmethod
+    def preprocess_df(df: pd.DataFrame, timestamp_col: str) -> pd.DataFrame:
+        if df[timestamp_col].is_monotonic_increasing:
+            return df
+
+        if type(df[timestamp_col][0]) != pd.Timestamp:
+            df[timestamp_col] = pd.to_datetime(df[timestamp_col])
+
+        df.sort_values(by=timestamp_col, inplace=True)
+        return df
+
     def get_data(self) -> (pd.DataFrame, int):
         # In case we are already done with this DF
         if self._current_row >= self._df.shape[0]:
             return None, -1
 
         self._df.reset_index()
         chunk_df = pd.DataFrame(columns=self._df.columns)
         # We can always take at least 1 row into the chunk
         chunk_df = pd.concat([chunk_df, self._df.iloc[self._current_row].to_frame().T])
         self._current_row += 1
-        chunk_start_datetime = parse(chunk_df.iloc[0][self._timestamp_col])
+        chunk_start_datetime = parse(str(chunk_df.iloc[0][self._timestamp_col]))
 
         if self._prev_chunk_datetime:
             # This is for the case where the boundaries of chunks are aligned with the max rows
             if not check_if_in_same_time_bucket(
                 self._prev_chunk_datetime, chunk_start_datetime, self._time_bucket
             ):
                 self._current_chunk_id += 1
@@ -57,15 +68,15 @@
         if self._current_row >= self._df.shape[0]:
             return chunk_df, self._current_chunk_id
 
         search_start_row = self._current_row
         search_end_row = min(search_start_row + self._max_rows - 1, self._df.shape[0])
         chunk_id_to_return = self._current_chunk_id
         for loc in range(search_start_row, search_end_row):
-            loc_datetime = parse(self._df.iloc[loc][self._timestamp_col])
+            loc_datetime = parse(str(self._df.iloc[loc][self._timestamp_col]))
 
             if check_if_in_same_time_bucket(
                 chunk_start_datetime, loc_datetime, self._time_bucket
             ):
                 chunk_df = pd.concat(
                     [chunk_df, self._df.iloc[self._current_row].to_frame().T]
                 )
```

## Comparing `datarobot_model_metrics-0.1.7.dist-info/METADATA` & `datarobot_model_metrics-0.1.8.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: datarobot-model-metrics
-Version: 0.1.7
+Version: 0.1.8
 Summary: datarobot-model-metrics is a framework to compute model ML metrics
 Home-page: https://github.com/datarobot/datarobot-model-metrics
 Author: DataRobot
 Author-email: info@datarobot.com
 License: DataRobot
 Platform: UNKNOWN
 Classifier: Programming Language :: Python :: 3
```

## Comparing `datarobot_model_metrics-0.1.7.dist-info/RECORD` & `datarobot_model_metrics-0.1.8.dist-info/RECORD`

 * *Files 15% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 dmm/__init__.py,sha256=w3zRSdtt2_upBZCJNj93DqZeXKPyfMKqo3Xo1yOHLeY,385
 dmm/batch_metric_evaluator.py,sha256=LmZkvxYeF8Dk98x0PWhbyWCGSqAO4cBeWAMzhyWvo50,9663
-dmm/constants.py,sha256=sNtJziqxxioScZUK_YlF08__C3zjxk16YYAOhRjAd6Y,747
+dmm/constants.py,sha256=dIxKDH4ayW8TWw7Yl1rXU071vwVsDqGL3Wqcw-AFTXg,771
 dmm/example_data_helper.py,sha256=oLcOTo-dNV0Pyapq9G6e7DZoVjfIZMWj7QrkBx61Mj4,6955
 dmm/metric_evaluator.py,sha256=0JZlhxb0Kcfx52HreUrAYDVfHP4uL2iiIldUVWhDkzM,14267
-dmm/time_bucket.py,sha256=cg42R1U_o7is6nZf5qUuvdc-2HBH9UKuACKjKe3dLto,3164
+dmm/time_bucket.py,sha256=vgnKcX8PSqfw5TC8rRxO1Xp25jUBTjzGkKINuEBj7Sg,3428
 dmm/utils.py,sha256=kaZ7erHZofSwqZL1ddd8GXK3wrZfvYZ7I0ziz2CgbL0,1690
 dmm/data_source/__init__.py,sha256=rsK8s1quedmNYchnUodsc4gUXAENM-N_rVVohhX9HMA,525
 dmm/data_source/data_source_base.py,sha256=5zJ9SZYs1ufbku11GYa4PQRY1lwOOsXbx8kDkiG1VMk,2096
-dmm/data_source/dataframe_source.py,sha256=mKEGXyNFVAsqiocAVKQlhbGlUlwjx77sl5KAlXT6nx4,2698
+dmm/data_source/dataframe_source.py,sha256=ptAxMx-fraAYt0ra0uR7nGDMAnBrSMDisz7EjKQb3so,3113
 dmm/data_source/datarobot_source.py,sha256=5HVm2LBZ89n_FhEoN0nAUaPFyNB2mu4ccSbtcj0XFBI,60597
 dmm/data_source/generator_source.py,sha256=O-GsreX8mQognj3u6LQxHkZ3yWj3sOgx_dojvObVdlI,3003
 dmm/metric/__init__.py,sha256=nIX41kZJKfQztTw93CXVLRbgTt5W1qhdK1uakWxL9CE,396
 dmm/metric/asymmetric_error.py,sha256=h4J7nzXw9BurtGrkoe4oe7QBI2l69XeB9CiGfpcKUxc,1620
 dmm/metric/median_absolute_error.py,sha256=qV0NpJdF6daTzJOaGpd8KAPG3gZWPS43FZxOb-rR0kE,320
 dmm/metric/metric_base.py,sha256=Rzsju5eZhoyafxo7ErFmO76sDcsvkb3SyODDwcNudy4,3569
 dmm/metric/missing_values.py,sha256=i9ujXCuOWEPrUteFXTCDGX6SM8RVd7cQoI6byQPga4E,957
 dmm/metric/sklearn_metric.py,sha256=Bv4ukOSZyOKjXK-_4b7KKmlkOVrYnwSX5GST_Hf-qpc,2014
-datarobot_model_metrics-0.1.7.dist-info/METADATA,sha256=a03C5GE7YeNLTBofcRoAOElqT-9ASUeuBhxhcgEDdKo,886
-datarobot_model_metrics-0.1.7.dist-info/WHEEL,sha256=a-zpFRIJzOq5QfuhBzbhiA1eHTzNCJn8OdRvhdNX0Rk,110
-datarobot_model_metrics-0.1.7.dist-info/top_level.txt,sha256=69FbTyYFh17OyfaIppCUhlu4QG-prAaQ6ovJ_X0SNG8,4
-datarobot_model_metrics-0.1.7.dist-info/RECORD,,
+datarobot_model_metrics-0.1.8.dist-info/METADATA,sha256=HRAimo1LoC9Ag9xao3baZPNmC0UjO9zfQ6D6ErsTqOo,886
+datarobot_model_metrics-0.1.8.dist-info/WHEEL,sha256=a-zpFRIJzOq5QfuhBzbhiA1eHTzNCJn8OdRvhdNX0Rk,110
+datarobot_model_metrics-0.1.8.dist-info/top_level.txt,sha256=69FbTyYFh17OyfaIppCUhlu4QG-prAaQ6ovJ_X0SNG8,4
+datarobot_model_metrics-0.1.8.dist-info/RECORD,,
```

